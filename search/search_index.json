{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Linux Learning Material Selamat Datang! Selamat datang di materi pembelajaran Linux, disini saya menyadur dari berbagai sumber serta saya alih-bahasa untuk dapat dipelajari dengan Bahasa Indonesia agar mudah dipahami dan dipraktikan dalam pembelajaran untuk memulai berkenalan dan belajar Linux. Dokumentasi yang saya sadur berasal dari dokumentasi Rocky Linux yang menurut saya cukup lengkap untuk menjadi materi pembelajaran awal untuk pemakaian Linux, sumber asli dari dokumentasi bisa Anda buka di Rocky Linux Documentation untuk saat ini masih dalam proses alih-bahasa dari bahasa Inggris menuju bahasa Indonesia. Ada juga landasan saya dalam membuat situs dokumentasi ini saya fork dari Dokumentasi Pembelajaran Magang di PT Lintang Kawuryan Malang dan kemungkinan akan memperbarui berbagai hal untuk memudahkan dalam mempelajari Linux dengan Bahasa Indonesia. Saya sendiri masih belajar dalam penggunaan Linux, oleh karena itu saya harap situs dokumentasi ini menjadi sarana baik saya maupun Anda dalam memulai berkenalan dan mempelajari Linux secara fundamental. Terima kasih! Menu Navigasi Bagian utama dari situs dokumentasi ini adalah: Guides : Panduan dasar dalam mengoperasikan Linux Books : Panduan yang lebih rinci mengenai operasi sistem Linux Tutorials : Berbagai tutorial Linux dalam pengoperasian Linux Gemstones : Beberapa kiat penggunaan skrip atau perintah umum dapat dibagikan di sini Menggunakan pencarian Jika Anda ingin menemukan informasi/dokumen spesifik, situs dokumentasi memiliki kemampuan pencarian teks lengkap. Cukup mulai mengetik di bidang entri 'Cari' di bilah menu atas dan situs akan mengembalikan hasil pencarian drill ke bawah Untuk membuka halaman di hasil pencarian cukup klik (atau ketuk di ponsel) pada halaman yang diinginkan dalam daftar yang ditampilkan.","title":"Home"},{"location":"#linux-learning-material","text":"","title":"Linux Learning Material"},{"location":"#selamat-datang","text":"Selamat datang di materi pembelajaran Linux, disini saya menyadur dari berbagai sumber serta saya alih-bahasa untuk dapat dipelajari dengan Bahasa Indonesia agar mudah dipahami dan dipraktikan dalam pembelajaran untuk memulai berkenalan dan belajar Linux. Dokumentasi yang saya sadur berasal dari dokumentasi Rocky Linux yang menurut saya cukup lengkap untuk menjadi materi pembelajaran awal untuk pemakaian Linux, sumber asli dari dokumentasi bisa Anda buka di Rocky Linux Documentation untuk saat ini masih dalam proses alih-bahasa dari bahasa Inggris menuju bahasa Indonesia. Ada juga landasan saya dalam membuat situs dokumentasi ini saya fork dari Dokumentasi Pembelajaran Magang di PT Lintang Kawuryan Malang dan kemungkinan akan memperbarui berbagai hal untuk memudahkan dalam mempelajari Linux dengan Bahasa Indonesia. Saya sendiri masih belajar dalam penggunaan Linux, oleh karena itu saya harap situs dokumentasi ini menjadi sarana baik saya maupun Anda dalam memulai berkenalan dan mempelajari Linux secara fundamental. Terima kasih!","title":"Selamat Datang!"},{"location":"#menu-navigasi","text":"Bagian utama dari situs dokumentasi ini adalah: Guides : Panduan dasar dalam mengoperasikan Linux Books : Panduan yang lebih rinci mengenai operasi sistem Linux Tutorials : Berbagai tutorial Linux dalam pengoperasian Linux Gemstones : Beberapa kiat penggunaan skrip atau perintah umum dapat dibagikan di sini","title":"Menu Navigasi"},{"location":"#menggunakan-pencarian","text":"Jika Anda ingin menemukan informasi/dokumen spesifik, situs dokumentasi memiliki kemampuan pencarian teks lengkap. Cukup mulai mengetik di bidang entri 'Cari' di bilah menu atas dan situs akan mengembalikan hasil pencarian drill ke bawah Untuk membuka halaman di hasil pencarian cukup klik (atau ketuk di ponsel) pada halaman yang diinginkan dalam daftar yang ditampilkan.","title":"Menggunakan pencarian"},{"location":"books/","text":"Rocky Linux Instructional Books You've found the Books section of the documentation. This is where longer-form documentation is kept. These documents are broken down into sections or \"chapters\" to make it easy for you to work through them at your own pace and keep track of your progress. These documents were created by people just like you, with a passion for certain subjects. Do you want to try your hand at writing an addition to this section? That's GREAT! Simply join the conversation on the Mattermost Documentation channel and we will help you on your way.","title":"Rocky Linux Instructional Books"},{"location":"books/#rocky-linux-instructional-books","text":"You've found the Books section of the documentation. This is where longer-form documentation is kept. These documents are broken down into sections or \"chapters\" to make it easy for you to work through them at your own pace and keep track of your progress. These documents were created by people just like you, with a passion for certain subjects. Do you want to try your hand at writing an addition to this section? That's GREAT! Simply join the conversation on the Mattermost Documentation channel and we will help you on your way.","title":"Rocky Linux Instructional Books"},{"location":"books/admin_guide/00-toc/","text":"Learning Linux with Rocky The Administration Guide is a collection of Educational Documents focused on System Administrators. They can be used by future System Administrators trying to get up to speed, by current System Administrators who would like a refresher, or by any Linux user who'd like to learn more about the Linux environment, commands, processes, and more. Like all documents of this type, it will evolve and update over time. Initially, we will discuss Linux, distributions, and the whole ecosystem around our operating system. We will then look at the user commands that are essential for getting up to speed with Linux. The more experienced users should also consult the chapter dedicated to the more \"advanced\" 'Commands.' Next comes the chapter on the VI editor. While Linux comes with many editors, VI is one of the most powerful. Other commands sometimes use identical syntaxes as VI ( sed comes to mind). So knowing something about VI, or at least demystifying its essential functions (how to open a file, save, quit or quit without saving), are very important to know. The user will become more comfortable with the other functions of VI as they use the editor. An alternative would be to use nano which comes installed by default in Rocky Linux. While not as versatile, it is simple to use, straightforward, and gets the job done. We can then get into the deep functioning of Linux to discover how the system manages: users. file systems. processes. Next, we will cover an essential subject for the System Administrator: The Backup Process. Many software solutions come with Linux to enhance Backups (rsnapshot, lsyncd, etcetera.)It is good to know the essential components of the backup that are within the operating system. We will investigate two tools: tar and the less widespread cpio in this chapter. Management of the system during the boot process has evolved significantly in recent years since the arrival of the systemd. We will conclude by examining the management of tasks, the implementation of the network, and software installation.","title":"Learning Linux With Rocky"},{"location":"books/admin_guide/00-toc/#learning-linux-with-rocky","text":"The Administration Guide is a collection of Educational Documents focused on System Administrators. They can be used by future System Administrators trying to get up to speed, by current System Administrators who would like a refresher, or by any Linux user who'd like to learn more about the Linux environment, commands, processes, and more. Like all documents of this type, it will evolve and update over time. Initially, we will discuss Linux, distributions, and the whole ecosystem around our operating system. We will then look at the user commands that are essential for getting up to speed with Linux. The more experienced users should also consult the chapter dedicated to the more \"advanced\" 'Commands.' Next comes the chapter on the VI editor. While Linux comes with many editors, VI is one of the most powerful. Other commands sometimes use identical syntaxes as VI ( sed comes to mind). So knowing something about VI, or at least demystifying its essential functions (how to open a file, save, quit or quit without saving), are very important to know. The user will become more comfortable with the other functions of VI as they use the editor. An alternative would be to use nano which comes installed by default in Rocky Linux. While not as versatile, it is simple to use, straightforward, and gets the job done. We can then get into the deep functioning of Linux to discover how the system manages: users. file systems. processes. Next, we will cover an essential subject for the System Administrator: The Backup Process. Many software solutions come with Linux to enhance Backups (rsnapshot, lsyncd, etcetera.)It is good to know the essential components of the backup that are within the operating system. We will investigate two tools: tar and the less widespread cpio in this chapter. Management of the system during the boot process has evolved significantly in recent years since the arrival of the systemd. We will conclude by examining the management of tasks, the implementation of the network, and software installation.","title":"Learning Linux with Rocky"},{"location":"books/admin_guide/01-presentation/","text":"Introduction to the Linux Operating System In this chapter you will learn about GNU/Linux distributions. Objectives : In this chapter you will learn how to: :heavy_check_mark: Describe the features and possible architectures of an operating system :heavy_check_mark: Recount the history of UNIX and GNU/Linux :heavy_check_mark: Choose the right Linux distribution for your needs :heavy_check_mark: Explain the philosophy of free and opensource software :heavy_check_mark: Discover the usefulness of the SHELL. :checkered_flag: generalities , linux , distributions Knowledge : :star: Complexity : :star: Reading time : 10 minutes What is an operating system? Linux, UNIX, BSD, Windows, and MacOS are all operating systems . !!! abstract An operating system is a **set of programs that manages the available resources of a computer**. Among this management of resources, the operating system has to: Manage the physical or virtual memory. The physical memory is made up of the RAM bars and the processor cache memory, which is used for the execution of programs. The virtual memory is a location on the hard disk (the swap partition) that allows the unloading of the physical memory and the saving of the current state of the system during the electrical shutdown of the computer. Intercept access to peripherals . Software is rarely allowed to access hardware directly (except for graphics cards for very specific needs). Provide applications with proper task management . The operating system is responsible for scheduling processes to occupy the processor. Protect files from unauthorized access. Collecting information about programs in use or in progress. Generalities UNIX - GNU/Linux History UNIX From 1964 to 1968 : MULTICS (MULTiplexed Information and Computing Service) is developed for MIT, Bell Labs (AT&T) and General Electric. 1969 : After the withdrawal of Bell (1969) and then General Electric from the project, two developers (Ken Thompson and Dennis Ritchie), joined later by Brian Kernighan, judging MULTICS to be too complex, launched the development of UNIX (UNiplexed Information and Computing Service). Originally developed in assembler, the designers of UNIX developed the B language and then the C language (1971) and completely rewrote UNIX. Having been developed in 1970, the reference date of UNIX/Linux systems is still set at January 01, 1970. The C language is still one of the most popular programming languages today! A low level language, close to the hardware, it allows the adaptation of the operating system to any machine architecture having a C compiler. UNIX is an open and evolving operating system that has played a major role in the history of computing. It has been the basis for many other systems: Linux, BSD, MacOS, etc. UNIX is still relevant today (HP-UX, AIX, Solaris, etc.) Minix 1987 : Andrew S. Tanenbaum develops MINIX, a simplified UNIX, to teach operating systems in a simple way. Mr. Tanenbaum makes the source code of his operating system available. Linux 1991 : A Finnish student, Linus Torvalds , creates an operating system dedicated to his personal computer and names it Linux. He publishes his first version 0.02, on the Usenet discussion forum and other developers come to help him improve his system. The term Linux is a play on words between the founder's first name, Linus, and UNIX. 1993 : The Debian distribution is created. Debian is a non-commercial, community-based distribution. Originally developed for use on servers, it is particularly well suited for this role, but it is intended to be a universal system and thus usable on a personal computer as well. Debian is used as the basis for many other distributions, such as Mint or Ubuntu. 1994 : The commercial distribution RedHat is created by the company RedHat, which is today the leading distributor of the GNU/Linux operating system. RedHat supports the community version Fedora and recently the free distribution CentOS. 1997 : The KDE desktop environment is created. It is based on the Qt component library and the C++ development language. 1999 : The Gnome desktop environment is created. It is based on the GTK+ component library. 2002 : The Arch distribution is created. Its particularity is to be released in Rolling Release (continuous update). 2004 : Ubuntu is created by the Canonical company (Mark Shuttleworth). It is based on Debian, but includes free and proprietary software. 2021 : Birth of Rocky Linux, based on RedHat distribution. Market share Linux is still not well known by the general public, even though they use it regularly. Indeed, Linux is hidden in smartphones , televisions , internet boxes , etc. Almost 70% of the web pages served in the world are served by a Linux or UNIX server! Linux equips a little more than 3% of personal computers but more than 82% of smartphones . Android being an operating system whose kernel is a Linux. Linux equips 100% of the 500 supercomputers since 2018. A supercomputer is a computer designed to achieve the highest possible performance with the techniques known at the time of its design, especially with regard to computing speed. Architectural design The kernel is the first software component. It is the heart of the Linux system. It manages the hardware resources of the system. The other software components must go through it to access the hardware. The shell is a utility that interprets user commands and ensures their execution. Main shells: Bourne shell, C shell, Korn shell and Bourne-Again shell (bash). Applications are user programs such as : Internet browser ; the word processor ; ... Multitask Linux belongs to the family of time-sharing operating systems. It shares process time between several programs, switching from one to another in a transparent way for the user. This implies: simultaneous execution of several programs; distribution of CPU time by the scheduler; reduction of problems due to a failed application; reduced performance when there are too many programs running. Multi user The purpose of Multics was to allow several users to work from several terminals (screen and keyboard) on a single computer (very expensive at the time). Linux, which is inspired by this operating system, has kept this ability to work with several users simultaneously and independently, each one having its own user account, memory space and access rights to files and software. Multiprocessor Linux is able to work with multi-processor computers or with multi-core processors. Multi platform Linux is written in a high-level language that can be adapted to different types of platforms during compilation. It therefore runs on : home computers (PC or laptop); servers (data, applications,...); portable computers (smartphones or tablets) embedded systems (car computer); active network elements (routers, switches) household appliances (TVs, refrigerators,...). Open Linux is based on recognized standards posix , TCP/IP, NFS, Samba ... allowing to share data and services with other application systems. The UNIX/Linux philosophy Everything is a file. Portability. Do only one thing and do it well. KISS: Keep It Simple Stupid. \"UNIX is basically a simple operating system, but you have to be a genius to understand the simplicity.\" ( Dennis Ritchie ) \"Unix is user-friendly. It just isn't promiscuous about which users it's friendly with.\" ( Steven King ) The GNU/LINUX distributions A Linux distribution is a consistent set of software assembled around the Linux kernel and ready to be installed along with the necessary components to manage this software (installation, removal, configuration). There are associative or community distributions (Debian, Rocky) or commercial (RedHat, Ubuntu). Each distribution offers one or more desktop environments , provides a set of pre-installed software and a library of additional software. Configuration options (kernel or services options for example) are specific to each one. This principle allows you to have distributions oriented to beginners (Ubuntu, Linux Mint...), to have a more complex approach (Gentoo, Arch), to be focused more towards servers (Debian, Redhat), or to be dedicated towards workstations . Desktop environments There are many graphic environments: Gnome , KDE , LXDE , XFCE , etc. There is something for everyone, and their ergonomics have nothing to be ashamed of when compared to Microsoft or Apple systems! So why is there so little enthusiasm for Linux, when there are no (or almost no) viruses for this system ? Maybe because all editors (Adobe) or manufacturers (Nvidia) do not play the free game and do not provide a version of their software or their drivers for GNU/Linux? Fear of change? The difficulty to find where to buy a Linux computer? Too few games (but not for long) distributed under Linux? Will the situation change with the arrival of the steam-box game console that runs on Linux? The Gnome 3 desktop environment no longer uses the concept of Desktop but that of Gnome Shell (not to be confused with the command line shell). It serves as a desktop, a dashboard, a notification area and a window selector. The Gnome desktop environment is based on the GTK+ component library. The KDE desktop environment is based on the Qt component library. It is traditionally more recommended for users coming from a Windows world. Free / Open source A user of a Microsoft or Mac operating system must purchase a license to use the operating system. This license has a cost, although it is usually transparent (the price of the license is included in the price of the computer). In the GNU/Linux world, the Free Software movement provides mostly free distributions. Free does not mean free! Open source : the source codes are available, so it is possible to consult and modify them under certain conditions. A free software is necessarily Open Source, but the opposite is not true since an Open Source software is separated from the freedom proposed by the GPL license. GPL License (General Public License) The GPL License guarantees the author of a software its intellectual property, but allows modification, redistribution or resale of software by third parties, provided that the source codes are provided with the software. The GPL is the license that came out of the GNU (GNU is Not UNIX) project, which was instrumental in creating Linux. It implies : the freedom to run the program, for any purpose; the freedom to study how the program works and adapt it to your needs the freedom to redistribute copies; the freedom to improve the program and publish your improvements, for the benefit of the whole community. On the other hand, even products licensed under the GPL can be paid for. This is not the product itself, but the guarantee that a team of developers will continue to work on it to make it evolve and troubleshoot errors, or even provide support to users. Areas of use A Linux distribution excels for : A server : HTTP, email, groupware, file sharing, etc. Security : Gateway, firewall, router, proxy, etc. Central computer : Banks, insurance, industry, etc. Embedded system : Routers, Internet boxes, SmartTV, etc. Linux is a suitable choice for hosting databases or websites, or as a mail server, DNS or firewall. In short, Linux can do just about anything, which explains the quantity of specific distributions. Shell Generalities The shell , known as command interface , allows users to send commands to the operating system. It is less visible today, since the implementation of graphical interfaces, but remains a privileged means on Linux systems which do not all have graphical interfaces and whose services do not always have a setting interface. It offers a real programming language including the classical structures: loops, alternatives, and the common constituents: variables, passing of parameters, and sub-programs. It allows the creation of scripts to automate certain actions (backups, creation of users, system monitoring, etc.). There are several types of shells available and configurable on a platform or according to the user's preference: sh, the POSIX standard shell ; csh, command-oriented shell in C ; bash, Bourne-Again Shell, Linux shell. etc, ... Functionalities Command execution (checks the command given and executes it); Input/Output redirection (returns data to a file instead of writing it on the screen); Connection process (manages the user's connection); Interpreted programming language (allowing the creation of scripts); Environment variables (access to information specific to the system during operation). Principle Check your Knowledge :heavy_check_mark: An operating system is a set of programs for managing the available resources of a computer: [ ] True [ ] False :heavy_check_mark: The operating system is brought to: [ ] Manage physical and virtual memory [ ] Allow direct access to peripherals [ ] Subcontract the management of tasks to the processor [ ] Collect information about the programs used or in use :heavy_check_mark: Among these personalities, which ones participated in the development of UNIX: [ ] Linus Torvalds [ ] Ken Thompson [ ] Lionel Richie [ ] Brian Kernighan [ ] Andrew Stuart Tanenbaum :heavy_check_mark: The original nationality of Linus Torvalds, creator of the Linux kernel, is: [ ] Swedish [ ] Finnish [ ] Norwegian [ ] Flemish [ ] French of course :heavy_check_mark: Which of the following distributions is the oldest: [ ] Debian [ ] Slackware [ ] RedHat [ ] Arch :heavy_check_mark: Is the Linux kernel: [ ] Multitasking [ ] Multi user [ ] Multiprocessor [ ] Multi-core [ ] Cross-platform [ ] Open :heavy_check_mark: Is free software necessarily open source? [ ] True [ ] False :heavy_check_mark: Is Open Source software necessarily free? [ ] True [ ] False :heavy_check_mark: Which of the following is not a shell: [ ] Jason [ ] Jason-Bourne shell (jbsh) [ ] Bourne-Again shell (bash) [ ] C shell (csh) [ ] Korn shell (ksh)","title":"Introduction to Linux"},{"location":"books/admin_guide/01-presentation/#introduction-to-the-linux-operating-system","text":"In this chapter you will learn about GNU/Linux distributions. Objectives : In this chapter you will learn how to: :heavy_check_mark: Describe the features and possible architectures of an operating system :heavy_check_mark: Recount the history of UNIX and GNU/Linux :heavy_check_mark: Choose the right Linux distribution for your needs :heavy_check_mark: Explain the philosophy of free and opensource software :heavy_check_mark: Discover the usefulness of the SHELL. :checkered_flag: generalities , linux , distributions Knowledge : :star: Complexity : :star: Reading time : 10 minutes","title":"Introduction to the Linux Operating System"},{"location":"books/admin_guide/01-presentation/#what-is-an-operating-system","text":"Linux, UNIX, BSD, Windows, and MacOS are all operating systems . !!! abstract An operating system is a **set of programs that manages the available resources of a computer**. Among this management of resources, the operating system has to: Manage the physical or virtual memory. The physical memory is made up of the RAM bars and the processor cache memory, which is used for the execution of programs. The virtual memory is a location on the hard disk (the swap partition) that allows the unloading of the physical memory and the saving of the current state of the system during the electrical shutdown of the computer. Intercept access to peripherals . Software is rarely allowed to access hardware directly (except for graphics cards for very specific needs). Provide applications with proper task management . The operating system is responsible for scheduling processes to occupy the processor. Protect files from unauthorized access. Collecting information about programs in use or in progress.","title":"What is an operating system?"},{"location":"books/admin_guide/01-presentation/#generalities-unix-gnulinux","text":"","title":"Generalities UNIX - GNU/Linux"},{"location":"books/admin_guide/01-presentation/#history","text":"","title":"History"},{"location":"books/admin_guide/01-presentation/#unix","text":"From 1964 to 1968 : MULTICS (MULTiplexed Information and Computing Service) is developed for MIT, Bell Labs (AT&T) and General Electric. 1969 : After the withdrawal of Bell (1969) and then General Electric from the project, two developers (Ken Thompson and Dennis Ritchie), joined later by Brian Kernighan, judging MULTICS to be too complex, launched the development of UNIX (UNiplexed Information and Computing Service). Originally developed in assembler, the designers of UNIX developed the B language and then the C language (1971) and completely rewrote UNIX. Having been developed in 1970, the reference date of UNIX/Linux systems is still set at January 01, 1970. The C language is still one of the most popular programming languages today! A low level language, close to the hardware, it allows the adaptation of the operating system to any machine architecture having a C compiler. UNIX is an open and evolving operating system that has played a major role in the history of computing. It has been the basis for many other systems: Linux, BSD, MacOS, etc. UNIX is still relevant today (HP-UX, AIX, Solaris, etc.)","title":"UNIX"},{"location":"books/admin_guide/01-presentation/#minix","text":"1987 : Andrew S. Tanenbaum develops MINIX, a simplified UNIX, to teach operating systems in a simple way. Mr. Tanenbaum makes the source code of his operating system available.","title":"Minix"},{"location":"books/admin_guide/01-presentation/#linux","text":"1991 : A Finnish student, Linus Torvalds , creates an operating system dedicated to his personal computer and names it Linux. He publishes his first version 0.02, on the Usenet discussion forum and other developers come to help him improve his system. The term Linux is a play on words between the founder's first name, Linus, and UNIX. 1993 : The Debian distribution is created. Debian is a non-commercial, community-based distribution. Originally developed for use on servers, it is particularly well suited for this role, but it is intended to be a universal system and thus usable on a personal computer as well. Debian is used as the basis for many other distributions, such as Mint or Ubuntu. 1994 : The commercial distribution RedHat is created by the company RedHat, which is today the leading distributor of the GNU/Linux operating system. RedHat supports the community version Fedora and recently the free distribution CentOS. 1997 : The KDE desktop environment is created. It is based on the Qt component library and the C++ development language. 1999 : The Gnome desktop environment is created. It is based on the GTK+ component library. 2002 : The Arch distribution is created. Its particularity is to be released in Rolling Release (continuous update). 2004 : Ubuntu is created by the Canonical company (Mark Shuttleworth). It is based on Debian, but includes free and proprietary software. 2021 : Birth of Rocky Linux, based on RedHat distribution.","title":"Linux"},{"location":"books/admin_guide/01-presentation/#market-share","text":"Linux is still not well known by the general public, even though they use it regularly. Indeed, Linux is hidden in smartphones , televisions , internet boxes , etc. Almost 70% of the web pages served in the world are served by a Linux or UNIX server! Linux equips a little more than 3% of personal computers but more than 82% of smartphones . Android being an operating system whose kernel is a Linux. Linux equips 100% of the 500 supercomputers since 2018. A supercomputer is a computer designed to achieve the highest possible performance with the techniques known at the time of its design, especially with regard to computing speed.","title":"Market share"},{"location":"books/admin_guide/01-presentation/#architectural-design","text":"The kernel is the first software component. It is the heart of the Linux system. It manages the hardware resources of the system. The other software components must go through it to access the hardware. The shell is a utility that interprets user commands and ensures their execution. Main shells: Bourne shell, C shell, Korn shell and Bourne-Again shell (bash). Applications are user programs such as : Internet browser ; the word processor ; ...","title":"Architectural design"},{"location":"books/admin_guide/01-presentation/#multitask","text":"Linux belongs to the family of time-sharing operating systems. It shares process time between several programs, switching from one to another in a transparent way for the user. This implies: simultaneous execution of several programs; distribution of CPU time by the scheduler; reduction of problems due to a failed application; reduced performance when there are too many programs running.","title":"Multitask"},{"location":"books/admin_guide/01-presentation/#multi-user","text":"The purpose of Multics was to allow several users to work from several terminals (screen and keyboard) on a single computer (very expensive at the time). Linux, which is inspired by this operating system, has kept this ability to work with several users simultaneously and independently, each one having its own user account, memory space and access rights to files and software.","title":"Multi user"},{"location":"books/admin_guide/01-presentation/#multiprocessor","text":"Linux is able to work with multi-processor computers or with multi-core processors.","title":"Multiprocessor"},{"location":"books/admin_guide/01-presentation/#multi-platform","text":"Linux is written in a high-level language that can be adapted to different types of platforms during compilation. It therefore runs on : home computers (PC or laptop); servers (data, applications,...); portable computers (smartphones or tablets) embedded systems (car computer); active network elements (routers, switches) household appliances (TVs, refrigerators,...).","title":"Multi platform"},{"location":"books/admin_guide/01-presentation/#open","text":"Linux is based on recognized standards posix , TCP/IP, NFS, Samba ... allowing to share data and services with other application systems.","title":"Open"},{"location":"books/admin_guide/01-presentation/#the-unixlinux-philosophy","text":"Everything is a file. Portability. Do only one thing and do it well. KISS: Keep It Simple Stupid. \"UNIX is basically a simple operating system, but you have to be a genius to understand the simplicity.\" ( Dennis Ritchie ) \"Unix is user-friendly. It just isn't promiscuous about which users it's friendly with.\" ( Steven King )","title":"The UNIX/Linux philosophy"},{"location":"books/admin_guide/01-presentation/#the-gnulinux-distributions","text":"A Linux distribution is a consistent set of software assembled around the Linux kernel and ready to be installed along with the necessary components to manage this software (installation, removal, configuration). There are associative or community distributions (Debian, Rocky) or commercial (RedHat, Ubuntu). Each distribution offers one or more desktop environments , provides a set of pre-installed software and a library of additional software. Configuration options (kernel or services options for example) are specific to each one. This principle allows you to have distributions oriented to beginners (Ubuntu, Linux Mint...), to have a more complex approach (Gentoo, Arch), to be focused more towards servers (Debian, Redhat), or to be dedicated towards workstations .","title":"The GNU/LINUX distributions"},{"location":"books/admin_guide/01-presentation/#desktop-environments","text":"There are many graphic environments: Gnome , KDE , LXDE , XFCE , etc. There is something for everyone, and their ergonomics have nothing to be ashamed of when compared to Microsoft or Apple systems! So why is there so little enthusiasm for Linux, when there are no (or almost no) viruses for this system ? Maybe because all editors (Adobe) or manufacturers (Nvidia) do not play the free game and do not provide a version of their software or their drivers for GNU/Linux? Fear of change? The difficulty to find where to buy a Linux computer? Too few games (but not for long) distributed under Linux? Will the situation change with the arrival of the steam-box game console that runs on Linux? The Gnome 3 desktop environment no longer uses the concept of Desktop but that of Gnome Shell (not to be confused with the command line shell). It serves as a desktop, a dashboard, a notification area and a window selector. The Gnome desktop environment is based on the GTK+ component library. The KDE desktop environment is based on the Qt component library. It is traditionally more recommended for users coming from a Windows world.","title":"Desktop environments"},{"location":"books/admin_guide/01-presentation/#free-open-source","text":"A user of a Microsoft or Mac operating system must purchase a license to use the operating system. This license has a cost, although it is usually transparent (the price of the license is included in the price of the computer). In the GNU/Linux world, the Free Software movement provides mostly free distributions. Free does not mean free! Open source : the source codes are available, so it is possible to consult and modify them under certain conditions. A free software is necessarily Open Source, but the opposite is not true since an Open Source software is separated from the freedom proposed by the GPL license.","title":"Free / Open source"},{"location":"books/admin_guide/01-presentation/#gpl-license-general-public-license","text":"The GPL License guarantees the author of a software its intellectual property, but allows modification, redistribution or resale of software by third parties, provided that the source codes are provided with the software. The GPL is the license that came out of the GNU (GNU is Not UNIX) project, which was instrumental in creating Linux. It implies : the freedom to run the program, for any purpose; the freedom to study how the program works and adapt it to your needs the freedom to redistribute copies; the freedom to improve the program and publish your improvements, for the benefit of the whole community. On the other hand, even products licensed under the GPL can be paid for. This is not the product itself, but the guarantee that a team of developers will continue to work on it to make it evolve and troubleshoot errors, or even provide support to users.","title":"GPL License (General Public License)"},{"location":"books/admin_guide/01-presentation/#areas-of-use","text":"A Linux distribution excels for : A server : HTTP, email, groupware, file sharing, etc. Security : Gateway, firewall, router, proxy, etc. Central computer : Banks, insurance, industry, etc. Embedded system : Routers, Internet boxes, SmartTV, etc. Linux is a suitable choice for hosting databases or websites, or as a mail server, DNS or firewall. In short, Linux can do just about anything, which explains the quantity of specific distributions.","title":"Areas of use"},{"location":"books/admin_guide/01-presentation/#shell","text":"","title":"Shell"},{"location":"books/admin_guide/01-presentation/#generalities","text":"The shell , known as command interface , allows users to send commands to the operating system. It is less visible today, since the implementation of graphical interfaces, but remains a privileged means on Linux systems which do not all have graphical interfaces and whose services do not always have a setting interface. It offers a real programming language including the classical structures: loops, alternatives, and the common constituents: variables, passing of parameters, and sub-programs. It allows the creation of scripts to automate certain actions (backups, creation of users, system monitoring, etc.). There are several types of shells available and configurable on a platform or according to the user's preference: sh, the POSIX standard shell ; csh, command-oriented shell in C ; bash, Bourne-Again Shell, Linux shell. etc, ...","title":"Generalities"},{"location":"books/admin_guide/01-presentation/#functionalities","text":"Command execution (checks the command given and executes it); Input/Output redirection (returns data to a file instead of writing it on the screen); Connection process (manages the user's connection); Interpreted programming language (allowing the creation of scripts); Environment variables (access to information specific to the system during operation).","title":"Functionalities"},{"location":"books/admin_guide/01-presentation/#principle","text":"","title":"Principle"},{"location":"books/admin_guide/01-presentation/#check-your-knowledge","text":":heavy_check_mark: An operating system is a set of programs for managing the available resources of a computer: [ ] True [ ] False :heavy_check_mark: The operating system is brought to: [ ] Manage physical and virtual memory [ ] Allow direct access to peripherals [ ] Subcontract the management of tasks to the processor [ ] Collect information about the programs used or in use :heavy_check_mark: Among these personalities, which ones participated in the development of UNIX: [ ] Linus Torvalds [ ] Ken Thompson [ ] Lionel Richie [ ] Brian Kernighan [ ] Andrew Stuart Tanenbaum :heavy_check_mark: The original nationality of Linus Torvalds, creator of the Linux kernel, is: [ ] Swedish [ ] Finnish [ ] Norwegian [ ] Flemish [ ] French of course :heavy_check_mark: Which of the following distributions is the oldest: [ ] Debian [ ] Slackware [ ] RedHat [ ] Arch :heavy_check_mark: Is the Linux kernel: [ ] Multitasking [ ] Multi user [ ] Multiprocessor [ ] Multi-core [ ] Cross-platform [ ] Open :heavy_check_mark: Is free software necessarily open source? [ ] True [ ] False :heavy_check_mark: Is Open Source software necessarily free? [ ] True [ ] False :heavy_check_mark: Which of the following is not a shell: [ ] Jason [ ] Jason-Bourne shell (jbsh) [ ] Bourne-Again shell (bash) [ ] C shell (csh) [ ] Korn shell (ksh)","title":"Check your Knowledge"},{"location":"books/admin_guide/03-commands/","text":"Commands for Linux Users In this chapter you will learn how to work with Linux with the commands. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: move in the system tree; :heavy_check_mark: create a text file, display its contents and modify it; :heavy_check_mark: use the most useful Linux commands. :checkered_flag: user commands , linux Knowledge : :star: Complexity : :star: Reading time : 40 minutes Generalities Current Linux systems have graphical utilities dedicated to the work of an administrator. However, it is important to be able to use the interface in command line mode for several reasons: The majority of system commands are common to all Linux distributions, which is not the case for graphical tools. It can happen that the system does not start correctly but that a backup command interpreter remains accessible. Remote administration is done on the command line with an SSH terminal. In order to preserve server resources, the graphical interface is either not installed or launched on demand. Administration is done by scripts. Learning these commands allows the administrator to connect to a Linux terminal, to manage its resources, its files, to identify the station, the terminal, and the connected users, etc. The users The user of a Linux system is defined in the /etc/passwd file, by: a login name , more commonly called \"login\", containing no spaces; a numeric identifier : UID (User Identifier); a group identifier : GID (Group Identifier); a command interpreter , a shell, which can be different from one user to another; a connection directory , the home directory . In other files by: a password , which will be encrypted before being stored ( /etc/shadow ); a command prompt , or prompt login, which will be symbolized by a # for administrators and a $ for other users ( /etc/profile ). Depending on the security policy implemented on the system, the password will have to contain a certain number of characters and meet certain complexity requirements. Among the existing command interpreters, the Bourne-Again Shell ( /bin/bash ) is the one most frequently used. It is assigned by default to new users. For various reasons, advanced Linux users can choose alternative shells from among the Korn Shell ( ksh ), the C Shell ( csh ), etc. The user's login directory is by convention stored in the /home directory of the workstation. It will contain the user's personal data and the configuration files of his applications. By default, at login, the login directory is selected as the current directory. A workstation type installation (with graphical interface) starts this interface on terminal 1. Linux being multi-user, it is possible to connect several users several times, on different physical terminals (TTY) or virtual terminals (PTS). Virtual terminals are available within a graphical environment. A user switches from one physical terminal to another using Alt + Fx from the command line or using CTRL + Alt + Fx . The shell Once the user is connected to a console, the shell displays the command prompt . It then behaves like an infinite loop, with each statement entered: displaying the command prompt; reading the command ; syntax analysis ; substitution of special characters ; execute the command; display the command prompt; etc. The key sequence CTRL + C is used to interrupt a running command. The use of a command generally follows this sequence: command [option(s)] [arguments(s)] The name of the command is often in lower case . A space separates each item. Short options begin with a dash ( -l ), while long options begin with two dashes ( --list ). A double dash ( -- ) indicates the end of the option list. It is possible to group some short options together: $ ls -l -i -a is equivalent to: $ ls -lia There can of course be several arguments after an option: $ ls -lia /etc /home /var In the literature, the term \"option\" is equivalent to the term \"parameter,\" which is more commonly used in programming. The optional side of an option or argument is symbolized by enclosing it in square brackets [ and ] . When more than one option is possible, a vertical bar called a \"pipe\" separates them [a|e|i] . General commands apropos , whatis and man commands It is impossible for an administrator at any level to know all the commands and options in detail. A manual is usually available for all installed commands. apropos command The command apropos allows you to search by keyword within these manual pages: Options Description -s , --sections list or --section list Limited to manual sections. -a or --and Displays only the item matching all the provided keywords. Example: $ apropos clear clear (1) - clear the terminal screen clear_console (1) - clear the console clearenv (3) - clear the environment clearerr (3) - check and reset stream status clearerr_unlocked (3) - nonlocking stdio functions feclearexcept (3) - floating-point rounding and exception handling fwup_clear_status (3) - library to support management of system firmware updates klogctl (3) - read and/or clear kernel message ring buffer; set console_loglevel sgt-samegame (6) - Block-clearing puzzle syslog (2) - read and/or clear kernel message ring buffer; set console_loglevel timerclear (3) - timeval operations XClearArea (3) - clear area or window XClearWindow (3) - clear area or window XSelectionClearEvent (3) - SelectionClear event structure To find the command that will allow changing the password of an account: $ apropos --exact password -a change chage (1) - change user password expiry information passwd (1) - change user password whatis command The whatis command displays the description of the command passed as argument: whatis clear Example: $ whatis clear clear (1) - clear the terminal screen man command Once found by apropos or whatis , the manual is read by man (\"Man is your friend\"). This set of manuals is divided into 8 sections, grouping information by topic, the default section being 1: Executable programs or commands; System calls (functions given by the kernel); Library calls (functions given by the library); Special files (usually found in /dev); File Formats and conventions (configuration files such as etc/passwd); Games (such as character-based applications); Miscellaneous (e.g. man (7)); System administration commands (usually only for root); Kernel routines (non-standard). Information about each section can be accessed by typing man x intro , where x is the section number. The command: man passwd will tell the administrator about the passwd command, its options, etc. While a: $ man 5 passwd will inform him about the files related to the command. Not all manual pages are translated from English. However, English manual pages are usually very accurate and provide all the information you need. The grammar and separation rules it uses may confuse beginner administrators, but after practice, I'm sure you'll find the information you want. The navigation in the manual is done with the arrows \u2191 and \u2193 . The manual is exited by pressing the q key. shutdown command The shutdown command allows you to electrically shut down a Linux server, either immediately or after a certain period of time. shutdown [-h] [-r] time [message] The shutdown time should be specified in the format hh:mm for a precise time, or +mm for a delay in minutes. To force an immediate stop, the word now will replace the time. In this case, the optional message is not sent to other users of the system. Examples: [root]# shutdown -h 0:30 \"Server shutdown at 0:30\" [root]# shutdown -r +5 Options: Options Remarks -h Shutdown the system electrically -r Restarts the system history command The history command displays the history of commands that have been entered by the user. The commands are stored in the .bash_history file in the user's login directory. Example of a history command $ history 147 man ls 148 man history Options Comments -w Write the current history to the history file -c The -c option will delete the history of the current session (but not the contents of the .bash_history file). Manipulating history: To manipulate the history, the following commands entered from the command prompt will: Keys Function !! Recall the last command placed. !n Recall the command by its number in the list. !string Recall the most recent command beginning with the string. \u2191 Recall the most recent command beginning with the string. \u2193 Recall the most recent command beginning with the string. The auto-completion Auto-completion is also a great help. It allows you to complete commands, entered paths, or file names. A press of the TAB key completes the entry in the case of a single solution. Otherwise, a second press will be required to obtain the list of possibilities. If a double press of the TAB key causes no reaction from the system, then there is no solution to the current completion. Display and identification clear command The clear command clears the contents of the terminal screen. In fact, to be more precise, it shifts the display so that the command prompt is at the top of the screen on the first line. In a terminal, the display will be permanently hidden, whereas in a graphical interface, a scrollbar will allow you to go back in the history of the virtual terminal. !!! Tip <kbd>CTRL</kbd> + <kbd>L</kbd> will have the same effect as the `clear` command echo command The echo command is used to display a string of characters. This command is most commonly used in administration scripts to inform the user during execution. The -n option indicates no newline output string (by default, newline output string). shell > echo -n \"123\";echo \"456\" 123456 shell > echo \"123\";echo \"456\" 123 456 For various reasons, the script developer may need to use special sequences (starting with a \\ character). In this case, the -e option will be stipulated, allowing interpretation of the sequences. Among the frequently used sequences, we can mention: Sequence Result \\a Send a sonor bip \\b Back \\n Adds a line break \\t Adds a horizontal tab \\v Adds vertical tab date command The date command displays the date and time. The command has the following syntax: date [-d AAAAMMJJ] [format] Examples: $ date Mon May 24 16:46:53 CEST 2021 $ date -d 20210517 +%j 137 In this last example, the -d option displays a given date. The +%j option formats this date to show only the day of the year. !!! Warning The format of a date can change depending on the value of the language defined in the environment variable `$LANG`. The date display can follow the following formats: Option Format +%A Locale's full weekday name (e.g., Sunday) +%B Locale's full month name (e.g., January) +%c Locale's date and time (e.g., Thu Mar 3 23:05:25 2005) +%d Day of month (e.g., 01) +%F Date in YYYY-MM-DD format +%G Year +%H Hour (00..23) +%j Day of the year (001..366) +%m Month number (01..12) +%M Minute (00..59) +%R Time in hh:mm format +%s Seconds since January 1, 1970 +%S Second (00..60) +%T Time in hh:mm:ss format +%u Day of the week ( 1 for Monday) +%V Week number ( +%V ) +%x Date in format DD/MM/YYYY The date command also allows you to change the system date and time. In this case, the -s option will be used. [root]# date -s \"2021-05-24 10:19\" The format to be used following the -s option is this: date -s \"[AA]AA-MM-JJ hh:mm:[ss]\" id , who and whoami commands The id command is used to display information about users and groups. By default, no user parameter is added, and the information of the currently logged in user and group is displayed\u3002 $ id rockstar uid=1000(rockstar) gid=1000(rockstar) groups=1000(rockstar),10(wheel) The -g , -G , -n and -u options display the main group GID, subgroup GIDs, names instead of numeric identifiers, and the user's UID respectively. The whoami command displays the login of the current user. The who command alone displays the names of logged in users: $ who rockstar tty1 2021-05-24 10:30 root pts/0 2021-05-24 10:31 Since Linux is multi-user, it is likely that multiple sessions are open on the same station, either physically or over the network. It is interesting to know which users are logged in, if only to communicate with them by sending messages. tty: represents a terminal. pts/: represents a virtual console in a graphical environment with the number after representing the instance of the virtual console (0, 1, 2...) The -r option also displays the runlevel (see chapter \"startup\"). File tree In Linux, the file tree is an inverted tree, called a single hierarchical tree , whose root is the directory / . The current directory is the directory where the user is located. The connection directory is the working directory associated with the user. The login directories are, by default, stored in the /home directory. When the user logs in, the current directory is the login directory. An absolute path references a file from the root by traversing the entire tree to the file level: /home/groupA/alice/file The relative path references that same file by traversing the entire tree from the current directory: ../alice/file In the above example, the \" .. \" refers to the parent directory of the current directory. A directory, even if it is empty, will necessarily contain at least two references : . : reference to itself. .. : reference to the parent directory of the current directory. A relative path can thus start with ./ or ../ . When the relative path refers to a subdirectory or file in the current directory, then the ./ is often omitted. Mentioning the first ./ in the tree will only really be required to run an executable file. Errors in paths can cause many problems: creating folders or files in the wrong places, unintentional deletions, etc. It is therefore strongly recommended to use auto-completion when entering paths. In the above example, we are looking to give the location of the file myfile from the directory of bob. By an absolute path , the current directory does not matter. We start at the root, and work our way down to the directories home , groupA , alice and finally the file myfile : /home/groupA/alice/myfile . By a relative path , our starting point being the current directory bob , we go up one level through .. (i.e., into the groupA directory), then down into the alice directory, and finally the myfile file: ../alice/myfile . pwd command The pwd (Print Working Directory) command displays the absolute path of the current directory. $ pwd /home/rockstar Use a relative path to reference a file or directory, or use the cd command to move to another directory, You must know its location in the file tree. Depending on the type of shell and the different parameters of its configuration file, the terminal prompt (also known as the command prompt) will display the absolute or relative path of the current directory. cd command The cd (Change Directory) command allows you to change the current directory, in other words, to move through the tree. $ cd /tmp $ pwd /tmp $ cd ../ $ pwd / $ cd $ pwd /home/rockstar As you can see in the last example above, the command cd with no arguments moves the current directory to the home directory . ls command The ls command displays the contents of a directory. ls [-a] [-i] [-l] [directory1] [directory2] [\u2026] Example: $ ls /home . .. rockstar The main options of the ls command are: Option Information -a Displays all files, even hidden ones. Hidden files in Linux are those beginning with . . -i Displays inode numbers. -l The -l command displays a vertical list of files with additional information formatted in columns. The ls command, however, has a lot of options (see man ): Option Information -d Displays information about a directory instead of listing its contents. -g Displays UID and GID rather than owner names. -h Displays file sizes in the most appropriate format (byte, kilobyte, megabyte, gigabyte, ...). h stands for Human Readable. -s Displays the number of blocks occupied by the file. One block equals 400K. -A Displays all files in the directory except . and .. -R Displays the contents of subdirectories recursively. -F Displays the type of files. Prints a / for a directory, * for executables, @ for a symbolic link, and nothing for a text file. -X Sort files according to their extensions. Description of columns: $ ls -lia /home 78489 drwx------ 4 rockstar rockstar 4096 25 oct. 08:10 rockstar Value Information 78489 Inode Number. drwx------ File type ( d ) and rights ( rwx------ ). 4 Number of subdirectories ( . and .. included). For a file, it represents the number of hard links, and 1 represents itself. rockstar User ownership. rockstar Group ownership. 4096 For files, it shows the size of the file. For directories, it shows the fixed value of 4096 bytes occupied by the file naming. To calculate the total size of a directory, use du -sh rockstar/ 25 oct. 08:10 Last modified date. rockstar The name of the file (or directory). !!! Note **Aliases** are frequently positioned in common distributions. This is the case of the alias `ll`: ``` alias ll='ls -l --color=auto' ``` The ls command has many options and here are some advanced examples of uses: List the files in /etc in order of last modification: $ ls -ltr /etc total 1332 -rw-r--r--. 1 root root 662 29 may 2021 logrotate.conf -rw-r--r--. 1 root root 272 17 may. 2021 mailcap -rw-------. 1 root root 122 12 may. 2021 securetty ... -rw-r--r--. 2 root root 85 18 may. 17:04 resolv.conf -rw-r--r--. 1 root root 44 18 may. 17:04 adjtime -rw-r--r--. 1 root root 283 18 may. 17:05 mtab List /var files larger than 1 megabyte but less than 1 gigabyte: $ ls -lhR /var | grep \\- | grep [1-9]*M ... -rw-r--r--. 1 apache apache 1.2M 10 may. 13:02 XB RiyazBdIt.ttf -rw-r--r--. 1 apache apache 1.2M 10 may. 13:02 XB RiyazBd.ttf -rw-r--r--. 1 apache apache 1.1M 10 may. 13:02 XB RiyazIt.ttf ... Of course, we highly recommend that you use the find command. $ find /var -size +1M -a -size -1024M -a -type f -exec ls -lh {} \\; Show the rights on a folder: To find out the rights to a folder, in our example /etc , the following command would not be appropriate: $ ls -l /etc total 1332 -rw-r--r--. 1 root root 44 18 nov. 17:04 adjtime -rw-r--r--. 1 root root 1512 12 janv. 2010 aliases -rw-r--r--. 1 root root 12288 17 nov. 17:41 aliases.db drwxr-xr-x. 2 root root 4096 17 nov. 17:48 alternatives ... The above command will display the contents of the folder (inside) by default. For the folder itself, you can use the -d option. $ ls -ld /etc drwxr-xr-x. 69 root root 4096 18 nov. 17:05 /etc Sort by file size, largest first: $ ls -lhS time/date format with -l : $ ls -l --time-style=\"+%Y-%m-%d %m-%d %H:%M\" / total 12378 dr-xr-xr-x. 2 root root 4096 2014-11-23 11-23 03:13 bin dr-xr-xr-x. 5 root root 1024 2014-11-23 11-23 05:29 boot Add the trailing slash to the end of folders: By default, the ls command does not display the last slash of a folder. In some cases, like for scripts for example, it is useful to display them: $ ls -dF /etc /etc/ Hide some extensions: $ ls /etc --hide=*.conf mkdir command The mkdir command creates a directory or directory tree. mkdir [-p] directory [directory] [...] Example: $ mkdir /home/rockstar/work The \"rockstar\" directory must exist to create the \"work\" directory. Otherwise, the -p option should be used. The -p option creates the parent directories if they do not exist. !!! Danger It is not recommended to use Linux command names as directory or file names. touch command The touch command changes the timestamp of a file or creates an empty file if the file does not exist. touch [-t date] file Example: $ touch /home/rockstar/myfile Option Information -t date Changes the date of last modification of the file with the specified date. Date format: [AAAA]MMJJhhmm[ss] !!! Tip The `touch` command is primarily used to create an empty file, but it can be useful for incremental or differential backups for example. Indeed, the only effect of executing a `touch` on a file will be to force it to be saved during the next backup. rmdir command The rmdir command deletes an empty directory. Example: $ rmdir /home/rockstar/work Option Information -p Removes the parent directory or directories provided if they are empty. !!! Tip To delete both a non-empty directory and its contents, use the `rm` command. rm command The rm command deletes a file or directory. rm [-f] [-r] file [file] [...] !!! Danger Any deletion of a file or directory is final. Options Information -f Do not ask whether to delete. -i Ask whether to delete. -r Delete a directory and recursively delete its subdirectories. !!! Note The `rm` command itself does not ask for confirmation when deleting files. However, with a RedHat/Rocky distribution, `rm` does ask for confirmation of deletion because the `rm` command is an `alias` of the `rm -i` command. Don't be surprised if on another distribution, like Debian for example, you don't get a confirmation request. Deleting a folder with the rm command, whether the folder is empty or not, will require the -r option to be added. The end of the options is signaled to the shell by a double dash -- . In the example: $ >-hard-hard # To create an empty file called -hard-hard hard-hard [CTRL+C] To interrupt the creation of the file $ rm -f -- -hard-hard The hard-hard file name starts with a - . Without the use of the -- the shell would have interpreted the -d in -hard-hard as an option. mv command The mv command moves and renames a file. mv file [file ...] destination Examples: $ mv /home/rockstar/file1 /home/rockstar/file2 $ mv /home/rockstar/file1 /home/rockstar/file2 /tmp Options Information -f Don't ask for confirmation if overwriting the destination file. -i Request confirmation if overwriting destination file (default). A few concrete cases will help you understand the difficulties that can arise: $ mv /home/rockstar/file1 /home/rockstar/file2 Renames file1 to file2 . If file2 already exists, replace the contents of the file with file1 . $ mv /home/rockstar/file1 /home/rockstar/file2 /tmp Moves file1 and file2 into the /tmp directory. $ mv file1 /repexist/file2 Moves file1 into repexist and renames it file2 . $ mv file1 file2 file1 is renamed to file2 . $ mv file1 /repexist If the destination directory exists, file1 is moved to /repexist . $ mv file1 /wrongrep If the destination directory does not exist, file1 is renamed to wrongrep in the root directory. cp command The cp command copies a file. cp file [file ...] destination Example: $ cp -r /home/rockstar /tmp Options Information -i Request confirmation if overwriting (default). -f Do not ask for confirmation if overwriting the destination file. -p Keeps the owner, permissions and timestamp of the copied file. -r Copies a directory with its files and subdirectories. -s Creates a symbolik links rather than copying. cp file1 /repexist/file2 file1 is copied to /repexist under the name file2 . $ cp file1 file2 file1 is copied as file2 to this directory. $ cp file1 /repexist If the destination directory exists, file1 is copied to /repexist . $ cp file1 /wrongrep If the destination directory does not exist, file1 is copied under the name wrongrep to the root directory. Visualization file command The file command displays the type of a file. file file1 [files] Example: $ file /etc/passwd /etc /etc/passwd: ASCII text /etc: directory more command The more command displays the contents of one or more files screen by screen. more file1 [files] Example: $ more /etc/passwd root:x:0:0:root:/root:/bin/bash ... Using the ENTER key, the move is line by line. Using the SPACE key, the move is page by page. /text allows you to search for the occurrence in the file. less command The less command displays the contents of one or more files. The less command is interactive and has its own commands for use. less file1 [files] The commands specific to less are: Command Action h Help. \u2191 \u2193 \u2192 \u2190 Move up, down a line, or to the right or left. Enter Move down one line. Space Move down one page. PgUp and PgDn Move up or down one page. gg and G Move to the first and last pages /text Search for text. q Quit the less command. cat command The cat command concatenates the contents of multiple files and displays the result on the standard output. cat file1 [files] Example 1 - Displaying the contents of a file to the standard output: $ cat /etc/passwd Example 2 - Displaying the contents of multiple files to standard output: $ cat /etc/passwd /etc/group Example 3 - Combining the contents of multiple files into one file using output redirection: $ cat /etc/passwd /etc/group > usersAndGroups.txt Example 4 - Displaying the line numbering: $ cat -n /etc/profile 1 # /etc/profile: system-wide .profile file for the Bourne shell (sh(1)) 2 # and Bourne compatible shells (bash(1), ksh(1), ash(1), ...). 3 4 if [ \"`id -u`\" -eq 0 ]; then 5 PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" 6 else \u2026 Example 5 - Shows the numbering of non-empty lines: $ cat -b /etc/profile 1 # /etc/profile: system-wide .profile file for the Bourne shell (sh(1)) 2 # and Bourne compatible shells (bash(1), ksh(1), ash(1), ...). 3 if [ \"`id -u`\" -eq 0 ]; then 4 PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" 5 else \u2026 tac command The tac command does almost the opposite of the cat command. It displays the contents of a file starting from the end (which is particularly interesting for reading logs!). Example: Display a log file by displaying the last line first: [root]# tac /var/log/messages | less head command The head command displays the beginning of a file. head [-n x] file Option Description -n x Display the first x lines of the file By default (without the -n option), the head command will display the first 10 lines of the file. tail command The tail command displays the end of a file. tail [-f] [-n x] file Option Description -n x Displays the last x lines of the file -f Displays changes to the file in real time Example: tail -n 3 /etc/passwd sshd:x:74:74:Privilege-separeted sshd:/var/empty /sshd:/sbin/nologin tcpdump::x:72:72::/:/sbin/nologin user1:x:500:500:grp1:/home/user1:/bin/bash With the -f option, the change information of the file will always be output unless the user exits the monitoring state with CTRL + C . This option is very frequently used to track log files (the logs) in real time. Without the -n option, the tail command displays the last 10 lines of the file. sort command The sort command sorts the lines of a file. It allows you to order the result of a command or the content of a file in a given order, numerically, alphabetically, by size (KB, MB, GB) or in reverse order. sort [-k] [-n] [-u] [-o file] [-t] file Example: $ sort -k 3,4 -t \":\" -n /etc/passwd root:x:0:0:root:/root:/bin/bash adm:x:3:4:adm:/var/adm/:/sbin/nologin Option Description -k Specify the columns to be separated. You can specify multiple columns -n Requests a numeric sort -o file Saves the sort to the specified file -t Specify a delimiter, which requires that the contents of the corresponding file must be regularly delimited column contents, otherwise they cannot be sorted properly -r Reverse the order of the result. Used in conjunction with the -n option to sort in order from largest to smallest -u Remove duplicates after sorting. Equivalent to sort file | uniq The sort command sorts the file only on the screen. The file is not modified by the sorting. To save the sort, use the -o option or an output redirection > . By default, the numbers are sorted according to their character. Thus, \"110\" will be before \"20\", which will itself be before \"3\". The -n option must be specified so that the numeric character blocks are sorted by their value. The sort command reverses the order of the results, with the -r option: $ sort -k 3 -t \":\" -n -r /etc/passwd nobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologin systemd-coredump:x:999:997:systemd Core Dumper:/:/sbin/nologin polkitd:x:998:996:User for polkitd:/:/sbin/nologin In this example, the sort command will sort the contents of the /etc/passwd file this time from largest uid to smallest. Some advanced examples of using the sort command: Shuffling values The sort command also allows you to shuffle values with the -R option: $ sort -R /etc/passwd Sorting IP addresses A system administrator is quickly confronted with the processing of IP addresses from the logs of his services such as SMTP, VSFTP or Apache. These addresses are typically extracted with the cut command. Here is an example with the file dns-client.txt : 192.168.1.10 192.168.1.200 5.1.150.146 208.128.150.98 208.128.150.99 $ sort -nr dns-client.txt 208.128.150.99 208.128.150.98 192.168.1.200 192.168.1.10 5.1.150.146 Sorting file by removing duplicates The sort command knows how to remove the duplicates from the file output using -u as option. Here is an example with the file colours.txt : Red Green Blue Red Pink $ sort -u colours.txt Blue Green Pink Red Sorting file by sizes The sort command knows how to recognize file sizes, from commands like ls with the -h option. Here is an example with the file size.txt : 1,7G 18M 69K 2,4M 1,2M 4,2G 6M 124M 12,4M 4G $ sort -hr size.txt 4,2G 4G 1,7G 124M 18M 12,4M 6M 2,4M 1,2M 69K wc command The wc command counts the number of lines, words and/or bytes in a file. wc [-l] [-m] [-w] file [files] Option Description -c Count the number of bytes. -m Count the number of characters. -l Counts the number of lines. -w Counts the number of words. Search find command The find command searches for files or directories location. find directory [-name name] [-type type] [-user login] [-date date] Since there are so many options to the find command, it is best to refer to the man . If the search directory is not specified, the find command will search from the current directory. Option Description -perm permissions Search for files by their permissions. -size size Search for files by size. -exec option of the find command It is possible to use the -exec option of the find command to execute a command on each result line: $ find /tmp -name *.txt -exec rm -f {} \\; The previous command searches for all files in the /tmp directory named *.txt and deletes them. !!! Tip \"Understand the -exec option\" In the example above, the `find` command will construct a string representing the command to be executed. If the `find` command finds three files named `log1.txt`, `log2.txt`, and `log3.txt`, then the `find` command will construct the string by replacing in the string `rm -f {} \\;` the braces with one of the results of the search, and do this as many times as there are results. This will give us: ``` rm -f /tmp/log1.txt ; rm -f /tmp/log2.txt ; rm -f /tmp/log3.txt ; ``` The `;` character is a special shell character that must be protected by a `\\` to prevent it from being interpreted too early by the `find` command (and not in the `-exec`). !!! Tip `$ find /tmp -name *.txt -delete` does the same thing. whereis command The whereis command searches for files related to a command. whereis [-b] [-m] [-s] command Example: $ whereis -b ls ls: /bin/ls Option Description -b Search only the binary file. -m Searches only for man pages. -s Searches only for source files. grep command The grep command searches for a string in a file. grep [-w] [-i] [-v] \"string\" file Example: $ grep -w \"root:\" /etc/passwd root:x:0:0:root:/root:/bin/bash Option Description -i Ignore the case of the searched string. -v Excludes lines containing the string. -w Search for the exact word. The grep command returns the complete line containing the string you are looking for. * The ^ special character is used to search for a string at the beginning of a line. * The special character $ searches for a string at the end of a line. $ grep -w \"^root\" /etc/passwd !!! Note This command is very powerful and it is highly recommended to consult its manual. It has many derivatives. It is possible to search for a string in a file tree with the -R option. grep -R \"Virtual\" /etc/httpd Meta-characters (wildcards) Meta-characters replace one or more characters (or even an absence of characters) during a search. These meta-characters are also known as wildcards. They can be combined. The * character replaces a string composed of any characters. The * character can also represent an absence of character. $ find /home -name \"test*\" /home/rockstar/test /home/rockstar/test1 /home/rockstar/test11 /home/rockstar/tests /home/rockstar/test362 Meta-characters allow more complex searches by replacing all or part of a word. Simply replace the unknowns with these special characters. The character ? replaces a single character, whatever it is. $ find /home -name \"test?\" /home/rockstar/test1 /home/rockstar/tests The square brackets [ and ] are used to specify the values that a single character can take. $ find /home -name \"test[123]*\" /home/rockstar/test1 /home/rockstar/test11 /home/rockstar/test362 !!! Note Always surround words containing meta-characters with `\"` to prevent them from being replaced by the names of files that meet the criteria. !!! Warning Do not confuse shell meta-characters with regular expression meta-characters. The `grep` command uses regular expression meta-characters. Redirects and pipes Standard input and output On UNIX and Linux systems, there are three standard streams. They allow programs, via the stdio.h library, to input or output information. These streams are called X channel or X file descriptor. By default: the keyboard is the input device for channel 0, called stdin ; the screen is the output device for channels 1 and 2, called stdout and stderr . stderr receives the error streams returned by a command. The other streams are directed to stdout . These streams point to peripheral files, but since everything is a file in UNIX/Linux, I/O streams can easily be diverted to other files. This principle is the strength of the shell. Input redirection It is possible to redirect the input stream from another file with the character < or << . The command will read the file instead of the keyboard: $ ftp -in serverftp << ftp-commands.txt !!! Note Only commands that require keyboard input will be able to handle input redirection. Input redirection can also be used to simulate user interactivity. The command will read the input stream until it encounters the defined keyword after the input redirection. This feature is used to script interactive commands: $ ftp -in serverftp << END user alice password put file bye END The keyword END can be replaced by any word. $ ftp -in serverftp << STOP user alice password put file bye STOP The shell exits the ftp command when it receives a line containing only the keyword. !!! Warning The ending keyword, here `END` or `STOP`, must be the only word on the line and must be at the beginning of the line. The standard input redirection is rarely used because most commands accept a filename as an argument. The command wc could be used like this: $ wc -l .bash_profile 27 .bash_profile # the number of lines is followed by the file name $ wc -l < .bash_profile 27 # returns only the number of lines Output redirection Standard output can be redirected to other files using the > or >> characters. The simple > redirection overwrites the contents of the output file: $ date +%F > date_file When the >> character is used, it indicates that the output result of the command is appended to the file content. $ date +%F >> date_file In both cases, the file is automatically created when it does not exist. The standard error output can also be redirected to another file. This time it will be necessary to specify the channel number (which can be omitted for channels 0 and 1): $ ls -R / 2> errors_file $ ls -R / 2>> errors_file Examples of redirection Redirection of 2 outputs to 2 files: $ ls -R / >> ok_file 2>> nok_file Redirection of the 2 outputs to a single file: $ ls -R / >> log_file 2>&1 Redirection of stderr to a \"bottomless pit\" ( /dev/null ): $ ls -R / 2>> /dev/null When both output streams are redirected, no information is displayed on the screen. To use both the output redirection and to keep the display, you will have to use the command tee . Pipes A pipe is a mechanism allowing you to link the standard output of a first command to the standard input of a second command. This communication is uni directional and is done with the | symbol. The pipe symbol | is obtained by pressing the SHIFT + | simultaneously. All data sent by the control on the left of the pipe through the standard output channel is sent to the standard input channel of the control on the right. The commands particularly used after a pipe are filters. Examples: Display only the beginning: $ ls -lia / | head Display only the end: $ ls -lia / | tail Sort the result: $ ls -lia / | sort Count the number of words / characters: $ ls -lia / | wc Search for a string in the result: $ ls -lia / | grep fichier Special points tee command The tee command is used to redirect the standard output of a command to a file while maintaining the screen display. It is combined with the | pipe to receive as input the output of the command to be redirected: $ ls -lia / | tee fic $ cat fic The -a option adds to the file instead of overwriting it. alias and unalias commands Using alias is a way to ask the shell to remember a particular command with its options and give it a name. For example: $ ll will replace the command: $ ls -l The alias command lists the aliases for the current session. Aliases are set by default on Linux distributions. Here, the aliases for a Rocky server: $ alias alias l.='ls -d .* --color=auto' alias ll='ls -l --color=auto' alias ls='ls --color=auto' alias vi='vim' alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' The aliases are only defined temporarily, for the time of the user session. For permanent use, they must be created in the: .bashrc file in the user's login directory; /etc/bashrc file for all users. !!! Warning Special care must be taken when using aliases which can be potentially dangerous! For example, an alias set up without the administrator's knowledge: ```bash alias cd='rm -Rf' ``` The unalias command allows you to delete aliases. To delete a single alias: $ unalias ll To delete all aliases: $ unalias -a To disable an alias temporarily, the combination is \\<alias name> . For example if we do: $ type ls it might return the following: ls is an alias to \u00ab ls -rt \u00bb Now that this is known, we can see the results of using the alias or disabling it one time with the \\ by executing the following: $ ls file* # order by time file3.txt file2.txt file1.txt $ \\ls file* # order by name file1.txt file2.txt file3.txt Aliases and useful functions grep alias. Colorize the result of the grep command: alias grep='grep --color=auto' mcd function It is common to create a folder and then move around in it: mcd() { mkdir -p \"$1\"; cd \"$1\"; } cls function Move to a folder and list its contents: cls() { cd \"$1\"; ls; } backup function Create a backup copy of a file: backup() { cp \"$1\"{,.bak}; } extract function Extract any type of archive: extract () { if [ -f $1 ] ; then case $1 in *.tar.bz2) tar xjf $1 ;; *.tar.gz) tar xzf $1 ;; *.bz2) bunzip2 $1 ;; *.rar) unrar e $1 ;; *.gz) gunzip $1 ;; *.tar) tar xf $1 ;; *.tbz2) tar xjf $1 ;; *.tgz) tar xzf $1 ;; *.zip) unzip $1 ;; *.Z) uncompress $1 ;; *.7z) 7z x $1 ;; *) echo \"'$1' cannot be extracted via extract()\" ;; esac else echo \"'$1' is not a valid file\" fi } If alias cmount returns the following: alias cmount=\"mount | column -t\" Then we can use cmount to show all of the system mounts in columns like this: [root]# cmount which would return our mounted filesystem in the following format: /dev/simfs on / type simfs (rw,relatime,usrquota,grpquota) proc on /proc type proc (rw,relatime) sysfs on /sys type sysfs (rw,relatime) none on /dev type devtmpfs (rw,relatime,mode=755) none on /dev/pts type devpts (rw,relatime,mode=600,ptmxmode=000) none on /dev/shm type tmpfs (rw,relatime) none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw,relatime) The character ; The ; character strings the commands. The commands will all run sequentially in the order of input once the user presses ENTER . $ ls /; cd /home; ls -lia; cd / Check your Knowledge :heavy_check_mark: What defines a user under Linux? (7 answers) :heavy_check_mark: What characterizes a long option for a command? :heavy_check_mark: Which commands allow you to search for help on a command? [ ] google [ ] chuck --norris [ ] info [ ] apropos [ ] whatis :heavy_check_mark: Which command allows you to view a user's history? :heavy_check_mark: Which command allows you to search for text in a file? [ ] find [ ] grep :heavy_check_mark: Which command allows you to search for a file? [ ] find [ ] grep :heavy_check_mark: Which command redirects the error stream of a command to a new errors.log file? [ ] ls -R / 2> errors.log [ ] ls -R / 2>> errors.log [ ] ls -R / 2> errors.log 2>&1","title":"Linux Commands"},{"location":"books/admin_guide/03-commands/#commands-for-linux-users","text":"In this chapter you will learn how to work with Linux with the commands. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: move in the system tree; :heavy_check_mark: create a text file, display its contents and modify it; :heavy_check_mark: use the most useful Linux commands. :checkered_flag: user commands , linux Knowledge : :star: Complexity : :star: Reading time : 40 minutes","title":"Commands for Linux Users"},{"location":"books/admin_guide/03-commands/#generalities","text":"Current Linux systems have graphical utilities dedicated to the work of an administrator. However, it is important to be able to use the interface in command line mode for several reasons: The majority of system commands are common to all Linux distributions, which is not the case for graphical tools. It can happen that the system does not start correctly but that a backup command interpreter remains accessible. Remote administration is done on the command line with an SSH terminal. In order to preserve server resources, the graphical interface is either not installed or launched on demand. Administration is done by scripts. Learning these commands allows the administrator to connect to a Linux terminal, to manage its resources, its files, to identify the station, the terminal, and the connected users, etc.","title":"Generalities"},{"location":"books/admin_guide/03-commands/#the-users","text":"The user of a Linux system is defined in the /etc/passwd file, by: a login name , more commonly called \"login\", containing no spaces; a numeric identifier : UID (User Identifier); a group identifier : GID (Group Identifier); a command interpreter , a shell, which can be different from one user to another; a connection directory , the home directory . In other files by: a password , which will be encrypted before being stored ( /etc/shadow ); a command prompt , or prompt login, which will be symbolized by a # for administrators and a $ for other users ( /etc/profile ). Depending on the security policy implemented on the system, the password will have to contain a certain number of characters and meet certain complexity requirements. Among the existing command interpreters, the Bourne-Again Shell ( /bin/bash ) is the one most frequently used. It is assigned by default to new users. For various reasons, advanced Linux users can choose alternative shells from among the Korn Shell ( ksh ), the C Shell ( csh ), etc. The user's login directory is by convention stored in the /home directory of the workstation. It will contain the user's personal data and the configuration files of his applications. By default, at login, the login directory is selected as the current directory. A workstation type installation (with graphical interface) starts this interface on terminal 1. Linux being multi-user, it is possible to connect several users several times, on different physical terminals (TTY) or virtual terminals (PTS). Virtual terminals are available within a graphical environment. A user switches from one physical terminal to another using Alt + Fx from the command line or using CTRL + Alt + Fx .","title":"The users"},{"location":"books/admin_guide/03-commands/#the-shell","text":"Once the user is connected to a console, the shell displays the command prompt . It then behaves like an infinite loop, with each statement entered: displaying the command prompt; reading the command ; syntax analysis ; substitution of special characters ; execute the command; display the command prompt; etc. The key sequence CTRL + C is used to interrupt a running command. The use of a command generally follows this sequence: command [option(s)] [arguments(s)] The name of the command is often in lower case . A space separates each item. Short options begin with a dash ( -l ), while long options begin with two dashes ( --list ). A double dash ( -- ) indicates the end of the option list. It is possible to group some short options together: $ ls -l -i -a is equivalent to: $ ls -lia There can of course be several arguments after an option: $ ls -lia /etc /home /var In the literature, the term \"option\" is equivalent to the term \"parameter,\" which is more commonly used in programming. The optional side of an option or argument is symbolized by enclosing it in square brackets [ and ] . When more than one option is possible, a vertical bar called a \"pipe\" separates them [a|e|i] .","title":"The shell"},{"location":"books/admin_guide/03-commands/#general-commands","text":"","title":"General commands"},{"location":"books/admin_guide/03-commands/#apropos-whatis-and-man-commands","text":"It is impossible for an administrator at any level to know all the commands and options in detail. A manual is usually available for all installed commands.","title":"apropos, whatis and man commands"},{"location":"books/admin_guide/03-commands/#apropos-command","text":"The command apropos allows you to search by keyword within these manual pages: Options Description -s , --sections list or --section list Limited to manual sections. -a or --and Displays only the item matching all the provided keywords. Example: $ apropos clear clear (1) - clear the terminal screen clear_console (1) - clear the console clearenv (3) - clear the environment clearerr (3) - check and reset stream status clearerr_unlocked (3) - nonlocking stdio functions feclearexcept (3) - floating-point rounding and exception handling fwup_clear_status (3) - library to support management of system firmware updates klogctl (3) - read and/or clear kernel message ring buffer; set console_loglevel sgt-samegame (6) - Block-clearing puzzle syslog (2) - read and/or clear kernel message ring buffer; set console_loglevel timerclear (3) - timeval operations XClearArea (3) - clear area or window XClearWindow (3) - clear area or window XSelectionClearEvent (3) - SelectionClear event structure To find the command that will allow changing the password of an account: $ apropos --exact password -a change chage (1) - change user password expiry information passwd (1) - change user password","title":"apropos command"},{"location":"books/admin_guide/03-commands/#whatis-command","text":"The whatis command displays the description of the command passed as argument: whatis clear Example: $ whatis clear clear (1) - clear the terminal screen","title":"whatis command"},{"location":"books/admin_guide/03-commands/#man-command","text":"Once found by apropos or whatis , the manual is read by man (\"Man is your friend\"). This set of manuals is divided into 8 sections, grouping information by topic, the default section being 1: Executable programs or commands; System calls (functions given by the kernel); Library calls (functions given by the library); Special files (usually found in /dev); File Formats and conventions (configuration files such as etc/passwd); Games (such as character-based applications); Miscellaneous (e.g. man (7)); System administration commands (usually only for root); Kernel routines (non-standard). Information about each section can be accessed by typing man x intro , where x is the section number. The command: man passwd will tell the administrator about the passwd command, its options, etc. While a: $ man 5 passwd will inform him about the files related to the command. Not all manual pages are translated from English. However, English manual pages are usually very accurate and provide all the information you need. The grammar and separation rules it uses may confuse beginner administrators, but after practice, I'm sure you'll find the information you want. The navigation in the manual is done with the arrows \u2191 and \u2193 . The manual is exited by pressing the q key.","title":"man command"},{"location":"books/admin_guide/03-commands/#shutdown-command","text":"The shutdown command allows you to electrically shut down a Linux server, either immediately or after a certain period of time. shutdown [-h] [-r] time [message] The shutdown time should be specified in the format hh:mm for a precise time, or +mm for a delay in minutes. To force an immediate stop, the word now will replace the time. In this case, the optional message is not sent to other users of the system. Examples: [root]# shutdown -h 0:30 \"Server shutdown at 0:30\" [root]# shutdown -r +5 Options: Options Remarks -h Shutdown the system electrically -r Restarts the system","title":"shutdown command"},{"location":"books/admin_guide/03-commands/#history-command","text":"The history command displays the history of commands that have been entered by the user. The commands are stored in the .bash_history file in the user's login directory. Example of a history command $ history 147 man ls 148 man history Options Comments -w Write the current history to the history file -c The -c option will delete the history of the current session (but not the contents of the .bash_history file). Manipulating history: To manipulate the history, the following commands entered from the command prompt will: Keys Function !! Recall the last command placed. !n Recall the command by its number in the list. !string Recall the most recent command beginning with the string. \u2191 Recall the most recent command beginning with the string. \u2193 Recall the most recent command beginning with the string.","title":"history command"},{"location":"books/admin_guide/03-commands/#the-auto-completion","text":"Auto-completion is also a great help. It allows you to complete commands, entered paths, or file names. A press of the TAB key completes the entry in the case of a single solution. Otherwise, a second press will be required to obtain the list of possibilities. If a double press of the TAB key causes no reaction from the system, then there is no solution to the current completion.","title":"The auto-completion"},{"location":"books/admin_guide/03-commands/#display-and-identification","text":"","title":"Display and identification"},{"location":"books/admin_guide/03-commands/#clear-command","text":"The clear command clears the contents of the terminal screen. In fact, to be more precise, it shifts the display so that the command prompt is at the top of the screen on the first line. In a terminal, the display will be permanently hidden, whereas in a graphical interface, a scrollbar will allow you to go back in the history of the virtual terminal. !!! Tip <kbd>CTRL</kbd> + <kbd>L</kbd> will have the same effect as the `clear` command","title":"clear command"},{"location":"books/admin_guide/03-commands/#echo-command","text":"The echo command is used to display a string of characters. This command is most commonly used in administration scripts to inform the user during execution. The -n option indicates no newline output string (by default, newline output string). shell > echo -n \"123\";echo \"456\" 123456 shell > echo \"123\";echo \"456\" 123 456 For various reasons, the script developer may need to use special sequences (starting with a \\ character). In this case, the -e option will be stipulated, allowing interpretation of the sequences. Among the frequently used sequences, we can mention: Sequence Result \\a Send a sonor bip \\b Back \\n Adds a line break \\t Adds a horizontal tab \\v Adds vertical tab","title":"echo command"},{"location":"books/admin_guide/03-commands/#date-command","text":"The date command displays the date and time. The command has the following syntax: date [-d AAAAMMJJ] [format] Examples: $ date Mon May 24 16:46:53 CEST 2021 $ date -d 20210517 +%j 137 In this last example, the -d option displays a given date. The +%j option formats this date to show only the day of the year. !!! Warning The format of a date can change depending on the value of the language defined in the environment variable `$LANG`. The date display can follow the following formats: Option Format +%A Locale's full weekday name (e.g., Sunday) +%B Locale's full month name (e.g., January) +%c Locale's date and time (e.g., Thu Mar 3 23:05:25 2005) +%d Day of month (e.g., 01) +%F Date in YYYY-MM-DD format +%G Year +%H Hour (00..23) +%j Day of the year (001..366) +%m Month number (01..12) +%M Minute (00..59) +%R Time in hh:mm format +%s Seconds since January 1, 1970 +%S Second (00..60) +%T Time in hh:mm:ss format +%u Day of the week ( 1 for Monday) +%V Week number ( +%V ) +%x Date in format DD/MM/YYYY The date command also allows you to change the system date and time. In this case, the -s option will be used. [root]# date -s \"2021-05-24 10:19\" The format to be used following the -s option is this: date -s \"[AA]AA-MM-JJ hh:mm:[ss]\"","title":"date command"},{"location":"books/admin_guide/03-commands/#id-who-and-whoami-commands","text":"The id command is used to display information about users and groups. By default, no user parameter is added, and the information of the currently logged in user and group is displayed\u3002 $ id rockstar uid=1000(rockstar) gid=1000(rockstar) groups=1000(rockstar),10(wheel) The -g , -G , -n and -u options display the main group GID, subgroup GIDs, names instead of numeric identifiers, and the user's UID respectively. The whoami command displays the login of the current user. The who command alone displays the names of logged in users: $ who rockstar tty1 2021-05-24 10:30 root pts/0 2021-05-24 10:31 Since Linux is multi-user, it is likely that multiple sessions are open on the same station, either physically or over the network. It is interesting to know which users are logged in, if only to communicate with them by sending messages. tty: represents a terminal. pts/: represents a virtual console in a graphical environment with the number after representing the instance of the virtual console (0, 1, 2...) The -r option also displays the runlevel (see chapter \"startup\").","title":"id, who and whoami commands"},{"location":"books/admin_guide/03-commands/#file-tree","text":"In Linux, the file tree is an inverted tree, called a single hierarchical tree , whose root is the directory / . The current directory is the directory where the user is located. The connection directory is the working directory associated with the user. The login directories are, by default, stored in the /home directory. When the user logs in, the current directory is the login directory. An absolute path references a file from the root by traversing the entire tree to the file level: /home/groupA/alice/file The relative path references that same file by traversing the entire tree from the current directory: ../alice/file In the above example, the \" .. \" refers to the parent directory of the current directory. A directory, even if it is empty, will necessarily contain at least two references : . : reference to itself. .. : reference to the parent directory of the current directory. A relative path can thus start with ./ or ../ . When the relative path refers to a subdirectory or file in the current directory, then the ./ is often omitted. Mentioning the first ./ in the tree will only really be required to run an executable file. Errors in paths can cause many problems: creating folders or files in the wrong places, unintentional deletions, etc. It is therefore strongly recommended to use auto-completion when entering paths. In the above example, we are looking to give the location of the file myfile from the directory of bob. By an absolute path , the current directory does not matter. We start at the root, and work our way down to the directories home , groupA , alice and finally the file myfile : /home/groupA/alice/myfile . By a relative path , our starting point being the current directory bob , we go up one level through .. (i.e., into the groupA directory), then down into the alice directory, and finally the myfile file: ../alice/myfile .","title":"File tree"},{"location":"books/admin_guide/03-commands/#pwd-command","text":"The pwd (Print Working Directory) command displays the absolute path of the current directory. $ pwd /home/rockstar Use a relative path to reference a file or directory, or use the cd command to move to another directory, You must know its location in the file tree. Depending on the type of shell and the different parameters of its configuration file, the terminal prompt (also known as the command prompt) will display the absolute or relative path of the current directory.","title":"pwd command"},{"location":"books/admin_guide/03-commands/#cd-command","text":"The cd (Change Directory) command allows you to change the current directory, in other words, to move through the tree. $ cd /tmp $ pwd /tmp $ cd ../ $ pwd / $ cd $ pwd /home/rockstar As you can see in the last example above, the command cd with no arguments moves the current directory to the home directory .","title":"cd command"},{"location":"books/admin_guide/03-commands/#ls-command","text":"The ls command displays the contents of a directory. ls [-a] [-i] [-l] [directory1] [directory2] [\u2026] Example: $ ls /home . .. rockstar The main options of the ls command are: Option Information -a Displays all files, even hidden ones. Hidden files in Linux are those beginning with . . -i Displays inode numbers. -l The -l command displays a vertical list of files with additional information formatted in columns. The ls command, however, has a lot of options (see man ): Option Information -d Displays information about a directory instead of listing its contents. -g Displays UID and GID rather than owner names. -h Displays file sizes in the most appropriate format (byte, kilobyte, megabyte, gigabyte, ...). h stands for Human Readable. -s Displays the number of blocks occupied by the file. One block equals 400K. -A Displays all files in the directory except . and .. -R Displays the contents of subdirectories recursively. -F Displays the type of files. Prints a / for a directory, * for executables, @ for a symbolic link, and nothing for a text file. -X Sort files according to their extensions. Description of columns: $ ls -lia /home 78489 drwx------ 4 rockstar rockstar 4096 25 oct. 08:10 rockstar Value Information 78489 Inode Number. drwx------ File type ( d ) and rights ( rwx------ ). 4 Number of subdirectories ( . and .. included). For a file, it represents the number of hard links, and 1 represents itself. rockstar User ownership. rockstar Group ownership. 4096 For files, it shows the size of the file. For directories, it shows the fixed value of 4096 bytes occupied by the file naming. To calculate the total size of a directory, use du -sh rockstar/ 25 oct. 08:10 Last modified date. rockstar The name of the file (or directory). !!! Note **Aliases** are frequently positioned in common distributions. This is the case of the alias `ll`: ``` alias ll='ls -l --color=auto' ``` The ls command has many options and here are some advanced examples of uses: List the files in /etc in order of last modification: $ ls -ltr /etc total 1332 -rw-r--r--. 1 root root 662 29 may 2021 logrotate.conf -rw-r--r--. 1 root root 272 17 may. 2021 mailcap -rw-------. 1 root root 122 12 may. 2021 securetty ... -rw-r--r--. 2 root root 85 18 may. 17:04 resolv.conf -rw-r--r--. 1 root root 44 18 may. 17:04 adjtime -rw-r--r--. 1 root root 283 18 may. 17:05 mtab List /var files larger than 1 megabyte but less than 1 gigabyte: $ ls -lhR /var | grep \\- | grep [1-9]*M ... -rw-r--r--. 1 apache apache 1.2M 10 may. 13:02 XB RiyazBdIt.ttf -rw-r--r--. 1 apache apache 1.2M 10 may. 13:02 XB RiyazBd.ttf -rw-r--r--. 1 apache apache 1.1M 10 may. 13:02 XB RiyazIt.ttf ... Of course, we highly recommend that you use the find command. $ find /var -size +1M -a -size -1024M -a -type f -exec ls -lh {} \\; Show the rights on a folder: To find out the rights to a folder, in our example /etc , the following command would not be appropriate: $ ls -l /etc total 1332 -rw-r--r--. 1 root root 44 18 nov. 17:04 adjtime -rw-r--r--. 1 root root 1512 12 janv. 2010 aliases -rw-r--r--. 1 root root 12288 17 nov. 17:41 aliases.db drwxr-xr-x. 2 root root 4096 17 nov. 17:48 alternatives ... The above command will display the contents of the folder (inside) by default. For the folder itself, you can use the -d option. $ ls -ld /etc drwxr-xr-x. 69 root root 4096 18 nov. 17:05 /etc Sort by file size, largest first: $ ls -lhS time/date format with -l : $ ls -l --time-style=\"+%Y-%m-%d %m-%d %H:%M\" / total 12378 dr-xr-xr-x. 2 root root 4096 2014-11-23 11-23 03:13 bin dr-xr-xr-x. 5 root root 1024 2014-11-23 11-23 05:29 boot Add the trailing slash to the end of folders: By default, the ls command does not display the last slash of a folder. In some cases, like for scripts for example, it is useful to display them: $ ls -dF /etc /etc/ Hide some extensions: $ ls /etc --hide=*.conf","title":"ls command"},{"location":"books/admin_guide/03-commands/#mkdir-command","text":"The mkdir command creates a directory or directory tree. mkdir [-p] directory [directory] [...] Example: $ mkdir /home/rockstar/work The \"rockstar\" directory must exist to create the \"work\" directory. Otherwise, the -p option should be used. The -p option creates the parent directories if they do not exist. !!! Danger It is not recommended to use Linux command names as directory or file names.","title":"mkdir command"},{"location":"books/admin_guide/03-commands/#touch-command","text":"The touch command changes the timestamp of a file or creates an empty file if the file does not exist. touch [-t date] file Example: $ touch /home/rockstar/myfile Option Information -t date Changes the date of last modification of the file with the specified date. Date format: [AAAA]MMJJhhmm[ss] !!! Tip The `touch` command is primarily used to create an empty file, but it can be useful for incremental or differential backups for example. Indeed, the only effect of executing a `touch` on a file will be to force it to be saved during the next backup.","title":"touch command"},{"location":"books/admin_guide/03-commands/#rmdir-command","text":"The rmdir command deletes an empty directory. Example: $ rmdir /home/rockstar/work Option Information -p Removes the parent directory or directories provided if they are empty. !!! Tip To delete both a non-empty directory and its contents, use the `rm` command.","title":"rmdir command"},{"location":"books/admin_guide/03-commands/#rm-command","text":"The rm command deletes a file or directory. rm [-f] [-r] file [file] [...] !!! Danger Any deletion of a file or directory is final. Options Information -f Do not ask whether to delete. -i Ask whether to delete. -r Delete a directory and recursively delete its subdirectories. !!! Note The `rm` command itself does not ask for confirmation when deleting files. However, with a RedHat/Rocky distribution, `rm` does ask for confirmation of deletion because the `rm` command is an `alias` of the `rm -i` command. Don't be surprised if on another distribution, like Debian for example, you don't get a confirmation request. Deleting a folder with the rm command, whether the folder is empty or not, will require the -r option to be added. The end of the options is signaled to the shell by a double dash -- . In the example: $ >-hard-hard # To create an empty file called -hard-hard hard-hard [CTRL+C] To interrupt the creation of the file $ rm -f -- -hard-hard The hard-hard file name starts with a - . Without the use of the -- the shell would have interpreted the -d in -hard-hard as an option.","title":"rm command"},{"location":"books/admin_guide/03-commands/#mv-command","text":"The mv command moves and renames a file. mv file [file ...] destination Examples: $ mv /home/rockstar/file1 /home/rockstar/file2 $ mv /home/rockstar/file1 /home/rockstar/file2 /tmp Options Information -f Don't ask for confirmation if overwriting the destination file. -i Request confirmation if overwriting destination file (default). A few concrete cases will help you understand the difficulties that can arise: $ mv /home/rockstar/file1 /home/rockstar/file2 Renames file1 to file2 . If file2 already exists, replace the contents of the file with file1 . $ mv /home/rockstar/file1 /home/rockstar/file2 /tmp Moves file1 and file2 into the /tmp directory. $ mv file1 /repexist/file2 Moves file1 into repexist and renames it file2 . $ mv file1 file2 file1 is renamed to file2 . $ mv file1 /repexist If the destination directory exists, file1 is moved to /repexist . $ mv file1 /wrongrep If the destination directory does not exist, file1 is renamed to wrongrep in the root directory.","title":"mv command"},{"location":"books/admin_guide/03-commands/#cp-command","text":"The cp command copies a file. cp file [file ...] destination Example: $ cp -r /home/rockstar /tmp Options Information -i Request confirmation if overwriting (default). -f Do not ask for confirmation if overwriting the destination file. -p Keeps the owner, permissions and timestamp of the copied file. -r Copies a directory with its files and subdirectories. -s Creates a symbolik links rather than copying. cp file1 /repexist/file2 file1 is copied to /repexist under the name file2 . $ cp file1 file2 file1 is copied as file2 to this directory. $ cp file1 /repexist If the destination directory exists, file1 is copied to /repexist . $ cp file1 /wrongrep If the destination directory does not exist, file1 is copied under the name wrongrep to the root directory.","title":"cp command"},{"location":"books/admin_guide/03-commands/#visualization","text":"","title":"Visualization"},{"location":"books/admin_guide/03-commands/#file-command","text":"The file command displays the type of a file. file file1 [files] Example: $ file /etc/passwd /etc /etc/passwd: ASCII text /etc: directory","title":"file command"},{"location":"books/admin_guide/03-commands/#more-command","text":"The more command displays the contents of one or more files screen by screen. more file1 [files] Example: $ more /etc/passwd root:x:0:0:root:/root:/bin/bash ... Using the ENTER key, the move is line by line. Using the SPACE key, the move is page by page. /text allows you to search for the occurrence in the file.","title":"more command"},{"location":"books/admin_guide/03-commands/#less-command","text":"The less command displays the contents of one or more files. The less command is interactive and has its own commands for use. less file1 [files] The commands specific to less are: Command Action h Help. \u2191 \u2193 \u2192 \u2190 Move up, down a line, or to the right or left. Enter Move down one line. Space Move down one page. PgUp and PgDn Move up or down one page. gg and G Move to the first and last pages /text Search for text. q Quit the less command.","title":"less command"},{"location":"books/admin_guide/03-commands/#cat-command","text":"The cat command concatenates the contents of multiple files and displays the result on the standard output. cat file1 [files] Example 1 - Displaying the contents of a file to the standard output: $ cat /etc/passwd Example 2 - Displaying the contents of multiple files to standard output: $ cat /etc/passwd /etc/group Example 3 - Combining the contents of multiple files into one file using output redirection: $ cat /etc/passwd /etc/group > usersAndGroups.txt Example 4 - Displaying the line numbering: $ cat -n /etc/profile 1 # /etc/profile: system-wide .profile file for the Bourne shell (sh(1)) 2 # and Bourne compatible shells (bash(1), ksh(1), ash(1), ...). 3 4 if [ \"`id -u`\" -eq 0 ]; then 5 PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" 6 else \u2026 Example 5 - Shows the numbering of non-empty lines: $ cat -b /etc/profile 1 # /etc/profile: system-wide .profile file for the Bourne shell (sh(1)) 2 # and Bourne compatible shells (bash(1), ksh(1), ash(1), ...). 3 if [ \"`id -u`\" -eq 0 ]; then 4 PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" 5 else \u2026","title":"cat command"},{"location":"books/admin_guide/03-commands/#tac-command","text":"The tac command does almost the opposite of the cat command. It displays the contents of a file starting from the end (which is particularly interesting for reading logs!). Example: Display a log file by displaying the last line first: [root]# tac /var/log/messages | less","title":"tac command"},{"location":"books/admin_guide/03-commands/#head-command","text":"The head command displays the beginning of a file. head [-n x] file Option Description -n x Display the first x lines of the file By default (without the -n option), the head command will display the first 10 lines of the file.","title":"head command"},{"location":"books/admin_guide/03-commands/#tail-command","text":"The tail command displays the end of a file. tail [-f] [-n x] file Option Description -n x Displays the last x lines of the file -f Displays changes to the file in real time Example: tail -n 3 /etc/passwd sshd:x:74:74:Privilege-separeted sshd:/var/empty /sshd:/sbin/nologin tcpdump::x:72:72::/:/sbin/nologin user1:x:500:500:grp1:/home/user1:/bin/bash With the -f option, the change information of the file will always be output unless the user exits the monitoring state with CTRL + C . This option is very frequently used to track log files (the logs) in real time. Without the -n option, the tail command displays the last 10 lines of the file.","title":"tail command"},{"location":"books/admin_guide/03-commands/#sort-command","text":"The sort command sorts the lines of a file. It allows you to order the result of a command or the content of a file in a given order, numerically, alphabetically, by size (KB, MB, GB) or in reverse order. sort [-k] [-n] [-u] [-o file] [-t] file Example: $ sort -k 3,4 -t \":\" -n /etc/passwd root:x:0:0:root:/root:/bin/bash adm:x:3:4:adm:/var/adm/:/sbin/nologin Option Description -k Specify the columns to be separated. You can specify multiple columns -n Requests a numeric sort -o file Saves the sort to the specified file -t Specify a delimiter, which requires that the contents of the corresponding file must be regularly delimited column contents, otherwise they cannot be sorted properly -r Reverse the order of the result. Used in conjunction with the -n option to sort in order from largest to smallest -u Remove duplicates after sorting. Equivalent to sort file | uniq The sort command sorts the file only on the screen. The file is not modified by the sorting. To save the sort, use the -o option or an output redirection > . By default, the numbers are sorted according to their character. Thus, \"110\" will be before \"20\", which will itself be before \"3\". The -n option must be specified so that the numeric character blocks are sorted by their value. The sort command reverses the order of the results, with the -r option: $ sort -k 3 -t \":\" -n -r /etc/passwd nobody:x:65534:65534:Kernel Overflow User:/:/sbin/nologin systemd-coredump:x:999:997:systemd Core Dumper:/:/sbin/nologin polkitd:x:998:996:User for polkitd:/:/sbin/nologin In this example, the sort command will sort the contents of the /etc/passwd file this time from largest uid to smallest. Some advanced examples of using the sort command: Shuffling values The sort command also allows you to shuffle values with the -R option: $ sort -R /etc/passwd Sorting IP addresses A system administrator is quickly confronted with the processing of IP addresses from the logs of his services such as SMTP, VSFTP or Apache. These addresses are typically extracted with the cut command. Here is an example with the file dns-client.txt : 192.168.1.10 192.168.1.200 5.1.150.146 208.128.150.98 208.128.150.99 $ sort -nr dns-client.txt 208.128.150.99 208.128.150.98 192.168.1.200 192.168.1.10 5.1.150.146 Sorting file by removing duplicates The sort command knows how to remove the duplicates from the file output using -u as option. Here is an example with the file colours.txt : Red Green Blue Red Pink $ sort -u colours.txt Blue Green Pink Red Sorting file by sizes The sort command knows how to recognize file sizes, from commands like ls with the -h option. Here is an example with the file size.txt : 1,7G 18M 69K 2,4M 1,2M 4,2G 6M 124M 12,4M 4G $ sort -hr size.txt 4,2G 4G 1,7G 124M 18M 12,4M 6M 2,4M 1,2M 69K","title":"sort command"},{"location":"books/admin_guide/03-commands/#wc-command","text":"The wc command counts the number of lines, words and/or bytes in a file. wc [-l] [-m] [-w] file [files] Option Description -c Count the number of bytes. -m Count the number of characters. -l Counts the number of lines. -w Counts the number of words.","title":"wc command"},{"location":"books/admin_guide/03-commands/#search","text":"","title":"Search"},{"location":"books/admin_guide/03-commands/#find-command","text":"The find command searches for files or directories location. find directory [-name name] [-type type] [-user login] [-date date] Since there are so many options to the find command, it is best to refer to the man . If the search directory is not specified, the find command will search from the current directory. Option Description -perm permissions Search for files by their permissions. -size size Search for files by size.","title":"find command"},{"location":"books/admin_guide/03-commands/#-exec-option-of-the-find-command","text":"It is possible to use the -exec option of the find command to execute a command on each result line: $ find /tmp -name *.txt -exec rm -f {} \\; The previous command searches for all files in the /tmp directory named *.txt and deletes them. !!! Tip \"Understand the -exec option\" In the example above, the `find` command will construct a string representing the command to be executed. If the `find` command finds three files named `log1.txt`, `log2.txt`, and `log3.txt`, then the `find` command will construct the string by replacing in the string `rm -f {} \\;` the braces with one of the results of the search, and do this as many times as there are results. This will give us: ``` rm -f /tmp/log1.txt ; rm -f /tmp/log2.txt ; rm -f /tmp/log3.txt ; ``` The `;` character is a special shell character that must be protected by a `\\` to prevent it from being interpreted too early by the `find` command (and not in the `-exec`). !!! Tip `$ find /tmp -name *.txt -delete` does the same thing.","title":"-exec option of the find command"},{"location":"books/admin_guide/03-commands/#whereis-command","text":"The whereis command searches for files related to a command. whereis [-b] [-m] [-s] command Example: $ whereis -b ls ls: /bin/ls Option Description -b Search only the binary file. -m Searches only for man pages. -s Searches only for source files.","title":"whereis command"},{"location":"books/admin_guide/03-commands/#grep-command","text":"The grep command searches for a string in a file. grep [-w] [-i] [-v] \"string\" file Example: $ grep -w \"root:\" /etc/passwd root:x:0:0:root:/root:/bin/bash Option Description -i Ignore the case of the searched string. -v Excludes lines containing the string. -w Search for the exact word. The grep command returns the complete line containing the string you are looking for. * The ^ special character is used to search for a string at the beginning of a line. * The special character $ searches for a string at the end of a line. $ grep -w \"^root\" /etc/passwd !!! Note This command is very powerful and it is highly recommended to consult its manual. It has many derivatives. It is possible to search for a string in a file tree with the -R option. grep -R \"Virtual\" /etc/httpd","title":"grep command"},{"location":"books/admin_guide/03-commands/#meta-characters-wildcards","text":"Meta-characters replace one or more characters (or even an absence of characters) during a search. These meta-characters are also known as wildcards. They can be combined. The * character replaces a string composed of any characters. The * character can also represent an absence of character. $ find /home -name \"test*\" /home/rockstar/test /home/rockstar/test1 /home/rockstar/test11 /home/rockstar/tests /home/rockstar/test362 Meta-characters allow more complex searches by replacing all or part of a word. Simply replace the unknowns with these special characters. The character ? replaces a single character, whatever it is. $ find /home -name \"test?\" /home/rockstar/test1 /home/rockstar/tests The square brackets [ and ] are used to specify the values that a single character can take. $ find /home -name \"test[123]*\" /home/rockstar/test1 /home/rockstar/test11 /home/rockstar/test362 !!! Note Always surround words containing meta-characters with `\"` to prevent them from being replaced by the names of files that meet the criteria. !!! Warning Do not confuse shell meta-characters with regular expression meta-characters. The `grep` command uses regular expression meta-characters.","title":"Meta-characters (wildcards)"},{"location":"books/admin_guide/03-commands/#redirects-and-pipes","text":"","title":"Redirects and pipes"},{"location":"books/admin_guide/03-commands/#standard-input-and-output","text":"On UNIX and Linux systems, there are three standard streams. They allow programs, via the stdio.h library, to input or output information. These streams are called X channel or X file descriptor. By default: the keyboard is the input device for channel 0, called stdin ; the screen is the output device for channels 1 and 2, called stdout and stderr . stderr receives the error streams returned by a command. The other streams are directed to stdout . These streams point to peripheral files, but since everything is a file in UNIX/Linux, I/O streams can easily be diverted to other files. This principle is the strength of the shell.","title":"Standard input and output"},{"location":"books/admin_guide/03-commands/#input-redirection","text":"It is possible to redirect the input stream from another file with the character < or << . The command will read the file instead of the keyboard: $ ftp -in serverftp << ftp-commands.txt !!! Note Only commands that require keyboard input will be able to handle input redirection. Input redirection can also be used to simulate user interactivity. The command will read the input stream until it encounters the defined keyword after the input redirection. This feature is used to script interactive commands: $ ftp -in serverftp << END user alice password put file bye END The keyword END can be replaced by any word. $ ftp -in serverftp << STOP user alice password put file bye STOP The shell exits the ftp command when it receives a line containing only the keyword. !!! Warning The ending keyword, here `END` or `STOP`, must be the only word on the line and must be at the beginning of the line. The standard input redirection is rarely used because most commands accept a filename as an argument. The command wc could be used like this: $ wc -l .bash_profile 27 .bash_profile # the number of lines is followed by the file name $ wc -l < .bash_profile 27 # returns only the number of lines","title":"Input redirection"},{"location":"books/admin_guide/03-commands/#output-redirection","text":"Standard output can be redirected to other files using the > or >> characters. The simple > redirection overwrites the contents of the output file: $ date +%F > date_file When the >> character is used, it indicates that the output result of the command is appended to the file content. $ date +%F >> date_file In both cases, the file is automatically created when it does not exist. The standard error output can also be redirected to another file. This time it will be necessary to specify the channel number (which can be omitted for channels 0 and 1): $ ls -R / 2> errors_file $ ls -R / 2>> errors_file","title":"Output redirection"},{"location":"books/admin_guide/03-commands/#examples-of-redirection","text":"Redirection of 2 outputs to 2 files: $ ls -R / >> ok_file 2>> nok_file Redirection of the 2 outputs to a single file: $ ls -R / >> log_file 2>&1 Redirection of stderr to a \"bottomless pit\" ( /dev/null ): $ ls -R / 2>> /dev/null When both output streams are redirected, no information is displayed on the screen. To use both the output redirection and to keep the display, you will have to use the command tee .","title":"Examples of redirection"},{"location":"books/admin_guide/03-commands/#pipes","text":"A pipe is a mechanism allowing you to link the standard output of a first command to the standard input of a second command. This communication is uni directional and is done with the | symbol. The pipe symbol | is obtained by pressing the SHIFT + | simultaneously. All data sent by the control on the left of the pipe through the standard output channel is sent to the standard input channel of the control on the right. The commands particularly used after a pipe are filters. Examples: Display only the beginning: $ ls -lia / | head Display only the end: $ ls -lia / | tail Sort the result: $ ls -lia / | sort Count the number of words / characters: $ ls -lia / | wc Search for a string in the result: $ ls -lia / | grep fichier","title":"Pipes"},{"location":"books/admin_guide/03-commands/#special-points","text":"","title":"Special points"},{"location":"books/admin_guide/03-commands/#tee-command","text":"The tee command is used to redirect the standard output of a command to a file while maintaining the screen display. It is combined with the | pipe to receive as input the output of the command to be redirected: $ ls -lia / | tee fic $ cat fic The -a option adds to the file instead of overwriting it.","title":"tee command"},{"location":"books/admin_guide/03-commands/#alias-and-unalias-commands","text":"Using alias is a way to ask the shell to remember a particular command with its options and give it a name. For example: $ ll will replace the command: $ ls -l The alias command lists the aliases for the current session. Aliases are set by default on Linux distributions. Here, the aliases for a Rocky server: $ alias alias l.='ls -d .* --color=auto' alias ll='ls -l --color=auto' alias ls='ls --color=auto' alias vi='vim' alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' The aliases are only defined temporarily, for the time of the user session. For permanent use, they must be created in the: .bashrc file in the user's login directory; /etc/bashrc file for all users. !!! Warning Special care must be taken when using aliases which can be potentially dangerous! For example, an alias set up without the administrator's knowledge: ```bash alias cd='rm -Rf' ``` The unalias command allows you to delete aliases. To delete a single alias: $ unalias ll To delete all aliases: $ unalias -a To disable an alias temporarily, the combination is \\<alias name> . For example if we do: $ type ls it might return the following: ls is an alias to \u00ab ls -rt \u00bb Now that this is known, we can see the results of using the alias or disabling it one time with the \\ by executing the following: $ ls file* # order by time file3.txt file2.txt file1.txt $ \\ls file* # order by name file1.txt file2.txt file3.txt","title":"alias and unalias commands"},{"location":"books/admin_guide/03-commands/#aliases-and-useful-functions","text":"grep alias. Colorize the result of the grep command: alias grep='grep --color=auto' mcd function It is common to create a folder and then move around in it: mcd() { mkdir -p \"$1\"; cd \"$1\"; } cls function Move to a folder and list its contents: cls() { cd \"$1\"; ls; } backup function Create a backup copy of a file: backup() { cp \"$1\"{,.bak}; } extract function Extract any type of archive: extract () { if [ -f $1 ] ; then case $1 in *.tar.bz2) tar xjf $1 ;; *.tar.gz) tar xzf $1 ;; *.bz2) bunzip2 $1 ;; *.rar) unrar e $1 ;; *.gz) gunzip $1 ;; *.tar) tar xf $1 ;; *.tbz2) tar xjf $1 ;; *.tgz) tar xzf $1 ;; *.zip) unzip $1 ;; *.Z) uncompress $1 ;; *.7z) 7z x $1 ;; *) echo \"'$1' cannot be extracted via extract()\" ;; esac else echo \"'$1' is not a valid file\" fi } If alias cmount returns the following: alias cmount=\"mount | column -t\" Then we can use cmount to show all of the system mounts in columns like this: [root]# cmount which would return our mounted filesystem in the following format: /dev/simfs on / type simfs (rw,relatime,usrquota,grpquota) proc on /proc type proc (rw,relatime) sysfs on /sys type sysfs (rw,relatime) none on /dev type devtmpfs (rw,relatime,mode=755) none on /dev/pts type devpts (rw,relatime,mode=600,ptmxmode=000) none on /dev/shm type tmpfs (rw,relatime) none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw,relatime)","title":"Aliases and useful functions"},{"location":"books/admin_guide/03-commands/#the-character","text":"The ; character strings the commands. The commands will all run sequentially in the order of input once the user presses ENTER . $ ls /; cd /home; ls -lia; cd /","title":"The character ;"},{"location":"books/admin_guide/03-commands/#check-your-knowledge","text":":heavy_check_mark: What defines a user under Linux? (7 answers) :heavy_check_mark: What characterizes a long option for a command? :heavy_check_mark: Which commands allow you to search for help on a command? [ ] google [ ] chuck --norris [ ] info [ ] apropos [ ] whatis :heavy_check_mark: Which command allows you to view a user's history? :heavy_check_mark: Which command allows you to search for text in a file? [ ] find [ ] grep :heavy_check_mark: Which command allows you to search for a file? [ ] find [ ] grep :heavy_check_mark: Which command redirects the error stream of a command to a new errors.log file? [ ] ls -R / 2> errors.log [ ] ls -R / 2>> errors.log [ ] ls -R / 2> errors.log 2>&1","title":"Check your Knowledge"},{"location":"books/admin_guide/04-advanced-commands/","text":"Advanced Commands for Linux users In this chapter you will learn some advanced commands for Linux. Objectives : In this chapter, future Linux administrators will learn: :heavy_check_mark: some useful commands not covered in the previous chapter; :heavy_check_mark: some advanced commands. :checkered_flag: user commands , Linux Knowledge : :star: Complexity : :star: :star: :star: Reading time : 20 minutes uniq command The uniq command is a very powerful command, used with the sort command, especially for log file analysis. It allows you to sort and display entries by removing duplicates. To illustrate how the uniq command works, let's use a firstnames.txt file containing a list of first names: antoine xavier steven patrick xavier antoine antoine steven !!! Note `uniq` requires the input file to be sorted because it only compares consecutive lines. Without an argument, the uniq command will not display identical lines that follow each other in the firstnames.txt file: $ sort firstnames.txt | uniq antoine patrick steven xavier To display only the rows that appear only once, use the -u option: $ sort firstnames.txt | uniq -u patrick Conversely, to display only the lines that appear at least twice in the file, you must use the -d option: $ sort firstnames.txt | uniq -d antoine steven xavier To simply delete lines that appear only once, use the -D option: $ sort firstnames.txt | uniq -D antoine antoine antoine steven steven xavier xavier Finally, to count the number of occurrences of each line, use the -c option: $ sort firstnames.txt | uniq -c 3 antoine 1 patrick 2 steven 2 xavier $ sort firstnames.txt | uniq -cd 3 antoine 2 steven 2 xavier xargs commands The xargs command allows the construction and execution of command lines from standard input. The xargs command reads whitespace or linefeed delimited arguments from standard input, and executes the command ( /bin/echo by default) one or more times using the initial arguments followed by the arguments read from standard input. A first and simplest example would be the following: $ xargs use of xargs <CTRL+D> use of xargs The xargs command waits for an input from the standard stdin input. Three lines are entered. The end of the user input is specified to xargs by the keystroke sequence CTRL + D . xargs then executes the default command echo followed by the three arguments corresponding to the user input, namely : $ echo \"use\" \"of\" \"xargs\" use of xargs It is possible to specify a command to be run by xargs . In the following example, xargs will run the command ls -ld on the set of folders specified in the standard input: $ xargs ls -ld /home /tmp /root <CTRL+D> drwxr-xr-x. 9 root root 4096 5 avril 11:10 /home dr-xr-x---. 2 root root 4096 5 avril 15:52 /root drwxrwxrwt. 3 root root 4096 6 avril 10:25 /tmp In practice, the xargs command executed the ls -ld /home /tmp /root command. What happens if the command to be executed does not accept multiple arguments as is the case with the find command? $ xargs find /var/log -name *.old *.log find: paths must precede expression: *.log The xargs command attempted to execute the find command with multiple arguments behind the -name option, which caused find to generate an error: $ find /var/log -name \"*.old\" \"*.log\" find: paths must precede expression: *.log In this case, the xargs command must be forced to execute the find command several times (once per line entered as standard input). The -L option followed by an integer allows you to specify the maximum number of entries to be processed with the command at one time: $ xargs -L 1 find /var/log -name *.old /var/log/dmesg.old *.log /var/log/boot.log /var/log/anaconda.yum.log /var/log/anaconda.storage.log /var/log/anaconda.log /var/log/yum.log /var/log/audit/audit.log /var/log/anaconda.ifcfg.log /var/log/dracut.log /var/log/anaconda.program.log <CTRL+D> If we wanted to be able to specify both arguments on the same line, we would have to use the -n 1 option: $ xargs -n 1 find /var/log -name *.old *.log /var/log/dmesg.old /var/log/boot.log /var/log/anaconda.yum.log /var/log/anaconda.storage.log /var/log/anaconda.log /var/log/yum.log /var/log/audit/audit.log /var/log/anaconda.ifcfg.log /var/log/dracut.log /var/log/anaconda.program.log <CTRL+D> Case study of a backup with a tar based on a search: $ find /var/log/ -name \"*.log\" -mtime -1 | xargs tar cvfP /root/log.tar $ tar tvfP /root/log.tar -rw-r--r-- root/root 1720 2017-04-05 15:43 /var/log/boot.log -rw-r--r-- root/root 499270 2017-04-06 11:01 /var/log/audit/audit.log The special feature of the xargs command is that it places the input argument at the end of the called command. This works very well with the above example since the files passed in will form the list of files to be added to the archive. Now, if we take the example of the cp command and want to copy a list of files in a directory, this list of files will be added at the end of the command... but what the cp command expects at the end of the command is the destination. To do this, we use the -I option to put the input arguments somewhere else than at the end of the line. $ find /var/log -type f -name \"*.log\" | xargs -I % cp % /root/backup The -I option allows you to specify a character (in our example the % character) where the input files to xargs will be placed. yum-utils package The yum-utils package is a collection of utilities from different authors for yum , which make it easier and more powerful to use. !!! Note While `yum` has been replaced by `dnf` in Rocky Linux 8, the package name has remained `yum-utils` although it can be installed as `dnf-utils` as well. These are classic YUM utilities implemented as CLI shims on top of DNF to maintain backwards compatibility with `yum-3`. Here are some examples of usage: repoquery command: The repoquery command is used to query the packages in the repository. Examples of use: Display the dependencies of a package(it can be a software package that has been installed or not installed), Equivalent to dnf deplist <package-name> . repoquery --requires Display the files provided by an installed package(does not work for packages that are not installed), Equivalent to rpm -ql <package-name> $ repoquery -l yum-utils /etc/bash_completion.d /etc/bash_completion.d/yum-utils.bash /usr/bin/debuginfo-install /usr/bin/find-repos-of-install /usr/bin/needs-restarting /usr/bin/package-cleanup /usr/bin/repo-graph /usr/bin/repo-rss /usr/bin/repoclosure /usr/bin/repodiff /usr/bin/repomanage /usr/bin/repoquery /usr/bin/reposync /usr/bin/repotrack /usr/bin/show-changed-rco /usr/bin/show-installed /usr/bin/verifytree /usr/bin/yum-builddep /usr/bin/yum-config-manager /usr/bin/yum-debug-dump /usr/bin/yum-debug-restore /usr/bin/yum-groups-manager /usr/bin/yumdownloader \u2026 yumdownloader command: The yumdownloader command downloads RPM packages from the repositories. Equivalent to dnf download --downloadonly --downloaddir ./ package-name !!! Note This command is very useful to quickly build a local repository of a few rpms! Example: yumdownloader will download the samba rpm package and all its dependencies: $ yumdownloader --destdir /var/tmp --resolve samba or $ dnf download --downloadonly --downloaddir /var/tmp --resolve samba Options Comments - -destdir The downloaded packages will be stored in the specified folder. --resolve Also downloads the package dependencies. psmisc packages The psmisc package contains utilities for managing system processes: pstree : the pstree command displays the current processes on the system in a tree-like structure. killall : the killall command sends a kill signal to all processes identified by name. fuser : the fuser command identifies the PID of processes that use the specified files or file systems. Examples: $ pstree systemd\u2500\u252c\u2500NetworkManager\u2500\u2500\u25002*[{NetworkManager}] \u251c\u2500agetty \u251c\u2500auditd\u2500\u2500\u2500{auditd} \u251c\u2500crond \u251c\u2500dbus-daemon\u2500\u2500\u2500{dbus-daemon} \u251c\u2500firewalld\u2500\u2500\u2500{firewalld} \u251c\u2500lvmetad \u251c\u2500master\u2500\u252c\u2500pickup \u2502 \u2514\u2500qmgr \u251c\u2500polkitd\u2500\u2500\u25005*[{polkitd}] \u251c\u2500rsyslogd\u2500\u2500\u25002*[{rsyslogd}] \u251c\u2500sshd\u2500\u2500\u2500sshd\u2500\u2500\u2500bash\u2500\u2500\u2500pstree \u251c\u2500systemd-journal \u251c\u2500systemd-logind \u251c\u2500systemd-udevd \u2514\u2500tuned\u2500\u2500\u25004*[{tuned}] # killall httpd Kill processes (option -k ) that access the /etc/httpd/conf/httpd.conf file: # fuser -k /etc/httpd/conf/httpd.conf watch command The watch command regularly executes a command and displays the result in the terminal in full screen. The -n option allows you to specify the number of seconds between each execution of the command. !!! Note To exit the `watch` command, you must type the keys: <kbd>CTRL</kbd>+<kbd>C</kbd> to kill the process. Examples: Display the end of the /etc/passwd file every 5 seconds: $ watch -n 5 tail -n 3 /etc/passwd Result: Every 5,0s: tail -n 3 /etc/passwd rockstar.rockylinux.lan: Thu Jul 1 15:43:59 2021 sssd:x:996:993:User for sssd:/:/sbin/nologin chrony:x:995:992::/var/lib/chrony:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin Monitoring the number of files in a folder: $ watch -n 1 'ls -l | wc -l' Display a clock: $ watch -t -n 1 date","title":"Advanced Linux Commands"},{"location":"books/admin_guide/04-advanced-commands/#advanced-commands-for-linux-users","text":"In this chapter you will learn some advanced commands for Linux. Objectives : In this chapter, future Linux administrators will learn: :heavy_check_mark: some useful commands not covered in the previous chapter; :heavy_check_mark: some advanced commands. :checkered_flag: user commands , Linux Knowledge : :star: Complexity : :star: :star: :star: Reading time : 20 minutes","title":"Advanced Commands for Linux users"},{"location":"books/admin_guide/04-advanced-commands/#uniq-command","text":"The uniq command is a very powerful command, used with the sort command, especially for log file analysis. It allows you to sort and display entries by removing duplicates. To illustrate how the uniq command works, let's use a firstnames.txt file containing a list of first names: antoine xavier steven patrick xavier antoine antoine steven !!! Note `uniq` requires the input file to be sorted because it only compares consecutive lines. Without an argument, the uniq command will not display identical lines that follow each other in the firstnames.txt file: $ sort firstnames.txt | uniq antoine patrick steven xavier To display only the rows that appear only once, use the -u option: $ sort firstnames.txt | uniq -u patrick Conversely, to display only the lines that appear at least twice in the file, you must use the -d option: $ sort firstnames.txt | uniq -d antoine steven xavier To simply delete lines that appear only once, use the -D option: $ sort firstnames.txt | uniq -D antoine antoine antoine steven steven xavier xavier Finally, to count the number of occurrences of each line, use the -c option: $ sort firstnames.txt | uniq -c 3 antoine 1 patrick 2 steven 2 xavier $ sort firstnames.txt | uniq -cd 3 antoine 2 steven 2 xavier","title":"uniq command"},{"location":"books/admin_guide/04-advanced-commands/#xargs-commands","text":"The xargs command allows the construction and execution of command lines from standard input. The xargs command reads whitespace or linefeed delimited arguments from standard input, and executes the command ( /bin/echo by default) one or more times using the initial arguments followed by the arguments read from standard input. A first and simplest example would be the following: $ xargs use of xargs <CTRL+D> use of xargs The xargs command waits for an input from the standard stdin input. Three lines are entered. The end of the user input is specified to xargs by the keystroke sequence CTRL + D . xargs then executes the default command echo followed by the three arguments corresponding to the user input, namely : $ echo \"use\" \"of\" \"xargs\" use of xargs It is possible to specify a command to be run by xargs . In the following example, xargs will run the command ls -ld on the set of folders specified in the standard input: $ xargs ls -ld /home /tmp /root <CTRL+D> drwxr-xr-x. 9 root root 4096 5 avril 11:10 /home dr-xr-x---. 2 root root 4096 5 avril 15:52 /root drwxrwxrwt. 3 root root 4096 6 avril 10:25 /tmp In practice, the xargs command executed the ls -ld /home /tmp /root command. What happens if the command to be executed does not accept multiple arguments as is the case with the find command? $ xargs find /var/log -name *.old *.log find: paths must precede expression: *.log The xargs command attempted to execute the find command with multiple arguments behind the -name option, which caused find to generate an error: $ find /var/log -name \"*.old\" \"*.log\" find: paths must precede expression: *.log In this case, the xargs command must be forced to execute the find command several times (once per line entered as standard input). The -L option followed by an integer allows you to specify the maximum number of entries to be processed with the command at one time: $ xargs -L 1 find /var/log -name *.old /var/log/dmesg.old *.log /var/log/boot.log /var/log/anaconda.yum.log /var/log/anaconda.storage.log /var/log/anaconda.log /var/log/yum.log /var/log/audit/audit.log /var/log/anaconda.ifcfg.log /var/log/dracut.log /var/log/anaconda.program.log <CTRL+D> If we wanted to be able to specify both arguments on the same line, we would have to use the -n 1 option: $ xargs -n 1 find /var/log -name *.old *.log /var/log/dmesg.old /var/log/boot.log /var/log/anaconda.yum.log /var/log/anaconda.storage.log /var/log/anaconda.log /var/log/yum.log /var/log/audit/audit.log /var/log/anaconda.ifcfg.log /var/log/dracut.log /var/log/anaconda.program.log <CTRL+D> Case study of a backup with a tar based on a search: $ find /var/log/ -name \"*.log\" -mtime -1 | xargs tar cvfP /root/log.tar $ tar tvfP /root/log.tar -rw-r--r-- root/root 1720 2017-04-05 15:43 /var/log/boot.log -rw-r--r-- root/root 499270 2017-04-06 11:01 /var/log/audit/audit.log The special feature of the xargs command is that it places the input argument at the end of the called command. This works very well with the above example since the files passed in will form the list of files to be added to the archive. Now, if we take the example of the cp command and want to copy a list of files in a directory, this list of files will be added at the end of the command... but what the cp command expects at the end of the command is the destination. To do this, we use the -I option to put the input arguments somewhere else than at the end of the line. $ find /var/log -type f -name \"*.log\" | xargs -I % cp % /root/backup The -I option allows you to specify a character (in our example the % character) where the input files to xargs will be placed.","title":"xargs commands"},{"location":"books/admin_guide/04-advanced-commands/#yum-utils-package","text":"The yum-utils package is a collection of utilities from different authors for yum , which make it easier and more powerful to use. !!! Note While `yum` has been replaced by `dnf` in Rocky Linux 8, the package name has remained `yum-utils` although it can be installed as `dnf-utils` as well. These are classic YUM utilities implemented as CLI shims on top of DNF to maintain backwards compatibility with `yum-3`. Here are some examples of usage: repoquery command: The repoquery command is used to query the packages in the repository. Examples of use: Display the dependencies of a package(it can be a software package that has been installed or not installed), Equivalent to dnf deplist <package-name> . repoquery --requires Display the files provided by an installed package(does not work for packages that are not installed), Equivalent to rpm -ql <package-name> $ repoquery -l yum-utils /etc/bash_completion.d /etc/bash_completion.d/yum-utils.bash /usr/bin/debuginfo-install /usr/bin/find-repos-of-install /usr/bin/needs-restarting /usr/bin/package-cleanup /usr/bin/repo-graph /usr/bin/repo-rss /usr/bin/repoclosure /usr/bin/repodiff /usr/bin/repomanage /usr/bin/repoquery /usr/bin/reposync /usr/bin/repotrack /usr/bin/show-changed-rco /usr/bin/show-installed /usr/bin/verifytree /usr/bin/yum-builddep /usr/bin/yum-config-manager /usr/bin/yum-debug-dump /usr/bin/yum-debug-restore /usr/bin/yum-groups-manager /usr/bin/yumdownloader \u2026 yumdownloader command: The yumdownloader command downloads RPM packages from the repositories. Equivalent to dnf download --downloadonly --downloaddir ./ package-name !!! Note This command is very useful to quickly build a local repository of a few rpms! Example: yumdownloader will download the samba rpm package and all its dependencies: $ yumdownloader --destdir /var/tmp --resolve samba or $ dnf download --downloadonly --downloaddir /var/tmp --resolve samba Options Comments - -destdir The downloaded packages will be stored in the specified folder. --resolve Also downloads the package dependencies.","title":"yum-utils package"},{"location":"books/admin_guide/04-advanced-commands/#psmisc-packages","text":"The psmisc package contains utilities for managing system processes: pstree : the pstree command displays the current processes on the system in a tree-like structure. killall : the killall command sends a kill signal to all processes identified by name. fuser : the fuser command identifies the PID of processes that use the specified files or file systems. Examples: $ pstree systemd\u2500\u252c\u2500NetworkManager\u2500\u2500\u25002*[{NetworkManager}] \u251c\u2500agetty \u251c\u2500auditd\u2500\u2500\u2500{auditd} \u251c\u2500crond \u251c\u2500dbus-daemon\u2500\u2500\u2500{dbus-daemon} \u251c\u2500firewalld\u2500\u2500\u2500{firewalld} \u251c\u2500lvmetad \u251c\u2500master\u2500\u252c\u2500pickup \u2502 \u2514\u2500qmgr \u251c\u2500polkitd\u2500\u2500\u25005*[{polkitd}] \u251c\u2500rsyslogd\u2500\u2500\u25002*[{rsyslogd}] \u251c\u2500sshd\u2500\u2500\u2500sshd\u2500\u2500\u2500bash\u2500\u2500\u2500pstree \u251c\u2500systemd-journal \u251c\u2500systemd-logind \u251c\u2500systemd-udevd \u2514\u2500tuned\u2500\u2500\u25004*[{tuned}] # killall httpd Kill processes (option -k ) that access the /etc/httpd/conf/httpd.conf file: # fuser -k /etc/httpd/conf/httpd.conf","title":"psmisc packages"},{"location":"books/admin_guide/04-advanced-commands/#watch-command","text":"The watch command regularly executes a command and displays the result in the terminal in full screen. The -n option allows you to specify the number of seconds between each execution of the command. !!! Note To exit the `watch` command, you must type the keys: <kbd>CTRL</kbd>+<kbd>C</kbd> to kill the process. Examples: Display the end of the /etc/passwd file every 5 seconds: $ watch -n 5 tail -n 3 /etc/passwd Result: Every 5,0s: tail -n 3 /etc/passwd rockstar.rockylinux.lan: Thu Jul 1 15:43:59 2021 sssd:x:996:993:User for sssd:/:/sbin/nologin chrony:x:995:992::/var/lib/chrony:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin Monitoring the number of files in a folder: $ watch -n 1 'ls -l | wc -l' Display a clock: $ watch -t -n 1 date","title":"watch command"},{"location":"books/admin_guide/05-vi/","text":"VI Text Editor In this chapter you will learn how to work with the VIsual editor. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: Use the main commands of the VI editor; :heavy_check_mark: Modify a text with the VI editor. :checkered_flag: user commands , linux Knowledge : :star: Complexity : :star: :star: Reading time : 20 minutes Visual ( VI ) is a very popular text editor under Linux, despite its limited ergonomics. It is indeed an editor entirely in text mode: each action is done with a key on the keyboard or dedicated commands. Very powerful, it is above all very practical since it is on the whole minimal for basic applications. It is therefore accessible in case of system failure. Its universality (it is present on all Linux distributions and under Unix) makes it a crucial tool for the administrator. Its functionalities are: Insert, delete, modify text; Copy words, lines or blocks of text; Search and replace characters. vi command The vi command opens the VI text editor. vi [-c command] [file] Example: $ vi /home/rockstar/file Option Information -c command Execute VI by specifying a command at the opening If the file exists at the location mentioned by the path, it is read by VI which is placed in commands mode. If the file does not exist, VI opens a blank file and an empty page is displayed on the screen. When the file is saved, it will take the name specified with the command. If the command vi is executed without specifying a file name, VI opens a blank file and an empty page is displayed on the screen. When the file is saved, VI will ask for a file name. The vim editor takes the interface and functions of VI with many improvements. vim [-c command] [file] Among these improvements, the user has syntax highlighting, which is very useful for editing shell scripts or configuration files. During a session, VI uses a buffer file in which it records all the changes made by the user. !!! Note As long as the user has not saved his work, the original file is not modified. At startup, VI is in commands mode. !!! Tip A line of text is ended by pressing <kbd>ENTER</kbd> but if the screen is not wide enough, VI makes automatic line breaks, _wrap_ configuration by default. These line breaks may not be desired, this is the _nowrap_ configuration. To exit VI, from the Commands mode, tap : then type: q to exit without saving ( quit ); w to save your work ( write ); wq ( write quit ) or x ( eXit ) to save and exit. In command mode, Click the Z key of uppercase status twice in a row to save and exit. To force the exit without confirmation, you must add ! to the previous commands. !!! Warning There is no periodic backup, so you must remember to save your work regularly. Operating mode In VI, there are 3 working modes: The command mode; The insertion mode; The ex mode. The philosophy of VI is to alternate between the command mode and the insertion mode. The third mode, ex , is a footer command mode from an old text editor. The Command Mode This is the default mode when VI starts up. To access it from any of the other modes, simply press the ESC key. At this time, all keyboard typing is interpreted as commands and the corresponding actions are executed. These are essentially commands for editing text (copy, paste, undo, ...). The commands are not displayed on the screen. The Insert mode This is the text modification mode. To access it from the command mode, you have to press special keys that will perform an action in addition to changing the mode. The text is not entered directly into the file but into a buffer zone in the memory. The changes are only effective when the file is saved. The Ex mode This is the file modification mode. To access it, you must first switch to command mode, then enter the ex command frequently starting with the character : . The command is validated by pressing the ENTER key. Moving the cursor In command mode, there are several ways to move the cursor. The mouse is not active in a text environment but is in a graphic environment, it is possible to move it character by character, but shortcuts exist to go faster. VI remains in command mode after moving the cursor. The cursor is placed under the desired character. From a character Move one or n characters to the left: \u2190 , n \u2190 , h or n h Move one or n characters to the right: \u2192 , n \u2192 , l or n l Move one or n characters up: \u2191 , n \u2191 , k or n k Move one or n characters down: \u2193 , n \u2193 , j or n j Move to the end of the line: $ or END Move to the beginning of the line: 0 or POS1 From the first character of a word Words are made up of letters or numbers. Punctuation characters and apostrophes separate words. If the cursor is in the middle of a word w moves to the next word, b moves to the beginning of the word. If the line is finished, VI goes automatically to the next line. Move one or n words to the right: w or n w Move one or n words to the left: b or n b From any location on a line Move to last line of text: G Move to line n : n G Move to the first line of the screen: H Move to the middle line of the screen: M Move to the last line of the screen: L Inserting text In command mode, there are several ways to insert text. VI switches to insert mode after entering one of these keys. !!! Note VI switches to *insertion* mode. So you will have to press the <kbd>ESC</kbd> key to return to *command* mode. In relation to a character Inserting text before a character: i ( insert ) Inserting text after a character: a ( append ) In relation to a line Inserting text at the beginning of a line: I Inserting text at the end of a line: A In relation to the text Inserting text before a line: O Inserting text after a line: o Characters, words and lines VI allows text editing by managing: characters, words, lines. In each case it is possible to : delete, replace, copy, cut, paste. These operations are done in command mode. Characters Delete one or n characters: x or n x Replace a character with another: r character Replace more than one character with others: R characters ESC !!! Note The <kbd>R</kbd> command switches to *replace* mode, which is a kind of *insert* mode. Words Delete (cut) one or n words: d w or n d w Copy one or n words: y w or n y w Paste a word once or n times after the cursor: p or n p Paste a word once or n times before the cursor: P or n P Replace one word: c w word ESC !!! Tip It is necessary to position the cursor under the first character of the word to cut (or copy) otherwise VI will cut (or copy) only the part of the word between the cursor and the end. To delete a word is to cut it. If it is not pasted afterwards, the buffer is emptied and the word is deleted. Lines Delete (cut) one or n lines: d d or n d d Copy one or n lines: y y or n y y Paste what has been copied or deleted once or n times after the current line: p or n p Paste what has been copied or deleted once or n times before the current line: P or n P Delete (cut) from the beginning of the line to the cursor: d 0 Delete (cut) from the cursor to the end of the line: d $ Copy from the beginning of the line to the cursor: y 0 Copy from the cursor to the end of the line: y $ Delete (cut) the text from the current line: d L or d G Copy the text from the current line: y L or y G Cancel an action Undo the last action: u Undo the actions on the current line: U Cancel cancellation Cancel a cancellation Ctrl+R EX commands The Ex mode allows you to act on the file (saving, layout, options, ...). It is also in Ex mode where search and replace commands are entered. The commands are displayed at the bottom of the page and must be validated with the ENTER key. To switch to Ex mode, from command mode, type : . Numbering the lines Show/hide numbering: :set nu and the longer :set number :set nonu and the longer :set nonumber Search for a string Search for a string from the cursor: /string Search for a string before the cursor: ?string Go to the next occurrence found: n Go to the previous occurrence found: N There are wildcards to facilitate the search in VI. [] : Searches for a range of characters or a single character whose possible values are specified. Example: /[Ww]ord : search word and Word /[1-9]word : search 1word , 2word \u2026 x word where x is a number ^ : Search for a string starting the line. Example: /^Word $ : Search for a string ending the line. Example: /Word$ . : Search for a word with an unknown letter. Example: /W.rd : search Word , Ward \u2026 * : Search for one or more characters, whatever they are. Example: /W*d Replace a string From the 1st to the last line of the text, replace the searched string by the specified string: :1,$ s/search/replace Note: You can also use :0,$s/search/replace to specify starting at the absolute beginning of the file. From line n to line m , replace the searched string with the specified string: :n,m s/search/replace By default, only the first occurrence found of each line is replaced. To force the replacement of each occurrence, you have to add /g at the end of the command: :n,m s/search/replace/g Browse an entire file to replace the searched string with the specified string: :% s/search/replace File operations Save the file: :w Save under another name: :w file Save from line n to line m in another file: :n,m w file Reload the last record of the file: e! Paste the content of another file after the cursor: :r file Quit editing a file without saving: :q Quit editing a file that has been modified during the session but not saved: :q! Exit the file and save: :wq or :x Other functions It is possible to execute VI by specifying the options to be loaded for the session. To do this, you must use the -c option: $ vi -c \"set nu\" /home/rockstar/file It is also possible to enter the Ex commands in a file named .exrc put in the user's login directory. At each VI or VIM startup, the commands will be read and applied. vimtutor command There is a tutorial for learning how to use VI. It is accessible with the command vimtutor . $ vimtutor","title":"VI Text Editor"},{"location":"books/admin_guide/05-vi/#vi-text-editor","text":"In this chapter you will learn how to work with the VIsual editor. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: Use the main commands of the VI editor; :heavy_check_mark: Modify a text with the VI editor. :checkered_flag: user commands , linux Knowledge : :star: Complexity : :star: :star: Reading time : 20 minutes Visual ( VI ) is a very popular text editor under Linux, despite its limited ergonomics. It is indeed an editor entirely in text mode: each action is done with a key on the keyboard or dedicated commands. Very powerful, it is above all very practical since it is on the whole minimal for basic applications. It is therefore accessible in case of system failure. Its universality (it is present on all Linux distributions and under Unix) makes it a crucial tool for the administrator. Its functionalities are: Insert, delete, modify text; Copy words, lines or blocks of text; Search and replace characters.","title":"VI Text Editor"},{"location":"books/admin_guide/05-vi/#vi-command","text":"The vi command opens the VI text editor. vi [-c command] [file] Example: $ vi /home/rockstar/file Option Information -c command Execute VI by specifying a command at the opening If the file exists at the location mentioned by the path, it is read by VI which is placed in commands mode. If the file does not exist, VI opens a blank file and an empty page is displayed on the screen. When the file is saved, it will take the name specified with the command. If the command vi is executed without specifying a file name, VI opens a blank file and an empty page is displayed on the screen. When the file is saved, VI will ask for a file name. The vim editor takes the interface and functions of VI with many improvements. vim [-c command] [file] Among these improvements, the user has syntax highlighting, which is very useful for editing shell scripts or configuration files. During a session, VI uses a buffer file in which it records all the changes made by the user. !!! Note As long as the user has not saved his work, the original file is not modified. At startup, VI is in commands mode. !!! Tip A line of text is ended by pressing <kbd>ENTER</kbd> but if the screen is not wide enough, VI makes automatic line breaks, _wrap_ configuration by default. These line breaks may not be desired, this is the _nowrap_ configuration. To exit VI, from the Commands mode, tap : then type: q to exit without saving ( quit ); w to save your work ( write ); wq ( write quit ) or x ( eXit ) to save and exit. In command mode, Click the Z key of uppercase status twice in a row to save and exit. To force the exit without confirmation, you must add ! to the previous commands. !!! Warning There is no periodic backup, so you must remember to save your work regularly.","title":"vi command"},{"location":"books/admin_guide/05-vi/#operating-mode","text":"In VI, there are 3 working modes: The command mode; The insertion mode; The ex mode. The philosophy of VI is to alternate between the command mode and the insertion mode. The third mode, ex , is a footer command mode from an old text editor.","title":"Operating mode"},{"location":"books/admin_guide/05-vi/#the-command-mode","text":"This is the default mode when VI starts up. To access it from any of the other modes, simply press the ESC key. At this time, all keyboard typing is interpreted as commands and the corresponding actions are executed. These are essentially commands for editing text (copy, paste, undo, ...). The commands are not displayed on the screen.","title":"The Command Mode"},{"location":"books/admin_guide/05-vi/#the-insert-mode","text":"This is the text modification mode. To access it from the command mode, you have to press special keys that will perform an action in addition to changing the mode. The text is not entered directly into the file but into a buffer zone in the memory. The changes are only effective when the file is saved.","title":"The Insert mode"},{"location":"books/admin_guide/05-vi/#the-ex-mode","text":"This is the file modification mode. To access it, you must first switch to command mode, then enter the ex command frequently starting with the character : . The command is validated by pressing the ENTER key.","title":"The Ex mode"},{"location":"books/admin_guide/05-vi/#moving-the-cursor","text":"In command mode, there are several ways to move the cursor. The mouse is not active in a text environment but is in a graphic environment, it is possible to move it character by character, but shortcuts exist to go faster. VI remains in command mode after moving the cursor. The cursor is placed under the desired character.","title":"Moving the cursor"},{"location":"books/admin_guide/05-vi/#from-a-character","text":"Move one or n characters to the left: \u2190 , n \u2190 , h or n h Move one or n characters to the right: \u2192 , n \u2192 , l or n l Move one or n characters up: \u2191 , n \u2191 , k or n k Move one or n characters down: \u2193 , n \u2193 , j or n j Move to the end of the line: $ or END Move to the beginning of the line: 0 or POS1","title":"From a character"},{"location":"books/admin_guide/05-vi/#from-the-first-character-of-a-word","text":"Words are made up of letters or numbers. Punctuation characters and apostrophes separate words. If the cursor is in the middle of a word w moves to the next word, b moves to the beginning of the word. If the line is finished, VI goes automatically to the next line. Move one or n words to the right: w or n w Move one or n words to the left: b or n b","title":"From the first character of a word"},{"location":"books/admin_guide/05-vi/#from-any-location-on-a-line","text":"Move to last line of text: G Move to line n : n G Move to the first line of the screen: H Move to the middle line of the screen: M Move to the last line of the screen: L","title":"From any location on a line"},{"location":"books/admin_guide/05-vi/#inserting-text","text":"In command mode, there are several ways to insert text. VI switches to insert mode after entering one of these keys. !!! Note VI switches to *insertion* mode. So you will have to press the <kbd>ESC</kbd> key to return to *command* mode.","title":"Inserting text"},{"location":"books/admin_guide/05-vi/#in-relation-to-a-character","text":"Inserting text before a character: i ( insert ) Inserting text after a character: a ( append )","title":"In relation to a character"},{"location":"books/admin_guide/05-vi/#in-relation-to-a-line","text":"Inserting text at the beginning of a line: I Inserting text at the end of a line: A","title":"In relation to a line"},{"location":"books/admin_guide/05-vi/#in-relation-to-the-text","text":"Inserting text before a line: O Inserting text after a line: o","title":"In relation to the text"},{"location":"books/admin_guide/05-vi/#characters-words-and-lines","text":"VI allows text editing by managing: characters, words, lines. In each case it is possible to : delete, replace, copy, cut, paste. These operations are done in command mode.","title":"Characters, words and lines"},{"location":"books/admin_guide/05-vi/#characters","text":"Delete one or n characters: x or n x Replace a character with another: r character Replace more than one character with others: R characters ESC !!! Note The <kbd>R</kbd> command switches to *replace* mode, which is a kind of *insert* mode.","title":"Characters"},{"location":"books/admin_guide/05-vi/#words","text":"Delete (cut) one or n words: d w or n d w Copy one or n words: y w or n y w Paste a word once or n times after the cursor: p or n p Paste a word once or n times before the cursor: P or n P Replace one word: c w word ESC !!! Tip It is necessary to position the cursor under the first character of the word to cut (or copy) otherwise VI will cut (or copy) only the part of the word between the cursor and the end. To delete a word is to cut it. If it is not pasted afterwards, the buffer is emptied and the word is deleted.","title":"Words"},{"location":"books/admin_guide/05-vi/#lines","text":"Delete (cut) one or n lines: d d or n d d Copy one or n lines: y y or n y y Paste what has been copied or deleted once or n times after the current line: p or n p Paste what has been copied or deleted once or n times before the current line: P or n P Delete (cut) from the beginning of the line to the cursor: d 0 Delete (cut) from the cursor to the end of the line: d $ Copy from the beginning of the line to the cursor: y 0 Copy from the cursor to the end of the line: y $ Delete (cut) the text from the current line: d L or d G Copy the text from the current line: y L or y G","title":"Lines"},{"location":"books/admin_guide/05-vi/#cancel-an-action","text":"Undo the last action: u Undo the actions on the current line: U","title":"Cancel an action"},{"location":"books/admin_guide/05-vi/#cancel-cancellation","text":"Cancel a cancellation Ctrl+R","title":"Cancel cancellation"},{"location":"books/admin_guide/05-vi/#ex-commands","text":"The Ex mode allows you to act on the file (saving, layout, options, ...). It is also in Ex mode where search and replace commands are entered. The commands are displayed at the bottom of the page and must be validated with the ENTER key. To switch to Ex mode, from command mode, type : .","title":"EX commands"},{"location":"books/admin_guide/05-vi/#numbering-the-lines","text":"Show/hide numbering: :set nu and the longer :set number :set nonu and the longer :set nonumber","title":"Numbering the lines"},{"location":"books/admin_guide/05-vi/#search-for-a-string","text":"Search for a string from the cursor: /string Search for a string before the cursor: ?string Go to the next occurrence found: n Go to the previous occurrence found: N There are wildcards to facilitate the search in VI. [] : Searches for a range of characters or a single character whose possible values are specified. Example: /[Ww]ord : search word and Word /[1-9]word : search 1word , 2word \u2026 x word where x is a number ^ : Search for a string starting the line. Example: /^Word $ : Search for a string ending the line. Example: /Word$ . : Search for a word with an unknown letter. Example: /W.rd : search Word , Ward \u2026 * : Search for one or more characters, whatever they are. Example: /W*d","title":"Search for a string"},{"location":"books/admin_guide/05-vi/#replace-a-string","text":"From the 1st to the last line of the text, replace the searched string by the specified string: :1,$ s/search/replace Note: You can also use :0,$s/search/replace to specify starting at the absolute beginning of the file. From line n to line m , replace the searched string with the specified string: :n,m s/search/replace By default, only the first occurrence found of each line is replaced. To force the replacement of each occurrence, you have to add /g at the end of the command: :n,m s/search/replace/g Browse an entire file to replace the searched string with the specified string: :% s/search/replace","title":"Replace a string"},{"location":"books/admin_guide/05-vi/#file-operations","text":"Save the file: :w Save under another name: :w file Save from line n to line m in another file: :n,m w file Reload the last record of the file: e! Paste the content of another file after the cursor: :r file Quit editing a file without saving: :q Quit editing a file that has been modified during the session but not saved: :q! Exit the file and save: :wq or :x","title":"File operations"},{"location":"books/admin_guide/05-vi/#other-functions","text":"It is possible to execute VI by specifying the options to be loaded for the session. To do this, you must use the -c option: $ vi -c \"set nu\" /home/rockstar/file It is also possible to enter the Ex commands in a file named .exrc put in the user's login directory. At each VI or VIM startup, the commands will be read and applied.","title":"Other functions"},{"location":"books/admin_guide/05-vi/#vimtutor-command","text":"There is a tutorial for learning how to use VI. It is accessible with the command vimtutor . $ vimtutor","title":"vimtutor command"},{"location":"books/admin_guide/06-users/","text":"User Management In this chapter you will learn how to manage user. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: add, delete or modify a group ; :heavy_check_mark: add, delete or modify a user ; :heavy_check_mark: know the syntax of the files associated with the management of groups and users ; :heavy_check_mark: change the owner or the group owner of a file; :heavy_check_mark: secure user accounts; :heavy_check_mark: change identity. :checkered_flag: users Knowledge : :star: :star: Complexity : :star: :star: Reading time : 30 minutes General Each user is a member of at least one group: this is their main group . Several users can be part of the same group. Users can belong to other groups. These users are invited to these secondary groups . !!! Note Each user has a primary group and can be invited into one or more secondary groups. Groups and users are managed by their unique numerical identifiers GID and UID . Account and group declaration files are located in /etc . * UID : User IDentifier . Unique user ID. * GID : Group IDentifier . Unique group identifier. !!! Danger You should always use the administration commands instead of manually editing the files. Group management Modified files, added lines: /etc/group /etc/gshadow groupadd command The groupadd command adds a group to the system. groupadd [-f] [-g GID] group Example: $ sudo groupadd -g 1012 GroupeB Option Description -g GID GID of the group to create. -f The system chooses a GID if the one specified by the -g option already exists. -r Creates a system group with a GID between SYS_GID_MIN and SYS_GID_MAX . These two variables are defined in /etc/login.defs . Group naming rules: No accents or special characters; Different from the name of an existing user or system files. !!! Note Under **Debian**, the administrator should use, except in scripts intended to be portable to all Linux distributions, the `addgroup` and `delgroup` commands as specified in the `man`: ``` $ man addgroup DESCRIPTION adduser and addgroup add users and groups to the system according to command line options and configuration information in /etc/adduser.conf. They are friendlier front ends to the low level tools like useradd, groupadd and usermod programs, by default choosing Debian policy conformant UID and GID values, creating a home directory with skeletal configuration, running a custom script, and other features. ``` Command groupmod The groupmod command allows you to modify an existing group on the system. groupmod [-g GID] [-n nom] group Example: $ sudo groupmod -g 1016 GroupP $ sudo groupmod -n GroupC GroupB Option Description -g GID New GID of the group to modify. -n name New name. It is possible to change the name of a group, its GID or both simultaneously. After modification, the files belonging to the group have an unknown GID . They must be reassigned the new GID . $ sudo find / -gid 1002 -exec chgrp 1016 {} \\; groupdel command The groupdel command is used to delete an existing group on the system. groupdel group Example: $ sudo groupdel GroupC !!! Tip To be deleted, a group must no longer contain users. Deleting the last user of an eponymous group will cause the system to delete the group. !!! Tip Each group has a unique `GID`. A group can be duplicated. By convention, the `GID` of system groups range from 0 (`root`) to 999. !!! Tip Since a user is necessarily part of a group, it is best to create the groups before adding the users. Therefore, a group may not have any members. /etc/group file This file contains the group information (separated by : ). $ sudo tail -1 /etc/group GroupP:x:516:patrick (1) (2)(3) (4) 1: Name of the group. 2: Password ( x if defined in /etc/gshadow ). 3: GID. 4: Guest members (separated by commas, does not contain core members). !!! Note Each line in the `/etc/group` file corresponds to a group. Users whose group is their main group are not listed at this level. This membership information is in fact already provided by the `/etc/passwd` file... /etc/gshadow file This file contains the security information about the groups (separated by : ). $ sudo grep GroupA /etc/gshadow GroupA:$6$2,9,v...SBn160:alain:rockstar (1) (2) (3) (4) 1: Name of the group. 2: Encrypted password. 3: Administrator of the group. 4: Guest members (separated by commas, does not contain core members). !!! Warning For each line in the `/etc/group` file there must be a corresponding line in the `/etc/gshadow` file. A ! in the password indicates that it is locked. Thus no user can use the password to access the group (since group members do not need it). User management Definition A user is defined as follows in the /etc/passwd file: 1: Login; 2: Password; 3: UID; 4: GID of the main group; 5: Comments; 6: Home directory; 7: Shell ( /bin/bash , /bin/nologin , ...). There are three types of users: root : the system administrator ; system users : Used by the system to manage application access rights ; regular user : Other account to log in to the system. Modified files, added lines: /etc/passwd /etc/shadow useradd command The useradd command is used to add a user. useradd [-u UID] [-g GID] [-d directory] [-s shell] login Example: $ sudo useradd -u 1000 -g 1013 -d /home/GroupC/carine carine Option Description -u UID UID of the user to create. -g GID GID of the main group. -d directory Home directory. -s shell Shell. -c Add a comment. -U Adds the user to a group with the same name created simultaneously. -M Does not create the connection directory. At creation, the account has no password and is locked. A password must be assigned to unlock the account. Account naming rules: No accents, capital letters or special characters; Different from the name of an existing group or system file; Set the options -u , -g , -d and -s at creation. !!! Warning The home directory tree must be created except for the last directory. The last directory is created by the useradd command, which takes the opportunity to copy the files from /etc/skel into it. A user can belong to several groups in addition to their main group. For secondary groups, the -G option must be used. Example: $ sudo useradd -u 1000 -g GroupA -G GroupP,GroupC albert !!! Note Under **Debian**, you will have to specify the `-m` option to force the creation of the login directory or set the `CREATE_HOME` variable in the `/etc/login.defs` file. In all cases, the administrator should use the `adduser` and `deluser` commands as specified in the `man`, except in scripts intended to be portable to all Linux distributions: ``` $ man useradd DESCRIPTION **useradd** is a low level utility for adding users. On Debian, administrators should usually use **adduser(8)** instead. ``` Default value for user creation. Modification of the file /etc/default/useradd . useradd -D [-b directory] [-g group] [-s shell] Example: $ sudo useradd -D -g 1000 -b /home -s /bin/bash Option Description -D Sets the default values for user creation. -b directory Sets the default login directory. -g group Sets the default group. -s shell Sets the default shell. -f The number of days after the password expires before the account is disabled. -e The date the account will be disabled. usermod command The usermod command allows to modify a user. usermod [-u UID] [-g GID] [-d directory] [-m] login Example: $ sudo usermod -u 1044 carine Options identical to the useradd command. Option Description -m Associated with the -d option, moves the contents of the old login directory to the new one. -l login New name. -e AAAA-MM-JJ Account expiration date. -L Locks the account. -U Unlocks the account. -a Prevents the user from being deleted from a subgroup when added to another subgroup. -G Specifies multiple subgroups when adding. With the usermod command, locking an account results in the addition of ! before the password in the /etc/shadow file. !!! Tip To be modified, a user must be disconnected and have no running processes. After changing the identifier, the files belonging to the user have an unknown UID . It must be reassigned the new UID . $ sudo find / -uid 1000 -exec chown 1044: {} \\; Where 1000 is the old UID and 1044 is the new one. It is possible to invite a user into one or more subgroups with the options -a and -G . Example: $ sudo usermod -aG GroupP,GroupC albert The usermod command acts as a modification and not as an addition. For a user invited to a group by this command and already positioned as a guest in other secondary groups, it will be necessary to indicate in the group management command all the groups to which he belongs otherwise he will disappear from them. The -a option changes this behavior. Examples: Invite albert in the group GroupP . $ sudo usermod -G GroupP albert Invites albert into the GroupG group, but removes him from the GroupP guest list. $ sudo usermod -G GroupG albert So either : $ sudo usermod -G GroupP,GroupG albert Or : $ sudo usermod -aG GroupG albert userdel command The userdel command allows you to delete a user's account. $ sudo userdel -r carine Option Description -r Deletes the connection directory and the contained files. !!! Tip To be deleted, a user must be logged out and have no running processes. userdel removes the user's line from the /etc/passwd and /etc/gshadow files. /etc/passwd file This file contains user information (separated by : ). $ sudo head -1 /etc/passwd root:x:0:0:root:/root:/bin/bash (1)(2)(3)(4)(5) (6) (7) 1: Login. 2: Password ( x if defined in /etc/shadow ). 3: UID. 4: GID of the main group. 5: Comment. 6: Home directory. 7: Shell. /etc/shadow file This file contains the users' security information (separated by : ). $ sudo tail -1 /etc/shadow root:$6$...:15399:0:99999:7::: (1) (2) (3) (4) (5) (6)(7,8,9) 1: Login. 2: Encrypted password. 3: Date of last change. 4: Minimum lifetime of the password. 5: Maximum lifetime of the password. 6: Number of days before warning. 7: Time to deactivate account after expiration. 8: Account expiration time. 9: Reserved for future use. !!! Danger For each line in the `/etc/passwd` file there must be a corresponding line in the `/etc/shadow` file. File owners !!! Danger All files necessarily belong to one user and one group. The main group of the user creating the file is, by default, the group that owns the file. Modification commands chown command The chown command allows you to change the owners of a file. chown [-R] [-v] login[:group] file Examples: $ sudo chown root myfile $ sudo chown albert:GroupA myfile Option Description -R Changes the owners of the directory and its contents. -v Displays the executed changes. To change only the owner user: $ sudo chown albert file To modify only the owner group: $ sudo chown :GroupA file Changing the user and owner group: $ sudo chown albert:GroupA file In the following example the group assigned will be the main group of the specified user. $ sudo chown albert: file chgrp command The chgrp command allows you to change the owner group of a file. chgrp [-R] [-v] group file Example: $ sudo chgrp group1 file Option Description -R Modifies the owner groups of the directory and its contents (recursion). -v Displays the executed changes. !!! Note It is possible to apply to a file an owner and an owner group by taking as reference those of another file: chown [options] --reference=RRFILE FILE For example: chown --reference=/etc/groups /etc/passwd Guest management gpasswd command The command gpasswd allows to manage a group. gpasswd [-a login] [-A login] [-d login] [-M login] group Examples: $ sudo gpasswd -A alain GroupA [alain]$ gpasswd -a patrick GroupA Option Description -a login Adds the user to the group. -A login Sets the group administrator. -d login Remove the user from the group. -M login Defines the complete list of guests. The command gpasswd -M acts as a modification, not an addition. # gpasswd GroupeA New Password : Re-enter new password : id command The id command displays the group names of a user. id login Example: $ sudo id alain uid=1000(alain) gid=1000(GroupA) groupes=1000(GroupA),1016(GroupP) newgrp command The newgrp command allows you to temporarily use a secondary group for file creation. newgrp [secondarygroups] Example: [alain]$ newgrp GroupB !!! Note After using this command, the files will be created with the `GID` of its subgroup. The command newgrp without parameters reassigns the main group. Securing passwd command The passwd command is used to manage a password. passwd [-d] [-l] [-S] [-u] [login] Examples: $ sudo passwd -l albert $ sudo passwd -n 60 -x 90 -w 80 -i 10 patrick Option Description -d Removes the password. -l Locks the account. -S Displays the account status. -u Unlocks the account. -e Expires the password. -n days Minimum password lifetime. -x days Maximum password lifetime. -w days Warning time before expiration. -i days Delay before deactivation when the password expires. With the passwd command, locking an account is accomplished by adding !! before the password in the /etc/shadow file. Using the command usermod -U command only removes one of the ! . So the account remains locked. Example: Alain changes his password: [alain]$ passwd root changes Alain's password $ sudo passwd alain !!! Note The `passwd` command is available to users to change their password (the old password is requested). The administrator can change the passwords of all users without restriction. They will have to comply with the security restrictions. When managing user accounts by shell script, it may be useful to set a default password after creating the user. This can be done by passing the password to the passwd command. Example: $ sudo echo \"azerty,1\" | passwd --stdin philippe !!! Warning The password is entered in clear text, `passwd` takes care of encrypting it. chage command The chage command is used to manage the account strategy. chage [-d date] [-E date] [-I days] [-l] [-m days] [-M days] [-W days] [login] Example: $ sudo chage -m 60 -M 90 -W 80 -I 10 alain Option Description -I days Delay before deactivation, password expired. -l Displays the policy details. -m days Minimum lifetime of the password. -M days Maximum lifetime of the password. -d AAAA-MM-JJ Last password change. -E AAAA-MM-JJ Account expiration date. -W days Warning time before expiration. The chage command also offers an interactive mode. The -d option forces the password to be changed at login. Examples: $ sudo chage philippe $ sudo chage -d 0 philippe !!! Note If no user is specified, the order will concern the user who enters it. Advanced management Configuration files: * /etc/default/useradd * /etc/login.defs * /etc/skel !!! Note Editing the `/etc/default/useradd` file is done with the `useradd` command. The other files are to be modified with a text editor. /etc/default/useradd file This file contains the default data settings. !!! Tip When creating a user, if the options are not specified, the system uses the default values defined in `/etc/default/useradd`. This file is modified by the command useradd -D ( useradd -D entered without any other option displays the contents of the /etc/default/useradd file). Value Comment GROUP Default group. HOME Path where the login directory for the user's name will be created. INACTIVE Number of days after the password expires before the account is disabled. EXPIRE Account expiration date. SHELL Command interpreter. SKEL Skeleton directory of the login directory. CREATE_MAIL_SPOOL Mailbox creation in /var/spool/mail . !!! Warning Without the `-g` option, the `useradd` command creates a group of the user's name name and places it there. In order for the useradd command to retrieve the value of the GROUP field from the /etc/default/useradd file, you must specify the -N option. Example: $ sudo useradd -u 501 -N GroupeA /etc/login.defs file This file contains many default parameters useful for creating or modifying users. This information is grouped by paragraph according to their use: Mailboxes; Passwords ; UID and GID ; Umask ; Connections; Terminals. /etc/skel directory When a user is created, their home directory and environment files are created. These files are automatically copied from the /etc/skel directory. .bash_logout .bash_profile .bashrc All files and directories placed in this directory will be copied to the user tree when they are created. Identity change su command The su command allows you to change the identity of the connected user. su [-] [-c command] [login] Examples: $ sudo su - alain [albert]$ su -c \"passwd alain\" Option Description - Loads the user's complete environment. -c command Executes the command under the user's identity. If the login is not specified, it will be root . Standard users will have to type the password for the new identity. !!! Tip There are successive 'layers' created (a stack of `bash` environments). To switch from one user to another, you must first type the `exit` command to take back your identity and then the `su` command to take another identity. Profile loading root endorses the identity of the user alain with su : ... /home/GroupA/alain/.bashrc /etc/bashrc ... root assumes the identity of the user alain with su - : ... /home/GroupA/alain/.bash_profile /home/GroupA/alain/.bashrc /etc/bashrc ... A user can temporarily (for another command or an entire session) assume the identity of another account. If no user is specified, the command will be for root ( su - ). It is necessary to know the password of the user whose identity is being endorsed unless it is root that is executing the command. An administrator can thus work on a standard user account and use the rights of the root account only occasionally.","title":"User Management"},{"location":"books/admin_guide/06-users/#user-management","text":"In this chapter you will learn how to manage user. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: add, delete or modify a group ; :heavy_check_mark: add, delete or modify a user ; :heavy_check_mark: know the syntax of the files associated with the management of groups and users ; :heavy_check_mark: change the owner or the group owner of a file; :heavy_check_mark: secure user accounts; :heavy_check_mark: change identity. :checkered_flag: users Knowledge : :star: :star: Complexity : :star: :star: Reading time : 30 minutes","title":"User Management"},{"location":"books/admin_guide/06-users/#general","text":"Each user is a member of at least one group: this is their main group . Several users can be part of the same group. Users can belong to other groups. These users are invited to these secondary groups . !!! Note Each user has a primary group and can be invited into one or more secondary groups. Groups and users are managed by their unique numerical identifiers GID and UID . Account and group declaration files are located in /etc . * UID : User IDentifier . Unique user ID. * GID : Group IDentifier . Unique group identifier. !!! Danger You should always use the administration commands instead of manually editing the files.","title":"General"},{"location":"books/admin_guide/06-users/#group-management","text":"Modified files, added lines: /etc/group /etc/gshadow","title":"Group management"},{"location":"books/admin_guide/06-users/#groupadd-command","text":"The groupadd command adds a group to the system. groupadd [-f] [-g GID] group Example: $ sudo groupadd -g 1012 GroupeB Option Description -g GID GID of the group to create. -f The system chooses a GID if the one specified by the -g option already exists. -r Creates a system group with a GID between SYS_GID_MIN and SYS_GID_MAX . These two variables are defined in /etc/login.defs . Group naming rules: No accents or special characters; Different from the name of an existing user or system files. !!! Note Under **Debian**, the administrator should use, except in scripts intended to be portable to all Linux distributions, the `addgroup` and `delgroup` commands as specified in the `man`: ``` $ man addgroup DESCRIPTION adduser and addgroup add users and groups to the system according to command line options and configuration information in /etc/adduser.conf. They are friendlier front ends to the low level tools like useradd, groupadd and usermod programs, by default choosing Debian policy conformant UID and GID values, creating a home directory with skeletal configuration, running a custom script, and other features. ```","title":"groupadd command"},{"location":"books/admin_guide/06-users/#command-groupmod","text":"The groupmod command allows you to modify an existing group on the system. groupmod [-g GID] [-n nom] group Example: $ sudo groupmod -g 1016 GroupP $ sudo groupmod -n GroupC GroupB Option Description -g GID New GID of the group to modify. -n name New name. It is possible to change the name of a group, its GID or both simultaneously. After modification, the files belonging to the group have an unknown GID . They must be reassigned the new GID . $ sudo find / -gid 1002 -exec chgrp 1016 {} \\;","title":"Command groupmod"},{"location":"books/admin_guide/06-users/#groupdel-command","text":"The groupdel command is used to delete an existing group on the system. groupdel group Example: $ sudo groupdel GroupC !!! Tip To be deleted, a group must no longer contain users. Deleting the last user of an eponymous group will cause the system to delete the group. !!! Tip Each group has a unique `GID`. A group can be duplicated. By convention, the `GID` of system groups range from 0 (`root`) to 999. !!! Tip Since a user is necessarily part of a group, it is best to create the groups before adding the users. Therefore, a group may not have any members.","title":"groupdel command"},{"location":"books/admin_guide/06-users/#etcgroup-file","text":"This file contains the group information (separated by : ). $ sudo tail -1 /etc/group GroupP:x:516:patrick (1) (2)(3) (4) 1: Name of the group. 2: Password ( x if defined in /etc/gshadow ). 3: GID. 4: Guest members (separated by commas, does not contain core members). !!! Note Each line in the `/etc/group` file corresponds to a group. Users whose group is their main group are not listed at this level. This membership information is in fact already provided by the `/etc/passwd` file...","title":"/etc/group file"},{"location":"books/admin_guide/06-users/#etcgshadow-file","text":"This file contains the security information about the groups (separated by : ). $ sudo grep GroupA /etc/gshadow GroupA:$6$2,9,v...SBn160:alain:rockstar (1) (2) (3) (4) 1: Name of the group. 2: Encrypted password. 3: Administrator of the group. 4: Guest members (separated by commas, does not contain core members). !!! Warning For each line in the `/etc/group` file there must be a corresponding line in the `/etc/gshadow` file. A ! in the password indicates that it is locked. Thus no user can use the password to access the group (since group members do not need it).","title":"/etc/gshadow file"},{"location":"books/admin_guide/06-users/#user-management_1","text":"","title":"User management"},{"location":"books/admin_guide/06-users/#definition","text":"A user is defined as follows in the /etc/passwd file: 1: Login; 2: Password; 3: UID; 4: GID of the main group; 5: Comments; 6: Home directory; 7: Shell ( /bin/bash , /bin/nologin , ...). There are three types of users: root : the system administrator ; system users : Used by the system to manage application access rights ; regular user : Other account to log in to the system. Modified files, added lines: /etc/passwd /etc/shadow","title":"Definition"},{"location":"books/admin_guide/06-users/#useradd-command","text":"The useradd command is used to add a user. useradd [-u UID] [-g GID] [-d directory] [-s shell] login Example: $ sudo useradd -u 1000 -g 1013 -d /home/GroupC/carine carine Option Description -u UID UID of the user to create. -g GID GID of the main group. -d directory Home directory. -s shell Shell. -c Add a comment. -U Adds the user to a group with the same name created simultaneously. -M Does not create the connection directory. At creation, the account has no password and is locked. A password must be assigned to unlock the account. Account naming rules: No accents, capital letters or special characters; Different from the name of an existing group or system file; Set the options -u , -g , -d and -s at creation. !!! Warning The home directory tree must be created except for the last directory. The last directory is created by the useradd command, which takes the opportunity to copy the files from /etc/skel into it. A user can belong to several groups in addition to their main group. For secondary groups, the -G option must be used. Example: $ sudo useradd -u 1000 -g GroupA -G GroupP,GroupC albert !!! Note Under **Debian**, you will have to specify the `-m` option to force the creation of the login directory or set the `CREATE_HOME` variable in the `/etc/login.defs` file. In all cases, the administrator should use the `adduser` and `deluser` commands as specified in the `man`, except in scripts intended to be portable to all Linux distributions: ``` $ man useradd DESCRIPTION **useradd** is a low level utility for adding users. On Debian, administrators should usually use **adduser(8)** instead. ```","title":"useradd command"},{"location":"books/admin_guide/06-users/#default-value-for-user-creation","text":"Modification of the file /etc/default/useradd . useradd -D [-b directory] [-g group] [-s shell] Example: $ sudo useradd -D -g 1000 -b /home -s /bin/bash Option Description -D Sets the default values for user creation. -b directory Sets the default login directory. -g group Sets the default group. -s shell Sets the default shell. -f The number of days after the password expires before the account is disabled. -e The date the account will be disabled.","title":"Default value for user creation."},{"location":"books/admin_guide/06-users/#usermod-command","text":"The usermod command allows to modify a user. usermod [-u UID] [-g GID] [-d directory] [-m] login Example: $ sudo usermod -u 1044 carine Options identical to the useradd command. Option Description -m Associated with the -d option, moves the contents of the old login directory to the new one. -l login New name. -e AAAA-MM-JJ Account expiration date. -L Locks the account. -U Unlocks the account. -a Prevents the user from being deleted from a subgroup when added to another subgroup. -G Specifies multiple subgroups when adding. With the usermod command, locking an account results in the addition of ! before the password in the /etc/shadow file. !!! Tip To be modified, a user must be disconnected and have no running processes. After changing the identifier, the files belonging to the user have an unknown UID . It must be reassigned the new UID . $ sudo find / -uid 1000 -exec chown 1044: {} \\; Where 1000 is the old UID and 1044 is the new one. It is possible to invite a user into one or more subgroups with the options -a and -G . Example: $ sudo usermod -aG GroupP,GroupC albert The usermod command acts as a modification and not as an addition. For a user invited to a group by this command and already positioned as a guest in other secondary groups, it will be necessary to indicate in the group management command all the groups to which he belongs otherwise he will disappear from them. The -a option changes this behavior. Examples: Invite albert in the group GroupP . $ sudo usermod -G GroupP albert Invites albert into the GroupG group, but removes him from the GroupP guest list. $ sudo usermod -G GroupG albert So either : $ sudo usermod -G GroupP,GroupG albert Or : $ sudo usermod -aG GroupG albert","title":"usermod command"},{"location":"books/admin_guide/06-users/#userdel-command","text":"The userdel command allows you to delete a user's account. $ sudo userdel -r carine Option Description -r Deletes the connection directory and the contained files. !!! Tip To be deleted, a user must be logged out and have no running processes. userdel removes the user's line from the /etc/passwd and /etc/gshadow files.","title":"userdel command"},{"location":"books/admin_guide/06-users/#etcpasswd-file","text":"This file contains user information (separated by : ). $ sudo head -1 /etc/passwd root:x:0:0:root:/root:/bin/bash (1)(2)(3)(4)(5) (6) (7) 1: Login. 2: Password ( x if defined in /etc/shadow ). 3: UID. 4: GID of the main group. 5: Comment. 6: Home directory. 7: Shell.","title":"/etc/passwd file"},{"location":"books/admin_guide/06-users/#etcshadow-file","text":"This file contains the users' security information (separated by : ). $ sudo tail -1 /etc/shadow root:$6$...:15399:0:99999:7::: (1) (2) (3) (4) (5) (6)(7,8,9) 1: Login. 2: Encrypted password. 3: Date of last change. 4: Minimum lifetime of the password. 5: Maximum lifetime of the password. 6: Number of days before warning. 7: Time to deactivate account after expiration. 8: Account expiration time. 9: Reserved for future use. !!! Danger For each line in the `/etc/passwd` file there must be a corresponding line in the `/etc/shadow` file.","title":"/etc/shadow file"},{"location":"books/admin_guide/06-users/#file-owners","text":"!!! Danger All files necessarily belong to one user and one group. The main group of the user creating the file is, by default, the group that owns the file.","title":"File owners"},{"location":"books/admin_guide/06-users/#modification-commands","text":"","title":"Modification commands"},{"location":"books/admin_guide/06-users/#chown-command","text":"The chown command allows you to change the owners of a file. chown [-R] [-v] login[:group] file Examples: $ sudo chown root myfile $ sudo chown albert:GroupA myfile Option Description -R Changes the owners of the directory and its contents. -v Displays the executed changes. To change only the owner user: $ sudo chown albert file To modify only the owner group: $ sudo chown :GroupA file Changing the user and owner group: $ sudo chown albert:GroupA file In the following example the group assigned will be the main group of the specified user. $ sudo chown albert: file","title":"chown command"},{"location":"books/admin_guide/06-users/#chgrp-command","text":"The chgrp command allows you to change the owner group of a file. chgrp [-R] [-v] group file Example: $ sudo chgrp group1 file Option Description -R Modifies the owner groups of the directory and its contents (recursion). -v Displays the executed changes. !!! Note It is possible to apply to a file an owner and an owner group by taking as reference those of another file: chown [options] --reference=RRFILE FILE For example: chown --reference=/etc/groups /etc/passwd","title":"chgrp command"},{"location":"books/admin_guide/06-users/#guest-management","text":"","title":"Guest management"},{"location":"books/admin_guide/06-users/#gpasswd-command","text":"The command gpasswd allows to manage a group. gpasswd [-a login] [-A login] [-d login] [-M login] group Examples: $ sudo gpasswd -A alain GroupA [alain]$ gpasswd -a patrick GroupA Option Description -a login Adds the user to the group. -A login Sets the group administrator. -d login Remove the user from the group. -M login Defines the complete list of guests. The command gpasswd -M acts as a modification, not an addition. # gpasswd GroupeA New Password : Re-enter new password :","title":"gpasswd command"},{"location":"books/admin_guide/06-users/#id-command","text":"The id command displays the group names of a user. id login Example: $ sudo id alain uid=1000(alain) gid=1000(GroupA) groupes=1000(GroupA),1016(GroupP)","title":"id command"},{"location":"books/admin_guide/06-users/#newgrp-command","text":"The newgrp command allows you to temporarily use a secondary group for file creation. newgrp [secondarygroups] Example: [alain]$ newgrp GroupB !!! Note After using this command, the files will be created with the `GID` of its subgroup. The command newgrp without parameters reassigns the main group.","title":"newgrp command"},{"location":"books/admin_guide/06-users/#securing","text":"","title":"Securing"},{"location":"books/admin_guide/06-users/#passwd-command","text":"The passwd command is used to manage a password. passwd [-d] [-l] [-S] [-u] [login] Examples: $ sudo passwd -l albert $ sudo passwd -n 60 -x 90 -w 80 -i 10 patrick Option Description -d Removes the password. -l Locks the account. -S Displays the account status. -u Unlocks the account. -e Expires the password. -n days Minimum password lifetime. -x days Maximum password lifetime. -w days Warning time before expiration. -i days Delay before deactivation when the password expires. With the passwd command, locking an account is accomplished by adding !! before the password in the /etc/shadow file. Using the command usermod -U command only removes one of the ! . So the account remains locked. Example: Alain changes his password: [alain]$ passwd root changes Alain's password $ sudo passwd alain !!! Note The `passwd` command is available to users to change their password (the old password is requested). The administrator can change the passwords of all users without restriction. They will have to comply with the security restrictions. When managing user accounts by shell script, it may be useful to set a default password after creating the user. This can be done by passing the password to the passwd command. Example: $ sudo echo \"azerty,1\" | passwd --stdin philippe !!! Warning The password is entered in clear text, `passwd` takes care of encrypting it.","title":"passwd command"},{"location":"books/admin_guide/06-users/#chage-command","text":"The chage command is used to manage the account strategy. chage [-d date] [-E date] [-I days] [-l] [-m days] [-M days] [-W days] [login] Example: $ sudo chage -m 60 -M 90 -W 80 -I 10 alain Option Description -I days Delay before deactivation, password expired. -l Displays the policy details. -m days Minimum lifetime of the password. -M days Maximum lifetime of the password. -d AAAA-MM-JJ Last password change. -E AAAA-MM-JJ Account expiration date. -W days Warning time before expiration. The chage command also offers an interactive mode. The -d option forces the password to be changed at login. Examples: $ sudo chage philippe $ sudo chage -d 0 philippe !!! Note If no user is specified, the order will concern the user who enters it.","title":"chage command"},{"location":"books/admin_guide/06-users/#advanced-management","text":"Configuration files: * /etc/default/useradd * /etc/login.defs * /etc/skel !!! Note Editing the `/etc/default/useradd` file is done with the `useradd` command. The other files are to be modified with a text editor.","title":"Advanced management"},{"location":"books/admin_guide/06-users/#etcdefaultuseradd-file","text":"This file contains the default data settings. !!! Tip When creating a user, if the options are not specified, the system uses the default values defined in `/etc/default/useradd`. This file is modified by the command useradd -D ( useradd -D entered without any other option displays the contents of the /etc/default/useradd file). Value Comment GROUP Default group. HOME Path where the login directory for the user's name will be created. INACTIVE Number of days after the password expires before the account is disabled. EXPIRE Account expiration date. SHELL Command interpreter. SKEL Skeleton directory of the login directory. CREATE_MAIL_SPOOL Mailbox creation in /var/spool/mail . !!! Warning Without the `-g` option, the `useradd` command creates a group of the user's name name and places it there. In order for the useradd command to retrieve the value of the GROUP field from the /etc/default/useradd file, you must specify the -N option. Example: $ sudo useradd -u 501 -N GroupeA","title":"/etc/default/useradd file"},{"location":"books/admin_guide/06-users/#etclogindefs-file","text":"This file contains many default parameters useful for creating or modifying users. This information is grouped by paragraph according to their use: Mailboxes; Passwords ; UID and GID ; Umask ; Connections; Terminals.","title":"/etc/login.defs file"},{"location":"books/admin_guide/06-users/#etcskel-directory","text":"When a user is created, their home directory and environment files are created. These files are automatically copied from the /etc/skel directory. .bash_logout .bash_profile .bashrc All files and directories placed in this directory will be copied to the user tree when they are created.","title":"/etc/skel directory"},{"location":"books/admin_guide/06-users/#identity-change","text":"","title":"Identity change"},{"location":"books/admin_guide/06-users/#su-command","text":"The su command allows you to change the identity of the connected user. su [-] [-c command] [login] Examples: $ sudo su - alain [albert]$ su -c \"passwd alain\" Option Description - Loads the user's complete environment. -c command Executes the command under the user's identity. If the login is not specified, it will be root . Standard users will have to type the password for the new identity. !!! Tip There are successive 'layers' created (a stack of `bash` environments). To switch from one user to another, you must first type the `exit` command to take back your identity and then the `su` command to take another identity.","title":"su command"},{"location":"books/admin_guide/06-users/#profile-loading","text":"root endorses the identity of the user alain with su : ... /home/GroupA/alain/.bashrc /etc/bashrc ... root assumes the identity of the user alain with su - : ... /home/GroupA/alain/.bash_profile /home/GroupA/alain/.bashrc /etc/bashrc ... A user can temporarily (for another command or an entire session) assume the identity of another account. If no user is specified, the command will be for root ( su - ). It is necessary to know the password of the user whose identity is being endorsed unless it is root that is executing the command. An administrator can thus work on a standard user account and use the rights of the root account only occasionally.","title":"Profile loading"},{"location":"books/admin_guide/07-file-systems/","text":"File System In this chapter you will learn how to work with filesystems. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: manage partitions on disk; :heavy_check_mark: use LVM for a better use of disk resources; :heavy_check_mark: provide users with a filesystem and manage the access rights. and also discover: :heavy_check_mark: how the tree structure is organized in Linux; :heavy_check_mark: the different types of files offered and how to work with them; :checkered_flag: hardware , disk , partition , lvm , linux Knowledge : :star: :star: Complexity : :star: :star: Reading time : 20 minutes Partitioning Partitioning will allow the installation of several operating systems because it is impossible to have several of them cohabit on the same logical drive. Partitioning also allows the separation of data logically (security, access optimization, ...). The division of the physical disk into partitioned volumes is recorded in the partition table, stored in the first sector of the disk (MBR: Master Boot Record ). The same physical disk can be divided into a maximum of 4 partitions: Primary (or main) Extended !!! Warning There can be only one extended partition per physical disk. In order to benefit from additional drives, the extended partition can be split into logical partitions The devices are the files identifying the various hardware detected by the motherboard. These files are stored without /dev . The service which detects new devices and gives them names is called udev . They are identified by their type. Storage devices are named hd for IDE hard drives and sd for other media. Then comes a letter that starts with a for the first device, then b , c , ... Finally we will find a number that defines the partitioned volume: 1 for the first primary partition, ... !!! Warning Beware, the extended partition, which does not support a file system, still has a number. There are at least two commands for partitioning a disk: fdisk and cfdisk . Both commands have an interactive menu. cfdisk is more reliable and better optimized, so it is best to use it. The only reason to use fdisk is when you want to list all logical devices with the -l option. sudo fdisk -l sudo fdisk -l /dev/sdc sudo fdisk -l /dev/sdc2 parted command The parted ( partition editor ) command is able to partition a disk. parted [-l] [device] It also has a recovery function capable of rewriting a deleted partition table. Under graphical interface, there is the very complete gparted tool: G nome PAR tition ED itor. The gparted -l command lists all logical devices on a computer. The gparted command alone will return to an interactive mode with its own internal options: help or an incorrect command will display these options. print all in this mode will have the same result as gparted -l on the command line. quit to return to the prompt. cfdisk command The cfdisk command is used to manage partitions. cfdisk device Example: $ sudo cfdisk /dev/sda Disk: /dev/sda Size: 16 GiB, 17179869184 bytes, 33554432 sectors Label: dos, identifier: 0xcf173747 Device Boot Start End Sectors Size Id Type >> /dev/sda1 * 2048 2099199 2097152 1G 83 Linux /dev/sda2 2099200 33554431 31455232 15G 8e Linux LVM lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk x Partition type: Linux (83) x x Attributes: 80 x xFilesystem UUID: 54a1f5a7-b8fa-4747-a87c-2dd635914d60 x x Filesystem: xfs x x Mountpoint: /boot (mounted) x mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj [Bootable] [ Delete ] [ Resize ] [ Quit ] [ Type ] [ Help ] [ Write ] [ Dump ] The preparation, without LVM , of the physical media goes through five steps: Setting up the physical disk; Partitioning of the volumes (geographical division of the disk, possibility of installing several systems, ...); Creation of the file systems (allows the operating system to manage the files, the tree structure, the rights, ...); Mounting of file systems (registration of the file system in the tree structure); Manage user access. Logical Volume Manager (LVM) L ogical V olume M anager ( LVM] ) Volume management creates an abstract layer on top of physical storage, offering advantages over using physical storage directly: More flexible disk capacity; Online data movement; Disks in stripe mode; Mirrored volumes (recopy); Volume snapshots ( snapshot ). The disadvantage is that if one of the physical volumes becomes out of order, then all the logical volumes that use this physical volume are lost. You will have to use LVM on raid disks. LVM is available under Linux from kernel version 2.4. !!! Note LVM is only managed by the operating system. Therefore the _BIOS_ needs at least one partition without LVM to boot. Volume groups The physical volumes PV Physical Volumes (from partitions) are combined into volume groups VG . Each VG represents disk space that can be partitioned into LV Logical Volumes . Extension is the smallest unit of fixed-size space that can be allocated. PE : Physical Extension LE : Logical Extension Logical volumes A volume group, VG , is divided into logical volumes, LV , offering different operating modes: Linear volumes; Volumes in stripe mode; Mirrored volumes. !!! Tip Striping_ improves performance by writing data to a predetermined number of physical volumes with a _round-robin_ technique. LVM commands for volume management pvcreate command The pvcreate command is used to create physical volumes. It turns Linux partitions (or disks) into physical volumes. pvcreate [-options] partition Example: [root]# pvcreate /dev/hdb1 pvcreate -- physical volume \u00ab /dev/hdb1 \u00bb successfully created You can also use a whole disk (which facilitates disk size increases in virtual environments for example). [root]# pvcreate /dev/hdb pvcreate -- physical volume \u00ab /dev/hdb \u00bb successfully created Option Description -f Forces the creation of the volume (disk already transformed into physical volume). vgcreate command The vgcreate command is used to create volume groups. It groups one or more physical volumes into a volume group. vgcreate volume physical_volume [PV...] Example: [root]# vgcreate volume1 /dev/hdb1 \u2026 vgcreate \u2013 volume group \u00ab volume1 \u00bb successfully created and activated lvcreate command The lvcreate command creates logical volumes. The file system is then created on these logical volumes. lvcreate -L size [-n name] VG_name Example: [root]# lvcreate \u2013L 600M \u2013n VolLog1 volume1 lvcreate -- logical volume \u00ab /dev/volume1/VolLog1 \u00bb successfully created Option Description -L size Logical volume size in K, M or G. -n name LV name. Special file created in /dev/name_volume with this name. LVM commands to view volume information pvdisplay command The pvdisplay command allows you to view information about the physical volumes. pvdisplay /dev/PV_name Example: [root]# pvdisplay /dev/PV_name vgdisplay command The vgdisplay command allows you to view information about volume groups. vgdisplay VG_name Example: [root]# vgdisplay volume1 lvdisplay command The lvdisplay command allows you to view information about the logical volumes. lvdisplay /dev/VG_name/LV_name Example: [root]# lvdisplay /dev/volume1/VolLog1 Preparation of the physical media The preparation with LVM of the physical support is broken down as follows: Setting up the physical disk Partitioning of the volumes LVM physical volume LVM volume groups LVM logical volumes Creating file systems Mounting file systems Manage user access Structure of a file system A file system FS is in charge of the following actions: Securing access and modification rights to files; Manipulating files: create, read, modify and delete; Locating files on the disk; Managing partition space. The Linux operating system is able to use different file systems (ext2, ext3, ext4, FAT16, FAT32, NTFS, HFS, BtrFS, JFS, XFS, ...). mkfs command The mkfs command allows you to create a Linux file system. mkfs [-t fstype] filesys Example: [root]# mkfs -t ext4 /dev/sda1 Option Description -t Indicates the type of file system to use. !!! Warning Without a file system it is not possible to use the disk space. Each file system has a structure which is identical on each partition. A boot block and a super block initialized by the system and then an inode table and a data area initialized by the administrator. !!! Note The only exception is the **swap** partition. Boot block The boot block occupies the first block on the disk and is present on all partitions. It contains the program that starts and initializes the system and is therefore only filled in for the boot partition. Super block The size of the super block table is defined at creation. It is present on each partition and contains the elements necessary for its utilization. It describes the File System: Name of the Logical Volume; Name of the File System; Type of the File System; File System Status; Size of the File System; Number of free blocks; Pointer to the beginning of the list of free blocks; Size of the inode list; Number and list of free inodes. A copy is loaded in the central memory as soon as the system is initialized. This copy is updated as soon as it is modified and the system saves it periodically (command sync ). When the system stops, it also copies this table in memory to its block. Table of inodes The size of the inode table is defined at its creation and is stored on the partition. It consists of records, called inodes, corresponding to the files created. Each record contains the addresses of the data blocks making up the file. !!! Note An inode number is unique within a file system. A copy is loaded in the central memory as soon as the system is initialized. This copy is updated as soon as it is modified and the system saves it periodically (command sync ). When the system stops, it also copies this table in memory to its block. A file is managed by its inode number. !!! Note The size of the inode table determines the maximum number of files the FS can contain. Information present in the inode table : Inode number; File type and access permissions; Owner identification number; Identification number of the owner group; Number of links on this file; Size of the file in bytes; Date the file was last accessed; Date the file was last modified; Date of the last modification of the inode (= creation); Table of several pointers (block table) to the logical blocks containing the pieces of the file. Data area Its size corresponds to the rest of the available space of the partition. This area contains the catalogs corresponding to each directory and the data blocks corresponding to the contents of the files. In order to guarantee the consistency of the file system , an image of the superblock and the inode table is loaded into memory (RAM) when the operating system is loaded so that all I/O operations are done through these system tables. When the user creates or modifies files, this memory image is updated first. The operating system must therefore regularly update the superblock of the logical disk ( sync command). These tables are written to the hard disk when the system is shut down. !!! Danger In the event of a sudden stop, the file system may lose its consistency and cause data loss. Repairing the file system It is possible to check the consistency of a file system with the fsck command. In case of errors, solutions are proposed to repair the inconsistencies. After repair, files that remain without entries in the inode table are attached to the /lost+found folder of the logical drive. fsck command The fsck command is a console-mode integrity check and repair tool for Linux file systems. fsck [-sACVRTNP] [ -t fstype ] filesys Example: [root]# fsck /dev/sda1 To check the root partition, it is possible to create a forcefsck file and reboot or run shutdown with the -F option. [root]# touch /forcefsck [root]# reboot or [root]# shutdown \u2013r -F now !!! Warning The partition to be checked must be unmounted. Organization of a file system By definition, a File System is a tree structure of directories built from a root directory (a logical device can only contain one file system). !!! Note In Linux everything is a file. Text document, directory, binary, partition, network resource, screen, keyboard, Unix kernel, user program, ... Linux meets the FHS ( Filesystems Hierarchy Standard ) (see man hier ) which defines the names of folders and their roles. Directory Observation Abbreviation of / Contains special directories /boot Files related to system startup /sbin Commands necessary for system startup and repair system binaries /bin Executables of basic system commands binaries /usr/bin System administration commands /lib Shared libraries and kernel modules libraries /usr Everything that is not necessary for minimal system operation UNIX System Resources /mnt For mounting temporary SF mount /media For mounting removable media /root Administrator's login directory /home User data /tmp Temporary files temporary /dev Special device files device /etc Configuration and script files editable text configuration /opt Specific to installed applications optional /proc Virtual file system representing different processes processes /var Miscellaneous variable files variables To perform a mount or unmount, at the tree level, you must not be under its mount point. Mounting on a non-empty directory does not delete the content. It is only hidden. Only the administrator can perform mounts. Mount points to be automatically mounted at boot time must be entered in /etc/fstab . /etc/fstab file The /etc/fstab file is read at system startup and contains the mounts to be performed. Each file system to be mounted is described on a single line, the fields being separated by spaces or tabs. !!! Note Lines are read sequentially (`fsck`, `mount`, `umount`). /dev/mapper/VolGroup-lv_root / ext4 defaults 1 1 UUID=46\u2026.92 /boot ext4 defaults 1 2 /dev/mapper/VolGroup-lv_swap swap swap defaults 0 0 tmpfs /dev/shm tmpfs defaults 0 0 devpts /dev/pts devpts gid=5,mode=620 0 0 sysfs /sys sysfs defaults 0 0 proc /proc proc defaults 0 0 1 2 3 4 5 6 Column Description 1 File system device ( /dev/sda1 , UUID=..., ...) 2 Mount point name, absolute path (except swap ) 3 Filesystem type (ext4, swap, ...) 4 Special options for mounting ( defaults , ro , ...) 5 Enable or disable backup management (0:not backed up, 1:backed up) 6 Check order when checking the SF with the fsck command (0:no check, 1:priority, 2:not priority) The mount -a command allows new mounts to be taken into account without rebooting. They are then written to the /etc/mtab file which contains the current mounts. !!! Warning Only the mount points listed in `/etc/fstab` will be mounted on reboot. It is possible to make a copy of the /etc/mtab file or to copy its contents to /etc/fstab . Mount management commands mount command The mount command allows you to mount and view the logical drives in the tree. mount [-option] [device] [directory] Example: [root]# mount /dev/sda7 /home Option Description -n Mount without writing to /etc/mtab . -t To indicate the type of file system to use. -a Mounts all filesystems mentioned in /etc/fstab . -r Mounts the file system read-only (equivalent to -o ro ). -w Mounts the file system read/write, by default (equivalent -o rw ). -o Argument followed by a comma-separated list of options ( remount , ro , ...). !!! Note The `mount` command alone displays all mounted file systems. umount command The umount command is used to unmount logical drives. umount [-option] [device] [directory] Example: [root]# umount /home [root]# umount /dev/sda7 Option Description -n Unmount without writing to /etc/mtab . -r If unmount fails, remount as read-only. -f Force unmount. -a Unmount all filesystems mentioned in /etc/fstab . !!! Note When disassembling, you must not stay below the mounting point. Otherwise, the following error message is displayed: `device is busy`. Types of files As in any system, in order to be able to find one's way through the tree structure and the file management, it is important to respect the file naming rules. Files are coded on 255 characters; All ASCII characters can be used; Uppercase and lowercase letters are differentiated; No notion of extension. Groups of words separated by spaces must be enclosed in quotation marks: [root]# mkdir \"working dir\" !!! Note While there is nothing technically wrong with creating a file or directory with a space in it, it is generally a \"best practice\" to avoid this and replace any space with an underscore. !!! Note The **.** at the beginning of the file name only serves to hide it from a simple `ls`. !!! Warning Under Linux, the extension of a file is not a necessary reference to open or modify it. However, it can be useful for the user. Examples of extension agreements: .c : source file in C language; .h : C and Fortran header file; .o : object file in C language; .tar : data file archived with the tar utility; .cpio : data file archived with the cpio utility; .gz : data file compressed with the gzip utility; .tgz : data file archived with the tar utility and compressed with the gzip utility; .html : web page. Details of a file name [root]# ls -liah /usr/bin/passwd 266037 -rwsr-xr-x 1 root root 59K mars 22 2019 /usr/bin/passwd 1 2 3 4 5 6 7 8 9 Row Description 1 Inode number 2 File type (1st character of the block of 10) 3 Access rights (last 9 characters of the block of 10) 4 Number of links (ordinary) or subdirectories (directories) 5 Name of the owner 6 Name of the group 7 Size (byte, kilo, mega) 8 Date of last update 9 Name of the file Different types of files The following types of files can be found on a system: Ordinary (text, binary, ...); Directories; Special (printers, screens, ...); Links; Communications (tubes and socket). Ordinary files These are text, program (source), executable (after compilation) or data (binary, ASCII) and multimedia files. [root]# ls -l myfile -rwxr-xr-x 1 root root 26 nov 31 15:21 myfile The dash - at the beginning of the rights group (10-character block) indicates that it is an ordinary file type. Directory files Directory files contain references to other files. By default in each directory are present . and .. . The . represents the position in the tree. The .. represents the father of the current position. [root]# ls -l mydirectory drwxr-xr-x 1 root root 26 nov 31 15:21 mydirectory The letter d at the beginning of the rights group indicates that it is a directory type file. Special files In order to communicate with peripherals (hard disks, printers, ...), Linux uses interface files called special files ( device file or special file ). They allow identification by the peripherals. These files are special because they do not contain data but specify the access mode to communicate with the device. They are defined in two modes: block mode; character mode. Block mode The special block mode file allows, using the system buffers, to transfer data to the device. [root]# ls -l /dev/sda brw------- 1 root root 8, 0 jan 1 1970 /dev/sda The letter b at the beginning of the rights group indicates that it is a special file block . Character mode The special character mode file is used to transfer data to the device as a stream of one character at a time without using a buffer. These are devices like printer, screen or DAT tapes, ... The standard output is the screen. [root]# ls -l /dev/tty0 crw------- 1 root root 8, 0 jan 1 1970 /dev/tty0 The letter c at the beginning of the rights group indicates that it is a special character file. Communication files These are the pipe ( pipes ) and the socket files. Pipe files pass information between processes by FIFO ( First In, First Out ). One process writes transient information to a pipe file and another reads it. After reading, the information is no longer accessible. Socket files allow bidirectional inter-process communication (on local or remote systems). They use an inode of the file system. Link files These files give the possibility to give several logical names to the same physical file. A new access point to the file is therefore created. There are two types of link files: Physical links; Symbolic links. Physical link The link file and the source file have the same inode number and the link counter is incremented. It is not possible to link different directories or files from different file systems. !!! Warning If the source file is destroyed, the counter is decremented and the link file still accesses the file. Command ln for a physical link The ln command allows you to create physical links. [root]# ls \u2013li letter 666 \u2013rwxr--r-- 1 root root \u2026 letter [root]# ln /home/paul/letter /home/jack/read [root]# ls \u2013li /home/*/* 666 \u2013rwxr--r-- 2 root root \u2026 letter 666 \u2013rwxr--r-- 2 root root \u2026 read Symbolic link Unlike the physical link, the symbolic link involves the creation of a new inode . At the symbolic link level, only a path is stored in the inode table. The file created contains only an indication of the path to the file. This notion no longer has the limitations of physical links and it is now possible to link directories and files belonging to different file systems. !!! Warning If the source file is destroyed, the link file can no longer access the file. ln command for a symbolic link The command ln with the argument -s allows to create symbolic links. [root]# ls \u2013li letter 666 -rwxr--r-- 1 root root \u2026 letter [root]# ln -s /home/paul/letter /tmp/read [root]# ls \u2013li /home/paul/letter /tmp/read 666 -rwxr--r--- 1 root root \u2026 letter 678 lrwxrwxrwx 1 root root \u2026 read -> letter File attributes Linux is a multi-user operating system where the control of access to files is essential. These controls are functions of: file access permissions ; users ( ugo Users Groups Others ). The command ls -l allows to display the attributes. There are 4 file access rights: r ead; w rite; e x ecution; - no right. !!! Warning The rights associated with files differ from those associated with directories (see below). The user types associated with file access rights are: u ser_ (owner) ; g roup_ (owner group); o thers (others users); In some commands it is possible to designate everyone with a ( all ). a = ugo Rights associated with ordinary files r ead: Allows reading a file ( cat , less , ...) and copying a file ( cp , ...). w rite: Allows modification of the file content ( cat , >> , vim , ...). e x ecute: Considers the file as an e X ecutable (binary or script). - : No permissions. !!! Note Moving or renaming a file depends on the rights of the target directory. Deleting a file depends on the rights of the parent directory. Rights associated with directories r ead: Allows reading the contents of a directory ( ls -R ). w rite: Allows modification of the contents of a directory ( touch ) and allows creation and deletion of files if the x permission is enabled. e x ecute: Allows descending in the directory ( cd ). - : No rights. Attribute management The display of rights is done with the command ls -l . It is the last 9 characters of the block of 10. More precisely 3 times 3 characters. [root]# ls -l /tmp/myfile -rwxrw-r-x 1 root sys ... /tmp/myfile 1 2 3 4 5 Row Description 1 Owner ( u ser) permissions, here rwx 2 Owner group permissions ( g roup), here rw- 3 Other users' permissions ( o thers), here r-x 4 File owner 5 Group owner of the file !!! Note Permissions apply to **u**ser, **g**roup and **o**ther (**ugo**) depending on the owner and group. By default, the owner of a file is the one who creates it. The group of the file is the group of the owner who created the file. The others are those which are not concerned by the previous cases. The attributes are changed with the chmod command. Only the administrator and the owner of a file can change the rights of a file. chmod command The chmod command allows you to change the access permissions to a file. chmod [option] mode file The mode indication can be an octal representation (e.g. 744 ) or a symbolic representation ([ ugoa ][ +=- ][ rwxst ]). Several symbolic operations can be separated by commas Example: [root]# chmod -R u+rwx,g+wx,o-r /tmp/file1 [root]# chmod g=x,o-r /tmp/file2 [root]# chmod -R o=r /tmp/file3 [root]# ls -l /tmp/fic* -rwxrwx--- 1 root root \u2026 /tmp/file1 -rwx--x--- 1 root root \u2026 /tmp/file2 -rwx--xr-- 1 root root \u2026 /tmp/file3 [root]# chmod 741 /tmp/file1 [root]# chmod -R 744 /tmp/file2 [root]# ls -l /tmp/fic* -rwxr----x 1 root root \u2026 /tmp/file1 -rwxr--r-- 1 root root \u2026 /tmp/file2 Option Observation -R Recursively modify the permissions of directories and their contents. There are two methods for making rights changes: The octal method; The symbolic method. !!! Warning The rights of files and directories are not dissociated. For some operations, it will be necessary to know the rights of the directory containing the file. A write-protected file can be deleted by another user as long as the rights of the directory containing it allow this user to perform this operation. Principle of the octal method Each right has a value. [root]# ls -l /tmp/myfile -rwxrwxrwx 1 root root ... /tmp/myfile [root]# chmod 741 /tmp/myfile -rwxr----x 1 root root ... /tmp/myfile Principle of the symbolic method This method can be considered as a \"literal\" association between a user type, an operator, and rights. [root]# chmod u+rwx,g+wx,o-r /tmp/myfile [root]# chmod g=x,o-r /tmp/myfile [root]# chmod o=r /tmp/myfile [root]# ls -l /tmp/myfile r--r-- 1 root root \u2026 /tmp/myfile [root]# chmod u+rwx,g+wx,o-r /tmp/myfile [root]# ls -l /tmp/myfile -rwxrwx--- 1 root root \u2026 /tmp/myfile Special rights In addition to the fundamental rights ( rwx ), there are the particular rights: set-user-ID ( SUID] ) set-group-ID ( SGID] ) sticky-bit As with the fundamental rights, the particular rights each have a value. This value is placed before the ugo set of rights. !!! Danger `S`, `S` and `T` in capital letters **if the right does not exist**. The sticky-bit One of the peculiarities of rights in Linux is that the right to write to a directory also allows deletion of all files, owner or not. The sticky-bit set on the directory will only allow users to delete files they own. This is the basic case for the /tmp directory. The setting of the sticky-bit can be done as follows: Octal method: [root]# chmod 1777 directory Symbolic method: [root]# chmod o+t directory Verification: [root]# ls -l drwxrwxrwt \u2026 directory SUID and SGID on a command These rights allow execution of a command according to the rights set on the command, and not according to the user's rights. The command is executed with the identity of the owner ( SUID ) or the group ( SGID ) of the command. !!! Note The identity of the user requesting the execution of the order is no longer taken into account. This is an additional possibility of access rights assigned to a user when it is necessary for them to have the same rights as the owner of a file or those of the group concerned. Indeed, a user may have to run a program (usually a system utility) but not have the necessary access rights. By setting the appropriate rights ( s at the owner level and/or at the group level), the user of the program has, for the time of its execution, the identity of the owner (or that of the group) of the program. Example: The file /usr/bin/passwd is an executable file (a command) with a SUID . When the user bob runs it, he will have to access the /etc/shadow file, but the permissions on this file do not allow bob to access it. Having a SUID this command, /usr/bin/passwd , will be executed with the UID of root and the GID of root . The latter being the owner of the /etc/shadow file, he will have read rights. The setting of SUID and SGID can be done as below with the command chmod : Octal method: [root]# chmod 4777 command1 [root]# chmod 2777 command2 Symbolic method: [root]# chmod u+s command1 [root]# chmod g+s command2 Verification: [root]# ls -l -rwsrwxrwx \u2026 command1 -rwxrwsrwx \u2026 command2 !!! Warning It is not possible to pass the _SUID_ or _SGID_ to a shell script. The system does not allow it because it is too dangerous for security! SGID on a file In a directory with the SGID right, any file created will inherit the group that owns the directory instead of that of the creating user. Example: [rockstar] $ ls -ld /data/ drwxrwsr-x 2 root users 4096 26 oct. 19:43 /data [rockstar] $ touch /data/test_sgid /tmp/fic_reference [rockstar] $ ls -ld /data/test_sgid /tmp/fic_reference -rw-r--r--. 1 rockstar users 0 26 oct. 19:43 /data/test_sgid <1> -rw-r--r--. 1 rockstar rockstar 0 26 oct. 19:43 /tmp/fic_ref <1> The test_sgid file inherits the group owner of its /data folder (in this case users ) whatever the main group of the rockstar user is. Default rights and mask When a file or directory is created, it already has permissions. For a directory: rwxr-xr-x or 755 . For a file: rw-r-r- or 644 . This behavior is defined by the default mask . The principle is to remove the value defined by the mask at maximum rights without the execution right. For a directory : For a file, the execution rights are removed: umask command The umask command allows you to display and modify the mask. umask [option] [mode] Example: $ umask 033 $ umask 0033 $ umask -S u=rwx,g=r,o=r $ touch umask_033 $ ls -la umask_033 -rw-r--r-- 1 rockstar rockstar 0 nov. 4 16:44 umask_033 $ umask 025 $ umask -S u=rwx,g=rx,o=w $ touch umask_025 $ ls -la umask_025 -rw-r---w- 1 rockstar rockstar 0 nov. 4 16:44 umask_025 Option Description -S Symbolic display of file rights. !!! Warning `umask` does not affect existing files. !!! Note `umask` modifies the mask until the disconnection. To keep the value, you have to modify the following profile files: For all users: /etc/profile /etc/bashrc For a particular user: ~/.bashrc !!! Warning `umask -S` displays the file rights (without the execute right) of the files that will be created. So it is not the display of the mask used to subtract the maximum value. !!! Tip The `umask` command being a _bash_ command, (a `type umask` returns `umask is a shell primitive`) you have to search `umask` in `man bash`.","title":"File System"},{"location":"books/admin_guide/07-file-systems/#file-system","text":"In this chapter you will learn how to work with filesystems. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: manage partitions on disk; :heavy_check_mark: use LVM for a better use of disk resources; :heavy_check_mark: provide users with a filesystem and manage the access rights. and also discover: :heavy_check_mark: how the tree structure is organized in Linux; :heavy_check_mark: the different types of files offered and how to work with them; :checkered_flag: hardware , disk , partition , lvm , linux Knowledge : :star: :star: Complexity : :star: :star: Reading time : 20 minutes","title":"File System"},{"location":"books/admin_guide/07-file-systems/#partitioning","text":"Partitioning will allow the installation of several operating systems because it is impossible to have several of them cohabit on the same logical drive. Partitioning also allows the separation of data logically (security, access optimization, ...). The division of the physical disk into partitioned volumes is recorded in the partition table, stored in the first sector of the disk (MBR: Master Boot Record ). The same physical disk can be divided into a maximum of 4 partitions: Primary (or main) Extended !!! Warning There can be only one extended partition per physical disk. In order to benefit from additional drives, the extended partition can be split into logical partitions The devices are the files identifying the various hardware detected by the motherboard. These files are stored without /dev . The service which detects new devices and gives them names is called udev . They are identified by their type. Storage devices are named hd for IDE hard drives and sd for other media. Then comes a letter that starts with a for the first device, then b , c , ... Finally we will find a number that defines the partitioned volume: 1 for the first primary partition, ... !!! Warning Beware, the extended partition, which does not support a file system, still has a number. There are at least two commands for partitioning a disk: fdisk and cfdisk . Both commands have an interactive menu. cfdisk is more reliable and better optimized, so it is best to use it. The only reason to use fdisk is when you want to list all logical devices with the -l option. sudo fdisk -l sudo fdisk -l /dev/sdc sudo fdisk -l /dev/sdc2","title":"Partitioning"},{"location":"books/admin_guide/07-file-systems/#parted-command","text":"The parted ( partition editor ) command is able to partition a disk. parted [-l] [device] It also has a recovery function capable of rewriting a deleted partition table. Under graphical interface, there is the very complete gparted tool: G nome PAR tition ED itor. The gparted -l command lists all logical devices on a computer. The gparted command alone will return to an interactive mode with its own internal options: help or an incorrect command will display these options. print all in this mode will have the same result as gparted -l on the command line. quit to return to the prompt.","title":"parted command"},{"location":"books/admin_guide/07-file-systems/#cfdisk-command","text":"The cfdisk command is used to manage partitions. cfdisk device Example: $ sudo cfdisk /dev/sda Disk: /dev/sda Size: 16 GiB, 17179869184 bytes, 33554432 sectors Label: dos, identifier: 0xcf173747 Device Boot Start End Sectors Size Id Type >> /dev/sda1 * 2048 2099199 2097152 1G 83 Linux /dev/sda2 2099200 33554431 31455232 15G 8e Linux LVM lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk x Partition type: Linux (83) x x Attributes: 80 x xFilesystem UUID: 54a1f5a7-b8fa-4747-a87c-2dd635914d60 x x Filesystem: xfs x x Mountpoint: /boot (mounted) x mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj [Bootable] [ Delete ] [ Resize ] [ Quit ] [ Type ] [ Help ] [ Write ] [ Dump ] The preparation, without LVM , of the physical media goes through five steps: Setting up the physical disk; Partitioning of the volumes (geographical division of the disk, possibility of installing several systems, ...); Creation of the file systems (allows the operating system to manage the files, the tree structure, the rights, ...); Mounting of file systems (registration of the file system in the tree structure); Manage user access.","title":"cfdisk command"},{"location":"books/admin_guide/07-file-systems/#logical-volume-manager-lvm","text":"L ogical V olume M anager ( LVM] ) Volume management creates an abstract layer on top of physical storage, offering advantages over using physical storage directly: More flexible disk capacity; Online data movement; Disks in stripe mode; Mirrored volumes (recopy); Volume snapshots ( snapshot ). The disadvantage is that if one of the physical volumes becomes out of order, then all the logical volumes that use this physical volume are lost. You will have to use LVM on raid disks. LVM is available under Linux from kernel version 2.4. !!! Note LVM is only managed by the operating system. Therefore the _BIOS_ needs at least one partition without LVM to boot.","title":"Logical Volume Manager (LVM)"},{"location":"books/admin_guide/07-file-systems/#volume-groups","text":"The physical volumes PV Physical Volumes (from partitions) are combined into volume groups VG . Each VG represents disk space that can be partitioned into LV Logical Volumes . Extension is the smallest unit of fixed-size space that can be allocated. PE : Physical Extension LE : Logical Extension","title":"Volume groups"},{"location":"books/admin_guide/07-file-systems/#logical-volumes","text":"A volume group, VG , is divided into logical volumes, LV , offering different operating modes: Linear volumes; Volumes in stripe mode; Mirrored volumes. !!! Tip Striping_ improves performance by writing data to a predetermined number of physical volumes with a _round-robin_ technique.","title":"Logical volumes"},{"location":"books/admin_guide/07-file-systems/#lvm-commands-for-volume-management","text":"","title":"LVM commands for volume management"},{"location":"books/admin_guide/07-file-systems/#pvcreate-command","text":"The pvcreate command is used to create physical volumes. It turns Linux partitions (or disks) into physical volumes. pvcreate [-options] partition Example: [root]# pvcreate /dev/hdb1 pvcreate -- physical volume \u00ab /dev/hdb1 \u00bb successfully created You can also use a whole disk (which facilitates disk size increases in virtual environments for example). [root]# pvcreate /dev/hdb pvcreate -- physical volume \u00ab /dev/hdb \u00bb successfully created Option Description -f Forces the creation of the volume (disk already transformed into physical volume).","title":"pvcreate command"},{"location":"books/admin_guide/07-file-systems/#vgcreate-command","text":"The vgcreate command is used to create volume groups. It groups one or more physical volumes into a volume group. vgcreate volume physical_volume [PV...] Example: [root]# vgcreate volume1 /dev/hdb1 \u2026 vgcreate \u2013 volume group \u00ab volume1 \u00bb successfully created and activated","title":"vgcreate command"},{"location":"books/admin_guide/07-file-systems/#lvcreate-command","text":"The lvcreate command creates logical volumes. The file system is then created on these logical volumes. lvcreate -L size [-n name] VG_name Example: [root]# lvcreate \u2013L 600M \u2013n VolLog1 volume1 lvcreate -- logical volume \u00ab /dev/volume1/VolLog1 \u00bb successfully created Option Description -L size Logical volume size in K, M or G. -n name LV name. Special file created in /dev/name_volume with this name.","title":"lvcreate command"},{"location":"books/admin_guide/07-file-systems/#lvm-commands-to-view-volume-information","text":"","title":"LVM commands to view volume information"},{"location":"books/admin_guide/07-file-systems/#pvdisplay-command","text":"The pvdisplay command allows you to view information about the physical volumes. pvdisplay /dev/PV_name Example: [root]# pvdisplay /dev/PV_name","title":"pvdisplay command"},{"location":"books/admin_guide/07-file-systems/#vgdisplay-command","text":"The vgdisplay command allows you to view information about volume groups. vgdisplay VG_name Example: [root]# vgdisplay volume1","title":"vgdisplay command"},{"location":"books/admin_guide/07-file-systems/#lvdisplay-command","text":"The lvdisplay command allows you to view information about the logical volumes. lvdisplay /dev/VG_name/LV_name Example: [root]# lvdisplay /dev/volume1/VolLog1","title":"lvdisplay command"},{"location":"books/admin_guide/07-file-systems/#preparation-of-the-physical-media","text":"The preparation with LVM of the physical support is broken down as follows: Setting up the physical disk Partitioning of the volumes LVM physical volume LVM volume groups LVM logical volumes Creating file systems Mounting file systems Manage user access","title":"Preparation of the physical media"},{"location":"books/admin_guide/07-file-systems/#structure-of-a-file-system","text":"A file system FS is in charge of the following actions: Securing access and modification rights to files; Manipulating files: create, read, modify and delete; Locating files on the disk; Managing partition space. The Linux operating system is able to use different file systems (ext2, ext3, ext4, FAT16, FAT32, NTFS, HFS, BtrFS, JFS, XFS, ...).","title":"Structure of a file system"},{"location":"books/admin_guide/07-file-systems/#mkfs-command","text":"The mkfs command allows you to create a Linux file system. mkfs [-t fstype] filesys Example: [root]# mkfs -t ext4 /dev/sda1 Option Description -t Indicates the type of file system to use. !!! Warning Without a file system it is not possible to use the disk space. Each file system has a structure which is identical on each partition. A boot block and a super block initialized by the system and then an inode table and a data area initialized by the administrator. !!! Note The only exception is the **swap** partition.","title":"mkfs command"},{"location":"books/admin_guide/07-file-systems/#boot-block","text":"The boot block occupies the first block on the disk and is present on all partitions. It contains the program that starts and initializes the system and is therefore only filled in for the boot partition.","title":"Boot block"},{"location":"books/admin_guide/07-file-systems/#super-block","text":"The size of the super block table is defined at creation. It is present on each partition and contains the elements necessary for its utilization. It describes the File System: Name of the Logical Volume; Name of the File System; Type of the File System; File System Status; Size of the File System; Number of free blocks; Pointer to the beginning of the list of free blocks; Size of the inode list; Number and list of free inodes. A copy is loaded in the central memory as soon as the system is initialized. This copy is updated as soon as it is modified and the system saves it periodically (command sync ). When the system stops, it also copies this table in memory to its block.","title":"Super block"},{"location":"books/admin_guide/07-file-systems/#table-of-inodes","text":"The size of the inode table is defined at its creation and is stored on the partition. It consists of records, called inodes, corresponding to the files created. Each record contains the addresses of the data blocks making up the file. !!! Note An inode number is unique within a file system. A copy is loaded in the central memory as soon as the system is initialized. This copy is updated as soon as it is modified and the system saves it periodically (command sync ). When the system stops, it also copies this table in memory to its block. A file is managed by its inode number. !!! Note The size of the inode table determines the maximum number of files the FS can contain. Information present in the inode table : Inode number; File type and access permissions; Owner identification number; Identification number of the owner group; Number of links on this file; Size of the file in bytes; Date the file was last accessed; Date the file was last modified; Date of the last modification of the inode (= creation); Table of several pointers (block table) to the logical blocks containing the pieces of the file.","title":"Table of inodes"},{"location":"books/admin_guide/07-file-systems/#data-area","text":"Its size corresponds to the rest of the available space of the partition. This area contains the catalogs corresponding to each directory and the data blocks corresponding to the contents of the files. In order to guarantee the consistency of the file system , an image of the superblock and the inode table is loaded into memory (RAM) when the operating system is loaded so that all I/O operations are done through these system tables. When the user creates or modifies files, this memory image is updated first. The operating system must therefore regularly update the superblock of the logical disk ( sync command). These tables are written to the hard disk when the system is shut down. !!! Danger In the event of a sudden stop, the file system may lose its consistency and cause data loss.","title":"Data area"},{"location":"books/admin_guide/07-file-systems/#repairing-the-file-system","text":"It is possible to check the consistency of a file system with the fsck command. In case of errors, solutions are proposed to repair the inconsistencies. After repair, files that remain without entries in the inode table are attached to the /lost+found folder of the logical drive.","title":"Repairing the file system"},{"location":"books/admin_guide/07-file-systems/#fsck-command","text":"The fsck command is a console-mode integrity check and repair tool for Linux file systems. fsck [-sACVRTNP] [ -t fstype ] filesys Example: [root]# fsck /dev/sda1 To check the root partition, it is possible to create a forcefsck file and reboot or run shutdown with the -F option. [root]# touch /forcefsck [root]# reboot or [root]# shutdown \u2013r -F now !!! Warning The partition to be checked must be unmounted.","title":"fsck command"},{"location":"books/admin_guide/07-file-systems/#organization-of-a-file-system","text":"By definition, a File System is a tree structure of directories built from a root directory (a logical device can only contain one file system). !!! Note In Linux everything is a file. Text document, directory, binary, partition, network resource, screen, keyboard, Unix kernel, user program, ... Linux meets the FHS ( Filesystems Hierarchy Standard ) (see man hier ) which defines the names of folders and their roles. Directory Observation Abbreviation of / Contains special directories /boot Files related to system startup /sbin Commands necessary for system startup and repair system binaries /bin Executables of basic system commands binaries /usr/bin System administration commands /lib Shared libraries and kernel modules libraries /usr Everything that is not necessary for minimal system operation UNIX System Resources /mnt For mounting temporary SF mount /media For mounting removable media /root Administrator's login directory /home User data /tmp Temporary files temporary /dev Special device files device /etc Configuration and script files editable text configuration /opt Specific to installed applications optional /proc Virtual file system representing different processes processes /var Miscellaneous variable files variables To perform a mount or unmount, at the tree level, you must not be under its mount point. Mounting on a non-empty directory does not delete the content. It is only hidden. Only the administrator can perform mounts. Mount points to be automatically mounted at boot time must be entered in /etc/fstab .","title":"Organization of a file system"},{"location":"books/admin_guide/07-file-systems/#etcfstab-file","text":"The /etc/fstab file is read at system startup and contains the mounts to be performed. Each file system to be mounted is described on a single line, the fields being separated by spaces or tabs. !!! Note Lines are read sequentially (`fsck`, `mount`, `umount`). /dev/mapper/VolGroup-lv_root / ext4 defaults 1 1 UUID=46\u2026.92 /boot ext4 defaults 1 2 /dev/mapper/VolGroup-lv_swap swap swap defaults 0 0 tmpfs /dev/shm tmpfs defaults 0 0 devpts /dev/pts devpts gid=5,mode=620 0 0 sysfs /sys sysfs defaults 0 0 proc /proc proc defaults 0 0 1 2 3 4 5 6 Column Description 1 File system device ( /dev/sda1 , UUID=..., ...) 2 Mount point name, absolute path (except swap ) 3 Filesystem type (ext4, swap, ...) 4 Special options for mounting ( defaults , ro , ...) 5 Enable or disable backup management (0:not backed up, 1:backed up) 6 Check order when checking the SF with the fsck command (0:no check, 1:priority, 2:not priority) The mount -a command allows new mounts to be taken into account without rebooting. They are then written to the /etc/mtab file which contains the current mounts. !!! Warning Only the mount points listed in `/etc/fstab` will be mounted on reboot. It is possible to make a copy of the /etc/mtab file or to copy its contents to /etc/fstab .","title":"/etc/fstab file"},{"location":"books/admin_guide/07-file-systems/#mount-management-commands","text":"","title":"Mount management commands"},{"location":"books/admin_guide/07-file-systems/#mount-command","text":"The mount command allows you to mount and view the logical drives in the tree. mount [-option] [device] [directory] Example: [root]# mount /dev/sda7 /home Option Description -n Mount without writing to /etc/mtab . -t To indicate the type of file system to use. -a Mounts all filesystems mentioned in /etc/fstab . -r Mounts the file system read-only (equivalent to -o ro ). -w Mounts the file system read/write, by default (equivalent -o rw ). -o Argument followed by a comma-separated list of options ( remount , ro , ...). !!! Note The `mount` command alone displays all mounted file systems.","title":"mount command"},{"location":"books/admin_guide/07-file-systems/#umount-command","text":"The umount command is used to unmount logical drives. umount [-option] [device] [directory] Example: [root]# umount /home [root]# umount /dev/sda7 Option Description -n Unmount without writing to /etc/mtab . -r If unmount fails, remount as read-only. -f Force unmount. -a Unmount all filesystems mentioned in /etc/fstab . !!! Note When disassembling, you must not stay below the mounting point. Otherwise, the following error message is displayed: `device is busy`.","title":"umount command"},{"location":"books/admin_guide/07-file-systems/#types-of-files","text":"As in any system, in order to be able to find one's way through the tree structure and the file management, it is important to respect the file naming rules. Files are coded on 255 characters; All ASCII characters can be used; Uppercase and lowercase letters are differentiated; No notion of extension. Groups of words separated by spaces must be enclosed in quotation marks: [root]# mkdir \"working dir\" !!! Note While there is nothing technically wrong with creating a file or directory with a space in it, it is generally a \"best practice\" to avoid this and replace any space with an underscore. !!! Note The **.** at the beginning of the file name only serves to hide it from a simple `ls`. !!! Warning Under Linux, the extension of a file is not a necessary reference to open or modify it. However, it can be useful for the user. Examples of extension agreements: .c : source file in C language; .h : C and Fortran header file; .o : object file in C language; .tar : data file archived with the tar utility; .cpio : data file archived with the cpio utility; .gz : data file compressed with the gzip utility; .tgz : data file archived with the tar utility and compressed with the gzip utility; .html : web page.","title":"Types of files"},{"location":"books/admin_guide/07-file-systems/#details-of-a-file-name","text":"[root]# ls -liah /usr/bin/passwd 266037 -rwsr-xr-x 1 root root 59K mars 22 2019 /usr/bin/passwd 1 2 3 4 5 6 7 8 9 Row Description 1 Inode number 2 File type (1st character of the block of 10) 3 Access rights (last 9 characters of the block of 10) 4 Number of links (ordinary) or subdirectories (directories) 5 Name of the owner 6 Name of the group 7 Size (byte, kilo, mega) 8 Date of last update 9 Name of the file","title":"Details of a file name"},{"location":"books/admin_guide/07-file-systems/#different-types-of-files","text":"The following types of files can be found on a system: Ordinary (text, binary, ...); Directories; Special (printers, screens, ...); Links; Communications (tubes and socket).","title":"Different types of files"},{"location":"books/admin_guide/07-file-systems/#ordinary-files","text":"These are text, program (source), executable (after compilation) or data (binary, ASCII) and multimedia files. [root]# ls -l myfile -rwxr-xr-x 1 root root 26 nov 31 15:21 myfile The dash - at the beginning of the rights group (10-character block) indicates that it is an ordinary file type.","title":"Ordinary files"},{"location":"books/admin_guide/07-file-systems/#directory-files","text":"Directory files contain references to other files. By default in each directory are present . and .. . The . represents the position in the tree. The .. represents the father of the current position. [root]# ls -l mydirectory drwxr-xr-x 1 root root 26 nov 31 15:21 mydirectory The letter d at the beginning of the rights group indicates that it is a directory type file.","title":"Directory files"},{"location":"books/admin_guide/07-file-systems/#special-files","text":"In order to communicate with peripherals (hard disks, printers, ...), Linux uses interface files called special files ( device file or special file ). They allow identification by the peripherals. These files are special because they do not contain data but specify the access mode to communicate with the device. They are defined in two modes: block mode; character mode.","title":"Special files"},{"location":"books/admin_guide/07-file-systems/#block-mode","text":"The special block mode file allows, using the system buffers, to transfer data to the device. [root]# ls -l /dev/sda brw------- 1 root root 8, 0 jan 1 1970 /dev/sda The letter b at the beginning of the rights group indicates that it is a special file block .","title":"Block mode"},{"location":"books/admin_guide/07-file-systems/#character-mode","text":"The special character mode file is used to transfer data to the device as a stream of one character at a time without using a buffer. These are devices like printer, screen or DAT tapes, ... The standard output is the screen. [root]# ls -l /dev/tty0 crw------- 1 root root 8, 0 jan 1 1970 /dev/tty0 The letter c at the beginning of the rights group indicates that it is a special character file.","title":"Character mode"},{"location":"books/admin_guide/07-file-systems/#communication-files","text":"These are the pipe ( pipes ) and the socket files. Pipe files pass information between processes by FIFO ( First In, First Out ). One process writes transient information to a pipe file and another reads it. After reading, the information is no longer accessible. Socket files allow bidirectional inter-process communication (on local or remote systems). They use an inode of the file system.","title":"Communication files"},{"location":"books/admin_guide/07-file-systems/#link-files","text":"These files give the possibility to give several logical names to the same physical file. A new access point to the file is therefore created. There are two types of link files: Physical links; Symbolic links.","title":"Link files"},{"location":"books/admin_guide/07-file-systems/#physical-link","text":"The link file and the source file have the same inode number and the link counter is incremented. It is not possible to link different directories or files from different file systems. !!! Warning If the source file is destroyed, the counter is decremented and the link file still accesses the file.","title":"Physical link"},{"location":"books/admin_guide/07-file-systems/#command-ln-for-a-physical-link","text":"The ln command allows you to create physical links. [root]# ls \u2013li letter 666 \u2013rwxr--r-- 1 root root \u2026 letter [root]# ln /home/paul/letter /home/jack/read [root]# ls \u2013li /home/*/* 666 \u2013rwxr--r-- 2 root root \u2026 letter 666 \u2013rwxr--r-- 2 root root \u2026 read","title":"Command ln for a physical link"},{"location":"books/admin_guide/07-file-systems/#symbolic-link","text":"Unlike the physical link, the symbolic link involves the creation of a new inode . At the symbolic link level, only a path is stored in the inode table. The file created contains only an indication of the path to the file. This notion no longer has the limitations of physical links and it is now possible to link directories and files belonging to different file systems. !!! Warning If the source file is destroyed, the link file can no longer access the file.","title":"Symbolic link"},{"location":"books/admin_guide/07-file-systems/#ln-command-for-a-symbolic-link","text":"The command ln with the argument -s allows to create symbolic links. [root]# ls \u2013li letter 666 -rwxr--r-- 1 root root \u2026 letter [root]# ln -s /home/paul/letter /tmp/read [root]# ls \u2013li /home/paul/letter /tmp/read 666 -rwxr--r--- 1 root root \u2026 letter 678 lrwxrwxrwx 1 root root \u2026 read -> letter","title":"ln command for a symbolic link"},{"location":"books/admin_guide/07-file-systems/#file-attributes","text":"Linux is a multi-user operating system where the control of access to files is essential. These controls are functions of: file access permissions ; users ( ugo Users Groups Others ). The command ls -l allows to display the attributes. There are 4 file access rights: r ead; w rite; e x ecution; - no right. !!! Warning The rights associated with files differ from those associated with directories (see below). The user types associated with file access rights are: u ser_ (owner) ; g roup_ (owner group); o thers (others users); In some commands it is possible to designate everyone with a ( all ). a = ugo","title":"File attributes"},{"location":"books/admin_guide/07-file-systems/#rights-associated-with-ordinary-files","text":"r ead: Allows reading a file ( cat , less , ...) and copying a file ( cp , ...). w rite: Allows modification of the file content ( cat , >> , vim , ...). e x ecute: Considers the file as an e X ecutable (binary or script). - : No permissions. !!! Note Moving or renaming a file depends on the rights of the target directory. Deleting a file depends on the rights of the parent directory.","title":"Rights associated with ordinary files"},{"location":"books/admin_guide/07-file-systems/#rights-associated-with-directories","text":"r ead: Allows reading the contents of a directory ( ls -R ). w rite: Allows modification of the contents of a directory ( touch ) and allows creation and deletion of files if the x permission is enabled. e x ecute: Allows descending in the directory ( cd ). - : No rights.","title":"Rights associated with directories"},{"location":"books/admin_guide/07-file-systems/#attribute-management","text":"The display of rights is done with the command ls -l . It is the last 9 characters of the block of 10. More precisely 3 times 3 characters. [root]# ls -l /tmp/myfile -rwxrw-r-x 1 root sys ... /tmp/myfile 1 2 3 4 5 Row Description 1 Owner ( u ser) permissions, here rwx 2 Owner group permissions ( g roup), here rw- 3 Other users' permissions ( o thers), here r-x 4 File owner 5 Group owner of the file !!! Note Permissions apply to **u**ser, **g**roup and **o**ther (**ugo**) depending on the owner and group. By default, the owner of a file is the one who creates it. The group of the file is the group of the owner who created the file. The others are those which are not concerned by the previous cases. The attributes are changed with the chmod command. Only the administrator and the owner of a file can change the rights of a file.","title":"Attribute management"},{"location":"books/admin_guide/07-file-systems/#chmod-command","text":"The chmod command allows you to change the access permissions to a file. chmod [option] mode file The mode indication can be an octal representation (e.g. 744 ) or a symbolic representation ([ ugoa ][ +=- ][ rwxst ]). Several symbolic operations can be separated by commas Example: [root]# chmod -R u+rwx,g+wx,o-r /tmp/file1 [root]# chmod g=x,o-r /tmp/file2 [root]# chmod -R o=r /tmp/file3 [root]# ls -l /tmp/fic* -rwxrwx--- 1 root root \u2026 /tmp/file1 -rwx--x--- 1 root root \u2026 /tmp/file2 -rwx--xr-- 1 root root \u2026 /tmp/file3 [root]# chmod 741 /tmp/file1 [root]# chmod -R 744 /tmp/file2 [root]# ls -l /tmp/fic* -rwxr----x 1 root root \u2026 /tmp/file1 -rwxr--r-- 1 root root \u2026 /tmp/file2 Option Observation -R Recursively modify the permissions of directories and their contents. There are two methods for making rights changes: The octal method; The symbolic method. !!! Warning The rights of files and directories are not dissociated. For some operations, it will be necessary to know the rights of the directory containing the file. A write-protected file can be deleted by another user as long as the rights of the directory containing it allow this user to perform this operation.","title":"chmod command"},{"location":"books/admin_guide/07-file-systems/#principle-of-the-octal-method","text":"Each right has a value. [root]# ls -l /tmp/myfile -rwxrwxrwx 1 root root ... /tmp/myfile [root]# chmod 741 /tmp/myfile -rwxr----x 1 root root ... /tmp/myfile","title":"Principle of the octal method"},{"location":"books/admin_guide/07-file-systems/#principle-of-the-symbolic-method","text":"This method can be considered as a \"literal\" association between a user type, an operator, and rights. [root]# chmod u+rwx,g+wx,o-r /tmp/myfile [root]# chmod g=x,o-r /tmp/myfile [root]# chmod o=r /tmp/myfile [root]# ls -l /tmp/myfile r--r-- 1 root root \u2026 /tmp/myfile [root]# chmod u+rwx,g+wx,o-r /tmp/myfile [root]# ls -l /tmp/myfile -rwxrwx--- 1 root root \u2026 /tmp/myfile","title":"Principle of the symbolic method"},{"location":"books/admin_guide/07-file-systems/#special-rights","text":"In addition to the fundamental rights ( rwx ), there are the particular rights: set-user-ID ( SUID] ) set-group-ID ( SGID] ) sticky-bit As with the fundamental rights, the particular rights each have a value. This value is placed before the ugo set of rights. !!! Danger `S`, `S` and `T` in capital letters **if the right does not exist**.","title":"Special rights"},{"location":"books/admin_guide/07-file-systems/#the-sticky-bit","text":"One of the peculiarities of rights in Linux is that the right to write to a directory also allows deletion of all files, owner or not. The sticky-bit set on the directory will only allow users to delete files they own. This is the basic case for the /tmp directory. The setting of the sticky-bit can be done as follows: Octal method: [root]# chmod 1777 directory Symbolic method: [root]# chmod o+t directory Verification: [root]# ls -l drwxrwxrwt \u2026 directory","title":"The sticky-bit"},{"location":"books/admin_guide/07-file-systems/#suid-and-sgid-on-a-command","text":"These rights allow execution of a command according to the rights set on the command, and not according to the user's rights. The command is executed with the identity of the owner ( SUID ) or the group ( SGID ) of the command. !!! Note The identity of the user requesting the execution of the order is no longer taken into account. This is an additional possibility of access rights assigned to a user when it is necessary for them to have the same rights as the owner of a file or those of the group concerned. Indeed, a user may have to run a program (usually a system utility) but not have the necessary access rights. By setting the appropriate rights ( s at the owner level and/or at the group level), the user of the program has, for the time of its execution, the identity of the owner (or that of the group) of the program. Example: The file /usr/bin/passwd is an executable file (a command) with a SUID . When the user bob runs it, he will have to access the /etc/shadow file, but the permissions on this file do not allow bob to access it. Having a SUID this command, /usr/bin/passwd , will be executed with the UID of root and the GID of root . The latter being the owner of the /etc/shadow file, he will have read rights. The setting of SUID and SGID can be done as below with the command chmod : Octal method: [root]# chmod 4777 command1 [root]# chmod 2777 command2 Symbolic method: [root]# chmod u+s command1 [root]# chmod g+s command2 Verification: [root]# ls -l -rwsrwxrwx \u2026 command1 -rwxrwsrwx \u2026 command2 !!! Warning It is not possible to pass the _SUID_ or _SGID_ to a shell script. The system does not allow it because it is too dangerous for security!","title":"SUID and SGID on a command"},{"location":"books/admin_guide/07-file-systems/#sgid-on-a-file","text":"In a directory with the SGID right, any file created will inherit the group that owns the directory instead of that of the creating user. Example: [rockstar] $ ls -ld /data/ drwxrwsr-x 2 root users 4096 26 oct. 19:43 /data [rockstar] $ touch /data/test_sgid /tmp/fic_reference [rockstar] $ ls -ld /data/test_sgid /tmp/fic_reference -rw-r--r--. 1 rockstar users 0 26 oct. 19:43 /data/test_sgid <1> -rw-r--r--. 1 rockstar rockstar 0 26 oct. 19:43 /tmp/fic_ref <1> The test_sgid file inherits the group owner of its /data folder (in this case users ) whatever the main group of the rockstar user is.","title":"SGID on a file"},{"location":"books/admin_guide/07-file-systems/#default-rights-and-mask","text":"When a file or directory is created, it already has permissions. For a directory: rwxr-xr-x or 755 . For a file: rw-r-r- or 644 . This behavior is defined by the default mask . The principle is to remove the value defined by the mask at maximum rights without the execution right. For a directory : For a file, the execution rights are removed:","title":"Default rights and mask"},{"location":"books/admin_guide/07-file-systems/#umask-command","text":"The umask command allows you to display and modify the mask. umask [option] [mode] Example: $ umask 033 $ umask 0033 $ umask -S u=rwx,g=r,o=r $ touch umask_033 $ ls -la umask_033 -rw-r--r-- 1 rockstar rockstar 0 nov. 4 16:44 umask_033 $ umask 025 $ umask -S u=rwx,g=rx,o=w $ touch umask_025 $ ls -la umask_025 -rw-r---w- 1 rockstar rockstar 0 nov. 4 16:44 umask_025 Option Description -S Symbolic display of file rights. !!! Warning `umask` does not affect existing files. !!! Note `umask` modifies the mask until the disconnection. To keep the value, you have to modify the following profile files: For all users: /etc/profile /etc/bashrc For a particular user: ~/.bashrc !!! Warning `umask -S` displays the file rights (without the execute right) of the files that will be created. So it is not the display of the mask used to subtract the maximum value. !!! Tip The `umask` command being a _bash_ command, (a `type umask` returns `umask is a shell primitive`) you have to search `umask` in `man bash`.","title":"umask command"},{"location":"books/admin_guide/08-process/","text":"Process Management In this chapter you will learn how to work with processes. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: Recognize the PID and PPID of a process; :heavy_check_mark: View and search for processes; :heavy_check_mark: Manage processes. :checkered_flag: process , linux Knowledge : :star: :star: Complexity : :star: Reading time : 20 minutes Generalities An operating system consists of processes. These processes are executed in a specific order and are related to each other. There are two categories of processes, those focused on the user environment and those focused on the hardware environment. When a program runs, the system will create a process by placing the program data and code in memory and creating a runtime stack . A process is therefore an instance of a program with an associated processor environment (ordinal counter, registers, etc...) and memory environment. Each process has: a PID : P rocess ID entifier , a unique process identifier; a PPID : P arent P rocess ID entifier , unique identifier of parent process. By successive filiations, the init process is the father of all processes. A process is always created by a parent process; A parent process can have multiple child processes. There is a parent/child relationship between processes. A child process is the result of the parent process calling the fork() primitive and duplicating its own code to create a child. The PID of the child is returned to the parent process so that it can talk to it. Each child has its parent's identifier, the PPID . The PID number represents the process at the time of execution. When the process finishes, the number is available again for another process. Running the same command several times will produce a different PID each time. !!! Note Processes are not to be confused with _threads_. Each process has its own memory context (resources and address space), while _threads_ from the same process share this same context. Viewing processes The ps command displays the status of running processes. ps [-e] [-f] [-u login] Example: # ps -fu root Option Description -e Displays all processes. -f Displays additional information. -u login Displays the user's processes. Some additional options: Option Description -g Displays the processes in the group. -t tty Displays the processes running from the terminal. -p PID Displays the process information. -H Displays the information in a tree structure. -I Displays additional information. --sort COL Sort the result according to a column. --headers Displays the header on each page of the terminal. --format \"%a %b %c\" Customize the output display format. Without an option specified, the ps command only displays processes running from the current terminal. The result is displayed in columns: # ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 Jan01 ? 00:00/03 /sbin/init Column Description UID Owner user. PID Process identifier. PPID Parent process identifier. C Priority of the process. STIME Date and time of execution. TTY Execution terminal. TIME Processing duration. CMD Command executed. The behaviour of the control can be fully customized: # ps -e --format \"%P %p %c %n\" --sort ppid --headers PPID PID COMMAND NI 0 1 systemd 0 0 2 kthreadd 0 1 516 systemd-journal 0 1 538 systemd-udevd 0 1 598 lvmetad 0 1 643 auditd -4 1 668 rtkit-daemon 1 1 670 sssd 0 Types of processes The user process: is started from a terminal associated with a user; accesses resources via requests or daemons. The system process ( demon ): is started by the system; is not associated with any terminal, and is owned by a system user (often root ); is loaded at boot time, resides in memory, and is waiting for a call; is usually identified by the letter d associated with the process name. System processes are therefore called daemons ( D isk A nd E xecution MON itor ). Permissions and rights When a command is executed, the user's credentials are passed to the created process. By default, the actual UID and GID (of the process) are therefore identical to the actual UID and GID (the UID and GID of the user who executed the command). When a SUID (and/or SGID ) is set on a command, the actual UID (and/or GID ) becomes that of the owner (and/or owner group) of the command and no longer that of the user or user group that issued the command. Effective and real UIDs are therefore different . Each time a file is accessed, the system checks the rights of the process according to its effective identifiers. Process management A process cannot be run indefinitely, as this would be to the detriment of other running processes and would prevent multitasking. The total processing time available is therefore divided into small ranges, and each process (with a priority) accesses the processor in a sequenced manner. The process will take several states during its life among the states: ready: waiting for the availability of the process; in execution: accesses the processor; suspended: waiting for an I/O (input/output); stopped: waiting for a signal from another process; zombie: request for destruction; dead: the father of the process kills his son. The end of process sequencing is as follows: Closing of the open files; Release of the used memory; Sending a signal to the parent and child processes. When a parent process dies, its children are said to be orphans. They are then adopted by the init process which will destroy them. The priority of a process The processor works in time sharing with each process occupying a quantity of processor time. The processes are classified by priority whose value varies from -20 (the highest priority) to +19 (the lowest priority). The default priority of a process is 0 . Modes of operation Processes can run in two ways: synchronous : the user loses access to the shell during command execution. The command prompt reappears at the end of the process execution. asynchronous : the process is processed in the background. The command prompt is displayed again immediately. The constraints of the asynchronous mode: the command or script must not wait for keyboard input; the command or script must not return any result on the screen; quitting the shell ends the process. Process management controls kill command The kill command sends a stop signal to a process. kill [-signal] PID Example: $ kill -9 1664 Code Signal Description 2 SIGINT Immediate termination of the process 9 SIGKILL Interrupt the process ( CTRL + D ) 15 SIGTERM Clean termination of the process 18 SIGCONT Resume the process 19 SIGSTOP Suspend the process Signals are the means of communication between processes. The kill command sends a signal to a process. !!! Tip The complete list of signals taken into account by the `kill` command is available by typing the command : ``` $ man 7 signal ``` nohup command nohup allows the launching of a process independently of a connection. nohup command Example: $ nohup myprogram.sh 0</dev/null & nohup ignores the SIGHUP signal sent when a user logs out. !!! Note \"Question\" `nohup` handles standard output and error, but not standard input, hence the redirection of this input to `/dev/null`. [CTRL] + [Z] By pressing the CTRL + Z keys simultaneously, the synchronous process is temporarily suspended. Access to the prompt is restored after displaying the number of the process that has just been suspended. & instruction The & statement executes the command asynchronously (the command is then called job ) and displays the number of job . Access to the prompt is then returned. Example: $ time ls -lR / > list.ls 2> /dev/null & [1] 15430 $ The job number is obtained during background processing and is displayed in square brackets, followed by the PID number. fg and bg commands The fg command puts the process in the foreground: $ time ls -lR / > list.ls 2>/dev/null & $ fg 1 time ls -lR / > list.ls 2/dev/null while the command bg places it in the background: [CTRL]+[Z] ^Z [1]+ Stopped $ bg 1 [1] 15430 $ Whether it was put in the background when it was created with the & argument or later with the CTRL + Z keys, a process can be brought back to the foreground with the fg command and its job number. jobs command The jobs command displays the list of processes running in the background and specifies their job number. Example: $ jobs [1]- Running sleep 1000 [2]+ Running find / > arbo.txt The columns represent: job number; the order in which the processes run a + : this process is the next process to run by default with fg or bg ; a - : this process is the next process to take the + ; Running (running process) or Stopped (suspended process). the command nice and renice commands The command nice allows the execution of a command by specifying its priority. nice priority command Example: $ nice -n+15 find / -name \"file\" Unlike root , a standard user can only reduce the priority of a process. Only values between +0 and +19 will be accepted. !!! Tip This last limitation can be lifted on a per-user or per-group basis by modifying the `/etc/security/limits.conf` file. The renice command allows you to change the priority of a running process. renice priority [-g GID] [-p PID] [-u UID] Example: $ renice +15 -p 1664 Option Description -g GID of the process owner group. -p PID of the process. -u UID of the process owner. The renice command acts on processes already running. It is therefore possible to change the priority of a specific process, but also of several processes belonging to a user or a group. !!! Tip The `pidof` command, coupled with the `xargs` command (see the Advanced Commands course), allows a new priority to be applied in a single command: ``` $ pidof sleep | xargs renice 20 ``` top command The top command displays the processes and their resource consumption. $ top PID USER PR NI ... %CPU %MEM TIME+ COMMAND 2514 root 20 0 15 5.5 0:01.14 top Column Description PID Process identifier. USER Owner user. PR Process priority. NI Nice value. %CPU Processor load. %MEM Memory load. TIME+ Processor usage time. COMMAND Command executed. The top command allows control of the processes in real time and in interactive mode. pgrep and pkill commands The pgrep command searches the running processes for a process name and displays the PID matching the selection criteria on the standard output. The pkill command will send the specified signal (by default SIGTERM ) to each process. pgrep process pkill [-signal] process Examples: Get the process number from sshd : $ pgrep -u root sshd Kill all tomcat processes: $ pkill tomcat","title":"Process Management"},{"location":"books/admin_guide/08-process/#process-management","text":"In this chapter you will learn how to work with processes. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: Recognize the PID and PPID of a process; :heavy_check_mark: View and search for processes; :heavy_check_mark: Manage processes. :checkered_flag: process , linux Knowledge : :star: :star: Complexity : :star: Reading time : 20 minutes","title":"Process Management"},{"location":"books/admin_guide/08-process/#generalities","text":"An operating system consists of processes. These processes are executed in a specific order and are related to each other. There are two categories of processes, those focused on the user environment and those focused on the hardware environment. When a program runs, the system will create a process by placing the program data and code in memory and creating a runtime stack . A process is therefore an instance of a program with an associated processor environment (ordinal counter, registers, etc...) and memory environment. Each process has: a PID : P rocess ID entifier , a unique process identifier; a PPID : P arent P rocess ID entifier , unique identifier of parent process. By successive filiations, the init process is the father of all processes. A process is always created by a parent process; A parent process can have multiple child processes. There is a parent/child relationship between processes. A child process is the result of the parent process calling the fork() primitive and duplicating its own code to create a child. The PID of the child is returned to the parent process so that it can talk to it. Each child has its parent's identifier, the PPID . The PID number represents the process at the time of execution. When the process finishes, the number is available again for another process. Running the same command several times will produce a different PID each time. !!! Note Processes are not to be confused with _threads_. Each process has its own memory context (resources and address space), while _threads_ from the same process share this same context.","title":"Generalities"},{"location":"books/admin_guide/08-process/#viewing-processes","text":"The ps command displays the status of running processes. ps [-e] [-f] [-u login] Example: # ps -fu root Option Description -e Displays all processes. -f Displays additional information. -u login Displays the user's processes. Some additional options: Option Description -g Displays the processes in the group. -t tty Displays the processes running from the terminal. -p PID Displays the process information. -H Displays the information in a tree structure. -I Displays additional information. --sort COL Sort the result according to a column. --headers Displays the header on each page of the terminal. --format \"%a %b %c\" Customize the output display format. Without an option specified, the ps command only displays processes running from the current terminal. The result is displayed in columns: # ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 Jan01 ? 00:00/03 /sbin/init Column Description UID Owner user. PID Process identifier. PPID Parent process identifier. C Priority of the process. STIME Date and time of execution. TTY Execution terminal. TIME Processing duration. CMD Command executed. The behaviour of the control can be fully customized: # ps -e --format \"%P %p %c %n\" --sort ppid --headers PPID PID COMMAND NI 0 1 systemd 0 0 2 kthreadd 0 1 516 systemd-journal 0 1 538 systemd-udevd 0 1 598 lvmetad 0 1 643 auditd -4 1 668 rtkit-daemon 1 1 670 sssd 0","title":"Viewing processes"},{"location":"books/admin_guide/08-process/#types-of-processes","text":"The user process: is started from a terminal associated with a user; accesses resources via requests or daemons. The system process ( demon ): is started by the system; is not associated with any terminal, and is owned by a system user (often root ); is loaded at boot time, resides in memory, and is waiting for a call; is usually identified by the letter d associated with the process name. System processes are therefore called daemons ( D isk A nd E xecution MON itor ).","title":"Types of processes"},{"location":"books/admin_guide/08-process/#permissions-and-rights","text":"When a command is executed, the user's credentials are passed to the created process. By default, the actual UID and GID (of the process) are therefore identical to the actual UID and GID (the UID and GID of the user who executed the command). When a SUID (and/or SGID ) is set on a command, the actual UID (and/or GID ) becomes that of the owner (and/or owner group) of the command and no longer that of the user or user group that issued the command. Effective and real UIDs are therefore different . Each time a file is accessed, the system checks the rights of the process according to its effective identifiers.","title":"Permissions and rights"},{"location":"books/admin_guide/08-process/#process-management_1","text":"A process cannot be run indefinitely, as this would be to the detriment of other running processes and would prevent multitasking. The total processing time available is therefore divided into small ranges, and each process (with a priority) accesses the processor in a sequenced manner. The process will take several states during its life among the states: ready: waiting for the availability of the process; in execution: accesses the processor; suspended: waiting for an I/O (input/output); stopped: waiting for a signal from another process; zombie: request for destruction; dead: the father of the process kills his son. The end of process sequencing is as follows: Closing of the open files; Release of the used memory; Sending a signal to the parent and child processes. When a parent process dies, its children are said to be orphans. They are then adopted by the init process which will destroy them.","title":"Process management"},{"location":"books/admin_guide/08-process/#the-priority-of-a-process","text":"The processor works in time sharing with each process occupying a quantity of processor time. The processes are classified by priority whose value varies from -20 (the highest priority) to +19 (the lowest priority). The default priority of a process is 0 .","title":"The priority of a process"},{"location":"books/admin_guide/08-process/#modes-of-operation","text":"Processes can run in two ways: synchronous : the user loses access to the shell during command execution. The command prompt reappears at the end of the process execution. asynchronous : the process is processed in the background. The command prompt is displayed again immediately. The constraints of the asynchronous mode: the command or script must not wait for keyboard input; the command or script must not return any result on the screen; quitting the shell ends the process.","title":"Modes of operation"},{"location":"books/admin_guide/08-process/#process-management-controls","text":"","title":"Process management controls"},{"location":"books/admin_guide/08-process/#kill-command","text":"The kill command sends a stop signal to a process. kill [-signal] PID Example: $ kill -9 1664 Code Signal Description 2 SIGINT Immediate termination of the process 9 SIGKILL Interrupt the process ( CTRL + D ) 15 SIGTERM Clean termination of the process 18 SIGCONT Resume the process 19 SIGSTOP Suspend the process Signals are the means of communication between processes. The kill command sends a signal to a process. !!! Tip The complete list of signals taken into account by the `kill` command is available by typing the command : ``` $ man 7 signal ```","title":"kill command"},{"location":"books/admin_guide/08-process/#nohup-command","text":"nohup allows the launching of a process independently of a connection. nohup command Example: $ nohup myprogram.sh 0</dev/null & nohup ignores the SIGHUP signal sent when a user logs out. !!! Note \"Question\" `nohup` handles standard output and error, but not standard input, hence the redirection of this input to `/dev/null`.","title":"nohup command"},{"location":"books/admin_guide/08-process/#ctrl-z","text":"By pressing the CTRL + Z keys simultaneously, the synchronous process is temporarily suspended. Access to the prompt is restored after displaying the number of the process that has just been suspended.","title":"[CTRL] + [Z]"},{"location":"books/admin_guide/08-process/#instruction","text":"The & statement executes the command asynchronously (the command is then called job ) and displays the number of job . Access to the prompt is then returned. Example: $ time ls -lR / > list.ls 2> /dev/null & [1] 15430 $ The job number is obtained during background processing and is displayed in square brackets, followed by the PID number.","title":"&amp; instruction"},{"location":"books/admin_guide/08-process/#fg-and-bg-commands","text":"The fg command puts the process in the foreground: $ time ls -lR / > list.ls 2>/dev/null & $ fg 1 time ls -lR / > list.ls 2/dev/null while the command bg places it in the background: [CTRL]+[Z] ^Z [1]+ Stopped $ bg 1 [1] 15430 $ Whether it was put in the background when it was created with the & argument or later with the CTRL + Z keys, a process can be brought back to the foreground with the fg command and its job number.","title":"fg and bg commands"},{"location":"books/admin_guide/08-process/#jobs-command","text":"The jobs command displays the list of processes running in the background and specifies their job number. Example: $ jobs [1]- Running sleep 1000 [2]+ Running find / > arbo.txt The columns represent: job number; the order in which the processes run a + : this process is the next process to run by default with fg or bg ; a - : this process is the next process to take the + ; Running (running process) or Stopped (suspended process). the command","title":"jobs command"},{"location":"books/admin_guide/08-process/#nice-and-renice-commands","text":"The command nice allows the execution of a command by specifying its priority. nice priority command Example: $ nice -n+15 find / -name \"file\" Unlike root , a standard user can only reduce the priority of a process. Only values between +0 and +19 will be accepted. !!! Tip This last limitation can be lifted on a per-user or per-group basis by modifying the `/etc/security/limits.conf` file. The renice command allows you to change the priority of a running process. renice priority [-g GID] [-p PID] [-u UID] Example: $ renice +15 -p 1664 Option Description -g GID of the process owner group. -p PID of the process. -u UID of the process owner. The renice command acts on processes already running. It is therefore possible to change the priority of a specific process, but also of several processes belonging to a user or a group. !!! Tip The `pidof` command, coupled with the `xargs` command (see the Advanced Commands course), allows a new priority to be applied in a single command: ``` $ pidof sleep | xargs renice 20 ```","title":"nice and renice commands"},{"location":"books/admin_guide/08-process/#top-command","text":"The top command displays the processes and their resource consumption. $ top PID USER PR NI ... %CPU %MEM TIME+ COMMAND 2514 root 20 0 15 5.5 0:01.14 top Column Description PID Process identifier. USER Owner user. PR Process priority. NI Nice value. %CPU Processor load. %MEM Memory load. TIME+ Processor usage time. COMMAND Command executed. The top command allows control of the processes in real time and in interactive mode.","title":"top command"},{"location":"books/admin_guide/08-process/#pgrep-and-pkill-commands","text":"The pgrep command searches the running processes for a process name and displays the PID matching the selection criteria on the standard output. The pkill command will send the specified signal (by default SIGTERM ) to each process. pgrep process pkill [-signal] process Examples: Get the process number from sshd : $ pgrep -u root sshd Kill all tomcat processes: $ pkill tomcat","title":"pgrep and pkill commands"},{"location":"books/admin_guide/09-backups/","text":"Backup and Restore In this chapter you will learn how to back up and restore your data with Linux. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: use the tar and cpio command to make a backup; :heavy_check_mark: check their backups and restore data; :heavy_check_mark: compress or decompress their backups. :checkered_flag: backup , restore , compression Knowledge : :star: :star: :star: Complexity : :star: :star: Reading time : 40 minutes !!! Note Throughout this chapter the command structures use \"device\" to specify both a target location for backup, and the source location when restoring. The device can be either external media or a local file. You should get a feel for this as the chapter unfolds, but you can always refer back to this note for clarification if you need to. The backup will answer a need to conserve and restore data in a sure and effective way. The backup allows you to protect yourself from the following: Destruction : voluntary or involuntary. Human or technical. Virus, ... Deletion : voluntary or involuntary. Human or technical. Virus, ... Integrity : data becomes unusable. No system is infallible, no human is infallible, so to avoid losing data, it must be backed up to be able to restore after a problem. The backup media should be kept in another room (or building) than the server so that a disaster does not destroy the server and the backups. In addition, the administrator must regularly check that the media are still readable. Generalities There are two principles, the backup and the archive . The archive destroys the information source after the operation. The backup preserves the source of information after the operation. These operations consist of saving information in a file, on a peripheral or a supported media (tapes, disks, ...). The process Backups require a lot of discipline and rigor from the system administrator. It is necessary to ask the following questions: What is the appropriate medium? What should be backed up? How many copies? How long will the backup take? Method? How often? Automatic or manual? Where to store it? How long will it be kept? Backup methods Complete : one or more filesystems are backed up (kernel, data, utilities, ...). Partial : one or more files are backed up (configurations, directories, ...). Differential : only files modified since the last complete backup are backed up. Incremental : only files modified since the last backup are backed up. Periodicity Pre-current : at a given time (before a system update, ...). Periodic : Daily, weekly, monthly, ... !!! Tip Before a system change, it can be useful to make a backup. However, there is no point in backing up data every day that is only changed every month. Restoration methods Depending on the utilities available, it will be possible to perform several types of restorations. Complete restoration : trees, ... Selective restoration : part of tree, files, ... It is possible to restore a whole backup but it is also possible to restore only a part of it. However, when restoring a directory, the files created after the backup are not deleted. !!! Tip To recover a directory as it was at the time of the backup, it is necessary to completely delete its contents before launching the restoration. The tools There are many utilities to make backups. editor tools ; graphical tools ; command line tools : tar , cpio , pax , dd , dump , ... The commands we will use here are tar and cpio . tar : easy to use ; allows adding files to an existing backup. cpio : retains owners; retains groups, dates and rights; skips damaged files; complete file system. !!! Note These commands save in a proprietary and standardized format. Naming convention The use of a naming convention makes it possible to quickly target the contents of a backup file and thus avoid hazardous restorations. name of the directory; utility used; options used; date. !!! Tip The name of the backup must be an explicit name. !!! Note The notion of extension under Linux does not exist. In other words, our use of extensions here is for the human operator. If the systems administrator sees a `.tar.gz` or `.tgz` file extension, for instance, then he knows how to deal with the file. Contents of a backup A backup generally contains the following elements: the file; the name; the owner; the size; the permissions access date. !!! Note The `inode` number is missing. Storage modes There are two different storage modes: file on disk; device. Tape ArchiveR - tar The tar command allows saving on several successive media (multi-volume options). It is possible to extract all or part of a backup. tar implicitly backs up in relative mode even if the path of the information to be backed up is mentioned in absolute mode. However, backups and restores in absolute mode are possible. Restoration guidelines The right questions to ask are: what: partial or complete; where: the place where the data will be restored; how: absolute or relative. !!! Warning Before a restoration, it is important to take time to think about and determine the most appropriate method to avoid mistakes. Restorations are usually performed after a problem has occurred that needs to be resolved quickly. A poor restoration can, in some cases, make the situation worse. Backing up with tar The default utility for creating backups on UNIX systems is the tar command. These backups can be compressed by bzip2 , xz , lzip , lzma , lzop , gzip , compress or zstd . tar allows you to extract a single file or a directory from a backup, view its contents or validate its integrity. Estimate the size of a backup The following command estimates the size in kilobytes of a possible tar file: $ tar cf - /directory/to/backup/ | wc -c 20480 $ tar czf - /directory/to/backup/ | wc -c 508 $ tar cjf - /directory/to/backup/ | wc -c 428 !!! Warning Beware, the presence of \"-\" in the command line disturbs `zsh`. Switch to `bash`! Naming convention for a tar backup Here is an example of a naming convention for a tar backup, knowing that the date is to be added to the name. keys Files Suffix Observation cvf home home.tar /home in relative mode, uncompressed form cvfP /etc etc.A.tar /etc in absolute mode, no compression cvfz usr usr.tar.gz /usr in relative mode, gzip compression cvfj usr usr.tar.bz2 /usr in relative mode, bzip2 compression cvfPz /home home.A.tar.gz home in absolute mode, gzip compression cvfPj /home home.A.tar.bz2 home in absolute mode, bzip2 compression \u2026 Create a backup Create a backup in relative mode Creating a non-compressed backup in relative mode is done with the cvf keys: tar c[vf] [device] [file(s)] Example: [root]# tar cvf /backups/home.133.tar /home/ Key Description c Creates a backup. v Displays the name of the processed files. f Allows you to specify the name of the backup (medium). !!! Tip The hyphen (`-`) in front of the `tar` keys is not necessary! Create a backup in absolute mode Creating a non-compressed backup explicitly in absolute mode is done with the cvfP keys: $ tar c[vf]P [device] [file(s)] Example: [root]# tar cvfP /backups/home.133.P.tar /home/ Key Description P Create a backup in absolute mode. !!! Warning With the `P` key, the path of the files to be backed up must be entered as **absolute**. If the two conditions (key `P` and path **absolute**) are not indicated, the backup is in relative mode. Creating a compressed backup with gzip Creating a compressed backup with gzip is done with the cvfz keys: $ tar cvzf backup.tar.gz dirname/ Key Description z Compresses the backup in gzip . !!! Note The `.tgz` extension is an equivalent extension to `.tar.gz`. !!! Note Keeping the `cvf` (`tvf` or `xvf`) keys unchanged for all backup operations and simply adding the compression key to the end of the keys makes the command easier to understand (e.g. `cvfz` or `cvfj`, etc.). Creating a compressed backup with bzip Creating a compressed backup with bzip is done with the keys cvfj : $ tar cvfj backup.tar.bz2 dirname/ Key Description j Compresses the backup in bzip2 . !!! Note The `.tbz` and `.tb2` extensions are equivalent to `.tar.bz2` extensions. Compression compress , gzip , bzip2 , lzip and xz Compression, and consequently decompression, will have an impact on resource consumption (time and CPU usage). Here is a ranking of the compression of a set of text files, from least to most efficient: compress ( .tar.Z ) gzip ( .tar.gz ) bzip2 ( .tar.bz2 ) lzip ( .tar.lz ) xz ( .tar.xz ) Add a file or directory to an existing backup It is possible to add one or more items to an existing backup. tar {r|A}[key(s)] [device] [file(s)] To add /etc/passwd to the backup /backups/home.133.tar : [root]# tar rvf /backups/home.133.tar /etc/passwd Adding a directory is similar. Here add dirtoadd to backup_name.tar : $ tar rvf backup_name.tar dirtoadd Key Description r Adds one or more files at the end of a direct access media backup (hard disk). A Adds one or more files at the end of a backup on sequential access media (tape). !!! Note It is not possible to add files or folders to a compressed backup. ``` $ tar rvfz backup.tgz filetoadd tar: Cannot update compressed archives Try `tar --help' or `tar --usage' for more information. ``` !!! Note If the backup was performed in relative mode, add files in relative mode. If the backup was done in absolute mode, add files in absolute mode. Mixing modes can cause problems when restoring. List the contents of a backup Viewing the contents of a backup without extracting it is possible. tar t[key(s)] [device] Key Description t Displays the content of a backup (compressed or not). Examples: $ tar tvf backup.tar $ tar tvfz backup.tar.gz $ tar tvfj backup.tar.bz2 When the number of files in a backup becomes large, it is possible to pipe the result of the tar command to a pager ( more , less , most , etc.): $ tar tvf backup.tar | less !!! Tip To list or retrieve the contents of a backup, it is not necessary to mention the compression algorithm used when the backup was created. That is, a `tar tvf` is equivalent to `tar tvfj`, to read the contents, and a `tar xvf` is equivalent to `tar xvfj`, to extract. !!! Tip Always check the contents of a backup. Check the integrity of a backup The integrity of a backup can be tested with the W key at the time of its creation: $ tar cvfW file_name.tar dir/ The integrity of a backup can be tested with the key d after its creation: $ tar vfd file_name.tar dir/ !!! Tip By adding a second `v` to the previous key, you will get the list of archived files as well as the differences between the archived files and those present in the file system. ``` $ tar vvfd /tmp/quodlibet.tar .quodlibet/ drwxr-x--- rockstar/rockstar 0 2021-05-21 00:11 .quodlibet/ -rw-r--r-- rockstar/rockstar 0 2021-05-19 00:59 .quodlibet/queue [\u2026] -rw------- rockstar/rockstar 3323 2021-05-21 00:11 .quodlibet/config .quodlibet/config: Mod time differs .quodlibet/config: Size differs [\u2026] ``` The W key is also used to compare the content of an archive against the filesystem: $ tar tvfW file_name.tar Verify 1/file1 1/file1: Mod time differs 1/file1: Size differs Verify 1/file2 Verify 1/file3 The verification with the W key cannot be done with a compressed archive. The key d must be used: $ tar dfz file_name.tgz $ tar dfj file_name.tar.bz2 Extract ( untar ) a backup Extract ( untar] ) a *.tar backup is done with the xvf keys: Extract the etc/exports file from the /savings/etc.133.tar backup into the etc directory of the active directory: $ tar xvf /backups/etc.133.tar etc/exports Extract all files from the compressed backup /backups/home.133.tar.bz2 into the active directory: [root]# tar xvfj /backups/home.133.tar.bz2 Extract all files from the backup /backups/etc.133.P.tar to their original directory: $ tar xvfP /backups/etc.133.P.tar !!! Warning Go to the right place. Check the contents of the backup. Key Description x Extract files from the backup, compressed or not. Extracting a tar-gzipped ( *.tar.gz ) backup is done with the xvfz keys: $ tar xvfz backup.tar.gz Extracting a tar-bzipped ( *.tar.bz2 ) backup is done with the xvfj keys: $ tar xvfj backup.tar.bz2 !!! Tip To extract or list the contents of a backup, it is not necessary to mention the compression algorithm used to create the backup. That is, a `tar xvf` is equivalent to `tar xvfj`, to extract the contents, and a `tar tvf` is equivalent to `tar tvfj`, to list. !!! Warning To restore the files in their original directory (key `P` of a `tar xvf`), you must have generated the backup with the absolute path. That is, with the `P` key of a `tar cvf`. Extract only a file from a tar backup To extract a specific file from a tar backup, specify the name of that file at the end of the tar xvf command. $ tar xvf backup.tar /path/to/file The previous command extracts only the /path/to/file file from the backup.tar backup. This file will be restored to the /path/to/ directory created, or already present, in the active directory. $ tar xvfz backup.tar.gz /path/to/file $ tar xvfj backup.tar.bz2 /path/to/file Extract a folder from a backup tar To extract only one directory (including its subdirectories and files) from a backup, specify the directory name at the end of the tar xvf command. $ tar xvf backup.tar /path/to/dir/ To extract multiple directories, specify each of the names one after the other: $ tar xvf backup.tar /path/to/dir1/ /path/to/dir2/ $ tar xvfz backup.tar.gz /path/to/dir1/ /path/to/dir2/ $ tar xvfj backup.tar.bz2 /path/to/dir1/ /path/to/dir2/ Extract a group of files from a tar backup using regular expressions ( regex ) Specify a regex to extract the files matching the specified selection pattern. For example, to extract all files with the extension .conf : $ tar xvf backup.tar --wildcards '*.conf' keys : --wildcards *.conf corresponds to files with the extension .conf . CoPy Input Output - cpio The cpio command allows saving on several successive media without specifying any options. It is possible to extract all or part of a backup. There is no option, unlike the tar command, to backup and compress at the same time. So it is done in two steps: backup and compression. To perform a backup with cpio , you have to specify a list of files to backup. This list is provided with the commands find , ls or cat . find : browse a tree, recursive or not; ls : list a directory, recursive or not; cat : reads a file containing the trees or files to be saved. !!! Note `ls` cannot be used with `-l` (details) or `-R` (recursive). It requires a simple list of names. Create a backup with cpio command Syntax of the cpio command: [files command |] cpio {-o| --create} [-options] [<file-list] [>device] Example: With a redirection of the output of cpio : $ find /etc | cpio -ov > /backups/etc.cpio Using the name of a backup media : $ find /etc | cpio -ovF /backups/etc.cpio The result of the find command is sent as input to the cpio command via a pipe (character | , AltGr + 6 ). Here, the find /etc command returns a list of files corresponding to the contents of the /etc directory (recursively) to the cpio command, which performs the backup. Do not forget the > sign when saving or the F save_name_cpio . Options Description -o Creates a backup ( output ). -v Displays the name of the processed files. -F Designates the backup to be modified (medium). Backup to a media : $ find /etc | cpio -ov > /dev/rmt0 The support can be of several types: tape drive: /dev/rmt0 ; a partition: /dev/sda5 , /dev/hda5 , etc. Type of backup Backup with relative path $ cd / $ find etc | cpio -o > /backups/etc.cpio Backup with absolute path $ find /etc | cpio -o > /backups/etc.A.cpio !!! Warning If the path specified in the `find` command is **absolute** then the backup will be performed in **absolute**. If the path indicated in the `find` command is **relative** then the backup will be done in **relative**. Add to a backup [files command |] cpio {-o| --create} -A [-options] [<fic-list] {F|>device} Example: $ find /etc/shadow | cpio -o -AF SystemFiles.A.cpio Adding files is only possible on direct access media. Option Description -A Adds one or more files to a backup on disk. -F Designates the backup to be modified. Compressing a backup Save then compress $ find /etc | cpio \u2013o > etc.A.cpio $ gzip /backups/etc.A.cpio $ ls /backups/etc.A.cpio* /backups/etc.A.cpio.gz Save and compress $ find /etc | cpio \u2013o | gzip > /backups/etc.A.cpio.gz There is no option, unlike the tar command, to save and compress at the same time. So it is done in two steps: saving and compressing. The syntax of the first method is easier to understand and remember, because it is done in two steps. For the first method, the backup file is automatically renamed by the gzip utility which adds .gz to the end of the file name. Similarly the bzip2 utility automatically adds .bz2 . Read the contents of a backup Syntax of the cpio command to read the contents of a cpio backup: cpio -t [-options] [<fic-list] Example: $ cpio -tv </backups/etc.152.cpio | less Options Description -t Reads a backup. -v Displays file attributes. After making a backup, you need to read its contents to be sure that there were no errors. In the same way, before performing a restore, you must read the contents of the backup that will be used. Restore a backup Syntax of the cpio command to restore a backup: cpio {-i| --extract} [-E file] [-options] [<device] Example: $ cpio -iv </backups/etc.152.cpio | less Options Description -i Restore a complete backup. -E file Restores only the files whose name is contained in file. --make-directories or -d Rebuilds the missing tree structure. -u Replaces all files even if they exist. --no-absolute-filenames Allows to restore a backup made in absolute mode in a relative way. !!! Warning By default, at the time of restoration, files on the disk whose last modification date is more recent or equal to the date of the backup are not restored (in order to avoid overwriting recent information with older information). The `u` option, on the other hand, allows you to restore older versions of the files. Examples: Absolute restoration of an absolute backup $ cpio \u2013ivF home.A.cpio Absolute restoration on an existing tree structure The u option allows you to overwrite existing files at the location where the restore takes place. $ cpio \u2013iuvF home.A.cpio Restore an absolute backup in relative mode The long option no-absolute-filenames allows a restoration in relative mode. Indeed the / at the beginning of the path will be removed. $ cpio --no-absolute-filenames -divuF home.A.cpio !!! Tip The creation of directories is perhaps necessary, hence the use of the `d` option Restore a relative backup $ cpio \u2013iv <etc.cpio Absolute restoration of a file or directory The restoration of a particular file or directory requires the creation of a list file that must then be deleted. echo \"/etc/passwd\" > tmp cpio \u2013iuE tmp -F etc.A.cpio rm -f tmp Compression - decompression utilities Using compression at the time of a backup can have a number of drawbacks: Lengthens the backup time as well as the restore time. It makes it impossible to add files to the backup. !!! Note It is therefore better to make a backup and compress it than to compress it during the backup. Compressing with gzip The gzip command compresses data. Syntax of the gzip command: gzip [options] [file ...] Example: $ gzip usr.tar $ ls usr.tar.gz The file receives the extension .gz . It keeps the same rights and the same last access and modification dates. Compressing with bunzip2 The bunzip2 command also compresses data. Syntax of the bzip2 command: bzip2 [options] [file ...] Example: $ bzip2 usr.cpio $ ls usr.cpio.bz2 The file name is given the extension .bz2 . Compression by bzip2 is better than compression by gzip but it takes longer to execute. Decompressing with gunzip The gunzip command decompresses compressed data. Syntax of the gunzip command: gunzip [options] [file ...] Example: $ gunzip usr.tar.gz $ ls usr.tar The file name is truncated by gunzip and the extension .gz is removed. gunzip also decompresses files with the following extensions: .z ; -z ; _z . Decompressing with bunzip2 The bunzip2 command decompresses compressed data. Syntax of the bzip2 command: bzip2 [options] [file ...] Example: $ bunzip2 usr.cpio.bz2 $ ls usr.cpio The file name is truncated by bunzip2 and the extension .bz2 is removed. bunzip2 also decompresses the file with the following extensions: -bz ; .tbz2 ; tbz .","title":"Backup and Restore"},{"location":"books/admin_guide/09-backups/#backup-and-restore","text":"In this chapter you will learn how to back up and restore your data with Linux. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: use the tar and cpio command to make a backup; :heavy_check_mark: check their backups and restore data; :heavy_check_mark: compress or decompress their backups. :checkered_flag: backup , restore , compression Knowledge : :star: :star: :star: Complexity : :star: :star: Reading time : 40 minutes !!! Note Throughout this chapter the command structures use \"device\" to specify both a target location for backup, and the source location when restoring. The device can be either external media or a local file. You should get a feel for this as the chapter unfolds, but you can always refer back to this note for clarification if you need to. The backup will answer a need to conserve and restore data in a sure and effective way. The backup allows you to protect yourself from the following: Destruction : voluntary or involuntary. Human or technical. Virus, ... Deletion : voluntary or involuntary. Human or technical. Virus, ... Integrity : data becomes unusable. No system is infallible, no human is infallible, so to avoid losing data, it must be backed up to be able to restore after a problem. The backup media should be kept in another room (or building) than the server so that a disaster does not destroy the server and the backups. In addition, the administrator must regularly check that the media are still readable.","title":"Backup and Restore"},{"location":"books/admin_guide/09-backups/#generalities","text":"There are two principles, the backup and the archive . The archive destroys the information source after the operation. The backup preserves the source of information after the operation. These operations consist of saving information in a file, on a peripheral or a supported media (tapes, disks, ...).","title":"Generalities"},{"location":"books/admin_guide/09-backups/#the-process","text":"Backups require a lot of discipline and rigor from the system administrator. It is necessary to ask the following questions: What is the appropriate medium? What should be backed up? How many copies? How long will the backup take? Method? How often? Automatic or manual? Where to store it? How long will it be kept?","title":"The process"},{"location":"books/admin_guide/09-backups/#backup-methods","text":"Complete : one or more filesystems are backed up (kernel, data, utilities, ...). Partial : one or more files are backed up (configurations, directories, ...). Differential : only files modified since the last complete backup are backed up. Incremental : only files modified since the last backup are backed up.","title":"Backup methods"},{"location":"books/admin_guide/09-backups/#periodicity","text":"Pre-current : at a given time (before a system update, ...). Periodic : Daily, weekly, monthly, ... !!! Tip Before a system change, it can be useful to make a backup. However, there is no point in backing up data every day that is only changed every month.","title":"Periodicity"},{"location":"books/admin_guide/09-backups/#restoration-methods","text":"Depending on the utilities available, it will be possible to perform several types of restorations. Complete restoration : trees, ... Selective restoration : part of tree, files, ... It is possible to restore a whole backup but it is also possible to restore only a part of it. However, when restoring a directory, the files created after the backup are not deleted. !!! Tip To recover a directory as it was at the time of the backup, it is necessary to completely delete its contents before launching the restoration.","title":"Restoration methods"},{"location":"books/admin_guide/09-backups/#the-tools","text":"There are many utilities to make backups. editor tools ; graphical tools ; command line tools : tar , cpio , pax , dd , dump , ... The commands we will use here are tar and cpio . tar : easy to use ; allows adding files to an existing backup. cpio : retains owners; retains groups, dates and rights; skips damaged files; complete file system. !!! Note These commands save in a proprietary and standardized format.","title":"The tools"},{"location":"books/admin_guide/09-backups/#naming-convention","text":"The use of a naming convention makes it possible to quickly target the contents of a backup file and thus avoid hazardous restorations. name of the directory; utility used; options used; date. !!! Tip The name of the backup must be an explicit name. !!! Note The notion of extension under Linux does not exist. In other words, our use of extensions here is for the human operator. If the systems administrator sees a `.tar.gz` or `.tgz` file extension, for instance, then he knows how to deal with the file.","title":"Naming convention"},{"location":"books/admin_guide/09-backups/#contents-of-a-backup","text":"A backup generally contains the following elements: the file; the name; the owner; the size; the permissions access date. !!! Note The `inode` number is missing.","title":"Contents of a backup"},{"location":"books/admin_guide/09-backups/#storage-modes","text":"There are two different storage modes: file on disk; device.","title":"Storage modes"},{"location":"books/admin_guide/09-backups/#tape-archiver-tar","text":"The tar command allows saving on several successive media (multi-volume options). It is possible to extract all or part of a backup. tar implicitly backs up in relative mode even if the path of the information to be backed up is mentioned in absolute mode. However, backups and restores in absolute mode are possible.","title":"Tape ArchiveR - tar"},{"location":"books/admin_guide/09-backups/#restoration-guidelines","text":"The right questions to ask are: what: partial or complete; where: the place where the data will be restored; how: absolute or relative. !!! Warning Before a restoration, it is important to take time to think about and determine the most appropriate method to avoid mistakes. Restorations are usually performed after a problem has occurred that needs to be resolved quickly. A poor restoration can, in some cases, make the situation worse.","title":"Restoration guidelines"},{"location":"books/admin_guide/09-backups/#backing-up-with-tar","text":"The default utility for creating backups on UNIX systems is the tar command. These backups can be compressed by bzip2 , xz , lzip , lzma , lzop , gzip , compress or zstd . tar allows you to extract a single file or a directory from a backup, view its contents or validate its integrity.","title":"Backing up with tar"},{"location":"books/admin_guide/09-backups/#estimate-the-size-of-a-backup","text":"The following command estimates the size in kilobytes of a possible tar file: $ tar cf - /directory/to/backup/ | wc -c 20480 $ tar czf - /directory/to/backup/ | wc -c 508 $ tar cjf - /directory/to/backup/ | wc -c 428 !!! Warning Beware, the presence of \"-\" in the command line disturbs `zsh`. Switch to `bash`!","title":"Estimate the size of a backup"},{"location":"books/admin_guide/09-backups/#naming-convention-for-a-tar-backup","text":"Here is an example of a naming convention for a tar backup, knowing that the date is to be added to the name. keys Files Suffix Observation cvf home home.tar /home in relative mode, uncompressed form cvfP /etc etc.A.tar /etc in absolute mode, no compression cvfz usr usr.tar.gz /usr in relative mode, gzip compression cvfj usr usr.tar.bz2 /usr in relative mode, bzip2 compression cvfPz /home home.A.tar.gz home in absolute mode, gzip compression cvfPj /home home.A.tar.bz2 home in absolute mode, bzip2 compression \u2026","title":"Naming convention for a tar backup"},{"location":"books/admin_guide/09-backups/#create-a-backup","text":"","title":"Create a backup"},{"location":"books/admin_guide/09-backups/#create-a-backup-in-relative-mode","text":"Creating a non-compressed backup in relative mode is done with the cvf keys: tar c[vf] [device] [file(s)] Example: [root]# tar cvf /backups/home.133.tar /home/ Key Description c Creates a backup. v Displays the name of the processed files. f Allows you to specify the name of the backup (medium). !!! Tip The hyphen (`-`) in front of the `tar` keys is not necessary!","title":"Create a backup in relative mode"},{"location":"books/admin_guide/09-backups/#create-a-backup-in-absolute-mode","text":"Creating a non-compressed backup explicitly in absolute mode is done with the cvfP keys: $ tar c[vf]P [device] [file(s)] Example: [root]# tar cvfP /backups/home.133.P.tar /home/ Key Description P Create a backup in absolute mode. !!! Warning With the `P` key, the path of the files to be backed up must be entered as **absolute**. If the two conditions (key `P` and path **absolute**) are not indicated, the backup is in relative mode.","title":"Create a backup in absolute mode"},{"location":"books/admin_guide/09-backups/#creating-a-compressed-backup-with-gzip","text":"Creating a compressed backup with gzip is done with the cvfz keys: $ tar cvzf backup.tar.gz dirname/ Key Description z Compresses the backup in gzip . !!! Note The `.tgz` extension is an equivalent extension to `.tar.gz`. !!! Note Keeping the `cvf` (`tvf` or `xvf`) keys unchanged for all backup operations and simply adding the compression key to the end of the keys makes the command easier to understand (e.g. `cvfz` or `cvfj`, etc.).","title":"Creating a compressed backup with gzip"},{"location":"books/admin_guide/09-backups/#creating-a-compressed-backup-with-bzip","text":"Creating a compressed backup with bzip is done with the keys cvfj : $ tar cvfj backup.tar.bz2 dirname/ Key Description j Compresses the backup in bzip2 . !!! Note The `.tbz` and `.tb2` extensions are equivalent to `.tar.bz2` extensions.","title":"Creating a compressed backup with bzip"},{"location":"books/admin_guide/09-backups/#compression-compress-gzip-bzip2-lzip-and-xz","text":"Compression, and consequently decompression, will have an impact on resource consumption (time and CPU usage). Here is a ranking of the compression of a set of text files, from least to most efficient: compress ( .tar.Z ) gzip ( .tar.gz ) bzip2 ( .tar.bz2 ) lzip ( .tar.lz ) xz ( .tar.xz )","title":"Compression compress, gzip, bzip2, lzip and xz"},{"location":"books/admin_guide/09-backups/#add-a-file-or-directory-to-an-existing-backup","text":"It is possible to add one or more items to an existing backup. tar {r|A}[key(s)] [device] [file(s)] To add /etc/passwd to the backup /backups/home.133.tar : [root]# tar rvf /backups/home.133.tar /etc/passwd Adding a directory is similar. Here add dirtoadd to backup_name.tar : $ tar rvf backup_name.tar dirtoadd Key Description r Adds one or more files at the end of a direct access media backup (hard disk). A Adds one or more files at the end of a backup on sequential access media (tape). !!! Note It is not possible to add files or folders to a compressed backup. ``` $ tar rvfz backup.tgz filetoadd tar: Cannot update compressed archives Try `tar --help' or `tar --usage' for more information. ``` !!! Note If the backup was performed in relative mode, add files in relative mode. If the backup was done in absolute mode, add files in absolute mode. Mixing modes can cause problems when restoring.","title":"Add a file or directory to an existing backup"},{"location":"books/admin_guide/09-backups/#list-the-contents-of-a-backup","text":"Viewing the contents of a backup without extracting it is possible. tar t[key(s)] [device] Key Description t Displays the content of a backup (compressed or not). Examples: $ tar tvf backup.tar $ tar tvfz backup.tar.gz $ tar tvfj backup.tar.bz2 When the number of files in a backup becomes large, it is possible to pipe the result of the tar command to a pager ( more , less , most , etc.): $ tar tvf backup.tar | less !!! Tip To list or retrieve the contents of a backup, it is not necessary to mention the compression algorithm used when the backup was created. That is, a `tar tvf` is equivalent to `tar tvfj`, to read the contents, and a `tar xvf` is equivalent to `tar xvfj`, to extract. !!! Tip Always check the contents of a backup.","title":"List the contents of a backup"},{"location":"books/admin_guide/09-backups/#check-the-integrity-of-a-backup","text":"The integrity of a backup can be tested with the W key at the time of its creation: $ tar cvfW file_name.tar dir/ The integrity of a backup can be tested with the key d after its creation: $ tar vfd file_name.tar dir/ !!! Tip By adding a second `v` to the previous key, you will get the list of archived files as well as the differences between the archived files and those present in the file system. ``` $ tar vvfd /tmp/quodlibet.tar .quodlibet/ drwxr-x--- rockstar/rockstar 0 2021-05-21 00:11 .quodlibet/ -rw-r--r-- rockstar/rockstar 0 2021-05-19 00:59 .quodlibet/queue [\u2026] -rw------- rockstar/rockstar 3323 2021-05-21 00:11 .quodlibet/config .quodlibet/config: Mod time differs .quodlibet/config: Size differs [\u2026] ``` The W key is also used to compare the content of an archive against the filesystem: $ tar tvfW file_name.tar Verify 1/file1 1/file1: Mod time differs 1/file1: Size differs Verify 1/file2 Verify 1/file3 The verification with the W key cannot be done with a compressed archive. The key d must be used: $ tar dfz file_name.tgz $ tar dfj file_name.tar.bz2","title":"Check the integrity of a backup"},{"location":"books/admin_guide/09-backups/#extract-untar-a-backup","text":"Extract ( untar] ) a *.tar backup is done with the xvf keys: Extract the etc/exports file from the /savings/etc.133.tar backup into the etc directory of the active directory: $ tar xvf /backups/etc.133.tar etc/exports Extract all files from the compressed backup /backups/home.133.tar.bz2 into the active directory: [root]# tar xvfj /backups/home.133.tar.bz2 Extract all files from the backup /backups/etc.133.P.tar to their original directory: $ tar xvfP /backups/etc.133.P.tar !!! Warning Go to the right place. Check the contents of the backup. Key Description x Extract files from the backup, compressed or not. Extracting a tar-gzipped ( *.tar.gz ) backup is done with the xvfz keys: $ tar xvfz backup.tar.gz Extracting a tar-bzipped ( *.tar.bz2 ) backup is done with the xvfj keys: $ tar xvfj backup.tar.bz2 !!! Tip To extract or list the contents of a backup, it is not necessary to mention the compression algorithm used to create the backup. That is, a `tar xvf` is equivalent to `tar xvfj`, to extract the contents, and a `tar tvf` is equivalent to `tar tvfj`, to list. !!! Warning To restore the files in their original directory (key `P` of a `tar xvf`), you must have generated the backup with the absolute path. That is, with the `P` key of a `tar cvf`.","title":"Extract (untar) a backup"},{"location":"books/admin_guide/09-backups/#extract-only-a-file-from-a-tar-backup","text":"To extract a specific file from a tar backup, specify the name of that file at the end of the tar xvf command. $ tar xvf backup.tar /path/to/file The previous command extracts only the /path/to/file file from the backup.tar backup. This file will be restored to the /path/to/ directory created, or already present, in the active directory. $ tar xvfz backup.tar.gz /path/to/file $ tar xvfj backup.tar.bz2 /path/to/file","title":"Extract only a file from a tar backup"},{"location":"books/admin_guide/09-backups/#extract-a-folder-from-a-backup-tar","text":"To extract only one directory (including its subdirectories and files) from a backup, specify the directory name at the end of the tar xvf command. $ tar xvf backup.tar /path/to/dir/ To extract multiple directories, specify each of the names one after the other: $ tar xvf backup.tar /path/to/dir1/ /path/to/dir2/ $ tar xvfz backup.tar.gz /path/to/dir1/ /path/to/dir2/ $ tar xvfj backup.tar.bz2 /path/to/dir1/ /path/to/dir2/","title":"Extract a folder from a backup tar"},{"location":"books/admin_guide/09-backups/#extract-a-group-of-files-from-a-tar-backup-using-regular-expressions-regex","text":"Specify a regex to extract the files matching the specified selection pattern. For example, to extract all files with the extension .conf : $ tar xvf backup.tar --wildcards '*.conf' keys : --wildcards *.conf corresponds to files with the extension .conf .","title":"Extract a group of files from a tar backup using regular expressions (regex)"},{"location":"books/admin_guide/09-backups/#copy-input-output-cpio","text":"The cpio command allows saving on several successive media without specifying any options. It is possible to extract all or part of a backup. There is no option, unlike the tar command, to backup and compress at the same time. So it is done in two steps: backup and compression. To perform a backup with cpio , you have to specify a list of files to backup. This list is provided with the commands find , ls or cat . find : browse a tree, recursive or not; ls : list a directory, recursive or not; cat : reads a file containing the trees or files to be saved. !!! Note `ls` cannot be used with `-l` (details) or `-R` (recursive). It requires a simple list of names.","title":"CoPy Input Output - cpio"},{"location":"books/admin_guide/09-backups/#create-a-backup-with-cpio-command","text":"Syntax of the cpio command: [files command |] cpio {-o| --create} [-options] [<file-list] [>device] Example: With a redirection of the output of cpio : $ find /etc | cpio -ov > /backups/etc.cpio Using the name of a backup media : $ find /etc | cpio -ovF /backups/etc.cpio The result of the find command is sent as input to the cpio command via a pipe (character | , AltGr + 6 ). Here, the find /etc command returns a list of files corresponding to the contents of the /etc directory (recursively) to the cpio command, which performs the backup. Do not forget the > sign when saving or the F save_name_cpio . Options Description -o Creates a backup ( output ). -v Displays the name of the processed files. -F Designates the backup to be modified (medium). Backup to a media : $ find /etc | cpio -ov > /dev/rmt0 The support can be of several types: tape drive: /dev/rmt0 ; a partition: /dev/sda5 , /dev/hda5 , etc.","title":"Create a backup with cpio command"},{"location":"books/admin_guide/09-backups/#type-of-backup","text":"","title":"Type of backup"},{"location":"books/admin_guide/09-backups/#backup-with-relative-path","text":"$ cd / $ find etc | cpio -o > /backups/etc.cpio","title":"Backup with relative path"},{"location":"books/admin_guide/09-backups/#backup-with-absolute-path","text":"$ find /etc | cpio -o > /backups/etc.A.cpio !!! Warning If the path specified in the `find` command is **absolute** then the backup will be performed in **absolute**. If the path indicated in the `find` command is **relative** then the backup will be done in **relative**.","title":"Backup with absolute path"},{"location":"books/admin_guide/09-backups/#add-to-a-backup","text":"[files command |] cpio {-o| --create} -A [-options] [<fic-list] {F|>device} Example: $ find /etc/shadow | cpio -o -AF SystemFiles.A.cpio Adding files is only possible on direct access media. Option Description -A Adds one or more files to a backup on disk. -F Designates the backup to be modified.","title":"Add to a backup"},{"location":"books/admin_guide/09-backups/#compressing-a-backup","text":"Save then compress $ find /etc | cpio \u2013o > etc.A.cpio $ gzip /backups/etc.A.cpio $ ls /backups/etc.A.cpio* /backups/etc.A.cpio.gz Save and compress $ find /etc | cpio \u2013o | gzip > /backups/etc.A.cpio.gz There is no option, unlike the tar command, to save and compress at the same time. So it is done in two steps: saving and compressing. The syntax of the first method is easier to understand and remember, because it is done in two steps. For the first method, the backup file is automatically renamed by the gzip utility which adds .gz to the end of the file name. Similarly the bzip2 utility automatically adds .bz2 .","title":"Compressing a backup"},{"location":"books/admin_guide/09-backups/#read-the-contents-of-a-backup","text":"Syntax of the cpio command to read the contents of a cpio backup: cpio -t [-options] [<fic-list] Example: $ cpio -tv </backups/etc.152.cpio | less Options Description -t Reads a backup. -v Displays file attributes. After making a backup, you need to read its contents to be sure that there were no errors. In the same way, before performing a restore, you must read the contents of the backup that will be used.","title":"Read the contents of a backup"},{"location":"books/admin_guide/09-backups/#restore-a-backup","text":"Syntax of the cpio command to restore a backup: cpio {-i| --extract} [-E file] [-options] [<device] Example: $ cpio -iv </backups/etc.152.cpio | less Options Description -i Restore a complete backup. -E file Restores only the files whose name is contained in file. --make-directories or -d Rebuilds the missing tree structure. -u Replaces all files even if they exist. --no-absolute-filenames Allows to restore a backup made in absolute mode in a relative way. !!! Warning By default, at the time of restoration, files on the disk whose last modification date is more recent or equal to the date of the backup are not restored (in order to avoid overwriting recent information with older information). The `u` option, on the other hand, allows you to restore older versions of the files. Examples: Absolute restoration of an absolute backup $ cpio \u2013ivF home.A.cpio Absolute restoration on an existing tree structure The u option allows you to overwrite existing files at the location where the restore takes place. $ cpio \u2013iuvF home.A.cpio Restore an absolute backup in relative mode The long option no-absolute-filenames allows a restoration in relative mode. Indeed the / at the beginning of the path will be removed. $ cpio --no-absolute-filenames -divuF home.A.cpio !!! Tip The creation of directories is perhaps necessary, hence the use of the `d` option Restore a relative backup $ cpio \u2013iv <etc.cpio Absolute restoration of a file or directory The restoration of a particular file or directory requires the creation of a list file that must then be deleted. echo \"/etc/passwd\" > tmp cpio \u2013iuE tmp -F etc.A.cpio rm -f tmp","title":"Restore a backup"},{"location":"books/admin_guide/09-backups/#compression-decompression-utilities","text":"Using compression at the time of a backup can have a number of drawbacks: Lengthens the backup time as well as the restore time. It makes it impossible to add files to the backup. !!! Note It is therefore better to make a backup and compress it than to compress it during the backup.","title":"Compression - decompression utilities"},{"location":"books/admin_guide/09-backups/#compressing-with-gzip","text":"The gzip command compresses data. Syntax of the gzip command: gzip [options] [file ...] Example: $ gzip usr.tar $ ls usr.tar.gz The file receives the extension .gz . It keeps the same rights and the same last access and modification dates.","title":"Compressing with gzip"},{"location":"books/admin_guide/09-backups/#compressing-with-bunzip2","text":"The bunzip2 command also compresses data. Syntax of the bzip2 command: bzip2 [options] [file ...] Example: $ bzip2 usr.cpio $ ls usr.cpio.bz2 The file name is given the extension .bz2 . Compression by bzip2 is better than compression by gzip but it takes longer to execute.","title":"Compressing with bunzip2"},{"location":"books/admin_guide/09-backups/#decompressing-with-gunzip","text":"The gunzip command decompresses compressed data. Syntax of the gunzip command: gunzip [options] [file ...] Example: $ gunzip usr.tar.gz $ ls usr.tar The file name is truncated by gunzip and the extension .gz is removed. gunzip also decompresses files with the following extensions: .z ; -z ; _z .","title":"Decompressing with gunzip"},{"location":"books/admin_guide/09-backups/#decompressing-with-bunzip2","text":"The bunzip2 command decompresses compressed data. Syntax of the bzip2 command: bzip2 [options] [file ...] Example: $ bunzip2 usr.cpio.bz2 $ ls usr.cpio The file name is truncated by bunzip2 and the extension .bz2 is removed. bunzip2 also decompresses the file with the following extensions: -bz ; .tbz2 ; tbz .","title":"Decompressing with bunzip2"},{"location":"books/admin_guide/10-boot/","text":"System Startup In this chapter you will learn how the system start. Objectives : In this chapter, future Linux administrators will learn: :heavy_check_mark: The different stages of the booting process; :heavy_check_mark: How Rocky Linux supports this boot via GRUB2 and systemd; :heavy_check_mark: How to protect GRUB2 from an attack; :heavy_check_mark: How to manage the services; :heavy_check_mark: How to access to the logs from journald. :checkered_flag: users Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 20 minutes The boot process It is important to understand the boot process of Linux in order to be able to solve problems that may occur. The boot process includes: The BIOS startup The BIOS (Basic Input/Output System) performs the POST (power on self test) to detect, test and initialize the system hardware components. It then loads the MBR (Master Boot Record). The Master boot record (MBR) The Master Boot Record is the first 512 bytes of the boot disk. The MBR discovers the boot device and loads the bootloader GRUB2 into memory and transfers control to it. The next 64 bytes contain the partition table of the disk. The GRUB2 bootloader The default bootloader for the Rocky 8 distribution is GRUB2 (GRand Unified Bootloader). GRUB2 replaces the old GRUB bootloader (also called GRUB legacy). The GRUB 2 configuration file is located under /boot/grub2/grub.cfg but this file should not be edited directly. The GRUB2 menu configuration settings are located under /etc/default/grub and are used to generate the grub.cfg file. # cat /etc/default/grub GRUB_TIMEOUT=5 GRUB_DEFAULT=saved GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=\"console\" GRUB_CMDLINE_LINUX=\"rd.lvm.lv=rhel/swap crashkernel=auto rd.lvm.lv=rhel/root rhgb quiet net.ifnames=0\" GRUB_DISABLE_RECOVERY=\"true\" If changes are made to one or more of these parameters, the grub2-mkconfig command must be run to regenerate the /boot/grub2/grub.cfg file. [root] # grub2-mkconfig \u2013o /boot/grub2/grub.cfg GRUB2 looks for the compressed kernel image (the vmlinuz file) in the /boot directory. GRUB2 loads the kernel image into memory and extracts the contents of the initramfs image file into a temporary folder in memory using the tmpfs file system. The kernel The kernel starts the systemd process with PID 1. root 1 0 0 02:10 ? 00:00:02 /usr/lib/systemd/systemd --switched-root --system --deserialize 23 systemd Systemd is the parent of all system processes. It reads the target of the /etc/systemd/system/default.target link (e.g. /usr/lib/systemd/system/multi-user.target ) to determine the default target of the system. The file defines the services to be started. Systemd then places the system in the target-defined state by performing the following initialization tasks: Set the machine name Initialize the network Initialize SELinux Display the welcome banner Initialize the hardware based on the arguments given to the kernel at boot time Mount the file systems, including virtual file systems like /proc Clean up directories in /var Start the virtual memory (swap) Protecting the GRUB2 bootloader Why protect the bootloader with a password? Prevent Single user mode access - If an attacker can boot into single user mode, he becomes the root user. Prevent access to GRUB console - If an attacker manages to use GRUB console, he can change its configuration or collect information about the system by using the cat command. Prevent access to insecure operating systems. If there is a dual boot on the system, an attacker can select an operating system like DOS at boot time that ignores access controls and file permissions. To password protect the GRUB2 bootloader: Remove -unrestricted from the main CLASS= statement in the /etc/grub.d/10_linux file. If a user has not yet been configured, use the grub2-setpassword command to provide a password for the root user: # grub2-setpassword A /boot/grub2/user.cfg file will be created if it was not already present. It contains the hashed password of the GRUB2. !!! Note This command only supports configurations with a single root user. [root]# cat /boot/grub2/user.cfg GRUB2_PASSWORD=grub.pbkdf2.sha512.10000.CC6F56....A21 Recreate the configuration file with the grub2-mkconfig command: [root]# grub2-mkconfig -o /boot/grub2/grub.cfg Generating grub configuration file ... Found linux image: /boot/vmlinuz-3.10.0-327.el7.x86_64 Found initrd image: /boot/initramfs-3.10.0-327.el7.x86_64.img Found linux image: /boot/vmlinuz-0-rescue-f9725b0c842348ce9e0bc81968cf7181 Found initrd image: /boot/initramfs-0-rescue-f9725b0c842348ce9e0bc81968cf7181.img done Restart the server and check. All entries defined in the GRUB menu will now require a user and password to be entered at each boot. The system will not boot a kernel without direct user intervention from the console. When the user is requested, enter root ; When a password is requested, enter the password provided at the grub2-setpassword command. To protect only the editing of GRUB menu entries and access to the console, the execution of the grub2-setpassword command is sufficient. There may be cases where you have good reasons for doing only that. This might be particularly true in a remote data center where entering a password each time a server is rebooted is either difficult or impossible to do. Systemd Systemd is a service manager for the Linux operating systems. It is developed to: remain compatible with older SysV initialization scripts, provide many features, such as parallel start of system services at system startup, on-demand activation of daemons, support for snapshots, or management of dependencies between services. !!! Note Systemd is the default initialization system since RedHat/CentOS 7. Systemd introduces the concept of systemd units. Type File extension Observation Service unit .service System service Target unit .target A group of systemd units Mount unit .automount An automatic mount point for file system !!! Note There are many types of units: Device unit, Mount unit, Path unit, Scope unit, Slice unit, Snapshot unit, Socket unit, Swap unit, Timer unit. Systemd supports system state snapshots and restore. Mount points can be configured as systemd targets. At startup, systemd creates listening sockets for all system services that support this type of activation and passes these sockets to these services as soon as they are started. This makes it possible to restart a service without losing a single message sent to it by the network during its unavailability. The corresponding socket remains accessible and all messages are queued. System services that use D-BUS for their inter-process communications can be started on demand the first time they are used by a client. Systemd stops or restarts only running services. Previous versions (before RHEL7) attempted to stop services directly without checking their current status. System services do not inherit any context (like HOME and PATH environment variables). Each service operates in its own execution context. All service unit operations are subject to a default timeout of 5 minutes to prevent a malfunctioning service from freezing the system. Managing system services Service units end with the .service file extension and have a similar purpose to init scripts. The systemctl command is used to display , start , stop , restart a system service: systemctl Description systemctl start name .service Start a service systemctl stop name .service Stops a service systemctl restart name .service Restart a service systemctl reload name .service Reload a configuration systemctl status name .service Checks if a service is running systemctl try-restart name .service Restart a service only if it is running systemctl list-units --type service --all Display the status of all services The systemctl command is also used for the enable or disable of system a service and displaying associated services: systemctl Description systemctl enable name .service Activate a service systemctl disable name .service Disable a service systemctl list-unit-files --type service Lists all services and checks if they are running systemctl list-dependencies --after Lists the services that start before the specified unit systemctl list-dependencies --before Lists the services that start after the specified unit Examples: systemctl stop nfs-server.service # or systemctl stop nfs-server To list all units currently loaded: systemctl list-units --type service To list all units to check if they are activated: systemctl list-unit-files --type service systemctl enable httpd.service systemctl disable bluetooth.service Example of a .service file for the postfix service postfix.service Unit File What follows is the content of the /usr/lib/systemd/system/postfix.service unit file as currently provided by the postfix package: [Unit] Description=Postfix Mail Transport Agent After=syslog.target network.target Conflicts=sendmail.service exim.service [Service] Type=forking PIDFile=/var/spool/postfix/pid/master.pid EnvironmentFile=-/etc/sysconfig/network ExecStartPre=-/usr/libexec/postfix/aliasesdb ExecStartPre=-/usr/libexec/postfix/chroot-update ExecStart=/usr/sbin/postfix start ExecReload=/usr/sbin/postfix reload ExecStop=/usr/sbin/postfix stop [Install] WantedBy=multi-user.target Using system targets On Rocky8/RHEL8, the concept of run levels has been replaced by Systemd targets. Systemd targets are represented by target units. Target units end with the .target file extension and their sole purpose is to group other Systemd units into a chain of dependencies. For example, the graphical.target unit, which is used to start a graphical session, starts system services such as the GNOME display manager ( gdm.service ) or the accounts service ( accounts-daemon.service ) and also activates the multi-user.target unit. Similarly, the multi-user.target unit starts other essential system services, such as NetworkManager ( NetworkManager.service ) or D-Bus ( dbus.service ) and activates another target unit named basic.target . Target Units Description poweroff.target Shuts down the system and turns it off rescue.target Activates a rescue shell multi-user.target Activates a multi-user system without graphical interface graphical.target Activates a multi-user system with graphical interface reboot.target Shuts down and restarts the system The default target To determine which target is used by default: systemctl get-default This command searches for the target of the symbolic link located at /etc/systemd/system/default.target and displays the result. $ systemctl get-default graphical.target The systemctl command can also provide a list of available targets: systemctl list-units --type target UNIT LOAD ACTIVE SUB DESCRIPTION basic.target loaded active active Basic System bluetooth.target loaded active active Bluetooth cryptsetup.target loaded active active Encrypted Volumes getty.target loaded active active Login Prompts graphical.target loaded active active Graphical Interface local-fs-pre.target loaded active active Local File Systems (Pre) local-fs.target loaded active active Local File Systems multi-user.target loaded active active Multi-User System network-online.target loaded active active Network is Online network.target loaded active active Network nss-user-lookup.target loaded active active User and Group Name Lookups paths.target loaded active active Paths remote-fs.target loaded active active Remote File Systems slices.target loaded active active Slices sockets.target loaded active active Sockets sound.target loaded active active Sound Card swap.target loaded active active Swap sysinit.target loaded active active System Initialization timers.target loaded active active Timers To configure the system to use a different default target: systemctl set-default name.target Example: # systemctl set-default multi-user.target rm '/etc/systemd/system/default.target' ln -s '/usr/lib/systemd/system/multi-user.target' '/etc/systemd/system/default.target' To switch to a different target unit in the current session: systemctl isolate name.target The Rescue mode provides a simple environment to repair your system in cases where it is impossible to perform a normal boot process. In rescue mode , the system attempts to mount all local file systems and start several important system services, but does not enable a network interface or allow other users to connect to the system at the same time. On Rocky 8, the rescue mode is equivalent to the old single user mode and requires the root password. To change the current target and enter rescue mode in the current session: systemctl rescue Emergency mode provides the most minimalist environment possible and allows the system to be repaired even in situations where the system is unable to enter rescue mode. In the emergency mode, the system mounts the root file system only for reading. It will not attempt to mount any other local file system, will not activate any network interface, and will start some essential services. To change the current target and enter emergency mode in the current session: systemctl emergency Shutdown, suspension and hibernation The systemctl command replaces a number of power management commands used in previous versions: Old command New command Description halt systemctl halt Shuts down the system. poweroff systemctl poweroff Turns off the system. reboot systemctl reboot Restarts the system. pm-suspend systemctl suspend Suspends the system. pm-hibernate systemctl hibernate Hibernates the system. pm-suspend-hybrid systemctl hybrid-sleep Hibernates and suspends the system. The journald process Log files can, in addition to rsyslogd , also be managed by the journald daemon which is a component of systemd . The journald daemon captures Syslog messages, kernel log messages, messages from the initial RAM disk and from the start of boot, as well as messages written to the standard output and the standard error output of all services, then indexes them and makes them available to the user. The format of the native log file, which is a structured and indexed binary file, improves searches and allows for faster operation, it also stores metadata information, such as timestamps or user IDs. journalctl command The journalctl command displays the log files. journalctl The command lists all log files generated on the system. The structure of this output is similar to that used in /var/log/messages/ but it offers some improvements: the priority of entries is marked visually; timestamps are converted to the local time zone of your system; all logged data is displayed, including rotating logs; the beginning of a start is marked with a special line. Using continuous display With continuous display, log messages are displayed in real time. journalctl -f This command returns a list of the ten most recent log lines. The journalctl utility then continues to run and waits for new changes to occur before displaying them immediately. Filtering messages It is possible to use different filtering methods to extract information that fits different needs. Log messages are often used to track erroneous behavior on the system. To view entries with a selected or higher priority: journalctl -p priority You must replace priority with one of the following keywords (or a number): debug (7), info (6), notice (5), warning (4), err (3), crit (2), alert (1), and emerg (0).","title":"System Startup"},{"location":"books/admin_guide/10-boot/#system-startup","text":"In this chapter you will learn how the system start. Objectives : In this chapter, future Linux administrators will learn: :heavy_check_mark: The different stages of the booting process; :heavy_check_mark: How Rocky Linux supports this boot via GRUB2 and systemd; :heavy_check_mark: How to protect GRUB2 from an attack; :heavy_check_mark: How to manage the services; :heavy_check_mark: How to access to the logs from journald. :checkered_flag: users Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 20 minutes","title":"System Startup"},{"location":"books/admin_guide/10-boot/#the-boot-process","text":"It is important to understand the boot process of Linux in order to be able to solve problems that may occur. The boot process includes:","title":"The boot process"},{"location":"books/admin_guide/10-boot/#the-bios-startup","text":"The BIOS (Basic Input/Output System) performs the POST (power on self test) to detect, test and initialize the system hardware components. It then loads the MBR (Master Boot Record).","title":"The BIOS startup"},{"location":"books/admin_guide/10-boot/#the-master-boot-record-mbr","text":"The Master Boot Record is the first 512 bytes of the boot disk. The MBR discovers the boot device and loads the bootloader GRUB2 into memory and transfers control to it. The next 64 bytes contain the partition table of the disk.","title":"The Master boot record (MBR)"},{"location":"books/admin_guide/10-boot/#the-grub2-bootloader","text":"The default bootloader for the Rocky 8 distribution is GRUB2 (GRand Unified Bootloader). GRUB2 replaces the old GRUB bootloader (also called GRUB legacy). The GRUB 2 configuration file is located under /boot/grub2/grub.cfg but this file should not be edited directly. The GRUB2 menu configuration settings are located under /etc/default/grub and are used to generate the grub.cfg file. # cat /etc/default/grub GRUB_TIMEOUT=5 GRUB_DEFAULT=saved GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=\"console\" GRUB_CMDLINE_LINUX=\"rd.lvm.lv=rhel/swap crashkernel=auto rd.lvm.lv=rhel/root rhgb quiet net.ifnames=0\" GRUB_DISABLE_RECOVERY=\"true\" If changes are made to one or more of these parameters, the grub2-mkconfig command must be run to regenerate the /boot/grub2/grub.cfg file. [root] # grub2-mkconfig \u2013o /boot/grub2/grub.cfg GRUB2 looks for the compressed kernel image (the vmlinuz file) in the /boot directory. GRUB2 loads the kernel image into memory and extracts the contents of the initramfs image file into a temporary folder in memory using the tmpfs file system.","title":"The GRUB2 bootloader"},{"location":"books/admin_guide/10-boot/#the-kernel","text":"The kernel starts the systemd process with PID 1. root 1 0 0 02:10 ? 00:00:02 /usr/lib/systemd/systemd --switched-root --system --deserialize 23","title":"The kernel"},{"location":"books/admin_guide/10-boot/#systemd","text":"Systemd is the parent of all system processes. It reads the target of the /etc/systemd/system/default.target link (e.g. /usr/lib/systemd/system/multi-user.target ) to determine the default target of the system. The file defines the services to be started. Systemd then places the system in the target-defined state by performing the following initialization tasks: Set the machine name Initialize the network Initialize SELinux Display the welcome banner Initialize the hardware based on the arguments given to the kernel at boot time Mount the file systems, including virtual file systems like /proc Clean up directories in /var Start the virtual memory (swap)","title":"systemd"},{"location":"books/admin_guide/10-boot/#protecting-the-grub2-bootloader","text":"Why protect the bootloader with a password? Prevent Single user mode access - If an attacker can boot into single user mode, he becomes the root user. Prevent access to GRUB console - If an attacker manages to use GRUB console, he can change its configuration or collect information about the system by using the cat command. Prevent access to insecure operating systems. If there is a dual boot on the system, an attacker can select an operating system like DOS at boot time that ignores access controls and file permissions. To password protect the GRUB2 bootloader: Remove -unrestricted from the main CLASS= statement in the /etc/grub.d/10_linux file. If a user has not yet been configured, use the grub2-setpassword command to provide a password for the root user: # grub2-setpassword A /boot/grub2/user.cfg file will be created if it was not already present. It contains the hashed password of the GRUB2. !!! Note This command only supports configurations with a single root user. [root]# cat /boot/grub2/user.cfg GRUB2_PASSWORD=grub.pbkdf2.sha512.10000.CC6F56....A21 Recreate the configuration file with the grub2-mkconfig command: [root]# grub2-mkconfig -o /boot/grub2/grub.cfg Generating grub configuration file ... Found linux image: /boot/vmlinuz-3.10.0-327.el7.x86_64 Found initrd image: /boot/initramfs-3.10.0-327.el7.x86_64.img Found linux image: /boot/vmlinuz-0-rescue-f9725b0c842348ce9e0bc81968cf7181 Found initrd image: /boot/initramfs-0-rescue-f9725b0c842348ce9e0bc81968cf7181.img done Restart the server and check. All entries defined in the GRUB menu will now require a user and password to be entered at each boot. The system will not boot a kernel without direct user intervention from the console. When the user is requested, enter root ; When a password is requested, enter the password provided at the grub2-setpassword command. To protect only the editing of GRUB menu entries and access to the console, the execution of the grub2-setpassword command is sufficient. There may be cases where you have good reasons for doing only that. This might be particularly true in a remote data center where entering a password each time a server is rebooted is either difficult or impossible to do.","title":"Protecting the GRUB2 bootloader"},{"location":"books/admin_guide/10-boot/#systemd_1","text":"Systemd is a service manager for the Linux operating systems. It is developed to: remain compatible with older SysV initialization scripts, provide many features, such as parallel start of system services at system startup, on-demand activation of daemons, support for snapshots, or management of dependencies between services. !!! Note Systemd is the default initialization system since RedHat/CentOS 7. Systemd introduces the concept of systemd units. Type File extension Observation Service unit .service System service Target unit .target A group of systemd units Mount unit .automount An automatic mount point for file system !!! Note There are many types of units: Device unit, Mount unit, Path unit, Scope unit, Slice unit, Snapshot unit, Socket unit, Swap unit, Timer unit. Systemd supports system state snapshots and restore. Mount points can be configured as systemd targets. At startup, systemd creates listening sockets for all system services that support this type of activation and passes these sockets to these services as soon as they are started. This makes it possible to restart a service without losing a single message sent to it by the network during its unavailability. The corresponding socket remains accessible and all messages are queued. System services that use D-BUS for their inter-process communications can be started on demand the first time they are used by a client. Systemd stops or restarts only running services. Previous versions (before RHEL7) attempted to stop services directly without checking their current status. System services do not inherit any context (like HOME and PATH environment variables). Each service operates in its own execution context. All service unit operations are subject to a default timeout of 5 minutes to prevent a malfunctioning service from freezing the system.","title":"Systemd"},{"location":"books/admin_guide/10-boot/#managing-system-services","text":"Service units end with the .service file extension and have a similar purpose to init scripts. The systemctl command is used to display , start , stop , restart a system service: systemctl Description systemctl start name .service Start a service systemctl stop name .service Stops a service systemctl restart name .service Restart a service systemctl reload name .service Reload a configuration systemctl status name .service Checks if a service is running systemctl try-restart name .service Restart a service only if it is running systemctl list-units --type service --all Display the status of all services The systemctl command is also used for the enable or disable of system a service and displaying associated services: systemctl Description systemctl enable name .service Activate a service systemctl disable name .service Disable a service systemctl list-unit-files --type service Lists all services and checks if they are running systemctl list-dependencies --after Lists the services that start before the specified unit systemctl list-dependencies --before Lists the services that start after the specified unit Examples: systemctl stop nfs-server.service # or systemctl stop nfs-server To list all units currently loaded: systemctl list-units --type service To list all units to check if they are activated: systemctl list-unit-files --type service systemctl enable httpd.service systemctl disable bluetooth.service","title":"Managing system services"},{"location":"books/admin_guide/10-boot/#example-of-a-service-file-for-the-postfix-service","text":"postfix.service Unit File What follows is the content of the /usr/lib/systemd/system/postfix.service unit file as currently provided by the postfix package: [Unit] Description=Postfix Mail Transport Agent After=syslog.target network.target Conflicts=sendmail.service exim.service [Service] Type=forking PIDFile=/var/spool/postfix/pid/master.pid EnvironmentFile=-/etc/sysconfig/network ExecStartPre=-/usr/libexec/postfix/aliasesdb ExecStartPre=-/usr/libexec/postfix/chroot-update ExecStart=/usr/sbin/postfix start ExecReload=/usr/sbin/postfix reload ExecStop=/usr/sbin/postfix stop [Install] WantedBy=multi-user.target","title":"Example of a .service file for the postfix service"},{"location":"books/admin_guide/10-boot/#using-system-targets","text":"On Rocky8/RHEL8, the concept of run levels has been replaced by Systemd targets. Systemd targets are represented by target units. Target units end with the .target file extension and their sole purpose is to group other Systemd units into a chain of dependencies. For example, the graphical.target unit, which is used to start a graphical session, starts system services such as the GNOME display manager ( gdm.service ) or the accounts service ( accounts-daemon.service ) and also activates the multi-user.target unit. Similarly, the multi-user.target unit starts other essential system services, such as NetworkManager ( NetworkManager.service ) or D-Bus ( dbus.service ) and activates another target unit named basic.target . Target Units Description poweroff.target Shuts down the system and turns it off rescue.target Activates a rescue shell multi-user.target Activates a multi-user system without graphical interface graphical.target Activates a multi-user system with graphical interface reboot.target Shuts down and restarts the system","title":"Using system targets"},{"location":"books/admin_guide/10-boot/#the-default-target","text":"To determine which target is used by default: systemctl get-default This command searches for the target of the symbolic link located at /etc/systemd/system/default.target and displays the result. $ systemctl get-default graphical.target The systemctl command can also provide a list of available targets: systemctl list-units --type target UNIT LOAD ACTIVE SUB DESCRIPTION basic.target loaded active active Basic System bluetooth.target loaded active active Bluetooth cryptsetup.target loaded active active Encrypted Volumes getty.target loaded active active Login Prompts graphical.target loaded active active Graphical Interface local-fs-pre.target loaded active active Local File Systems (Pre) local-fs.target loaded active active Local File Systems multi-user.target loaded active active Multi-User System network-online.target loaded active active Network is Online network.target loaded active active Network nss-user-lookup.target loaded active active User and Group Name Lookups paths.target loaded active active Paths remote-fs.target loaded active active Remote File Systems slices.target loaded active active Slices sockets.target loaded active active Sockets sound.target loaded active active Sound Card swap.target loaded active active Swap sysinit.target loaded active active System Initialization timers.target loaded active active Timers To configure the system to use a different default target: systemctl set-default name.target Example: # systemctl set-default multi-user.target rm '/etc/systemd/system/default.target' ln -s '/usr/lib/systemd/system/multi-user.target' '/etc/systemd/system/default.target' To switch to a different target unit in the current session: systemctl isolate name.target The Rescue mode provides a simple environment to repair your system in cases where it is impossible to perform a normal boot process. In rescue mode , the system attempts to mount all local file systems and start several important system services, but does not enable a network interface or allow other users to connect to the system at the same time. On Rocky 8, the rescue mode is equivalent to the old single user mode and requires the root password. To change the current target and enter rescue mode in the current session: systemctl rescue Emergency mode provides the most minimalist environment possible and allows the system to be repaired even in situations where the system is unable to enter rescue mode. In the emergency mode, the system mounts the root file system only for reading. It will not attempt to mount any other local file system, will not activate any network interface, and will start some essential services. To change the current target and enter emergency mode in the current session: systemctl emergency","title":"The default target"},{"location":"books/admin_guide/10-boot/#shutdown-suspension-and-hibernation","text":"The systemctl command replaces a number of power management commands used in previous versions: Old command New command Description halt systemctl halt Shuts down the system. poweroff systemctl poweroff Turns off the system. reboot systemctl reboot Restarts the system. pm-suspend systemctl suspend Suspends the system. pm-hibernate systemctl hibernate Hibernates the system. pm-suspend-hybrid systemctl hybrid-sleep Hibernates and suspends the system.","title":"Shutdown, suspension and hibernation"},{"location":"books/admin_guide/10-boot/#the-journald-process","text":"Log files can, in addition to rsyslogd , also be managed by the journald daemon which is a component of systemd . The journald daemon captures Syslog messages, kernel log messages, messages from the initial RAM disk and from the start of boot, as well as messages written to the standard output and the standard error output of all services, then indexes them and makes them available to the user. The format of the native log file, which is a structured and indexed binary file, improves searches and allows for faster operation, it also stores metadata information, such as timestamps or user IDs.","title":"The journald process"},{"location":"books/admin_guide/10-boot/#journalctl-command","text":"The journalctl command displays the log files. journalctl The command lists all log files generated on the system. The structure of this output is similar to that used in /var/log/messages/ but it offers some improvements: the priority of entries is marked visually; timestamps are converted to the local time zone of your system; all logged data is displayed, including rotating logs; the beginning of a start is marked with a special line.","title":"journalctl command"},{"location":"books/admin_guide/10-boot/#using-continuous-display","text":"With continuous display, log messages are displayed in real time. journalctl -f This command returns a list of the ten most recent log lines. The journalctl utility then continues to run and waits for new changes to occur before displaying them immediately.","title":"Using continuous display"},{"location":"books/admin_guide/10-boot/#filtering-messages","text":"It is possible to use different filtering methods to extract information that fits different needs. Log messages are often used to track erroneous behavior on the system. To view entries with a selected or higher priority: journalctl -p priority You must replace priority with one of the following keywords (or a number): debug (7), info (6), notice (5), warning (4), err (3), crit (2), alert (1), and emerg (0).","title":"Filtering messages"},{"location":"books/admin_guide/11-tasks/","text":"Task Management In this chapter you will learn how to manage scheduled tasks. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: Linux deals with the tasks scheduling; :heavy_check_mark: restrict the use of cron to certain users; :heavy_check_mark: schedule tasks. :checkered_flag: crontab , crond , scheduling , linux Knowledge : :star: :star: Complexity : :star: :star: Reading time : 15 minutes Generalities The scheduling of tasks is managed with the cron utility. It allows the periodic execution of tasks. It is reserved to the administrator for system tasks but can be used by normal users for tasks or scripts that they have access to. To access the cron utility, we use: crontab . The cron service is used for: Repetitive administration operations; Backups; Monitoring of system activity; Program execution. crontab is short for cron table , but can be thought of as a task scheduling table. !!! Warning To set up a schedule, the system must have the correct time set. How the service works The cron service is run by a crond daemon present in memory. To check its status: [root] # systemctl status crond !!! Tip If the `crond` daemon is not running, you will have to initialize it manually and/or automatically at startup. Indeed, even if tasks are scheduled, they will not be launched. Initialization of the crond daemon in manual: [root]# systemctl {status|start|restart|stop} crond Initialization of the crond daemon at startup: [root]# systemctl enable crond Security In order to implement a schedule, a user must have permission to use the cron service. This permission varies according to the information contained in the files below: /etc/cron.allow /etc/cron.deny !!! Warning If neither file is present, all users can use `cron`. The cron.allow and cron.deny Files File /etc/cron.allow Only users contained in this file are allowed to use cron . If it exists and is empty, no users can use cron . !!! Warning If `cron.allow` is present, `cron.deny` is **ignored**. File /etc/cron.deny Users in this file are not allowed to use cron . If it is empty, all users can use cron . By default, /etc/cron.deny exists and is empty and /etc/cron.allow does not exist. Allowing a user Only user1 will be able to use cron . [root]# vi /etc/cron.allow user1 Prohibit a user Only user2 will not be able to use cron . [root]# vi /etc/cron.deny user2 cron.allow must not be present. Scheduling tasks When a user schedules a task, a file with his name is created under /var/spool/cron/ . This file contains all the information the crond needs to know regarding all tasks created by this user, the commands or programs to run, and when to run them (hour, minute, day ...). The crontab command The crontab command is used to manage the schedule file. crontab [-u user] [-e | -l | -r] Example: [root]# crontab -u user1 -e Option Description -e Edit the schedule file with vi -l Displays the contents of the schedule file -u Name of the user whose schedule file is to be manipulated -r Delete the schedule file !!! Warning `crontab` without option deletes the old schedule file and waits for the user to enter new lines. You have to press <kbd>ctrl</kbd> + <kbd>d</kbd> to exit this editing mode. Only `root` can use the `-u user` option to manage another user's schedule file. The example above allows root to schedule a task for user1. Uses of crontab The uses of crontab are many and include: Modifications to the crontab files taken into account immediately; No need to restart. On the other hand, the following points must be taken into account: The program must be autonomous; Provide redirections (stdin, stdout, stderr); It is not relevant to run commands that use input/output requests on a terminal. !!! Note It is important to understand that the purpose of scheduling is to perform tasks automatically, without the need for external intervention. The crontab file The crontab file is structured according to the following rules. Each line of this file corresponds to a schedule; Each line has six fields, 5 for the time and 1 for the order; Each field is separated by a space or a tab; Each line ends with a carriage return; A # at the beginning of the line comments it. [root]# crontab \u2013e 10 4 1 * * /root/scripts/backup.sh 1 2 3 4 5 6 Field Description Detail 1 Minute(s) From 0 to 59 2 Hour(s) From 0 to 23 3 Day(s) of the month From 1 to 31 4 Month of the year From 1 to 12 5 Day(s) of the week From 0 to 7 (0=7=sunday) 6 Task to execute Full command or script !!! Warning The tasks to be executed must use absolute paths and if possible use redirects. In order to simplify the notation for the definition of time, it is advisable to use special symbols. Wildcards Description * All possible values of the field - Indicates a range of values , Indicates a list of values / Defines a step Examples: Script executed on April 15 at 10:25 am: 25 10 15 04 * /root/scripts/script > /log/\u2026 Run at 11am and then at 4pm every day: 00 11,16 * * * /root/scripts/script > /log/\u2026 Run every hour from 11am to 4pm every day: 00 11-16 * * * /root/scripts/script > /log/\u2026 Run every 10 minutes during working hours: */10 8-17 * * 1-5 /root/scripts/script > /log/\u2026 For the root user, crontab also has some special time settings: Setting Description @reboot Run command on system reboot @hourly Run command every hour @daily Runs daily just after midnight @weekly Runs command every Sunday just after midnight @monthly Runs command on the first day of the month just after midnight @annually Runs January 1st just after midnight Task execution process A user, rockstar, wants to edit his crontab file: 1) crond checks to see if he is allowed ( /etc/cron.allow and /etc/cron.deny ). 2) If he is, he accesses his crontab file ( /var/spool/cron/rockstar ). Every minute crond reads the schedule files. 3) It executes the scheduled tasks. 4) It reports systematically in a log file ( /var/log/cron ).","title":"Task Management"},{"location":"books/admin_guide/11-tasks/#task-management","text":"In this chapter you will learn how to manage scheduled tasks. Objectives : In this chapter, future Linux administrators will learn how to: :heavy_check_mark: Linux deals with the tasks scheduling; :heavy_check_mark: restrict the use of cron to certain users; :heavy_check_mark: schedule tasks. :checkered_flag: crontab , crond , scheduling , linux Knowledge : :star: :star: Complexity : :star: :star: Reading time : 15 minutes","title":"Task Management"},{"location":"books/admin_guide/11-tasks/#generalities","text":"The scheduling of tasks is managed with the cron utility. It allows the periodic execution of tasks. It is reserved to the administrator for system tasks but can be used by normal users for tasks or scripts that they have access to. To access the cron utility, we use: crontab . The cron service is used for: Repetitive administration operations; Backups; Monitoring of system activity; Program execution. crontab is short for cron table , but can be thought of as a task scheduling table. !!! Warning To set up a schedule, the system must have the correct time set.","title":"Generalities"},{"location":"books/admin_guide/11-tasks/#how-the-service-works","text":"The cron service is run by a crond daemon present in memory. To check its status: [root] # systemctl status crond !!! Tip If the `crond` daemon is not running, you will have to initialize it manually and/or automatically at startup. Indeed, even if tasks are scheduled, they will not be launched. Initialization of the crond daemon in manual: [root]# systemctl {status|start|restart|stop} crond Initialization of the crond daemon at startup: [root]# systemctl enable crond","title":"How the service works"},{"location":"books/admin_guide/11-tasks/#security","text":"In order to implement a schedule, a user must have permission to use the cron service. This permission varies according to the information contained in the files below: /etc/cron.allow /etc/cron.deny !!! Warning If neither file is present, all users can use `cron`.","title":"Security"},{"location":"books/admin_guide/11-tasks/#the-cronallow-and-crondeny-files","text":"File /etc/cron.allow Only users contained in this file are allowed to use cron . If it exists and is empty, no users can use cron . !!! Warning If `cron.allow` is present, `cron.deny` is **ignored**. File /etc/cron.deny Users in this file are not allowed to use cron . If it is empty, all users can use cron . By default, /etc/cron.deny exists and is empty and /etc/cron.allow does not exist.","title":"The cron.allow and cron.deny Files"},{"location":"books/admin_guide/11-tasks/#allowing-a-user","text":"Only user1 will be able to use cron . [root]# vi /etc/cron.allow user1","title":"Allowing a user"},{"location":"books/admin_guide/11-tasks/#prohibit-a-user","text":"Only user2 will not be able to use cron . [root]# vi /etc/cron.deny user2 cron.allow must not be present.","title":"Prohibit a user"},{"location":"books/admin_guide/11-tasks/#scheduling-tasks","text":"When a user schedules a task, a file with his name is created under /var/spool/cron/ . This file contains all the information the crond needs to know regarding all tasks created by this user, the commands or programs to run, and when to run them (hour, minute, day ...).","title":"Scheduling tasks"},{"location":"books/admin_guide/11-tasks/#the-crontab-command","text":"The crontab command is used to manage the schedule file. crontab [-u user] [-e | -l | -r] Example: [root]# crontab -u user1 -e Option Description -e Edit the schedule file with vi -l Displays the contents of the schedule file -u Name of the user whose schedule file is to be manipulated -r Delete the schedule file !!! Warning `crontab` without option deletes the old schedule file and waits for the user to enter new lines. You have to press <kbd>ctrl</kbd> + <kbd>d</kbd> to exit this editing mode. Only `root` can use the `-u user` option to manage another user's schedule file. The example above allows root to schedule a task for user1.","title":"The crontab command"},{"location":"books/admin_guide/11-tasks/#uses-of-crontab","text":"The uses of crontab are many and include: Modifications to the crontab files taken into account immediately; No need to restart. On the other hand, the following points must be taken into account: The program must be autonomous; Provide redirections (stdin, stdout, stderr); It is not relevant to run commands that use input/output requests on a terminal. !!! Note It is important to understand that the purpose of scheduling is to perform tasks automatically, without the need for external intervention.","title":"Uses of crontab"},{"location":"books/admin_guide/11-tasks/#the-crontab-file","text":"The crontab file is structured according to the following rules. Each line of this file corresponds to a schedule; Each line has six fields, 5 for the time and 1 for the order; Each field is separated by a space or a tab; Each line ends with a carriage return; A # at the beginning of the line comments it. [root]# crontab \u2013e 10 4 1 * * /root/scripts/backup.sh 1 2 3 4 5 6 Field Description Detail 1 Minute(s) From 0 to 59 2 Hour(s) From 0 to 23 3 Day(s) of the month From 1 to 31 4 Month of the year From 1 to 12 5 Day(s) of the week From 0 to 7 (0=7=sunday) 6 Task to execute Full command or script !!! Warning The tasks to be executed must use absolute paths and if possible use redirects. In order to simplify the notation for the definition of time, it is advisable to use special symbols. Wildcards Description * All possible values of the field - Indicates a range of values , Indicates a list of values / Defines a step Examples: Script executed on April 15 at 10:25 am: 25 10 15 04 * /root/scripts/script > /log/\u2026 Run at 11am and then at 4pm every day: 00 11,16 * * * /root/scripts/script > /log/\u2026 Run every hour from 11am to 4pm every day: 00 11-16 * * * /root/scripts/script > /log/\u2026 Run every 10 minutes during working hours: */10 8-17 * * 1-5 /root/scripts/script > /log/\u2026 For the root user, crontab also has some special time settings: Setting Description @reboot Run command on system reboot @hourly Run command every hour @daily Runs daily just after midnight @weekly Runs command every Sunday just after midnight @monthly Runs command on the first day of the month just after midnight @annually Runs January 1st just after midnight","title":"The crontab file"},{"location":"books/admin_guide/11-tasks/#task-execution-process","text":"A user, rockstar, wants to edit his crontab file: 1) crond checks to see if he is allowed ( /etc/cron.allow and /etc/cron.deny ). 2) If he is, he accesses his crontab file ( /var/spool/cron/rockstar ). Every minute crond reads the schedule files. 3) It executes the scheduled tasks. 4) It reports systematically in a log file ( /var/log/cron ).","title":"Task execution process"},{"location":"books/admin_guide/12-network/","text":"Implementing the Network In this chapter you will learn how to work with and manage the network. Objectives : In this chapter you will learn how to: :heavy_check_mark: Configure a workstation to use DHCP; :heavy_check_mark: Configure a workstation to use a static configuration; :heavy_check_mark: Configure a workstation to use a gateway; :heavy_check_mark: Configure a workstation to use DNS servers; :heavy_check_mark: Troubleshoot the network of a workstation. :checkered_flag: network , linux , ip Knowledge : :star: :star: Complexity : :star: :star: Reading time : 30 minutes Generalities To illustrate this chapter, we will use the following architecture. It will allow us to consider : integration in a LAN (local area network); the configuration of a gateway to reach a remote server; the configuration of a DNS server and the implementation of name resolution. The minimum parameters to be defined for the machine are: the name of the machine ; the IP address; the subnet mask. Example: pc-rocky ; 192.168.1.10 ; 255.255.255.0 . The notation called CIDR is more and more frequent: 192.168.1.10/24 IP addresses are used for the proper routing of messages (packets). They are divided into two parts: the fixed part, identifying the network; the identifier of the host in the network. The subnet mask is a set of 4 bytes intended to isolate: the network address ( NetID or SubnetID ) by performing a bitwise logical AND between the IP address and the mask; the host address ( HostID ) by performing a bitwise logical AND between the IP address and the complement of the mask. There are also specific addresses within a network, which must be identified. The first address of a range as well as the last one have a particular role: The first address of a range is the network address . It is used to identify networks and to route information from one network to another. The last address of a range is the broadcast address . It is used to broadcast information to all the machines on the network. MAC address / IP address A MAC address is a physical identifier written in the factory onto the device. This is sometimes referred to as the hardware address. It consists of 6 bytes often given in hexadecimal form (for example 5E:FF:56:A2:AF:15). It is composed of : 3 bytes of the manufacturer identifier and 3 bytes of the serial number. !!! Warning This last statement is nowadays a little less true with virtualization. There are also software solutions for changing the MAC address. An Internet Protocol ( IP ) address is an identification number permanently or temporarily assigned to each device connected to a computer network using the Internet Protocol. One part defines the network address (NetID or SubnetID as the case may be), the other part defines the address of the host in the network (HostID). The relative size of each part varies according to the network (sub)mask. An IPv4 address defines an address on 4 bytes. The number of available addresses being close to saturation a new standard was created, the IPv6 defined on 16 bytes. IPv6 is often represented by 8 groups of 2 bytes separated by a colon. Insignificant zeros can be omitted, one or more groups of 4 consecutive zeros can be replaced by a double colon. Subnet masks have from 0 to 128 bits. (for example 21ac:0000:0000:0611:21e0:00ba:321b:54da/64 or 21ac::611:21e0:ba:321b:54da/64) In a web address or URL (Uniform Resource Locator), an ip address can be followed by a colon and the port address (which indicates the application to which the data is destined). Also to avoid confusion in a URL, the IPv6 address is written in square brackets [ ], colon, port address. IP and MAC addresses must be unique on a network! DNS Domain Client machines can be part of a DNS ( Domain Name System , e.g. mydomain.lan ) domain. The fully qualified machine name ( FQDN ) becomes pc-rocky.mydomain.lan . A set of computers can be grouped into a logical, name-resolving, set called a DNS domain. A DNS domain is not, of course, limited to a single physical network. In order for a computer to be part of a DNS domain, it must be given a DNS suffix (here mydomain.lan ) as well as servers that it can query. Reminder of the OSI model !!! Note \"Memory aid\" To remember the order of the layers of the OSI model, remember the following sentence: __Please Do Not Touch Steven's Pet Alligator__. Layer Protocoles 7 - Application POP, IMAP, SMTP, SSH, SNMP, HTTP, FTP, ... 6 - Presentation ASCII, MIME, ... 5 - Session TLS, SSL, NetBIOS, ... 4 - Transport TLS, SSL, TCP, UDP, ... 3 - Network IPv4, IPv6, ARP, ... 2 - Data Link Ethernet, WiFi, Token Ring, ... 1 - Physical Cables, optical fibers, radio waves, ... Layer 1 (Physical) supports transmission over a communication channel (Wifi, Optical fiber, RJ cable, etc.). Unit: the bit. Layer 2 (Data Link) supports network topology (token-ring, star, bus, etc.), data splitting and transmission errors. Unit: the frame. Layer 3 (Network) supports end-to-end data transmission (IP routing = Gateway). Unit: the packet. Layer 4 (Transport) supports service type (connected or unconnected) encryption and flow control. Unit: the segment or the datagram. Layer 5 (Session) supports the communication between two computers. Layer 6 (Presentation) represents the area that is independent of data at the application layer. Essentially this layer translates from network format to the application format, or or from the application format to the network format. Layer 7 (Application) represents the contact with the user. It provides the services offered by the network: http, dns, ftp, imap, pop, smtp, etc. The naming of interfaces lo is the \" loopback \" interface which allows TCP/IP programs to communicate with each other without leaving the local machine. This enables testing if the network module of the system is working properly and also allows pinging the localhost. All packets that enter through localhost leave through localhost. The packets received are the packets sent. The Linux kernel assigns interface names with a specific prefix depending on the type. Traditionally, all Ethernet interfaces, for example, began with eth . The prefix was followed by a number, the first being 0 (eth0, eth1, eth2...). The wifi interfaces were given a wlan prefix. On Rocky8 Linux distributions, systemd will name interfaces with the new following policy where \"X\" represents a number: enoX : on-board devices ensX : PCI Express hotplug slot enpXsX : physical/geographical location of the connector of the hardware ... Using the ip command Forget the old ifconfig command! Think ip ! !!! Note Comment for administrators of older Linux systems: The historical network management command is `ifconfig`. This command has been replaced by the `ip` command, which is already well known to network administrators. The `ip` command is the only command to manage **IP address, ARP, routing, etc.**. The `ifconfig` command is no longer installed by default in Rocky8. It is important to get into good habits now. The hostname The hostname command displays or sets the host name of the system hostname [-f] [hostname] Option Description -f Display the FQDN -i Display the system IPs address !!! Tip This command is used by various network programs to identify the machine. To assign a host name, it is possible to use the hostname command, but the changes will not be retained at the next boot. The command with no arguments displays the host name. To set the host name, the file /etc/sysconfig/network must be modified: NETWORKING=yes HOSTNAME=pc-rocky.mondomaine.lan The RedHat boot script also consults the /etc/hosts file to resolve the host name of the system. When the system boots, Linux evaluates the HOSTNAME value in the /etc/sysconfig/network file. It then uses the /etc/hosts file to evaluate the main IP address of the server and its host name. It deduces the DNS domain name. It is therefore essential to fill in these two files before any configuration of network services. !!! Tip To know if this configuration is well done, the commands `hostname` and `hostname -f` must answer with the expected values. /etc/hosts file The /etc/hosts file is a static host name mapping table, which follows the following format: @IP <hostname> [alias] [# comment] Example of /etc/hosts file: 127.0.0.1 localhost localhost.localdomain ::1 localhost localhost.localdomain 192.168.1.10 rockstar.rockylinux.lan rockstar The /etc/hosts file is still used by the system, especially at boot time when the system FQDN is determined. !!! Tip RedHat recommends that at least one line containing the system name be filled in. If the DNS service ( D domain N ame S ervice) is not in place, you must fill in all the names in the hosts file for each of your machines. The /etc/hosts file contains one line per entry, with the IP address, the FQDN, then the host name (in that order) and a series of aliases (alias1 alias2 ...). The alias is an option. /etc/nsswitch.conf file The NSS ( N ame S ervice S witch) allows configuration files (e.g. /etc/passwd , /etc/group , /etc/hosts ) to be substituted for one or more centralized databases. The /etc/nsswitch.conf file is used to configure the name service databases. passwd: files shadow: files group: files hosts: files dns In this case, Linux will first look for a host name match ( hosts: line) in the /etc/hosts file ( files value) before querying DNS ( dns value)! This behavior can simply be changed by editing the /etc/nsswitch.conf file. Of course, it is possible to imagine querying an LDAP, MySQL or other server by configuring the name service to respond to system requests for hosts, users, groups, etc. The resolution of the name service can be tested with the getent command that we will see later in this course. /etc/resolv.conf file The /etc/resolv.conf file contains the DNS name resolution configuration. #Generated by NetworkManager domain mondomaine.lan search mondomaine.lan nameserver 192.168.1.254 !!! Tip This file is historical. It is no longer filled in directly! Newer generations of distributions have generally integrated the NetworkManager service. This service allows you to manage the configuration more efficiently, either in graphical or console mode. It allows for the addition of DNS servers from the configuration file of a network interface. It then dynamically populates the /etc/resolv.conf file which should never be edited directly, otherwise the configuration changes will be lost the next time the network service is started. ip command The ip command from the iproute2 package allows you to configure an interface and its routing table. Display interfaces : [root]# ip link Display interfaces information: [root]# ip addr show Display the information of an interface : [root]# ip addr show eth0 Display the ARP table: [root]# ip neigh All historical network management commands have been grouped under the ip command, which is well known to network administrators. DHCP configuration The DHCP protocol ( D ynamic H ost C Control P rotocol) allows you to obtain a complete IP configuration via the network. This is the default configuration mode of a network interface under Rocky Linux, which explains why a system connected to the network of an Internet router can function without additional configuration. The configuration of interfaces under Rocky Linux is done in the /etc/sysconfig/network-scripts/ folder. For each Ethernet interface, a ifcfg-ethX file allows for the configuration of the associated interface. DEVICE=eth0 ONBOOT=yes BOOTPROTO=dhcp HWADDR=00:0c:29:96:32:e3 Interface name : (must be in the file name) DEVICE=eth0 Automatically start the interface: ONBOOT=yes Make a DHCP request when the interface starts up: BOOTPROTO=dhcp Specify the MAC address (optional but useful when there are several interfaces) : HWADDR=00:0c:29:96:32:e3 !!! Tip If NetworkManager is installed, the changes are taken into account automatically. If not, you have to restart the network service. Restart the network service: [root]# systemctl restart NetworkManager Static configuration The static configuration requires at least: DEVICE=eth0 ONBOOT=yes BOOTPROTO=none IPADDR=192.168.1.10 NETMASK=255.255.255.0 Here we are replacing \"dhcp\" with \"none\" which equals static configuration: BOOTPROTO=none IP Address: IPADDR=192.168.1.10 Subnet mask: NETMASK=255.255.255.0 The mask can be specified with a prefix: PREFIX=24 !!! Warning You must use NETMASK OR PREFIX - Not both! Routing DEVICE=eth0 ONBOOT=yes BOOTPROTO=none HWADDR=00:0c:29:96:32:e3 IPADDR=192.168.1.10 NETMASK=255.255.255.0 GATEWAY=192.168.1.254 The ip route command: [root]# ip route show 192.168.1.0/24 dev eth0 [\u2026] src 192.168.1.10 metric 1 default via 192.168.1.254 dev eth0 proto static It is a good idea to know how to read a routing table, especially in an environment with multiple network interfaces. In the example shown, the 192.168.1.0/24 network is reachable directly from the eth0 device, so there is a metric at 1 (does not traverse a router). All other networks than the previous one will be reachable, again from the eth0 device, but this time the packets will be addressed to a 192.168.1.254 gateway. The routing protocol is a static protocol (although it is possible to add a route to a dynamically assigned address in Linux). Name resolution A system needs to resolve: FQDNs into IP addresses www.free.fr = 212.27.48.10 IP addresses into names 212.27.48.10 = www.free.fr or to obtain information about an area: MX de free.fr = 10 mx1.free.fr + 20 mx2.free.fr DEVICE=eth0 ONBOOT=yes BOOTPROTO=none HWADDR=00:0c:29:96:32:e3 IPADDR=192.168.1.10 NETMASK=255.255.255.0 GATEWAY=192.168.1.254 DNS1=172.16.1.2 DNS2=172.16.1.3 DOMAIN=rockylinux.lan In this case, to reach the DNS, you have to go through the gateway. #Generated by NetworkManager domain mondomaine.lan search mondomaine.lan nameserver 172.16.1.2 nameserver 172.16.1.3 The file has been updated by NetworkManager. Troubleshooting The ping command sends datagrams to another machine and waits for a response. It is the basic command for testing the network because it checks the connectivity between your network interface and another. Syntax of the ping command: ping [-c numerical] destination The -c (count) option allows you to stop the command after the countdown in seconds. Example: [root]# ping \u2013c 4 localhost !!! Tip Validate connectivity from near to far 1) Validate the TCP/IP software layer [root]# ping localhost \"Pinging\" the inner loop does not detect a hardware failure on the network interface. It simply determines whether the IP software configuration is correct. 2) Validate the network card [root]# ping 192.168.1.10 To determine that the network card is functional, we must now ping its IP address. The network card, if the network cable is not connected, should be in a \"down\" state. If the ping does not work, first check the network cable to your network switch and reassemble the interface (see the if up command), then check the interface itself. 3) Validate the connectivity of the gateway [root]# ping 192.168.1.254 4) Validate the connectivity of a remote server [root]# ping 172.16.1.2 5) Validate the DNS service [root]# ping www.free.fr dig command The dig command is used to query the DNS server. The dig command syntax: dig [-t type] [+short] [name] Examples: [root]# dig +short rockylinux.org 76.223.126.88 [root]# dig -t MX +short rockylinux.org \ue0b2 \u2714 5 alt1.aspmx.l.google.com. ... The dig command is used to query DNS servers. It is very verbose by default, but this behavior can be changed with the +short option. It is also possible to specify a DNS record type to resolve, such as an MX type to get information about the mail exchangers for a domain. getent command The getent (get entry) command is used to get an NSSwitch entry ( hosts + dns ) Syntax of the getent command: getent hosts name Example: [root]# getent hosts rockylinux.org 76.223.126.88 rockylinux.org Querying only a DNS server may return an erroneous result that does not take into account the contents of a hosts file, although this should be rare nowadays. To take the /etc/hosts file into account as well, the NSSwitch name service must be queried, which will take care of any DNS resolution. ipcalc command The ipcalc ( ip calculation ) command is used to calculate the address of a network or broadcast from an IP address and a mask. Syntax of the ipcalc command: ipcalc [options] IP <netmask> Example: [root]# ipcalc \u2013b 172.16.66.203 255.255.240.0 BROADCAST=172.16.79.255 !!! Tip This command is interesting followed by a redirection to automatically fill in the configuration files of your interfaces: ``` [root]# ipcalc \u2013b 172.16.66.203 255.255.240.0 >> /etc/sysconfig/network-scripts/ifcfg-eth0 ``` Option Description -b Displays the broadcast address. -n Displays the network address and mask. ipcalc is a simple way to calculate the IP information of a host. The various options indicate what information ipcalc should display on the standard output. Multiple options can be specified. An IP address on which to operate must be specified. Most operations also require a network mask or CIDR prefix. Option short Option long Description -b --broadcast Displays the broadcast address of the given IP address and the network mask. -h --hostname Displays the hostname of the IP address given via DNS. -n --netmask Calculates the network mask for the given IP address. Assumes that the IP address is part of a complete class A, B, or C network. Many networks do not use default network masks, in which case an incorrect incorrect value will be returned. -p --prefix Indicates the prefix of the mask/IP address. -n --network Indicates the network address of the given IP address and mask. -s --silent Never displays any error messages. ss command The ss ( socket statistics ) command displays the listening ports on the network. Syntax of the ss command: ss [-tuna] Example: [root]# ss \u2013tuna tcp LISTEN 0 128 *:22 *:* The commands ss and netstat (to follow) will be very important for the rest of your Linux life. When implementing network services, it is very common to check with one of these two commands that the service is listening on the expected ports. netstat command !!! Warning The `netstat` command is now deprecated and is no-longer installed by default on Rocky Linux. You may still find some Linux versions that have it installed, but it is best to move on to using `ss` for everything that you would have used `netstat` for. The netstat command ( network statistics ) displays the listening ports on the network. Syntax of the netstat command: netstat -tapn Example: [root]# netstat \u2013tapn tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 2161/sshd IP or MAC address conflicts A misconfiguration can cause multiple interfaces to use the same IP address. This can happen when a network has multiple DHCP servers or when the same IP address is manually assigned multiple times. When the network is malfunctioning, and when an IP address conflict could be the cause, it is possible to use the arp-scan software (requires the EPEL repository): $ dnf install arp-scan Example: $ arp-scan -I eth0 -l 172.16.1.104 00:01:02:03:04:05 3COM CORPORATION 172.16.1.107 00:0c:29:1b:eb:97 VMware, Inc. 172.16.1.250 00:26:ab:b1:b7:f6 (Unknown) 172.16.1.252 00:50:56:a9:6a:ed VMWare, Inc. 172.16.1.253 00:50:56:b6:78:ec VMWare, Inc. 172.16.1.253 00:50:56:b6:78:ec VMWare, Inc. (DUP: 2) 172.16.1.253 00:50:56:b6:78:ec VMWare, Inc. (DUP: 3) 172.16.1.253 00:50:56:b6:78:ec VMWare, Inc. (DUP: 4) 172.16.1.232 88:51:fb:5e:fa:b3 (Unknown) (DUP: 2) !!! Tip As the above example shows, it is also possible to have MAC address conflicts! These problems are brought about by virtualization technologies and the copying of virtual machines. Hot configuration The ip command can hot add an IP address to an interface ip addr add @IP dev DEVICE Example: [root]# ip addr add 192.168.2.10 dev eth1 The ip command allows for the activation or deactivation of an interface: ip link set DEVICE up ip link set DEVICE down Example: [root]# ip link set eth1 up [root]# ip link set eth1 down The ip command is used to add a route: ip route add [default|netaddr] via @IP [dev device] Example: [root]# ip route add default via 192.168.1.254 [root]# ip route add 192.168.100.0/24 via 192.168.2.254 dev eth1 In summary The files used in this chapter are : A complete interface configuration could be this (file /etc/sysconfig/network-scripts/ifcfg-eth0 ): DEVICE=eth0 ONBOOT=yes BOOTPROTO=none HWADDR=00:0c:29:96:32:e3 IPADDR=192.168.1.10 NETMASK=255.255.255.0 GATEWAY=192.168.1.254 DNS1=172.16.1.1 DNS2=172.16.1.2 DOMAIN=rockylinux.lan The troubleshooting method should go from closest to farthest: ping localhost (software test) ping IP-address (hardware test) ping gateway (connectivity test) ping remote-server (routing test) DNS query (dig or ping)","title":"Implementing the Network"},{"location":"books/admin_guide/12-network/#implementing-the-network","text":"In this chapter you will learn how to work with and manage the network. Objectives : In this chapter you will learn how to: :heavy_check_mark: Configure a workstation to use DHCP; :heavy_check_mark: Configure a workstation to use a static configuration; :heavy_check_mark: Configure a workstation to use a gateway; :heavy_check_mark: Configure a workstation to use DNS servers; :heavy_check_mark: Troubleshoot the network of a workstation. :checkered_flag: network , linux , ip Knowledge : :star: :star: Complexity : :star: :star: Reading time : 30 minutes","title":"Implementing the Network"},{"location":"books/admin_guide/12-network/#generalities","text":"To illustrate this chapter, we will use the following architecture. It will allow us to consider : integration in a LAN (local area network); the configuration of a gateway to reach a remote server; the configuration of a DNS server and the implementation of name resolution. The minimum parameters to be defined for the machine are: the name of the machine ; the IP address; the subnet mask. Example: pc-rocky ; 192.168.1.10 ; 255.255.255.0 . The notation called CIDR is more and more frequent: 192.168.1.10/24 IP addresses are used for the proper routing of messages (packets). They are divided into two parts: the fixed part, identifying the network; the identifier of the host in the network. The subnet mask is a set of 4 bytes intended to isolate: the network address ( NetID or SubnetID ) by performing a bitwise logical AND between the IP address and the mask; the host address ( HostID ) by performing a bitwise logical AND between the IP address and the complement of the mask. There are also specific addresses within a network, which must be identified. The first address of a range as well as the last one have a particular role: The first address of a range is the network address . It is used to identify networks and to route information from one network to another. The last address of a range is the broadcast address . It is used to broadcast information to all the machines on the network.","title":"Generalities"},{"location":"books/admin_guide/12-network/#mac-address-ip-address","text":"A MAC address is a physical identifier written in the factory onto the device. This is sometimes referred to as the hardware address. It consists of 6 bytes often given in hexadecimal form (for example 5E:FF:56:A2:AF:15). It is composed of : 3 bytes of the manufacturer identifier and 3 bytes of the serial number. !!! Warning This last statement is nowadays a little less true with virtualization. There are also software solutions for changing the MAC address. An Internet Protocol ( IP ) address is an identification number permanently or temporarily assigned to each device connected to a computer network using the Internet Protocol. One part defines the network address (NetID or SubnetID as the case may be), the other part defines the address of the host in the network (HostID). The relative size of each part varies according to the network (sub)mask. An IPv4 address defines an address on 4 bytes. The number of available addresses being close to saturation a new standard was created, the IPv6 defined on 16 bytes. IPv6 is often represented by 8 groups of 2 bytes separated by a colon. Insignificant zeros can be omitted, one or more groups of 4 consecutive zeros can be replaced by a double colon. Subnet masks have from 0 to 128 bits. (for example 21ac:0000:0000:0611:21e0:00ba:321b:54da/64 or 21ac::611:21e0:ba:321b:54da/64) In a web address or URL (Uniform Resource Locator), an ip address can be followed by a colon and the port address (which indicates the application to which the data is destined). Also to avoid confusion in a URL, the IPv6 address is written in square brackets [ ], colon, port address. IP and MAC addresses must be unique on a network!","title":"MAC address / IP address"},{"location":"books/admin_guide/12-network/#dns-domain","text":"Client machines can be part of a DNS ( Domain Name System , e.g. mydomain.lan ) domain. The fully qualified machine name ( FQDN ) becomes pc-rocky.mydomain.lan . A set of computers can be grouped into a logical, name-resolving, set called a DNS domain. A DNS domain is not, of course, limited to a single physical network. In order for a computer to be part of a DNS domain, it must be given a DNS suffix (here mydomain.lan ) as well as servers that it can query.","title":"DNS Domain"},{"location":"books/admin_guide/12-network/#reminder-of-the-osi-model","text":"!!! Note \"Memory aid\" To remember the order of the layers of the OSI model, remember the following sentence: __Please Do Not Touch Steven's Pet Alligator__. Layer Protocoles 7 - Application POP, IMAP, SMTP, SSH, SNMP, HTTP, FTP, ... 6 - Presentation ASCII, MIME, ... 5 - Session TLS, SSL, NetBIOS, ... 4 - Transport TLS, SSL, TCP, UDP, ... 3 - Network IPv4, IPv6, ARP, ... 2 - Data Link Ethernet, WiFi, Token Ring, ... 1 - Physical Cables, optical fibers, radio waves, ... Layer 1 (Physical) supports transmission over a communication channel (Wifi, Optical fiber, RJ cable, etc.). Unit: the bit. Layer 2 (Data Link) supports network topology (token-ring, star, bus, etc.), data splitting and transmission errors. Unit: the frame. Layer 3 (Network) supports end-to-end data transmission (IP routing = Gateway). Unit: the packet. Layer 4 (Transport) supports service type (connected or unconnected) encryption and flow control. Unit: the segment or the datagram. Layer 5 (Session) supports the communication between two computers. Layer 6 (Presentation) represents the area that is independent of data at the application layer. Essentially this layer translates from network format to the application format, or or from the application format to the network format. Layer 7 (Application) represents the contact with the user. It provides the services offered by the network: http, dns, ftp, imap, pop, smtp, etc.","title":"Reminder of the OSI model"},{"location":"books/admin_guide/12-network/#the-naming-of-interfaces","text":"lo is the \" loopback \" interface which allows TCP/IP programs to communicate with each other without leaving the local machine. This enables testing if the network module of the system is working properly and also allows pinging the localhost. All packets that enter through localhost leave through localhost. The packets received are the packets sent. The Linux kernel assigns interface names with a specific prefix depending on the type. Traditionally, all Ethernet interfaces, for example, began with eth . The prefix was followed by a number, the first being 0 (eth0, eth1, eth2...). The wifi interfaces were given a wlan prefix. On Rocky8 Linux distributions, systemd will name interfaces with the new following policy where \"X\" represents a number: enoX : on-board devices ensX : PCI Express hotplug slot enpXsX : physical/geographical location of the connector of the hardware ...","title":"The naming of interfaces"},{"location":"books/admin_guide/12-network/#using-the-ip-command","text":"Forget the old ifconfig command! Think ip ! !!! Note Comment for administrators of older Linux systems: The historical network management command is `ifconfig`. This command has been replaced by the `ip` command, which is already well known to network administrators. The `ip` command is the only command to manage **IP address, ARP, routing, etc.**. The `ifconfig` command is no longer installed by default in Rocky8. It is important to get into good habits now.","title":"Using the ip command"},{"location":"books/admin_guide/12-network/#the-hostname","text":"The hostname command displays or sets the host name of the system hostname [-f] [hostname] Option Description -f Display the FQDN -i Display the system IPs address !!! Tip This command is used by various network programs to identify the machine. To assign a host name, it is possible to use the hostname command, but the changes will not be retained at the next boot. The command with no arguments displays the host name. To set the host name, the file /etc/sysconfig/network must be modified: NETWORKING=yes HOSTNAME=pc-rocky.mondomaine.lan The RedHat boot script also consults the /etc/hosts file to resolve the host name of the system. When the system boots, Linux evaluates the HOSTNAME value in the /etc/sysconfig/network file. It then uses the /etc/hosts file to evaluate the main IP address of the server and its host name. It deduces the DNS domain name. It is therefore essential to fill in these two files before any configuration of network services. !!! Tip To know if this configuration is well done, the commands `hostname` and `hostname -f` must answer with the expected values.","title":"The hostname"},{"location":"books/admin_guide/12-network/#etchosts-file","text":"The /etc/hosts file is a static host name mapping table, which follows the following format: @IP <hostname> [alias] [# comment] Example of /etc/hosts file: 127.0.0.1 localhost localhost.localdomain ::1 localhost localhost.localdomain 192.168.1.10 rockstar.rockylinux.lan rockstar The /etc/hosts file is still used by the system, especially at boot time when the system FQDN is determined. !!! Tip RedHat recommends that at least one line containing the system name be filled in. If the DNS service ( D domain N ame S ervice) is not in place, you must fill in all the names in the hosts file for each of your machines. The /etc/hosts file contains one line per entry, with the IP address, the FQDN, then the host name (in that order) and a series of aliases (alias1 alias2 ...). The alias is an option.","title":"/etc/hosts file"},{"location":"books/admin_guide/12-network/#etcnsswitchconf-file","text":"The NSS ( N ame S ervice S witch) allows configuration files (e.g. /etc/passwd , /etc/group , /etc/hosts ) to be substituted for one or more centralized databases. The /etc/nsswitch.conf file is used to configure the name service databases. passwd: files shadow: files group: files hosts: files dns In this case, Linux will first look for a host name match ( hosts: line) in the /etc/hosts file ( files value) before querying DNS ( dns value)! This behavior can simply be changed by editing the /etc/nsswitch.conf file. Of course, it is possible to imagine querying an LDAP, MySQL or other server by configuring the name service to respond to system requests for hosts, users, groups, etc. The resolution of the name service can be tested with the getent command that we will see later in this course.","title":"/etc/nsswitch.conf file"},{"location":"books/admin_guide/12-network/#etcresolvconf-file","text":"The /etc/resolv.conf file contains the DNS name resolution configuration. #Generated by NetworkManager domain mondomaine.lan search mondomaine.lan nameserver 192.168.1.254 !!! Tip This file is historical. It is no longer filled in directly! Newer generations of distributions have generally integrated the NetworkManager service. This service allows you to manage the configuration more efficiently, either in graphical or console mode. It allows for the addition of DNS servers from the configuration file of a network interface. It then dynamically populates the /etc/resolv.conf file which should never be edited directly, otherwise the configuration changes will be lost the next time the network service is started.","title":"/etc/resolv.conf file"},{"location":"books/admin_guide/12-network/#ip-command","text":"The ip command from the iproute2 package allows you to configure an interface and its routing table. Display interfaces : [root]# ip link Display interfaces information: [root]# ip addr show Display the information of an interface : [root]# ip addr show eth0 Display the ARP table: [root]# ip neigh All historical network management commands have been grouped under the ip command, which is well known to network administrators.","title":"ip command"},{"location":"books/admin_guide/12-network/#dhcp-configuration","text":"The DHCP protocol ( D ynamic H ost C Control P rotocol) allows you to obtain a complete IP configuration via the network. This is the default configuration mode of a network interface under Rocky Linux, which explains why a system connected to the network of an Internet router can function without additional configuration. The configuration of interfaces under Rocky Linux is done in the /etc/sysconfig/network-scripts/ folder. For each Ethernet interface, a ifcfg-ethX file allows for the configuration of the associated interface. DEVICE=eth0 ONBOOT=yes BOOTPROTO=dhcp HWADDR=00:0c:29:96:32:e3 Interface name : (must be in the file name) DEVICE=eth0 Automatically start the interface: ONBOOT=yes Make a DHCP request when the interface starts up: BOOTPROTO=dhcp Specify the MAC address (optional but useful when there are several interfaces) : HWADDR=00:0c:29:96:32:e3 !!! Tip If NetworkManager is installed, the changes are taken into account automatically. If not, you have to restart the network service. Restart the network service: [root]# systemctl restart NetworkManager","title":"DHCP configuration"},{"location":"books/admin_guide/12-network/#static-configuration","text":"The static configuration requires at least: DEVICE=eth0 ONBOOT=yes BOOTPROTO=none IPADDR=192.168.1.10 NETMASK=255.255.255.0 Here we are replacing \"dhcp\" with \"none\" which equals static configuration: BOOTPROTO=none IP Address: IPADDR=192.168.1.10 Subnet mask: NETMASK=255.255.255.0 The mask can be specified with a prefix: PREFIX=24 !!! Warning You must use NETMASK OR PREFIX - Not both!","title":"Static configuration"},{"location":"books/admin_guide/12-network/#routing","text":"DEVICE=eth0 ONBOOT=yes BOOTPROTO=none HWADDR=00:0c:29:96:32:e3 IPADDR=192.168.1.10 NETMASK=255.255.255.0 GATEWAY=192.168.1.254 The ip route command: [root]# ip route show 192.168.1.0/24 dev eth0 [\u2026] src 192.168.1.10 metric 1 default via 192.168.1.254 dev eth0 proto static It is a good idea to know how to read a routing table, especially in an environment with multiple network interfaces. In the example shown, the 192.168.1.0/24 network is reachable directly from the eth0 device, so there is a metric at 1 (does not traverse a router). All other networks than the previous one will be reachable, again from the eth0 device, but this time the packets will be addressed to a 192.168.1.254 gateway. The routing protocol is a static protocol (although it is possible to add a route to a dynamically assigned address in Linux).","title":"Routing"},{"location":"books/admin_guide/12-network/#name-resolution","text":"A system needs to resolve: FQDNs into IP addresses www.free.fr = 212.27.48.10 IP addresses into names 212.27.48.10 = www.free.fr or to obtain information about an area: MX de free.fr = 10 mx1.free.fr + 20 mx2.free.fr DEVICE=eth0 ONBOOT=yes BOOTPROTO=none HWADDR=00:0c:29:96:32:e3 IPADDR=192.168.1.10 NETMASK=255.255.255.0 GATEWAY=192.168.1.254 DNS1=172.16.1.2 DNS2=172.16.1.3 DOMAIN=rockylinux.lan In this case, to reach the DNS, you have to go through the gateway. #Generated by NetworkManager domain mondomaine.lan search mondomaine.lan nameserver 172.16.1.2 nameserver 172.16.1.3 The file has been updated by NetworkManager.","title":"Name resolution"},{"location":"books/admin_guide/12-network/#troubleshooting","text":"The ping command sends datagrams to another machine and waits for a response. It is the basic command for testing the network because it checks the connectivity between your network interface and another. Syntax of the ping command: ping [-c numerical] destination The -c (count) option allows you to stop the command after the countdown in seconds. Example: [root]# ping \u2013c 4 localhost !!! Tip Validate connectivity from near to far 1) Validate the TCP/IP software layer [root]# ping localhost \"Pinging\" the inner loop does not detect a hardware failure on the network interface. It simply determines whether the IP software configuration is correct. 2) Validate the network card [root]# ping 192.168.1.10 To determine that the network card is functional, we must now ping its IP address. The network card, if the network cable is not connected, should be in a \"down\" state. If the ping does not work, first check the network cable to your network switch and reassemble the interface (see the if up command), then check the interface itself. 3) Validate the connectivity of the gateway [root]# ping 192.168.1.254 4) Validate the connectivity of a remote server [root]# ping 172.16.1.2 5) Validate the DNS service [root]# ping www.free.fr","title":"Troubleshooting"},{"location":"books/admin_guide/12-network/#dig-command","text":"The dig command is used to query the DNS server. The dig command syntax: dig [-t type] [+short] [name] Examples: [root]# dig +short rockylinux.org 76.223.126.88 [root]# dig -t MX +short rockylinux.org \ue0b2 \u2714 5 alt1.aspmx.l.google.com. ... The dig command is used to query DNS servers. It is very verbose by default, but this behavior can be changed with the +short option. It is also possible to specify a DNS record type to resolve, such as an MX type to get information about the mail exchangers for a domain.","title":"dig command"},{"location":"books/admin_guide/12-network/#getent-command","text":"The getent (get entry) command is used to get an NSSwitch entry ( hosts + dns ) Syntax of the getent command: getent hosts name Example: [root]# getent hosts rockylinux.org 76.223.126.88 rockylinux.org Querying only a DNS server may return an erroneous result that does not take into account the contents of a hosts file, although this should be rare nowadays. To take the /etc/hosts file into account as well, the NSSwitch name service must be queried, which will take care of any DNS resolution.","title":"getent command"},{"location":"books/admin_guide/12-network/#ipcalc-command","text":"The ipcalc ( ip calculation ) command is used to calculate the address of a network or broadcast from an IP address and a mask. Syntax of the ipcalc command: ipcalc [options] IP <netmask> Example: [root]# ipcalc \u2013b 172.16.66.203 255.255.240.0 BROADCAST=172.16.79.255 !!! Tip This command is interesting followed by a redirection to automatically fill in the configuration files of your interfaces: ``` [root]# ipcalc \u2013b 172.16.66.203 255.255.240.0 >> /etc/sysconfig/network-scripts/ifcfg-eth0 ``` Option Description -b Displays the broadcast address. -n Displays the network address and mask. ipcalc is a simple way to calculate the IP information of a host. The various options indicate what information ipcalc should display on the standard output. Multiple options can be specified. An IP address on which to operate must be specified. Most operations also require a network mask or CIDR prefix. Option short Option long Description -b --broadcast Displays the broadcast address of the given IP address and the network mask. -h --hostname Displays the hostname of the IP address given via DNS. -n --netmask Calculates the network mask for the given IP address. Assumes that the IP address is part of a complete class A, B, or C network. Many networks do not use default network masks, in which case an incorrect incorrect value will be returned. -p --prefix Indicates the prefix of the mask/IP address. -n --network Indicates the network address of the given IP address and mask. -s --silent Never displays any error messages.","title":"ipcalc command"},{"location":"books/admin_guide/12-network/#ss-command","text":"The ss ( socket statistics ) command displays the listening ports on the network. Syntax of the ss command: ss [-tuna] Example: [root]# ss \u2013tuna tcp LISTEN 0 128 *:22 *:* The commands ss and netstat (to follow) will be very important for the rest of your Linux life. When implementing network services, it is very common to check with one of these two commands that the service is listening on the expected ports.","title":"ss command"},{"location":"books/admin_guide/12-network/#netstat-command","text":"!!! Warning The `netstat` command is now deprecated and is no-longer installed by default on Rocky Linux. You may still find some Linux versions that have it installed, but it is best to move on to using `ss` for everything that you would have used `netstat` for. The netstat command ( network statistics ) displays the listening ports on the network. Syntax of the netstat command: netstat -tapn Example: [root]# netstat \u2013tapn tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 2161/sshd","title":"netstat command"},{"location":"books/admin_guide/12-network/#ip-or-mac-address-conflicts","text":"A misconfiguration can cause multiple interfaces to use the same IP address. This can happen when a network has multiple DHCP servers or when the same IP address is manually assigned multiple times. When the network is malfunctioning, and when an IP address conflict could be the cause, it is possible to use the arp-scan software (requires the EPEL repository): $ dnf install arp-scan Example: $ arp-scan -I eth0 -l 172.16.1.104 00:01:02:03:04:05 3COM CORPORATION 172.16.1.107 00:0c:29:1b:eb:97 VMware, Inc. 172.16.1.250 00:26:ab:b1:b7:f6 (Unknown) 172.16.1.252 00:50:56:a9:6a:ed VMWare, Inc. 172.16.1.253 00:50:56:b6:78:ec VMWare, Inc. 172.16.1.253 00:50:56:b6:78:ec VMWare, Inc. (DUP: 2) 172.16.1.253 00:50:56:b6:78:ec VMWare, Inc. (DUP: 3) 172.16.1.253 00:50:56:b6:78:ec VMWare, Inc. (DUP: 4) 172.16.1.232 88:51:fb:5e:fa:b3 (Unknown) (DUP: 2) !!! Tip As the above example shows, it is also possible to have MAC address conflicts! These problems are brought about by virtualization technologies and the copying of virtual machines.","title":"IP or MAC address conflicts"},{"location":"books/admin_guide/12-network/#hot-configuration","text":"The ip command can hot add an IP address to an interface ip addr add @IP dev DEVICE Example: [root]# ip addr add 192.168.2.10 dev eth1 The ip command allows for the activation or deactivation of an interface: ip link set DEVICE up ip link set DEVICE down Example: [root]# ip link set eth1 up [root]# ip link set eth1 down The ip command is used to add a route: ip route add [default|netaddr] via @IP [dev device] Example: [root]# ip route add default via 192.168.1.254 [root]# ip route add 192.168.100.0/24 via 192.168.2.254 dev eth1","title":"Hot configuration"},{"location":"books/admin_guide/12-network/#in-summary","text":"The files used in this chapter are : A complete interface configuration could be this (file /etc/sysconfig/network-scripts/ifcfg-eth0 ): DEVICE=eth0 ONBOOT=yes BOOTPROTO=none HWADDR=00:0c:29:96:32:e3 IPADDR=192.168.1.10 NETMASK=255.255.255.0 GATEWAY=192.168.1.254 DNS1=172.16.1.1 DNS2=172.16.1.2 DOMAIN=rockylinux.lan The troubleshooting method should go from closest to farthest: ping localhost (software test) ping IP-address (hardware test) ping gateway (connectivity test) ping remote-server (routing test) DNS query (dig or ping)","title":"In summary"},{"location":"books/admin_guide/13-softwares/","tags":["education","software","software management"],"text":"Software Management Generalities On a Linux system, it is possible to install software in two ways: * Using an installation package; * Compiling from source files. !!! Note Installing from source is not covered here. As a rule, you should use the package method unless the software you want is not available via the package manager. The reason for this is that dependencies are generally managed by the package system, whereas with source, you need to manage the dependencies manually. The package : This is a single file containing all the data needed to install the program. It can be executed directly on the system from a software repository. The source files : Some software is not provided in packages ready to be installed, but via an archive containing the source files. It is up to the administrator to prepare these files and compile them to install the program. RPM : RedHat Package Manager RPM (RedHat Package Manager) is a software management system. It is possible to install, uninstall, update or check software contained in packages. RPM is the format used by all RedHat based distributions (RockyLinux, Fedora, CentOS, SuSe, Mandriva, ...). Its equivalent in the Debian world is DPKG (Debian Package). The name of an RPM package follows a specific nomenclature: rpm command The rpm command allows you to install a package. rpm [-i][-U] package.rpm [-e] package Example (for a package named 'package'): rpm -ivh package.rpm Option Description -i package.rpm Installs the package. -U package.rpm Updates an already installed package. -e package.rpm Uninstalls the package. -h Displays a progress bar. -v Informs about the progress of the operation. --test Tests the command without executing it. The rpm command also allows you to query the system package database by adding the -q option. It is possible to execute several types of queries to obtain different information about the installed packages. The RPM database is located in the directory /var/lib/rpm . Example: rpm -qa This command queries all the packages installed on the system. rpm -q [-a][-i][-l] package [-f] file Example: rpm -qil package rpm -qf /path/to/file Option Description -a Lists all packages installed on the system. -i __package__ Displays the package information. -l __package__ Lists the files contained in the package. -f Shows the name of the package containing the specified file. --last The list of packages is given by installation date (the last installed packages appear first). !!! Warning After the `-q` option, the package name must be exact. Metacharacters (wildcards) are not supported. !!! Tip However, it is possible to list all installed packages and filter with the `grep` command. Example: list the last installed packages: sudo rpm -qa --last | head NetworkManager-config-server-1.26.0-13.el8.noarch Mon 24 May 2021 02:34:00 PM CEST iwl2030-firmware-18.168.6.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl2000-firmware-18.168.6.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl135-firmware-18.168.6.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl105-firmware-18.168.6.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl100-firmware-39.31.5.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl1000-firmware-39.31.5.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST alsa-sof-firmware-1.5-2.el8.noarch Mon 24 May 2021 02:34:00 PM CEST iwl7260-firmware-25.30.13.0-101.el8.1.noarch Mon 24 May 2021 02:33:59 PM CEST iwl6050-firmware-41.28.5.1-101.el8.1.noarch Mon 24 May 2021 02:33:59 PM CEST Example: list the installation history of the kernel: sudo rpm -qa --last kernel kernel-4.18.0-305.el8.x86_64 Tue 25 May 2021 06:04:56 AM CEST kernel-4.18.0-240.22.1.el8.x86_64 Mon 24 May 2021 02:33:35 PM CEST Example: list all installed packages with a specific name using grep : sudo dnf list installed | grep httpd centos-logos-httpd.noarch 80.5-2.el8 @baseos httpd.x86_64 2.4.37-30.module_el8.3.0+561+97fdbbcc @appstream httpd-filesystem.noarch 2.4.37-30.module_el8.3.0+561+97fdbbcc @appstream httpd-tools.x86_64 2.4.37-30.module_el8.3.0+561+97fdbbcc @appstream DNF : Dandified Yum DNF ( Dandified Yum ) is a software package manager, successor of YUM ( Yellow dog U pdater M odified). It works with RPM** packages grouped in a local or remote repository (a directory for storing packages). For the most common commands, its usage is identical to that of yum . The dnf command allows the management of packages by comparing those installed on the system with those in the repositories defined on the server. It also automatically installs dependencies, if they are also present in the repositories. dnf is the manager used by many RedHat based distributions (RockyLinux, Fedora, CentOS, ...). Its equivalent in the Debian world is APT ( A dvanced P ackaging T ool). dnf command The dnf command allows you to install a package by specifying only the short name. dnf [install][remove][list all][search][info] package Example: dnf install tree Only the short name of the package is required. Option Description install Installs the package. remove Uninstall the package. list all Lists the packages already in the repository. search Search for a package in the repository. provides */command_name Search for a command. info Displays the package information. autoremove Removes all packages installed as dependencies but no longer needed. The dnf install command allows you to install the desired package without worrying about its dependencies, which will be resolved directly by dnf itself. dnf install nginx Last metadata expiration check: 3:13:41 ago on Wed 23 Mar 2022 07:19:24 AM CET. Dependencies resolved. ============================================================================================================================ Package Architecture Version Repository Size ============================================================================================================================ Installing: nginx aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 543 k Installing dependencies: nginx-all-modules noarch 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 22 k nginx-mod-http-image-filter aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 33 k nginx-mod-http-perl aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 44 k nginx-mod-http-xslt-filter aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 32 k nginx-mod-mail aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 60 k nginx-mod-stream aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 82 k Transaction Summary ============================================================================================================================ Install 7 Packages Total download size: 816 k Installed size: 2.2 M Is this ok [y/N]: In case you don't remember the exact name of the package, you can search for it with the command dnf search name . As you can see, there is a section that contains the exact name and another one that contains the package correspondence, all of which are highlighted for easier searching. dnf search nginx Last metadata expiration check: 0:20:55 ago on Wed 23 Mar 2022 10:40:43 AM CET. =============================================== Name Exactly Matched: nginx ================================================ nginx.aarch64 : A high performance web server and reverse proxy server ============================================== Name & Summary Matched: nginx =============================================== collectd-nginx.aarch64 : Nginx plugin for collectd munin-nginx.noarch : NGINX support for Munin resource monitoring nginx-all-modules.noarch : A meta package that installs all available Nginx modules nginx-filesystem.noarch : The basic directory layout for the Nginx server nginx-mod-http-image-filter.aarch64 : Nginx HTTP image filter module nginx-mod-http-perl.aarch64 : Nginx HTTP perl module nginx-mod-http-xslt-filter.aarch64 : Nginx XSLT module nginx-mod-mail.aarch64 : Nginx mail modules nginx-mod-stream.aarch64 : Nginx stream modules pagure-web-nginx.noarch : Nginx configuration for Pagure pcp-pmda-nginx.aarch64 : Performance Co-Pilot (PCP) metrics for the Nginx Webserver python3-certbot-nginx.noarch : The nginx plugin for certbot Another way to search for a package by entering an additional search key is to send the result of the dnf command through a pipe to the grep command with the desired key. dnf search nginx | grep mod Last metadata expiration check: 3:44:49 ago on Wed 23 Mar 2022 06:16:47 PM CET. nginx-all-modules.noarch : A meta package that installs all available Nginx modules nginx-mod-http-image-filter.aarch64 : Nginx HTTP image filter module nginx-mod-http-perl.aarch64 : Nginx HTTP perl module nginx-mod-http-xslt-filter.aarch64 : Nginx XSLT module nginx-mod-mail.aarch64 : Nginx mail modules nginx-mod-stream.aarch64 : Nginx stream modules The dnf remove command removes a package from the system and its dependencies. Below is an excerpt of the dnf remove httpd command. dnf remove httpd Dependencies resolved. ============================================================================================================================ Package Architecture Version Repository Size ============================================================================================================================ Removing: httpd aarch64 2.4.37-43.module+el8.5.0+727+743c5577.1 @appstream 8.9 M Removing dependent packages: mod_ssl aarch64 1:2.4.37-43.module+el8.5.0+727+743c5577.1 @appstream 274 k php aarch64 7.4.19-1.module+el8.5.0+696+61e7c9ba @appstream 4.4 M python3-certbot-apache noarch 1.22.0-1.el8 @epel 539 k Removing unused dependencies: apr aarch64 1.6.3-12.el8 @appstream 299 k apr-util aarch64 1.6.1-6.el8.1 @appstream 224 k apr-util-bdb aarch64 1.6.1-6.el8.1 @appstream 67 k apr-util-openssl aarch64 1.6.1-6.el8.1 @appstream 68 k augeas-libs aarch64 1.12.0-6.el8 @baseos 1.4 M httpd-filesystem noarch 2.4.37-43.module+el8.5.0+727+743c5577.1 @appstream 400 httpd-tools aarch64 2.4.37-43.module+el8.5.0+727+743c5577.1 ... The dnf list command lists all the packages installed on the system and present in the repository. It accepts several parameters: Parameter Description all Lists the installed packages and then those available on the repositories. available Lists only the packages available for installation. updates Lists packages that can be upgraded. obsoletes Lists the packages made obsolete by higher versions available. recent Lists the latest packages added to the repository. The dnf info command, as you might expect, provides detailed information about a package: dnf info firewalld Last metadata expiration check: 15:47:27 ago on Tue 22 Mar 2022 05:49:42 PM CET. Installed Packages Name : firewalld Version : 0.9.3 Release : 7.el8 Architecture : noarch Size : 2.0 M Source : firewalld-0.9.3-7.el8.src.rpm Repository : @System From repo : baseos Summary : A firewall daemon with D-Bus interface providing a dynamic firewall URL : http://www.firewalld.org License : GPLv2+ Description : firewalld is a firewall service daemon that provides a dynamic customizable : firewall with a D-Bus interface. Available Packages Name : firewalld Version : 0.9.3 Release : 7.el8_5.1 Architecture : noarch Size : 501 k Source : firewalld-0.9.3-7.el8_5.1.src.rpm Repository : baseos Summary : A firewall daemon with D-Bus interface providing a dynamic firewall URL : http://www.firewalld.org License : GPLv2+ Description : firewalld is a firewall service daemon that provides a dynamic customizable : firewall with a D-Bus interface. Sometimes you only know the executable you want to use but not the package that contains it, in this case you can use the command dnf provides */package_name which will search the database for you for the desired match. Example of a search for the semanage command: dnf provides */semanage Last metadata expiration check: 1:12:29 ago on Wed 23 Mar 2022 10:40:43 AM CET. libsemanage-devel-2.9-6.el8.aarch64 : Header files and libraries used to build policy manipulation tools Repo : powertools Matched from: Filename : /usr/include/semanage policycoreutils-python-utils-2.9-16.el8.noarch : SELinux policy core python utilities Repo : baseos Matched from: Filename : /usr/sbin/semanage Filename : /usr/share/bash-completion/completions/semanage The dnf autoremove command does not need any parameters. Dnf takes care of searching for candidate packages for removal. dnf autoremove Last metadata expiration check: 0:24:40 ago on Wed 23 Mar 2022 06:16:47 PM CET. Dependencies resolved. Nothing to do. Complete! Other useful dnf options Option Description repolist Lists the repositories configured on the system. grouplist Lists available package collections. clean Removes temporary files. The dnf repolist command lists the repositories configured on the system. By default it lists only the enabled repositories but can be used with these parameters: Parameter Description --all Lists all the repositories. --enabled Default --disabled Lists only disabled repositories. Example: dnf repolist repo id repo name appstream Rocky Linux 8 - AppStream baseos Rocky Linux 8 - BaseOS epel Extra Packages for Enterprise Linux 8 - aarch64 epel-modular Extra Packages for Enterprise Linux Modular 8 - aarch64 extras Rocky Linux 8 - Extras powertools Rocky Linux 8 - PowerTools rockyrpi Rocky Linux 8 - Rasperry Pi And an excerpt of the command with the --all flag. dnf repolist --all ... repo id repo name status appstream Rocky Linux 8 - AppStream enabled appstream-debug Rocky Linux 8 - AppStream - Source disabled appstream-source Rocky Linux 8 - AppStream - Source disabled baseos Rocky Linux 8 - BaseOS enabled baseos-debug Rocky Linux 8 - BaseOS - Source disabled baseos-source Rocky Linux 8 - BaseOS - Source disabled devel Rocky Linux 8 - Devel WARNING! FOR BUILDROOT AND KOJI USE disabled epel Extra Packages for Enterprise Linux 8 - aarch64 enabled epel-debuginfo Extra Packages for Enterprise Linux 8 - aarch64 - Debug disabled epel-modular Extra Packages for Enterprise Linux Modular 8 - aarch64 enabled epel-modular-debuginfo Extra Packages for Enterprise Linux Modular 8 - aarch64 - Debug disabled epel-modular-source Extra Packages for Enterprise Linux Modular 8 - aarch64 - Source ... And below is an excerpt from the list of disabled repositories. dnf repolist --disabled repo id repo name appstream-debug Rocky Linux 8 - AppStream - Source appstream-source Rocky Linux 8 - AppStream - Source baseos-debug Rocky Linux 8 - BaseOS - Source baseos-source Rocky Linux 8 - BaseOS - Source devel Rocky Linux 8 - Devel WARNING! FOR BUILDROOT AND KOJI USE epel-debuginfo Extra Packages for Enterprise Linux 8 - aarch64 - Debug epel-modular-debuginfo Extra Packages for Enterprise Linux Modular 8 - aarch64 - Debug epel-modular-source Extra Packages for Enterprise Linux Modular 8 - aarch64 - Source epel-source Extra Packages for Enterprise Linux 8 - aarch64 - Source epel-testing Extra Packages for Enterprise Linux 8 - Testing - aarch64 ... Using the -v option enhances the list with a lot of additional information. Below you can see part of the result of the command. dnf repolist -v ... Repo-id : powertools Repo-name : Rocky Linux 8 - PowerTools Repo-revision : 8.5 Repo-distro-tags : [cpe:/o:rocky:rocky:8]: , , 8, L, R, c, i, k, n, o, u, x, y Repo-updated : Wed 16 Mar 2022 10:07:49 PM CET Repo-pkgs : 1,650 Repo-available-pkgs: 1,107 Repo-size : 6.4 G Repo-mirrors : https://mirrors.rockylinux.org/mirrorlist?arch=aarch64&repo=PowerTools-8 Repo-baseurl : http://mirror.netweaver.uk/rocky/8.5/PowerTools/aarch64/os/ (56 more) Repo-expire : 172,800 second(s) (last: Tue 22 Mar 2022 05:49:24 PM CET) Repo-filename : /etc/yum.repos.d/Rocky-PowerTools.repo ... !!! info \"Using Groups\" Groups are a collection of a set of packages (you can think of them as a virtual packages) that logically groups a set of applications to accomplish a purpose (a desktop environment, a server, development tools, etc.). The dnf grouplist command lists all available groups. dnf grouplist Last metadata expiration check: 1:52:00 ago on Wed 23 Mar 2022 02:11:43 PM CET. Available Environment Groups: Server with GUI Server Minimal Install KDE Plasma Workspaces Custom Operating System Available Groups: Container Management .NET Core Development RPM Development Tools Development Tools Headless Management Legacy UNIX Compatibility Network Servers Scientific Support Security Tools Smart Card Support System Tools Fedora Packager Xfce The dnf groupinstall command allows you to install one of these groups. dnf groupinstall \"Network Servers\" Last metadata expiration check: 2:33:26 ago on Wed 23 Mar 2022 02:11:43 PM CET. Dependencies resolved. ================================================================================ Package Architecture Version Repository Size ================================================================================ Installing Groups: Network Servers Transaction Summary ================================================================================ Is this ok [y/N]: Note that it is good practice to enclose the group name in double quotes as without the command it will only execute correctly if the group name does not contain spaces. So a dnf groupinstall Network Servers produces the following error. dnf groupinstall Network Servers Last metadata expiration check: 3:05:45 ago on Wed 23 Mar 2022 02:11:43 PM CET. Module or Group 'Network' is not available. Module or Group 'Servers' is not available. Error: Nothing to do. The corresponding command to remove a group is dnf groupremove \"name group\" . The dnf clean command cleans all caches and temporary files created by dnf . It can be used with the following parameters. Parameters Description all Removes all temporary files created for enabled repositories. dbcache Removes cache files for the repository metadata. expire-cache Remove the local cookie files. metadata Removes all the repositories metadata. packages Removes any cached packages. How DNF works The DNF manager relies on one or more configuration files to target the repositories containing the RPM packages. These files are located in /etc/yum.repos.d/ and must end with .repo in order to be used by DNF. Example: /etc/yum.repos.d/Rocky-BaseOS.repo Each .repo file consists of at least the following information, one directive per line. Example: [baseos] # Short name of the repository name=Rocky Linux $releasever - BaseOS # Short name of the repository #Detailed name mirrorlist=http://mirrors.rockylinux.org/mirrorlist?arch=$basearch&repo=BaseOS-$releasever # http address of a list or mirror #baseurl=http://dl.rockylinux.org/$contentdir/$releasever/BaseOS/$basearch/os/ # http address for direct access gpgcheck=1 # Repository requiring a signature enabled=1 # Activated =1, or not activated =0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial # GPG public key path By default, the enabled directive is absent which means that the repository is enabled. To disable a repository, you must specify the enabled=0 directive. The EPEL repository What is EPEL and how is it used? EPEL ( E xtra P ackages for E nterprise L inux) is an open-source and free community-based repository maintained by the EPEL Fedora Special Interest Group that provides a set of additional packages for RHEL (and CentOS, Rocky Linux, and others) from the Fedora sources. It provides packages that are not included in the official RHEL repositories. These are not included because they are not considered necessary in an enterprise environment or deemed outside the scope of RHEL. We must not forget that RHEL is an enterprise class distribution, and desktop utilities or other specialized software may not be a priority for an enterprise project. Installation Installation of the necessary files can be easily done with the package provided by default from Rocky Linux. If you are behind an internet proxy: export http_proxy=http://172.16.1.10:8080 Then: dnf install epel-release Once installed you can check that the package has been installed correctly with the command dnf info . dnf info epel-release Last metadata expiration check: 1:30:29 ago on Thu 24 Mar 2022 09:36:42 AM CET. Installed Packages Name : epel-release Version : 8 Release : 14.el8 Architecture : noarch Size : 32 k Source : epel-release-8-14.el8.src.rpm Repository : @System From repo : epel Summary : Extra Packages for Enterprise Linux repository configuration URL : http://download.fedoraproject.org/pub/epel License : GPLv2 Description : This package contains the Extra Packages for Enterprise Linux : (EPEL) repository GPG key as well as configuration for yum. The package, as you can see from the package description above, does not contain executables, libraries, etc.. but only the configuration files and GPG keys for setting up the repository. Another way to verify the correct installation is to query the rpm database. rpm -qa | grep epel epel-release-8-14.el8.noarch Now you need to run an update to let dnf recognize the repository. You will be asked to accept the GPG keys of the repositories. Clearly, you have to answer YES in order to use them. dnf update Once the update is complete you can check that the repository has been configured correctly with the dnf repolist command which should now list the new repositories. dnf repolist repo id repo name ... epel Extra Packages for Enterprise Linux 8 - aarch64 epel-modular Extra Packages for Enterprise Linux Modular 8 - aarch64 ... The repository configuration files are located in /etc/yum.repos.d/ . ll /etc/yum.repos.d/ | grep epel -rw-r--r--. 1 root root 1485 Jan 31 17:19 epel-modular.repo -rw-r--r--. 1 root root 1422 Jan 31 17:19 epel.repo -rw-r--r--. 1 root root 1584 Jan 31 17:19 epel-testing-modular.repo -rw-r--r--. 1 root root 1521 Jan 31 17:19 epel-testing.repo And below we can see the contents of the file epel.repo . [epel] name=Extra Packages for Enterprise Linux $releasever - $basearch # It is much more secure to use the metalink, but if you wish to use a local mirror # place its address here. #baseurl=https://download.example/pub/epel/$releasever/Everything/$basearch metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-$releasever&arch=$basearch&infra=$infra&content=$contentdir enabled=1 gpgcheck=1 countme=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8 [epel-debuginfo] name=Extra Packages for Enterprise Linux $releasever - $basearch - Debug # It is much more secure to use the metalink, but if you wish to use a local mirror # place its address here. #baseurl=https://download.example/pub/epel/$releasever/Everything/$basearch/debug metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-$releasever&arch=$basearch&infra=$infra&content=$contentdir enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8 gpgcheck=1 [epel-source] name=Extra Packages for Enterprise Linux $releasever - $basearch - Source # It is much more secure to use the metalink, but if you wish to use a local mirror # place it's address here. #baseurl=https://download.example/pub/epel/$releasever/Everything/source/tree/ metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-source-$releasever&arch=$basearch&infra=$infra&content=$contentdir enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8 gpgcheck=1 Using EPEL At this point, once configured, we are ready to install the packages from EPEL. To start, we can list the packages available in the repository with the command: dnf --disablerepo=\"*\" --enablerepo=\"epel\" list available And an excerpt of the command dnf --disablerepo=\"*\" --enablerepo=\"epel\" list available | less Last metadata expiration check: 1:58:22 ago on Fri 25 Mar 2022 09:23:29 AM CET. Available Packages 3proxy.aarch64 0.8.13-1.el8 epel AMF-devel.noarch 1.4.23-2.el8 epel AMF-samples.noarch 1.4.23-2.el8 epel AusweisApp2.aarch64 1.22.3-1.el8 epel AusweisApp2-data.noarch 1.22.3-1.el8 epel AusweisApp2-doc.noarch 1.22.3-1.el8 epel BackupPC.aarch64 4.4.0-1.el8 epel BackupPC-XS.aarch64 0.62-1.el8 epel BibTool.aarch64 2.68-1.el8 epel CCfits.aarch64 2.5-14.el8 epel CCfits-devel.aarch64 2.5-14.el8 epel ... From the command we can see that to install from EPEL we must force dnf to query the requested repository with the options --disablerepo and --enablerepo , this is because otherwise a match found in other optional repositories (RPM Fusion, REMI, ELRepo, etc.) could be newer and therefore have priority. These options are not necessary if you have only installed EPEL as an optional repository because the packages in the repository will never be available in the official ones. At least in the same version! !!! attention \"Support consideration\" One aspect to consider regarding support (updates, bug fixes, security patches) is that EPEL packages have no official support from RHEL and technically their life could last the space of a development of Fedora (six months) and then disappear. This is a remote possibility but one to consider. So to install a package from the EPEL repositories you would use: dnf --disablerepo=\"*\" --enablerepo=\"epel\" install nmon Last metadata expiration check: 2:01:36 ago on Fri 25 Mar 2022 04:28:04 PM CET. Dependencies resolved. ============================================================================================================================================================== Package Architecture Version Repository Size ============================================================================================================================================================== Installing: nmon aarch64 16m-1.el8 epel 71 k Transaction Summary ============================================================================================================================================================== Install 1 Package Total download size: 71 k Installed size: 214 k Is this ok [y/N]: Conclusion EPEL is not an official repository for RHEL. But it can be useful for administrators and developers who work with RHEL or derivatives and need some utilities prepared for RHEL from a source they can feel confident about.","title":"Software Management"},{"location":"books/admin_guide/13-softwares/#software-management","text":"","title":"Software Management"},{"location":"books/admin_guide/13-softwares/#generalities","text":"On a Linux system, it is possible to install software in two ways: * Using an installation package; * Compiling from source files. !!! Note Installing from source is not covered here. As a rule, you should use the package method unless the software you want is not available via the package manager. The reason for this is that dependencies are generally managed by the package system, whereas with source, you need to manage the dependencies manually. The package : This is a single file containing all the data needed to install the program. It can be executed directly on the system from a software repository. The source files : Some software is not provided in packages ready to be installed, but via an archive containing the source files. It is up to the administrator to prepare these files and compile them to install the program.","title":"Generalities"},{"location":"books/admin_guide/13-softwares/#rpm-redhat-package-manager","text":"RPM (RedHat Package Manager) is a software management system. It is possible to install, uninstall, update or check software contained in packages. RPM is the format used by all RedHat based distributions (RockyLinux, Fedora, CentOS, SuSe, Mandriva, ...). Its equivalent in the Debian world is DPKG (Debian Package). The name of an RPM package follows a specific nomenclature:","title":"RPM : RedHat Package Manager"},{"location":"books/admin_guide/13-softwares/#rpm-command","text":"The rpm command allows you to install a package. rpm [-i][-U] package.rpm [-e] package Example (for a package named 'package'): rpm -ivh package.rpm Option Description -i package.rpm Installs the package. -U package.rpm Updates an already installed package. -e package.rpm Uninstalls the package. -h Displays a progress bar. -v Informs about the progress of the operation. --test Tests the command without executing it. The rpm command also allows you to query the system package database by adding the -q option. It is possible to execute several types of queries to obtain different information about the installed packages. The RPM database is located in the directory /var/lib/rpm . Example: rpm -qa This command queries all the packages installed on the system. rpm -q [-a][-i][-l] package [-f] file Example: rpm -qil package rpm -qf /path/to/file Option Description -a Lists all packages installed on the system. -i __package__ Displays the package information. -l __package__ Lists the files contained in the package. -f Shows the name of the package containing the specified file. --last The list of packages is given by installation date (the last installed packages appear first). !!! Warning After the `-q` option, the package name must be exact. Metacharacters (wildcards) are not supported. !!! Tip However, it is possible to list all installed packages and filter with the `grep` command. Example: list the last installed packages: sudo rpm -qa --last | head NetworkManager-config-server-1.26.0-13.el8.noarch Mon 24 May 2021 02:34:00 PM CEST iwl2030-firmware-18.168.6.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl2000-firmware-18.168.6.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl135-firmware-18.168.6.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl105-firmware-18.168.6.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl100-firmware-39.31.5.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST iwl1000-firmware-39.31.5.1-101.el8.1.noarch Mon 24 May 2021 02:34:00 PM CEST alsa-sof-firmware-1.5-2.el8.noarch Mon 24 May 2021 02:34:00 PM CEST iwl7260-firmware-25.30.13.0-101.el8.1.noarch Mon 24 May 2021 02:33:59 PM CEST iwl6050-firmware-41.28.5.1-101.el8.1.noarch Mon 24 May 2021 02:33:59 PM CEST Example: list the installation history of the kernel: sudo rpm -qa --last kernel kernel-4.18.0-305.el8.x86_64 Tue 25 May 2021 06:04:56 AM CEST kernel-4.18.0-240.22.1.el8.x86_64 Mon 24 May 2021 02:33:35 PM CEST Example: list all installed packages with a specific name using grep : sudo dnf list installed | grep httpd centos-logos-httpd.noarch 80.5-2.el8 @baseos httpd.x86_64 2.4.37-30.module_el8.3.0+561+97fdbbcc @appstream httpd-filesystem.noarch 2.4.37-30.module_el8.3.0+561+97fdbbcc @appstream httpd-tools.x86_64 2.4.37-30.module_el8.3.0+561+97fdbbcc @appstream","title":"rpm command"},{"location":"books/admin_guide/13-softwares/#dnf-dandified-yum","text":"DNF ( Dandified Yum ) is a software package manager, successor of YUM ( Yellow dog U pdater M odified). It works with RPM** packages grouped in a local or remote repository (a directory for storing packages). For the most common commands, its usage is identical to that of yum . The dnf command allows the management of packages by comparing those installed on the system with those in the repositories defined on the server. It also automatically installs dependencies, if they are also present in the repositories. dnf is the manager used by many RedHat based distributions (RockyLinux, Fedora, CentOS, ...). Its equivalent in the Debian world is APT ( A dvanced P ackaging T ool).","title":"DNF : Dandified Yum"},{"location":"books/admin_guide/13-softwares/#dnf-command","text":"The dnf command allows you to install a package by specifying only the short name. dnf [install][remove][list all][search][info] package Example: dnf install tree Only the short name of the package is required. Option Description install Installs the package. remove Uninstall the package. list all Lists the packages already in the repository. search Search for a package in the repository. provides */command_name Search for a command. info Displays the package information. autoremove Removes all packages installed as dependencies but no longer needed. The dnf install command allows you to install the desired package without worrying about its dependencies, which will be resolved directly by dnf itself. dnf install nginx Last metadata expiration check: 3:13:41 ago on Wed 23 Mar 2022 07:19:24 AM CET. Dependencies resolved. ============================================================================================================================ Package Architecture Version Repository Size ============================================================================================================================ Installing: nginx aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 543 k Installing dependencies: nginx-all-modules noarch 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 22 k nginx-mod-http-image-filter aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 33 k nginx-mod-http-perl aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 44 k nginx-mod-http-xslt-filter aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 32 k nginx-mod-mail aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 60 k nginx-mod-stream aarch64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream 82 k Transaction Summary ============================================================================================================================ Install 7 Packages Total download size: 816 k Installed size: 2.2 M Is this ok [y/N]: In case you don't remember the exact name of the package, you can search for it with the command dnf search name . As you can see, there is a section that contains the exact name and another one that contains the package correspondence, all of which are highlighted for easier searching. dnf search nginx Last metadata expiration check: 0:20:55 ago on Wed 23 Mar 2022 10:40:43 AM CET. =============================================== Name Exactly Matched: nginx ================================================ nginx.aarch64 : A high performance web server and reverse proxy server ============================================== Name & Summary Matched: nginx =============================================== collectd-nginx.aarch64 : Nginx plugin for collectd munin-nginx.noarch : NGINX support for Munin resource monitoring nginx-all-modules.noarch : A meta package that installs all available Nginx modules nginx-filesystem.noarch : The basic directory layout for the Nginx server nginx-mod-http-image-filter.aarch64 : Nginx HTTP image filter module nginx-mod-http-perl.aarch64 : Nginx HTTP perl module nginx-mod-http-xslt-filter.aarch64 : Nginx XSLT module nginx-mod-mail.aarch64 : Nginx mail modules nginx-mod-stream.aarch64 : Nginx stream modules pagure-web-nginx.noarch : Nginx configuration for Pagure pcp-pmda-nginx.aarch64 : Performance Co-Pilot (PCP) metrics for the Nginx Webserver python3-certbot-nginx.noarch : The nginx plugin for certbot Another way to search for a package by entering an additional search key is to send the result of the dnf command through a pipe to the grep command with the desired key. dnf search nginx | grep mod Last metadata expiration check: 3:44:49 ago on Wed 23 Mar 2022 06:16:47 PM CET. nginx-all-modules.noarch : A meta package that installs all available Nginx modules nginx-mod-http-image-filter.aarch64 : Nginx HTTP image filter module nginx-mod-http-perl.aarch64 : Nginx HTTP perl module nginx-mod-http-xslt-filter.aarch64 : Nginx XSLT module nginx-mod-mail.aarch64 : Nginx mail modules nginx-mod-stream.aarch64 : Nginx stream modules The dnf remove command removes a package from the system and its dependencies. Below is an excerpt of the dnf remove httpd command. dnf remove httpd Dependencies resolved. ============================================================================================================================ Package Architecture Version Repository Size ============================================================================================================================ Removing: httpd aarch64 2.4.37-43.module+el8.5.0+727+743c5577.1 @appstream 8.9 M Removing dependent packages: mod_ssl aarch64 1:2.4.37-43.module+el8.5.0+727+743c5577.1 @appstream 274 k php aarch64 7.4.19-1.module+el8.5.0+696+61e7c9ba @appstream 4.4 M python3-certbot-apache noarch 1.22.0-1.el8 @epel 539 k Removing unused dependencies: apr aarch64 1.6.3-12.el8 @appstream 299 k apr-util aarch64 1.6.1-6.el8.1 @appstream 224 k apr-util-bdb aarch64 1.6.1-6.el8.1 @appstream 67 k apr-util-openssl aarch64 1.6.1-6.el8.1 @appstream 68 k augeas-libs aarch64 1.12.0-6.el8 @baseos 1.4 M httpd-filesystem noarch 2.4.37-43.module+el8.5.0+727+743c5577.1 @appstream 400 httpd-tools aarch64 2.4.37-43.module+el8.5.0+727+743c5577.1 ... The dnf list command lists all the packages installed on the system and present in the repository. It accepts several parameters: Parameter Description all Lists the installed packages and then those available on the repositories. available Lists only the packages available for installation. updates Lists packages that can be upgraded. obsoletes Lists the packages made obsolete by higher versions available. recent Lists the latest packages added to the repository. The dnf info command, as you might expect, provides detailed information about a package: dnf info firewalld Last metadata expiration check: 15:47:27 ago on Tue 22 Mar 2022 05:49:42 PM CET. Installed Packages Name : firewalld Version : 0.9.3 Release : 7.el8 Architecture : noarch Size : 2.0 M Source : firewalld-0.9.3-7.el8.src.rpm Repository : @System From repo : baseos Summary : A firewall daemon with D-Bus interface providing a dynamic firewall URL : http://www.firewalld.org License : GPLv2+ Description : firewalld is a firewall service daemon that provides a dynamic customizable : firewall with a D-Bus interface. Available Packages Name : firewalld Version : 0.9.3 Release : 7.el8_5.1 Architecture : noarch Size : 501 k Source : firewalld-0.9.3-7.el8_5.1.src.rpm Repository : baseos Summary : A firewall daemon with D-Bus interface providing a dynamic firewall URL : http://www.firewalld.org License : GPLv2+ Description : firewalld is a firewall service daemon that provides a dynamic customizable : firewall with a D-Bus interface. Sometimes you only know the executable you want to use but not the package that contains it, in this case you can use the command dnf provides */package_name which will search the database for you for the desired match. Example of a search for the semanage command: dnf provides */semanage Last metadata expiration check: 1:12:29 ago on Wed 23 Mar 2022 10:40:43 AM CET. libsemanage-devel-2.9-6.el8.aarch64 : Header files and libraries used to build policy manipulation tools Repo : powertools Matched from: Filename : /usr/include/semanage policycoreutils-python-utils-2.9-16.el8.noarch : SELinux policy core python utilities Repo : baseos Matched from: Filename : /usr/sbin/semanage Filename : /usr/share/bash-completion/completions/semanage The dnf autoremove command does not need any parameters. Dnf takes care of searching for candidate packages for removal. dnf autoremove Last metadata expiration check: 0:24:40 ago on Wed 23 Mar 2022 06:16:47 PM CET. Dependencies resolved. Nothing to do. Complete!","title":"dnf command"},{"location":"books/admin_guide/13-softwares/#other-useful-dnf-options","text":"Option Description repolist Lists the repositories configured on the system. grouplist Lists available package collections. clean Removes temporary files. The dnf repolist command lists the repositories configured on the system. By default it lists only the enabled repositories but can be used with these parameters: Parameter Description --all Lists all the repositories. --enabled Default --disabled Lists only disabled repositories. Example: dnf repolist repo id repo name appstream Rocky Linux 8 - AppStream baseos Rocky Linux 8 - BaseOS epel Extra Packages for Enterprise Linux 8 - aarch64 epel-modular Extra Packages for Enterprise Linux Modular 8 - aarch64 extras Rocky Linux 8 - Extras powertools Rocky Linux 8 - PowerTools rockyrpi Rocky Linux 8 - Rasperry Pi And an excerpt of the command with the --all flag. dnf repolist --all ... repo id repo name status appstream Rocky Linux 8 - AppStream enabled appstream-debug Rocky Linux 8 - AppStream - Source disabled appstream-source Rocky Linux 8 - AppStream - Source disabled baseos Rocky Linux 8 - BaseOS enabled baseos-debug Rocky Linux 8 - BaseOS - Source disabled baseos-source Rocky Linux 8 - BaseOS - Source disabled devel Rocky Linux 8 - Devel WARNING! FOR BUILDROOT AND KOJI USE disabled epel Extra Packages for Enterprise Linux 8 - aarch64 enabled epel-debuginfo Extra Packages for Enterprise Linux 8 - aarch64 - Debug disabled epel-modular Extra Packages for Enterprise Linux Modular 8 - aarch64 enabled epel-modular-debuginfo Extra Packages for Enterprise Linux Modular 8 - aarch64 - Debug disabled epel-modular-source Extra Packages for Enterprise Linux Modular 8 - aarch64 - Source ... And below is an excerpt from the list of disabled repositories. dnf repolist --disabled repo id repo name appstream-debug Rocky Linux 8 - AppStream - Source appstream-source Rocky Linux 8 - AppStream - Source baseos-debug Rocky Linux 8 - BaseOS - Source baseos-source Rocky Linux 8 - BaseOS - Source devel Rocky Linux 8 - Devel WARNING! FOR BUILDROOT AND KOJI USE epel-debuginfo Extra Packages for Enterprise Linux 8 - aarch64 - Debug epel-modular-debuginfo Extra Packages for Enterprise Linux Modular 8 - aarch64 - Debug epel-modular-source Extra Packages for Enterprise Linux Modular 8 - aarch64 - Source epel-source Extra Packages for Enterprise Linux 8 - aarch64 - Source epel-testing Extra Packages for Enterprise Linux 8 - Testing - aarch64 ... Using the -v option enhances the list with a lot of additional information. Below you can see part of the result of the command. dnf repolist -v ... Repo-id : powertools Repo-name : Rocky Linux 8 - PowerTools Repo-revision : 8.5 Repo-distro-tags : [cpe:/o:rocky:rocky:8]: , , 8, L, R, c, i, k, n, o, u, x, y Repo-updated : Wed 16 Mar 2022 10:07:49 PM CET Repo-pkgs : 1,650 Repo-available-pkgs: 1,107 Repo-size : 6.4 G Repo-mirrors : https://mirrors.rockylinux.org/mirrorlist?arch=aarch64&repo=PowerTools-8 Repo-baseurl : http://mirror.netweaver.uk/rocky/8.5/PowerTools/aarch64/os/ (56 more) Repo-expire : 172,800 second(s) (last: Tue 22 Mar 2022 05:49:24 PM CET) Repo-filename : /etc/yum.repos.d/Rocky-PowerTools.repo ... !!! info \"Using Groups\" Groups are a collection of a set of packages (you can think of them as a virtual packages) that logically groups a set of applications to accomplish a purpose (a desktop environment, a server, development tools, etc.). The dnf grouplist command lists all available groups. dnf grouplist Last metadata expiration check: 1:52:00 ago on Wed 23 Mar 2022 02:11:43 PM CET. Available Environment Groups: Server with GUI Server Minimal Install KDE Plasma Workspaces Custom Operating System Available Groups: Container Management .NET Core Development RPM Development Tools Development Tools Headless Management Legacy UNIX Compatibility Network Servers Scientific Support Security Tools Smart Card Support System Tools Fedora Packager Xfce The dnf groupinstall command allows you to install one of these groups. dnf groupinstall \"Network Servers\" Last metadata expiration check: 2:33:26 ago on Wed 23 Mar 2022 02:11:43 PM CET. Dependencies resolved. ================================================================================ Package Architecture Version Repository Size ================================================================================ Installing Groups: Network Servers Transaction Summary ================================================================================ Is this ok [y/N]: Note that it is good practice to enclose the group name in double quotes as without the command it will only execute correctly if the group name does not contain spaces. So a dnf groupinstall Network Servers produces the following error. dnf groupinstall Network Servers Last metadata expiration check: 3:05:45 ago on Wed 23 Mar 2022 02:11:43 PM CET. Module or Group 'Network' is not available. Module or Group 'Servers' is not available. Error: Nothing to do. The corresponding command to remove a group is dnf groupremove \"name group\" . The dnf clean command cleans all caches and temporary files created by dnf . It can be used with the following parameters. Parameters Description all Removes all temporary files created for enabled repositories. dbcache Removes cache files for the repository metadata. expire-cache Remove the local cookie files. metadata Removes all the repositories metadata. packages Removes any cached packages.","title":"Other useful dnf options"},{"location":"books/admin_guide/13-softwares/#how-dnf-works","text":"The DNF manager relies on one or more configuration files to target the repositories containing the RPM packages. These files are located in /etc/yum.repos.d/ and must end with .repo in order to be used by DNF. Example: /etc/yum.repos.d/Rocky-BaseOS.repo Each .repo file consists of at least the following information, one directive per line. Example: [baseos] # Short name of the repository name=Rocky Linux $releasever - BaseOS # Short name of the repository #Detailed name mirrorlist=http://mirrors.rockylinux.org/mirrorlist?arch=$basearch&repo=BaseOS-$releasever # http address of a list or mirror #baseurl=http://dl.rockylinux.org/$contentdir/$releasever/BaseOS/$basearch/os/ # http address for direct access gpgcheck=1 # Repository requiring a signature enabled=1 # Activated =1, or not activated =0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial # GPG public key path By default, the enabled directive is absent which means that the repository is enabled. To disable a repository, you must specify the enabled=0 directive.","title":"How DNF works"},{"location":"books/admin_guide/13-softwares/#the-epel-repository","text":"","title":"The EPEL repository"},{"location":"books/admin_guide/13-softwares/#what-is-epel-and-how-is-it-used","text":"EPEL ( E xtra P ackages for E nterprise L inux) is an open-source and free community-based repository maintained by the EPEL Fedora Special Interest Group that provides a set of additional packages for RHEL (and CentOS, Rocky Linux, and others) from the Fedora sources. It provides packages that are not included in the official RHEL repositories. These are not included because they are not considered necessary in an enterprise environment or deemed outside the scope of RHEL. We must not forget that RHEL is an enterprise class distribution, and desktop utilities or other specialized software may not be a priority for an enterprise project.","title":"What is EPEL and how is it used?"},{"location":"books/admin_guide/13-softwares/#installation","text":"Installation of the necessary files can be easily done with the package provided by default from Rocky Linux. If you are behind an internet proxy: export http_proxy=http://172.16.1.10:8080 Then: dnf install epel-release Once installed you can check that the package has been installed correctly with the command dnf info . dnf info epel-release Last metadata expiration check: 1:30:29 ago on Thu 24 Mar 2022 09:36:42 AM CET. Installed Packages Name : epel-release Version : 8 Release : 14.el8 Architecture : noarch Size : 32 k Source : epel-release-8-14.el8.src.rpm Repository : @System From repo : epel Summary : Extra Packages for Enterprise Linux repository configuration URL : http://download.fedoraproject.org/pub/epel License : GPLv2 Description : This package contains the Extra Packages for Enterprise Linux : (EPEL) repository GPG key as well as configuration for yum. The package, as you can see from the package description above, does not contain executables, libraries, etc.. but only the configuration files and GPG keys for setting up the repository. Another way to verify the correct installation is to query the rpm database. rpm -qa | grep epel epel-release-8-14.el8.noarch Now you need to run an update to let dnf recognize the repository. You will be asked to accept the GPG keys of the repositories. Clearly, you have to answer YES in order to use them. dnf update Once the update is complete you can check that the repository has been configured correctly with the dnf repolist command which should now list the new repositories. dnf repolist repo id repo name ... epel Extra Packages for Enterprise Linux 8 - aarch64 epel-modular Extra Packages for Enterprise Linux Modular 8 - aarch64 ... The repository configuration files are located in /etc/yum.repos.d/ . ll /etc/yum.repos.d/ | grep epel -rw-r--r--. 1 root root 1485 Jan 31 17:19 epel-modular.repo -rw-r--r--. 1 root root 1422 Jan 31 17:19 epel.repo -rw-r--r--. 1 root root 1584 Jan 31 17:19 epel-testing-modular.repo -rw-r--r--. 1 root root 1521 Jan 31 17:19 epel-testing.repo And below we can see the contents of the file epel.repo . [epel] name=Extra Packages for Enterprise Linux $releasever - $basearch # It is much more secure to use the metalink, but if you wish to use a local mirror # place its address here. #baseurl=https://download.example/pub/epel/$releasever/Everything/$basearch metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-$releasever&arch=$basearch&infra=$infra&content=$contentdir enabled=1 gpgcheck=1 countme=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8 [epel-debuginfo] name=Extra Packages for Enterprise Linux $releasever - $basearch - Debug # It is much more secure to use the metalink, but if you wish to use a local mirror # place its address here. #baseurl=https://download.example/pub/epel/$releasever/Everything/$basearch/debug metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-$releasever&arch=$basearch&infra=$infra&content=$contentdir enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8 gpgcheck=1 [epel-source] name=Extra Packages for Enterprise Linux $releasever - $basearch - Source # It is much more secure to use the metalink, but if you wish to use a local mirror # place it's address here. #baseurl=https://download.example/pub/epel/$releasever/Everything/source/tree/ metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-source-$releasever&arch=$basearch&infra=$infra&content=$contentdir enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8 gpgcheck=1","title":"Installation"},{"location":"books/admin_guide/13-softwares/#using-epel","text":"At this point, once configured, we are ready to install the packages from EPEL. To start, we can list the packages available in the repository with the command: dnf --disablerepo=\"*\" --enablerepo=\"epel\" list available And an excerpt of the command dnf --disablerepo=\"*\" --enablerepo=\"epel\" list available | less Last metadata expiration check: 1:58:22 ago on Fri 25 Mar 2022 09:23:29 AM CET. Available Packages 3proxy.aarch64 0.8.13-1.el8 epel AMF-devel.noarch 1.4.23-2.el8 epel AMF-samples.noarch 1.4.23-2.el8 epel AusweisApp2.aarch64 1.22.3-1.el8 epel AusweisApp2-data.noarch 1.22.3-1.el8 epel AusweisApp2-doc.noarch 1.22.3-1.el8 epel BackupPC.aarch64 4.4.0-1.el8 epel BackupPC-XS.aarch64 0.62-1.el8 epel BibTool.aarch64 2.68-1.el8 epel CCfits.aarch64 2.5-14.el8 epel CCfits-devel.aarch64 2.5-14.el8 epel ... From the command we can see that to install from EPEL we must force dnf to query the requested repository with the options --disablerepo and --enablerepo , this is because otherwise a match found in other optional repositories (RPM Fusion, REMI, ELRepo, etc.) could be newer and therefore have priority. These options are not necessary if you have only installed EPEL as an optional repository because the packages in the repository will never be available in the official ones. At least in the same version! !!! attention \"Support consideration\" One aspect to consider regarding support (updates, bug fixes, security patches) is that EPEL packages have no official support from RHEL and technically their life could last the space of a development of Fedora (six months) and then disappear. This is a remote possibility but one to consider. So to install a package from the EPEL repositories you would use: dnf --disablerepo=\"*\" --enablerepo=\"epel\" install nmon Last metadata expiration check: 2:01:36 ago on Fri 25 Mar 2022 04:28:04 PM CET. Dependencies resolved. ============================================================================================================================================================== Package Architecture Version Repository Size ============================================================================================================================================================== Installing: nmon aarch64 16m-1.el8 epel 71 k Transaction Summary ============================================================================================================================================================== Install 1 Package Total download size: 71 k Installed size: 214 k Is this ok [y/N]:","title":"Using EPEL"},{"location":"books/admin_guide/13-softwares/#conclusion","text":"EPEL is not an official repository for RHEL. But it can be useful for administrators and developers who work with RHEL or derivatives and need some utilities prepared for RHEL from a source they can feel confident about.","title":"Conclusion"},{"location":"books/disa_stig/disa_stig_part1/","tags":["DISA","STIG","security","enterprise"],"text":"HOWTO: STIG Rocky Linux 8 Fast - Part 1 Terminology Reference DISA - Defense Information Systems Agency RHEL8 - Red Hat Enterprise Linux 8 STIG - Secure Technical Implementation Guide SCAP - Secure Content Automation Protocol DoD - Department of Defense Introduction In this guide we are going to cover how to apply the DISA STIG for RHEL8 for a New Installation of Rocky Linux 8. As multi-part series, we will also be covering how to test STIG compliance, adapt STIG settings, and apply other STIG content in this environment. Rocky Linux is a bug for bug derivative of RHEL 8 and as such the content published for the DISA RHEL8 STIG is in parity for both operating systems. Even better news, applying STIG settings is built into the Rocky Linux 8 anaconda installer, under Security Profiles. Under the hood this is all powered by a tool called OpenSCAP , which lets you both configure the system to be compliant with the DISA STIG (fast!), and also test the systems compliance after you\u2019ve installed. I\u2019ll be doing this on a virtual machine in my environment, but everything here would apply the exact same way on bare iron. Step 1: Create the Virtual Machine 2G memory 30G disk 1 core Step 2: Download the Rocky Linux 8 DVD ISO Download Rocky Linux DVD . Note: The minimal ISO does not contain the content needed to apply the STIG for Rocky Linux 8, you need to use the DVD or a network install. Step 3: Boot the Installer Step 4: Select Partitioning FIRST This is probably the most complicated step in the installation, and a requirement to be compliant with the STIG. You will need to partition the operating system's filesystem in a way that will probably create new problems. In other words: You\u2019re going to need to know exactly what your storage requirements are. !!! tip \"Pro-Tip\" Linux lets you resize filesystems, which we\u2019ll cover in another article. Suffice to say, this is one of the bigger issues applying the DISA STIG on bare iron, frequently requiring full re-installs to solve, so over spec the size you need here. Select \"Custom\" and then \"Done\" Start Adding Partitions DISA STIG partitioning scheme for a 30G disk. My use case is as a simple web server: / (10G) /boot (500m) /var (10G) /var/log (4G) /var/log/audit (1G) /home (1G) /tmp (1G) /var/tmp (1G) Swap (2G) !!! tip \"Pro-Tip\" Configure / last and give it a really high number, this will put all the slack disk space left on / and you will not have to do any math. !!! tip \"Pro-Tip\" Re-iterating from the previous Pro-Tip: OVER SPEC your filesystems, even if you have to grow them again later. Click \"Done\", and \"Accept Changes\" Step 5: Configure software for your environment: Server install without a GUI. This will matter in Step 6 , so if you are using a UI or a workstation configuration the security profile will be different. Step 6: Select Security Profile This is going to configure a number of security settings on the system based on the selected policy, leveraging the SCAP framework. It will modify the packages you selected in Step 5 , adding or removing components needed. If you did select a GUI install in Step 5 , and you use the non-GUI STIG in this step, it will remove the GUI. Adjust accordingly! Select the DISA STIG for Red Hat Enterprise Linux 8: Click \"Select Profile\", and note the changes it is going to make to the system. This will set options on mount points, add/remove applications, and make other configuration changes: Step 7: Click \"Done\", and Continue To Final Setup Step 8: Create a user account, and set that user to administrator In later tutorials we can get into joining this to a FreeIPA enterprise configuration. For now, we\u2019ll treat this as a standalone. Note that I am not setting a root password, rather we give our default user sudo access. Step 9: Click \"Done\", and then \"Begin Installation\" Step 10: Once the installation is completes, click \"Reboot System\" Step 11: Log in to your STIG'd Rocky Linux 8 System! If all went well, you should see the default DoD warning banner here. About The Author Scott Shinn is the CTO for Atomicorp, and part of the Rocky Linux Security team. He has been involved with federal information systems at the White House, Department of Defense, and Intelligence Community since 1995. Part of that was creating STIG\u2019s and the requirement that you use them and I am so very sorry about that.","title":"DISA STIG On Rocky Linux 8 - Part 1"},{"location":"books/disa_stig/disa_stig_part1/#howto-stig-rocky-linux-8-fast-part-1","text":"","title":"HOWTO: STIG Rocky Linux 8 Fast - Part 1"},{"location":"books/disa_stig/disa_stig_part1/#terminology-reference","text":"DISA - Defense Information Systems Agency RHEL8 - Red Hat Enterprise Linux 8 STIG - Secure Technical Implementation Guide SCAP - Secure Content Automation Protocol DoD - Department of Defense","title":"Terminology Reference"},{"location":"books/disa_stig/disa_stig_part1/#introduction","text":"In this guide we are going to cover how to apply the DISA STIG for RHEL8 for a New Installation of Rocky Linux 8. As multi-part series, we will also be covering how to test STIG compliance, adapt STIG settings, and apply other STIG content in this environment. Rocky Linux is a bug for bug derivative of RHEL 8 and as such the content published for the DISA RHEL8 STIG is in parity for both operating systems. Even better news, applying STIG settings is built into the Rocky Linux 8 anaconda installer, under Security Profiles. Under the hood this is all powered by a tool called OpenSCAP , which lets you both configure the system to be compliant with the DISA STIG (fast!), and also test the systems compliance after you\u2019ve installed. I\u2019ll be doing this on a virtual machine in my environment, but everything here would apply the exact same way on bare iron.","title":"Introduction"},{"location":"books/disa_stig/disa_stig_part1/#step-1-create-the-virtual-machine","text":"2G memory 30G disk 1 core","title":"Step 1: Create the Virtual Machine"},{"location":"books/disa_stig/disa_stig_part1/#step-2-download-the-rocky-linux-8-dvd-iso","text":"Download Rocky Linux DVD . Note: The minimal ISO does not contain the content needed to apply the STIG for Rocky Linux 8, you need to use the DVD or a network install.","title":"Step 2: Download the Rocky Linux 8 DVD ISO"},{"location":"books/disa_stig/disa_stig_part1/#step-3-boot-the-installer","text":"","title":"Step 3: Boot the Installer"},{"location":"books/disa_stig/disa_stig_part1/#step-4-select-partitioning-first","text":"This is probably the most complicated step in the installation, and a requirement to be compliant with the STIG. You will need to partition the operating system's filesystem in a way that will probably create new problems. In other words: You\u2019re going to need to know exactly what your storage requirements are. !!! tip \"Pro-Tip\" Linux lets you resize filesystems, which we\u2019ll cover in another article. Suffice to say, this is one of the bigger issues applying the DISA STIG on bare iron, frequently requiring full re-installs to solve, so over spec the size you need here. Select \"Custom\" and then \"Done\" Start Adding Partitions DISA STIG partitioning scheme for a 30G disk. My use case is as a simple web server: / (10G) /boot (500m) /var (10G) /var/log (4G) /var/log/audit (1G) /home (1G) /tmp (1G) /var/tmp (1G) Swap (2G) !!! tip \"Pro-Tip\" Configure / last and give it a really high number, this will put all the slack disk space left on / and you will not have to do any math. !!! tip \"Pro-Tip\" Re-iterating from the previous Pro-Tip: OVER SPEC your filesystems, even if you have to grow them again later. Click \"Done\", and \"Accept Changes\"","title":"Step 4: Select Partitioning FIRST"},{"location":"books/disa_stig/disa_stig_part1/#step-5-configure-software-for-your-environment-server-install-without-a-gui","text":"This will matter in Step 6 , so if you are using a UI or a workstation configuration the security profile will be different.","title":"Step 5: Configure software for your environment: Server install without a GUI."},{"location":"books/disa_stig/disa_stig_part1/#step-6-select-security-profile","text":"This is going to configure a number of security settings on the system based on the selected policy, leveraging the SCAP framework. It will modify the packages you selected in Step 5 , adding or removing components needed. If you did select a GUI install in Step 5 , and you use the non-GUI STIG in this step, it will remove the GUI. Adjust accordingly! Select the DISA STIG for Red Hat Enterprise Linux 8: Click \"Select Profile\", and note the changes it is going to make to the system. This will set options on mount points, add/remove applications, and make other configuration changes:","title":"Step 6: Select Security Profile"},{"location":"books/disa_stig/disa_stig_part1/#step-7-click-done-and-continue-to-final-setup","text":"","title":"Step 7: Click \"Done\", and Continue To Final Setup"},{"location":"books/disa_stig/disa_stig_part1/#step-8-create-a-user-account-and-set-that-user-to-administrator","text":"In later tutorials we can get into joining this to a FreeIPA enterprise configuration. For now, we\u2019ll treat this as a standalone. Note that I am not setting a root password, rather we give our default user sudo access.","title":"Step 8: Create a user account, and set that user to administrator"},{"location":"books/disa_stig/disa_stig_part1/#step-9-click-done-and-then-begin-installation","text":"","title":"Step 9: Click \"Done\", and then \"Begin Installation\""},{"location":"books/disa_stig/disa_stig_part1/#step-10-once-the-installation-is-completes-click-reboot-system","text":"","title":"Step 10: Once the installation is completes, click \"Reboot System\""},{"location":"books/disa_stig/disa_stig_part1/#step-11-log-in-to-your-stigd-rocky-linux-8-system","text":"If all went well, you should see the default DoD warning banner here.","title":"Step 11: Log in to your STIG'd Rocky Linux 8 System!"},{"location":"books/disa_stig/disa_stig_part1/#about-the-author","text":"Scott Shinn is the CTO for Atomicorp, and part of the Rocky Linux Security team. He has been involved with federal information systems at the White House, Department of Defense, and Intelligence Community since 1995. Part of that was creating STIG\u2019s and the requirement that you use them and I am so very sorry about that.","title":"About The Author"},{"location":"books/learning_ansible/00-toc/","text":"Learning Ansible with Rocky Ansible is a simple, yet powerful, automation engine for Linux. This tutorial will guide you through the concepts of using Ansible to automate your IT tasks in a way that is (hopefully) fun and informative. Using the exercises throughout these chapters, will help you gain a comfort level with Ansible in real-world applications.","title":"Learning Ansible with Rocky"},{"location":"books/learning_ansible/00-toc/#learning-ansible-with-rocky","text":"Ansible is a simple, yet powerful, automation engine for Linux. This tutorial will guide you through the concepts of using Ansible to automate your IT tasks in a way that is (hopefully) fun and informative. Using the exercises throughout these chapters, will help you gain a comfort level with Ansible in real-world applications.","title":"Learning Ansible with Rocky"},{"location":"books/learning_ansible/01-basic/","text":"Ansible Basics In this chapter you will learn how to work with Ansible. Objectives : In this chapter you will learn how to: :heavy_check_mark: Implement Ansible; :heavy_check_mark: Apply configuration changes on a server; :heavy_check_mark: Create first Ansible playbooks; :checkered_flag: ansible , module , playbook Knowledge : :star: :star: :star: Complexity : :star: :star: Reading time : 30 minutes Ansible centralizes and automates administration tasks. It is: agentless (it does not require specific deployments on clients), idempotent (same effect each time it is run) It uses the SSH protocol to remotely configure Linux clients or the WinRM protocol to work with Windows clients. If none of these protocols is available, it is always possible for Ansible to use an API, which makes Ansible a real Swiss army knife for the configuration of servers, workstations, docker services, network equipment, etc. (Almost everything in fact). !!! Warning The opening of SSH or WinRM flows to all clients from the Ansible server, makes it a critical element of the architecture that must be carefully monitored. As Ansible is push-based, it will not keep the state of its targeted servers between each of its executions. On the contrary, it will perform new state checks each time it is executed. It is said to be stateless. It will help you with: provisioning (deploying a new VM), application deployments configuration management, automation, orchestration (when more than 1 target is in use). !!! Note Ansible was originally written by Michael DeHaan, the founder of other tools such as Cobbler. ![Michael DeHaan](images/Michael_DeHaan01.jpg) The earliest first version was 0.0.1, released on March 9, 2012. On October 17, 2015, AnsibleWorks (the company behind Ansible) was acquired by Red Hat for $150 million. To offer a graphical interface to your daily use of Ansible, you can install some tools like Ansible Tower (RedHat), which is not free, its opensource counterpart Awx, or other projects like Jenkins and the excellent Rundeck can also be used. !!! Abstract To follow this training, you will need at least 2 servers under Rocky8: * the first one will be the **management machine**, Ansible will be installed on it. * the second one will be the server to configure and manage (another Linux than Rocky Linux will do just as well). In the examples below, the administration station has the IP address 172.16.1.10, the managed station 172.16.1.11. It is up to you to adapt the examples according to your IP addressing plan. The Ansible vocabulary The management machine : the machine on which Ansible is installed. Since Ansible is agentless , no software is deployed on the managed servers. The inventory : a file containing information about the managed servers. The tasks : a task is a block defining a procedure to be executed (e.g. create a user or a group, install a software package, etc.). A module : a module abstracts a task. There are many modules provided by Ansible. The playbooks : a simple file in yaml format defining the target servers and the tasks to be performed. A role : a role allows you to organize the playbooks and all the other necessary files (templates, scripts, etc.) to facilitate the sharing and reuse of code. A collection : a collection includes a logical set of playbooks, roles, modules, and plugins. The facts : these are global variables containing information about the system (machine name, system version, network interface and configuration, etc.). The handlers : these are used to cause a service to be stopped or restarted in the event of a change. Installation on the management server Ansible is available in the EPEL repository but comes as version 2.9.21, which is quite old now. You can see how this is done by following along here, but skip the actual installation steps, as we will be installing the latest version. The EPEL is required for both versions, so you can go ahead and install that now: EPEL installation: $ sudo dnf install epel-release If we were installing Ansible from the EPEL we could do the following: $ sudo dnf install ansible $ ansible --version 2.9.21 As we want to use a newer version of Ansible, we will install it from python3-pip : !!! Note Remove Ansible if you have installed it previously from _EPEL_. $ sudo dnf install python38 python38-pip python38-wheel python3-argcomplete rust cargo curl !!! Note `python3-argcomplete` is provided by _EPEL_. Please install epel-release if not done yet. This package will help you complete Ansible commands. Before we actually install Ansible, we need to tell Rocky Linux that we want to use the newly installed version of Python. The reason is that if we continue to the install without this, the default python3 (version 3.6 as of this writing), will be used instead of the newly installed version 3.8. Set the version you want to use by entering the following command: sudo alternatives --set python /usr/bin/python3.8 sudo alternatives --set python3 /usr/bin/python3.8 We can now install Ansible: $ sudo pip3 install ansible $ sudo activate-global-python-argcomplete Check your Ansible version: $ ansible --version ansible [core 2.11.2] config file = None configured module search path = ['/home/ansible/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /usr/local/lib/python3.8/site-packages/ansible ansible collection location = /home/ansible/.ansible/collections:/usr/share/ansible/collections executable location = /usr/local/bin/ansible python version = 3.8.6 (default, Jun 29 2021, 21:14:45) [GCC 8.4.1 20200928 (Red Hat 8.4.1-1)] jinja version = 3.0.1 libyaml = True Configuration files The server configuration is located under /etc/ansible . There are two main configuration files: The main configuration file ansible.cfg where the commands, modules, plugins, and ssh configuration reside; The client machine management inventory file hosts where the clients, and groups of clients are declared. As we installed Ansible with pip , those files do not exist. We will have to create them by hand. An example of the ansible.cfg is given here and an example of the hosts file here . $ sudo mkdir /etc/ansible $ sudo curl -o /etc/ansible/ansible.cfg https://raw.githubusercontent.com/ansible/ansible/devel/examples/ansible.cfg $ sudo curl -o /etc/ansible/hosts https://raw.githubusercontent.com/ansible/ansible/devel/examples/hosts You can also use the ansible-config command to generate a new configuration file: usage: ansible-config [-h] [--version] [-v] {list,dump,view,init} ... View ansible configuration. positional arguments: {list,dump,view,init} list Print all config options dump Dump configuration view View configuration file init Create initial configuration Example: ansible-config init --disabled > /etc/ansible/ansible.cfg The --disabled option allows you to comment out the set of options by prefixing them with a ; . The inventory file /etc/ansible/hosts As Ansible will have to work with all your equipment to be configured, it is very important to provide it with one (or more) well-structured inventory file(s), which perfectly matches your organization. It is sometimes necessary to think carefully about how to build this file. Go to the default inventory file, which is located under /etc/ansible/hosts . Some examples are provided and commented: # This is the default ansible 'hosts' file. # # It should live in /etc/ansible/hosts # # - Comments begin with the '#' character # - Blank lines are ignored # - Groups of hosts are delimited by [header] elements # - You can enter hostnames or ip addresses # - A hostname/ip can be a member of multiple groups # Ex 1: Ungrouped hosts, specify before any group headers: ## green.example.com ## blue.example.com ## 192.168.100.1 ## 192.168.100.10 # Ex 2: A collection of hosts belonging to the 'webservers' group: ## [webservers] ## alpha.example.org ## beta.example.org ## 192.168.1.100 ## 192.168.1.110 # If you have multiple hosts following a pattern, you can specify # them like this: ## www[001:006].example.com # Ex 3: A collection of database servers in the 'dbservers' group: ## [dbservers] ## ## db01.intranet.mydomain.net ## db02.intranet.mydomain.net ## 10.25.1.56 ## 10.25.1.57 # Here's another example of host ranges, this time there are no # leading 0s: ## db-[99:101]-node.example.com As you can see, the file provided as an example uses the INI format, which is well known to system administrators. Please note that you can choose another file format (like yaml for example), but for the first tests, the INI format is well adapted to our future examples. Obviously, in production, the inventory can be generated automatically, especially if you have a virtualization environment like VMware VSphere or a cloud environment (Aws, Openstack or other). Creating a hostgroup in /etc/ansible/hosts : As you may have noticed, the groups are declared in square brackets. Then come the elements belonging to the groups. You can create, for example, a rocky8 group by inserting the following block into this file: [rocky8] 172.16.1.10 172.16.1.11 Groups can be used within other groups. In this case, it must be specified that the parent group is composed of subgroups with the :chidren attribute like this: [linux:children] rocky8 debian9 [ansible:children] ansible_management ansible_clients [ansible_management] 172.16.1.10 [ansible_clients] 172.16.1.10 We won't go any further for the moment on the subject of inventory, but if you're interested, consider checking this link . Now that our management server is installed and our inventory is ready, it's time to run our first ansible commands. ansible command line usage The ansible command launches a task on one or more target hosts. ansible <host-pattern> [-m module_name] [-a args] [options] Examples: !!! Warning Since we have not yet configured authentication on our 2 test servers, not all the following examples will work. They are given as examples to facilitate understanding, and will be fully functional later in this chapter. List the hosts belonging to the rocky8 group: ansible rocky8 --list-hosts Ping a host group with the ping module: ansible rocky8 -m ping Display facts from a host group with the setup module: ansible rocky8 -m setup Run a command on a host group by invoking the command module with arguments: ansible rocky8 -m command -a 'uptime' Run a command with administrator privileges: ansible ansible_clients --become -m command -a 'reboot' Run a command using a custom inventory file: ansible rocky8 -i ./local-inventory -m command -a 'date' !!! Note As in this example, it is sometimes simpler to separate the declaration of managed devices into several files (by cloud project for example) and provide Ansible with the path to these files, rather than to maintain a long inventory file. Option Information -a 'arguments' The arguments to pass to the module. -b -K Requests a password and runs the command with higher privileges. --user=username Uses this user to connect to the target host instead of the current user. --become-user=username Executes the operation as this user (default: root ). -C Simulation. Does not make any changes to the target but tests it to see what should be changed. -m module Runs the module called Preparing the client On both management machine and clients, we will create an ansible user dedicated to the operations performed by Ansible. This user will have to use sudo rights, so it will have to be added to the wheel group. This user will be used: On the administration station side: to run ansible commands and ssh to managed clients. On the managed stations (here the server that serves as your administration station also serves as a client, so it is managed by itself) to execute the commands launched from the administration station: it must therefore have sudo rights. On both machines, create an ansible user, dedicated to ansible: $ sudo useradd ansible $ sudo usermod -aG wheel ansible Set a password for this user: $ sudo passwd ansible Modify the sudoers config to allow members of the wheel group to sudo without password: $ sudo visudo Our goal here is to comment out the default, and uncomment the NOPASSWD option so that these lines looks like this when we are done: ## Allows people in group wheel to run all commands # %wheel ALL=(ALL) ALL ## Same thing without a password %wheel ALL=(ALL) NOPASSWD: ALL !!! Warning If you receive the following error message when entering Ansible commands, it probably means that you forgot this step on one of your clients: `\"msg\": \"Missing sudo password` When using management from this point on, start working with this new user: $ sudo su - ansible Test with the ping module By default password login is not allowed by Ansible. Uncomment the following line from the [defaults] section in the /etc/ansible/ansible.cfg configuration file and set it to True: ask_pass = True Run a ping on each server of the rocky8 group: # ansible rocky8 -m ping SSH password: 172.16.1.10 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } 172.16.1.11 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } !!! Note You are asked for the `ansible` password of the remote servers, which is a security problem... !!! Tip If you get this error `\"msg\": \"to use the 'ssh' connection type with passwords, you must install the sshpass program\"`, you can just install `sshpass` on the management station: ``` $ sudo dnf install sshpass ``` !!! Abstract You can now test the commands that didn't work previously in this chapter. Key authentication Password authentication will be replaced by a much more secure private/public key authentication. Creating an SSH key The dual-key will be generated with the command ssh-keygen on the management station by the ansible user: [ansible]$ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/ansible/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/ansible/.ssh/id_rsa. Your public key has been saved in /home/ansible/.ssh/id_rsa.pub. The key fingerprint is: SHA256:Oa1d2hYzzdO0e/K10XPad25TA1nrSVRPIuS4fnmKr9g ansible@localhost.localdomain The key's randomart image is: +---[RSA 3072]----+ | .o . +| | o . =.| | . . + +| | o . = =.| | S o = B.o| | = + = =+| | . + = o+B| | o + o *@| | . Eoo .+B| +----[SHA256]-----+ The public key can be copied to the servers: # ssh-copy-id ansible@172.16.1.10 # ssh-copy-id ansible@172.16.1.11 Re-comment the following line from the [defaults] section in the /etc/ansible/ansible.cfg configuration file to prevent password authentication: #ask_pass = True Private key authentication test For the next test, the shell module, allowing remote command execution, is used: # ansible rocky8 -m shell -a \"uptime\" 172.16.1.10 | SUCCESS | rc=0 >> 12:36:18 up 57 min, 1 user, load average: 0.00, 0.00, 0.00 172.16.1.11 | SUCCESS | rc=0 >> 12:37:07 up 57 min, 1 user, load average: 0.00, 0.00, 0.00 No password is required, private/public key authentication works! !!! Note In production environment, you should now remove the `ansible` passwords previously set to enforce your security (as now an authentication password is not necessary). Using Ansible Ansible can be used from the shell or via playbooks. The modules The list of modules classified by category can be found here . Ansible offers more than 750! The modules are now grouped into module collections, a list of which can be found here . Collections are a distribution format for Ansible content that can include playbooks, roles, modules, and plugins. A module is invoked with the -m option of the ansible command: ansible <host-pattern> [-m module_name] [-a args] [options] There is a module for almost every need! It is thus advised, instead of using the shell module, to look for a module adapted to the need. Each category of need has its own module. Here is a non exhaustive list: Type Examples System Management user (users management), group (groups management), etc. Software management dnf , yum , apt , pip , npm File management copy , fetch , lineinfile , template , archive Database management mysql , postgresql , redis Cloud management amazon S3 , cloudstack , openstack Cluster management consul , zookeeper Send commands shell , script , expect Downloads get_url Source management git , gitlab Example of software installation The dnf module allows for the installation of software on the target clients: # ansible rocky8 --become -m dnf -a name=\"httpd\" 172.16.1.10 | SUCCESS => { \"changed\": true, \"msg\": \"\", \"rc\": 0, \"results\": [ ... \\n\\nComplete!\\n\" ] } 172.16.1.11 | SUCCESS => { \"changed\": true, \"msg\": \"\", \"rc\": 0, \"results\": [ ... \\n\\nComplete!\\n\" ] } The installed software being a service, it is now necessary to start it with the module systemd : # ansible rocky8 --become -m systemd -a \"name=httpd state=started\" 172.16.1.10 | SUCCESS => { \"changed\": true, \"name\": \"httpd\", \"state\": \"started\" } 172.16.1.11 | SUCCESS => { \"changed\": true, \"name\": \"httpd\", \"state\": \"started\" } !!! Tip Try to launch those last 2 commands twice. You will observe that the first time Ansible will take actions to reach the state set by the command. The second time, it will do nothing because it will have detected that the state is already reached! Exercises To help discover more about Ansible and to get used to searching the Ansible documentation, here are some exercises you can do before going on: Create the groups Paris, Tokio, NewYork Create the user supervisor Change the user to have a uid of 10000 Change the user so that it belongs to the Paris group Install the tree software Stop the crond service Create en empty file with 644 rights Update your client distribution Restart your client !!! Warning Do not use the shell module. Look in the documentation for the appropriate modules! setup module: introduction to facts The system facts are variables retrieved by Ansible via its setup module. Take a look at the different facts of your clients to get an idea of the amount of information that can be easily retrieved via a simple command. We'll see later how to use facts in our playbooks and how to create our own facts. # ansible ansible_clients -m setup | less 192.168.1.11 | SUCCESS => { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ \"192.168.1.11\" ], \"ansible_all_ipv6_addresses\": [ \"2001:861:3dc3:fcf0:a00:27ff:fef7:28be\", \"fe80::a00:27ff:fef7:28be\" ], \"ansible_apparmor\": { \"status\": \"disabled\" }, \"ansible_architecture\": \"x86_64\", \"ansible_bios_date\": \"12/01/2006\", \"ansible_bios_vendor\": \"innotek GmbH\", \"ansible_bios_version\": \"VirtualBox\", \"ansible_board_asset_tag\": \"NA\", \"ansible_board_name\": \"VirtualBox\", \"ansible_board_serial\": \"NA\", \"ansible_board_vendor\": \"Oracle Corporation\", ... Now that we have seen how to configure a remote server with Ansible on the command line, we will be able to introduce the notion of playbook. Playbooks are another way to use Ansible, which is not much more complex, but which will make it easier to reuse your code. Playbooks Ansible's playbooks describe a policy to be applied to remote systems, to force their configuration. Playbooks are written in an easily understandable text format that groups together a set of tasks: the yaml format. !!! Note Learn more about [yaml here](https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html) ansible-playbook <file.yml> ... [options] The options are identical to the ansible command. The command returns the following error codes: Code Error 0 OK or no matching host 1 Error 2 One or more hosts are failing 3 One or more hosts are unreachable 4 Analyze error 5 Bad or incomplete options 99 Run interrupted by user 250 Unexpected error !!! Note Please note that `ansible` will return Ok when there is no host matching your target, which might mislead you! Example of Apache and MySQL playbook The following playbook allows us to install Apache and MariaDB on our target servers. Create a test.yml file with the following content: --- - hosts: rocky8 <1> become: true <2> become_user: root tasks: - name: ensure apache is at the latest version dnf: name=httpd,php,php-mysqli state=latest - name: ensure httpd is started systemd: name=httpd state=started - name: ensure mariadb is at the latest version dnf: name=mariadb-server state=latest - name: ensure mariadb is started systemd: name=mariadb state=started ... <1> The targeted group or the targeted server must exist in the inventory <2> Once connected, the user becomes root (via sudo by default) The execution of the playbook is done with the command ansible-playbook : $ ansible-playbook test.yml PLAY [rocky8] **************************************************************** TASK [setup] ****************************************************************** ok: [172.16.1.10] ok: [172.16.1.11] TASK [ensure apache is at the latest version] ********************************* ok: [172.16.1.10] ok: [172.16.1.11] TASK [ensure httpd is started] ************************************************ changed: [172.16.1.10] changed: [172.16.1.11] TASK [ensure mariadb is at the latest version] ********************************** changed: [172.16.1.10] changed: [172.16.1.11] TASK [ensure mariadb is started] *********************************************** changed: [172.16.1.10] changed: [172.16.1.11] PLAY RECAP ********************************************************************* 172.16.1.10 : ok=5 changed=3 unreachable=0 failed=0 172.16.1.11 : ok=5 changed=3 unreachable=0 failed=0 For more readability, it is recommended to write your playbooks in full yaml format. In the previous example, the arguments are given on the same line as the module, the value of the argument following its name separated by an = . Look at the same playbook in full yaml: --- - hosts: rocky8 become: true become_user: root tasks: - name: ensure apache is at the latest version dnf: name: httpd,php,php-mysqli state: latest - name: ensure httpd is started systemd: name: httpd state: started - name: ensure mariadb is at the latest version dnf: name: mariadb-server state: latest - name: ensure mariadb is started systemd: name: mariadb state: started ... !!! Tip `dnf` is one of the modules that allow you to give it a list as argument. Note about collections: Ansible now provides modules in the form of collections. Some modules are provided by default within the ansible.builtin collection, others must be installed manually via the: ansible-galaxy collection install [collectionname] where [collectionname] is the name of the collection. (the square brackets here are used to highlight the need to replace this with an actual collection name, and are NOT part of the command.) The previous example should be written like this: --- - hosts: rocky8 become: true become_user: root tasks: - name: ensure apache is at the latest version ansible.builtin.dnf: name: httpd,php,php-mysqli state: latest - name: ensure httpd is started ansible.builtin.systemd: name: httpd state: started - name: ensure mariadb is at the latest version ansible.builtin.dnf: name: mariadb-server state: latest - name: ensure mariadb is started ansible.builtin.systemd: name: mariadb state: started ... A playbook is not limited to one target: --- - hosts: webservers become: true become_user: root tasks: - name: ensure apache is at the latest version ansible.builtin.dnf: name: httpd,php,php-mysqli state: latest - name: ensure httpd is started ansible.builtin.systemd: name: httpd state: started - hosts: databases become: true become_user: root - name: ensure mariadb is at the latest version ansible.builtin.dnf: name: mariadb-server state: latest - name: ensure mariadb is started ansible.builtin.systemd: name: mariadb state: started ... You can check the syntax of your playbook: $ ansible-playbook --syntax-check play.yml You can also use a \"linter\" for yaml: $ dnf install -y yamllint then check the yaml syntax of your playbooks: $ yamllint test.yml test.yml 8:1 error syntax error: could not find expected ':' (syntax) Exercices results Create the groups Paris, Tokio, NewYork Create the user supervisor Change the user to have a uid of 10000 Change the user so that it belongs to the Paris group Install the tree software Stop the crond service Create en empty file with 0644 rights Update your client distribution Restart your client ansible ansible_clients --become -m group -a \"name=Paris\" ansible ansible_clients --become -m group -a \"name=Tokio\" ansible ansible_clients --become -m group -a \"name=NewYork\" ansible ansible_clients --become -m user -a \"name=Supervisor\" ansible ansible_clients --become -m user -a \"name=Supervisor uid=10000\" ansible ansible_clients --become -m user -a \"name=Supervisor uid=10000 groups=Paris\" ansible ansible_clients --become -m dnf -a \"name=tree\" ansible ansible_clients --become -m systemd -a \"name=crond state=stopped\" ansible ansible_clients --become -m copy -a \"content='' dest=/tmp/test force=no mode=0644\" ansible ansible_clients --become -m dnf -a \"name=* state=latest\" ansible ansible_clients --become -m reboot","title":"Ansible Basics"},{"location":"books/learning_ansible/01-basic/#ansible-basics","text":"In this chapter you will learn how to work with Ansible. Objectives : In this chapter you will learn how to: :heavy_check_mark: Implement Ansible; :heavy_check_mark: Apply configuration changes on a server; :heavy_check_mark: Create first Ansible playbooks; :checkered_flag: ansible , module , playbook Knowledge : :star: :star: :star: Complexity : :star: :star: Reading time : 30 minutes Ansible centralizes and automates administration tasks. It is: agentless (it does not require specific deployments on clients), idempotent (same effect each time it is run) It uses the SSH protocol to remotely configure Linux clients or the WinRM protocol to work with Windows clients. If none of these protocols is available, it is always possible for Ansible to use an API, which makes Ansible a real Swiss army knife for the configuration of servers, workstations, docker services, network equipment, etc. (Almost everything in fact). !!! Warning The opening of SSH or WinRM flows to all clients from the Ansible server, makes it a critical element of the architecture that must be carefully monitored. As Ansible is push-based, it will not keep the state of its targeted servers between each of its executions. On the contrary, it will perform new state checks each time it is executed. It is said to be stateless. It will help you with: provisioning (deploying a new VM), application deployments configuration management, automation, orchestration (when more than 1 target is in use). !!! Note Ansible was originally written by Michael DeHaan, the founder of other tools such as Cobbler. ![Michael DeHaan](images/Michael_DeHaan01.jpg) The earliest first version was 0.0.1, released on March 9, 2012. On October 17, 2015, AnsibleWorks (the company behind Ansible) was acquired by Red Hat for $150 million. To offer a graphical interface to your daily use of Ansible, you can install some tools like Ansible Tower (RedHat), which is not free, its opensource counterpart Awx, or other projects like Jenkins and the excellent Rundeck can also be used. !!! Abstract To follow this training, you will need at least 2 servers under Rocky8: * the first one will be the **management machine**, Ansible will be installed on it. * the second one will be the server to configure and manage (another Linux than Rocky Linux will do just as well). In the examples below, the administration station has the IP address 172.16.1.10, the managed station 172.16.1.11. It is up to you to adapt the examples according to your IP addressing plan.","title":"Ansible Basics"},{"location":"books/learning_ansible/01-basic/#the-ansible-vocabulary","text":"The management machine : the machine on which Ansible is installed. Since Ansible is agentless , no software is deployed on the managed servers. The inventory : a file containing information about the managed servers. The tasks : a task is a block defining a procedure to be executed (e.g. create a user or a group, install a software package, etc.). A module : a module abstracts a task. There are many modules provided by Ansible. The playbooks : a simple file in yaml format defining the target servers and the tasks to be performed. A role : a role allows you to organize the playbooks and all the other necessary files (templates, scripts, etc.) to facilitate the sharing and reuse of code. A collection : a collection includes a logical set of playbooks, roles, modules, and plugins. The facts : these are global variables containing information about the system (machine name, system version, network interface and configuration, etc.). The handlers : these are used to cause a service to be stopped or restarted in the event of a change.","title":"The Ansible vocabulary"},{"location":"books/learning_ansible/01-basic/#installation-on-the-management-server","text":"Ansible is available in the EPEL repository but comes as version 2.9.21, which is quite old now. You can see how this is done by following along here, but skip the actual installation steps, as we will be installing the latest version. The EPEL is required for both versions, so you can go ahead and install that now: EPEL installation: $ sudo dnf install epel-release If we were installing Ansible from the EPEL we could do the following: $ sudo dnf install ansible $ ansible --version 2.9.21 As we want to use a newer version of Ansible, we will install it from python3-pip : !!! Note Remove Ansible if you have installed it previously from _EPEL_. $ sudo dnf install python38 python38-pip python38-wheel python3-argcomplete rust cargo curl !!! Note `python3-argcomplete` is provided by _EPEL_. Please install epel-release if not done yet. This package will help you complete Ansible commands. Before we actually install Ansible, we need to tell Rocky Linux that we want to use the newly installed version of Python. The reason is that if we continue to the install without this, the default python3 (version 3.6 as of this writing), will be used instead of the newly installed version 3.8. Set the version you want to use by entering the following command: sudo alternatives --set python /usr/bin/python3.8 sudo alternatives --set python3 /usr/bin/python3.8 We can now install Ansible: $ sudo pip3 install ansible $ sudo activate-global-python-argcomplete Check your Ansible version: $ ansible --version ansible [core 2.11.2] config file = None configured module search path = ['/home/ansible/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /usr/local/lib/python3.8/site-packages/ansible ansible collection location = /home/ansible/.ansible/collections:/usr/share/ansible/collections executable location = /usr/local/bin/ansible python version = 3.8.6 (default, Jun 29 2021, 21:14:45) [GCC 8.4.1 20200928 (Red Hat 8.4.1-1)] jinja version = 3.0.1 libyaml = True","title":"Installation on the management server"},{"location":"books/learning_ansible/01-basic/#configuration-files","text":"The server configuration is located under /etc/ansible . There are two main configuration files: The main configuration file ansible.cfg where the commands, modules, plugins, and ssh configuration reside; The client machine management inventory file hosts where the clients, and groups of clients are declared. As we installed Ansible with pip , those files do not exist. We will have to create them by hand. An example of the ansible.cfg is given here and an example of the hosts file here . $ sudo mkdir /etc/ansible $ sudo curl -o /etc/ansible/ansible.cfg https://raw.githubusercontent.com/ansible/ansible/devel/examples/ansible.cfg $ sudo curl -o /etc/ansible/hosts https://raw.githubusercontent.com/ansible/ansible/devel/examples/hosts You can also use the ansible-config command to generate a new configuration file: usage: ansible-config [-h] [--version] [-v] {list,dump,view,init} ... View ansible configuration. positional arguments: {list,dump,view,init} list Print all config options dump Dump configuration view View configuration file init Create initial configuration Example: ansible-config init --disabled > /etc/ansible/ansible.cfg The --disabled option allows you to comment out the set of options by prefixing them with a ; .","title":"Configuration files"},{"location":"books/learning_ansible/01-basic/#the-inventory-file-etcansiblehosts","text":"As Ansible will have to work with all your equipment to be configured, it is very important to provide it with one (or more) well-structured inventory file(s), which perfectly matches your organization. It is sometimes necessary to think carefully about how to build this file. Go to the default inventory file, which is located under /etc/ansible/hosts . Some examples are provided and commented: # This is the default ansible 'hosts' file. # # It should live in /etc/ansible/hosts # # - Comments begin with the '#' character # - Blank lines are ignored # - Groups of hosts are delimited by [header] elements # - You can enter hostnames or ip addresses # - A hostname/ip can be a member of multiple groups # Ex 1: Ungrouped hosts, specify before any group headers: ## green.example.com ## blue.example.com ## 192.168.100.1 ## 192.168.100.10 # Ex 2: A collection of hosts belonging to the 'webservers' group: ## [webservers] ## alpha.example.org ## beta.example.org ## 192.168.1.100 ## 192.168.1.110 # If you have multiple hosts following a pattern, you can specify # them like this: ## www[001:006].example.com # Ex 3: A collection of database servers in the 'dbservers' group: ## [dbservers] ## ## db01.intranet.mydomain.net ## db02.intranet.mydomain.net ## 10.25.1.56 ## 10.25.1.57 # Here's another example of host ranges, this time there are no # leading 0s: ## db-[99:101]-node.example.com As you can see, the file provided as an example uses the INI format, which is well known to system administrators. Please note that you can choose another file format (like yaml for example), but for the first tests, the INI format is well adapted to our future examples. Obviously, in production, the inventory can be generated automatically, especially if you have a virtualization environment like VMware VSphere or a cloud environment (Aws, Openstack or other). Creating a hostgroup in /etc/ansible/hosts : As you may have noticed, the groups are declared in square brackets. Then come the elements belonging to the groups. You can create, for example, a rocky8 group by inserting the following block into this file: [rocky8] 172.16.1.10 172.16.1.11 Groups can be used within other groups. In this case, it must be specified that the parent group is composed of subgroups with the :chidren attribute like this: [linux:children] rocky8 debian9 [ansible:children] ansible_management ansible_clients [ansible_management] 172.16.1.10 [ansible_clients] 172.16.1.10 We won't go any further for the moment on the subject of inventory, but if you're interested, consider checking this link . Now that our management server is installed and our inventory is ready, it's time to run our first ansible commands.","title":"The inventory file /etc/ansible/hosts"},{"location":"books/learning_ansible/01-basic/#ansible-command-line-usage","text":"The ansible command launches a task on one or more target hosts. ansible <host-pattern> [-m module_name] [-a args] [options] Examples: !!! Warning Since we have not yet configured authentication on our 2 test servers, not all the following examples will work. They are given as examples to facilitate understanding, and will be fully functional later in this chapter. List the hosts belonging to the rocky8 group: ansible rocky8 --list-hosts Ping a host group with the ping module: ansible rocky8 -m ping Display facts from a host group with the setup module: ansible rocky8 -m setup Run a command on a host group by invoking the command module with arguments: ansible rocky8 -m command -a 'uptime' Run a command with administrator privileges: ansible ansible_clients --become -m command -a 'reboot' Run a command using a custom inventory file: ansible rocky8 -i ./local-inventory -m command -a 'date' !!! Note As in this example, it is sometimes simpler to separate the declaration of managed devices into several files (by cloud project for example) and provide Ansible with the path to these files, rather than to maintain a long inventory file. Option Information -a 'arguments' The arguments to pass to the module. -b -K Requests a password and runs the command with higher privileges. --user=username Uses this user to connect to the target host instead of the current user. --become-user=username Executes the operation as this user (default: root ). -C Simulation. Does not make any changes to the target but tests it to see what should be changed. -m module Runs the module called","title":"ansible command line usage"},{"location":"books/learning_ansible/01-basic/#preparing-the-client","text":"On both management machine and clients, we will create an ansible user dedicated to the operations performed by Ansible. This user will have to use sudo rights, so it will have to be added to the wheel group. This user will be used: On the administration station side: to run ansible commands and ssh to managed clients. On the managed stations (here the server that serves as your administration station also serves as a client, so it is managed by itself) to execute the commands launched from the administration station: it must therefore have sudo rights. On both machines, create an ansible user, dedicated to ansible: $ sudo useradd ansible $ sudo usermod -aG wheel ansible Set a password for this user: $ sudo passwd ansible Modify the sudoers config to allow members of the wheel group to sudo without password: $ sudo visudo Our goal here is to comment out the default, and uncomment the NOPASSWD option so that these lines looks like this when we are done: ## Allows people in group wheel to run all commands # %wheel ALL=(ALL) ALL ## Same thing without a password %wheel ALL=(ALL) NOPASSWD: ALL !!! Warning If you receive the following error message when entering Ansible commands, it probably means that you forgot this step on one of your clients: `\"msg\": \"Missing sudo password` When using management from this point on, start working with this new user: $ sudo su - ansible","title":"Preparing the client"},{"location":"books/learning_ansible/01-basic/#test-with-the-ping-module","text":"By default password login is not allowed by Ansible. Uncomment the following line from the [defaults] section in the /etc/ansible/ansible.cfg configuration file and set it to True: ask_pass = True Run a ping on each server of the rocky8 group: # ansible rocky8 -m ping SSH password: 172.16.1.10 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } 172.16.1.11 | SUCCESS => { \"changed\": false, \"ping\": \"pong\" } !!! Note You are asked for the `ansible` password of the remote servers, which is a security problem... !!! Tip If you get this error `\"msg\": \"to use the 'ssh' connection type with passwords, you must install the sshpass program\"`, you can just install `sshpass` on the management station: ``` $ sudo dnf install sshpass ``` !!! Abstract You can now test the commands that didn't work previously in this chapter.","title":"Test with the ping module"},{"location":"books/learning_ansible/01-basic/#key-authentication","text":"Password authentication will be replaced by a much more secure private/public key authentication.","title":"Key authentication"},{"location":"books/learning_ansible/01-basic/#creating-an-ssh-key","text":"The dual-key will be generated with the command ssh-keygen on the management station by the ansible user: [ansible]$ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/ansible/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/ansible/.ssh/id_rsa. Your public key has been saved in /home/ansible/.ssh/id_rsa.pub. The key fingerprint is: SHA256:Oa1d2hYzzdO0e/K10XPad25TA1nrSVRPIuS4fnmKr9g ansible@localhost.localdomain The key's randomart image is: +---[RSA 3072]----+ | .o . +| | o . =.| | . . + +| | o . = =.| | S o = B.o| | = + = =+| | . + = o+B| | o + o *@| | . Eoo .+B| +----[SHA256]-----+ The public key can be copied to the servers: # ssh-copy-id ansible@172.16.1.10 # ssh-copy-id ansible@172.16.1.11 Re-comment the following line from the [defaults] section in the /etc/ansible/ansible.cfg configuration file to prevent password authentication: #ask_pass = True","title":"Creating an SSH key"},{"location":"books/learning_ansible/01-basic/#private-key-authentication-test","text":"For the next test, the shell module, allowing remote command execution, is used: # ansible rocky8 -m shell -a \"uptime\" 172.16.1.10 | SUCCESS | rc=0 >> 12:36:18 up 57 min, 1 user, load average: 0.00, 0.00, 0.00 172.16.1.11 | SUCCESS | rc=0 >> 12:37:07 up 57 min, 1 user, load average: 0.00, 0.00, 0.00 No password is required, private/public key authentication works! !!! Note In production environment, you should now remove the `ansible` passwords previously set to enforce your security (as now an authentication password is not necessary).","title":"Private key authentication test"},{"location":"books/learning_ansible/01-basic/#using-ansible","text":"Ansible can be used from the shell or via playbooks.","title":"Using Ansible"},{"location":"books/learning_ansible/01-basic/#the-modules","text":"The list of modules classified by category can be found here . Ansible offers more than 750! The modules are now grouped into module collections, a list of which can be found here . Collections are a distribution format for Ansible content that can include playbooks, roles, modules, and plugins. A module is invoked with the -m option of the ansible command: ansible <host-pattern> [-m module_name] [-a args] [options] There is a module for almost every need! It is thus advised, instead of using the shell module, to look for a module adapted to the need. Each category of need has its own module. Here is a non exhaustive list: Type Examples System Management user (users management), group (groups management), etc. Software management dnf , yum , apt , pip , npm File management copy , fetch , lineinfile , template , archive Database management mysql , postgresql , redis Cloud management amazon S3 , cloudstack , openstack Cluster management consul , zookeeper Send commands shell , script , expect Downloads get_url Source management git , gitlab","title":"The modules"},{"location":"books/learning_ansible/01-basic/#example-of-software-installation","text":"The dnf module allows for the installation of software on the target clients: # ansible rocky8 --become -m dnf -a name=\"httpd\" 172.16.1.10 | SUCCESS => { \"changed\": true, \"msg\": \"\", \"rc\": 0, \"results\": [ ... \\n\\nComplete!\\n\" ] } 172.16.1.11 | SUCCESS => { \"changed\": true, \"msg\": \"\", \"rc\": 0, \"results\": [ ... \\n\\nComplete!\\n\" ] } The installed software being a service, it is now necessary to start it with the module systemd : # ansible rocky8 --become -m systemd -a \"name=httpd state=started\" 172.16.1.10 | SUCCESS => { \"changed\": true, \"name\": \"httpd\", \"state\": \"started\" } 172.16.1.11 | SUCCESS => { \"changed\": true, \"name\": \"httpd\", \"state\": \"started\" } !!! Tip Try to launch those last 2 commands twice. You will observe that the first time Ansible will take actions to reach the state set by the command. The second time, it will do nothing because it will have detected that the state is already reached!","title":"Example of software installation"},{"location":"books/learning_ansible/01-basic/#exercises","text":"To help discover more about Ansible and to get used to searching the Ansible documentation, here are some exercises you can do before going on: Create the groups Paris, Tokio, NewYork Create the user supervisor Change the user to have a uid of 10000 Change the user so that it belongs to the Paris group Install the tree software Stop the crond service Create en empty file with 644 rights Update your client distribution Restart your client !!! Warning Do not use the shell module. Look in the documentation for the appropriate modules!","title":"Exercises"},{"location":"books/learning_ansible/01-basic/#setup-module-introduction-to-facts","text":"The system facts are variables retrieved by Ansible via its setup module. Take a look at the different facts of your clients to get an idea of the amount of information that can be easily retrieved via a simple command. We'll see later how to use facts in our playbooks and how to create our own facts. # ansible ansible_clients -m setup | less 192.168.1.11 | SUCCESS => { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ \"192.168.1.11\" ], \"ansible_all_ipv6_addresses\": [ \"2001:861:3dc3:fcf0:a00:27ff:fef7:28be\", \"fe80::a00:27ff:fef7:28be\" ], \"ansible_apparmor\": { \"status\": \"disabled\" }, \"ansible_architecture\": \"x86_64\", \"ansible_bios_date\": \"12/01/2006\", \"ansible_bios_vendor\": \"innotek GmbH\", \"ansible_bios_version\": \"VirtualBox\", \"ansible_board_asset_tag\": \"NA\", \"ansible_board_name\": \"VirtualBox\", \"ansible_board_serial\": \"NA\", \"ansible_board_vendor\": \"Oracle Corporation\", ... Now that we have seen how to configure a remote server with Ansible on the command line, we will be able to introduce the notion of playbook. Playbooks are another way to use Ansible, which is not much more complex, but which will make it easier to reuse your code.","title":"setup module: introduction to facts"},{"location":"books/learning_ansible/01-basic/#playbooks","text":"Ansible's playbooks describe a policy to be applied to remote systems, to force their configuration. Playbooks are written in an easily understandable text format that groups together a set of tasks: the yaml format. !!! Note Learn more about [yaml here](https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html) ansible-playbook <file.yml> ... [options] The options are identical to the ansible command. The command returns the following error codes: Code Error 0 OK or no matching host 1 Error 2 One or more hosts are failing 3 One or more hosts are unreachable 4 Analyze error 5 Bad or incomplete options 99 Run interrupted by user 250 Unexpected error !!! Note Please note that `ansible` will return Ok when there is no host matching your target, which might mislead you!","title":"Playbooks"},{"location":"books/learning_ansible/01-basic/#example-of-apache-and-mysql-playbook","text":"The following playbook allows us to install Apache and MariaDB on our target servers. Create a test.yml file with the following content: --- - hosts: rocky8 <1> become: true <2> become_user: root tasks: - name: ensure apache is at the latest version dnf: name=httpd,php,php-mysqli state=latest - name: ensure httpd is started systemd: name=httpd state=started - name: ensure mariadb is at the latest version dnf: name=mariadb-server state=latest - name: ensure mariadb is started systemd: name=mariadb state=started ... <1> The targeted group or the targeted server must exist in the inventory <2> Once connected, the user becomes root (via sudo by default) The execution of the playbook is done with the command ansible-playbook : $ ansible-playbook test.yml PLAY [rocky8] **************************************************************** TASK [setup] ****************************************************************** ok: [172.16.1.10] ok: [172.16.1.11] TASK [ensure apache is at the latest version] ********************************* ok: [172.16.1.10] ok: [172.16.1.11] TASK [ensure httpd is started] ************************************************ changed: [172.16.1.10] changed: [172.16.1.11] TASK [ensure mariadb is at the latest version] ********************************** changed: [172.16.1.10] changed: [172.16.1.11] TASK [ensure mariadb is started] *********************************************** changed: [172.16.1.10] changed: [172.16.1.11] PLAY RECAP ********************************************************************* 172.16.1.10 : ok=5 changed=3 unreachable=0 failed=0 172.16.1.11 : ok=5 changed=3 unreachable=0 failed=0 For more readability, it is recommended to write your playbooks in full yaml format. In the previous example, the arguments are given on the same line as the module, the value of the argument following its name separated by an = . Look at the same playbook in full yaml: --- - hosts: rocky8 become: true become_user: root tasks: - name: ensure apache is at the latest version dnf: name: httpd,php,php-mysqli state: latest - name: ensure httpd is started systemd: name: httpd state: started - name: ensure mariadb is at the latest version dnf: name: mariadb-server state: latest - name: ensure mariadb is started systemd: name: mariadb state: started ... !!! Tip `dnf` is one of the modules that allow you to give it a list as argument. Note about collections: Ansible now provides modules in the form of collections. Some modules are provided by default within the ansible.builtin collection, others must be installed manually via the: ansible-galaxy collection install [collectionname] where [collectionname] is the name of the collection. (the square brackets here are used to highlight the need to replace this with an actual collection name, and are NOT part of the command.) The previous example should be written like this: --- - hosts: rocky8 become: true become_user: root tasks: - name: ensure apache is at the latest version ansible.builtin.dnf: name: httpd,php,php-mysqli state: latest - name: ensure httpd is started ansible.builtin.systemd: name: httpd state: started - name: ensure mariadb is at the latest version ansible.builtin.dnf: name: mariadb-server state: latest - name: ensure mariadb is started ansible.builtin.systemd: name: mariadb state: started ... A playbook is not limited to one target: --- - hosts: webservers become: true become_user: root tasks: - name: ensure apache is at the latest version ansible.builtin.dnf: name: httpd,php,php-mysqli state: latest - name: ensure httpd is started ansible.builtin.systemd: name: httpd state: started - hosts: databases become: true become_user: root - name: ensure mariadb is at the latest version ansible.builtin.dnf: name: mariadb-server state: latest - name: ensure mariadb is started ansible.builtin.systemd: name: mariadb state: started ... You can check the syntax of your playbook: $ ansible-playbook --syntax-check play.yml You can also use a \"linter\" for yaml: $ dnf install -y yamllint then check the yaml syntax of your playbooks: $ yamllint test.yml test.yml 8:1 error syntax error: could not find expected ':' (syntax)","title":"Example of Apache and MySQL playbook"},{"location":"books/learning_ansible/01-basic/#exercices-results","text":"Create the groups Paris, Tokio, NewYork Create the user supervisor Change the user to have a uid of 10000 Change the user so that it belongs to the Paris group Install the tree software Stop the crond service Create en empty file with 0644 rights Update your client distribution Restart your client ansible ansible_clients --become -m group -a \"name=Paris\" ansible ansible_clients --become -m group -a \"name=Tokio\" ansible ansible_clients --become -m group -a \"name=NewYork\" ansible ansible_clients --become -m user -a \"name=Supervisor\" ansible ansible_clients --become -m user -a \"name=Supervisor uid=10000\" ansible ansible_clients --become -m user -a \"name=Supervisor uid=10000 groups=Paris\" ansible ansible_clients --become -m dnf -a \"name=tree\" ansible ansible_clients --become -m systemd -a \"name=crond state=stopped\" ansible ansible_clients --become -m copy -a \"content='' dest=/tmp/test force=no mode=0644\" ansible ansible_clients --become -m dnf -a \"name=* state=latest\" ansible ansible_clients --become -m reboot","title":"Exercices results"},{"location":"books/learning_ansible/02-advanced/","text":"Ansible Intermediate In this chapter you will continue to learn how to work with Ansible. Objectives : In this chapter you will learn how to: :heavy_check_mark: work with variables; :heavy_check_mark: use loops; :heavy_check_mark: manage state changes and react to them; :heavy_check_mark: manage asynchronous tasks. :checkered_flag: ansible , module , playbook Knowledge : :star: :star: :star: Complexity : :star: :star: Reading time : 30 minutes In the previous chapter, you learned how to install Ansible, use it on the command line, or how to write playbooks to promote the re-usability of your code. In this chapter, we can start to discover some more advanced notions of how to use Ansible, and discover some interesting tasks that you will use very regularly. The variables !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html). Under Ansible, there are different types of primitive variables: strings, integers, booleans. These variables can be organized as: dictionaries, lists. A variable can be defined in different places, like in a playbook, in a role or from the command line for example. For example, from a playbook: --- - hosts: apache1 vars: port_http: 80 service: debian: apache2 rhel: httpd or from the command line: $ ansible-playbook deploy-http.yml --extra-vars \"service=httpd\" Once defined, a variable can be used by calling it between double braces: {{ port_http }} for a simple value, {{ service['rhel'] }} or {{ service.rhel }} for a dictionary. For example: - name: make sure apache is started ansible.builtin.systemd: name: \"{{ service['rhel'] }}\" state: started Of course, it is also possible to access the global variables (the facts ) of Ansible (OS type, IP addresses, VM name, etc.). Outsourcing variables Variables can be included in a file external to the playbook, in which case this file must be defined in the playbook with the vars_files directive: --- - hosts: apache1 vars_files: - myvariables.yml The myvariables.yml file: --- port_http: 80 ansible.builtin.systemd:: debian: apache2 rhel: httpd It can also be added dynamically with the use of the module include_vars : - name: Include secrets. ansible.builtin.include_vars: file: vault.yml Display a variable To display a variable, you have to activate the debug module as follows: - ansible.builtin.debug: var: \"{{ service['debian'] }}\" You can also use the variable inside a text: - ansible.builtin.debug: msg: \"Print a variable in a message : {{ service['debian'] }}\" Save the return of a task To save the return of a task and to be able to access it later, you have to use the keyword register inside the task itself. Use of a stored variable: - name: /home content shell: ls /home register: homes - name: Print the first directory name ansible.builtin.debug: var: homes.stdout_lines[0] - name: Print the first directory name ansible.builtin.debug: var: homes.stdout_lines[1] !!! Note The variable `homes.stdout_lines` is a list of variables of type string, a way to organize variables that we had not yet encountered. The strings that make up the stored variable can be accessed via the stdout value (which allows you to do things like homes.stdout.find(\"core\") != -1 ), to exploit them using a loop (see loop ), or simply by their indices as seen in the previous example. Exercices Write a playbook play-vars.yml that prints the distribution name of the target with its major version, using global variables. Write a playbook using the following dictionary to display the services that will be installed: service: web: name: apache rpm: httpd db: name: mariadb rpm: mariadb-server The default type should be \"web\". Override the type variable using the command line Externalize variables in a vars.yml file Loop management With the help of loop, you can iterate a task over a list, a hash, or dictionary for example. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html). Simple example of use, creation of 4 users: - name: add users user: name: \"{{ item }}\" state: present groups: \"users\" loop: - antoine - patrick - steven - xavier At each iteration of the loop, the value of the list used is stored in the item variable, accessible in the loop code. Of course, a list can be defined in an external file: users: - antoine - patrick - steven - xavier and be used inside the task like this (after having include the vars file): - name: add users user: name: \"{{ item }}\" state: present groups: \"users\" loop: \"{{ users }}\" We can use the example seen during the study of stored variables to improve it. Use of a stored variable: - name: /home content shell: ls /home register: homes - name: Print the directories name ansible.builtin.debug: msg: \"Directory => {{ item }}\" loop: \"{{ homes.stdout_lines }}\" A dictionary can also be used in a loop. In this case, you will have to transform the dictionary into an item with what is called a jinja filter (jinja is the templating engine used by Ansible): | dict2items . In the loop, it becomes possible to use item.key which corresponds to the dictionary key, and item.value which corresponds to the values of the key. Let's see this through a concrete example, showing the management of the system users: --- - hosts: rocky8 become: true become_user: root vars: users: antoine: group: users state: present steven: group: users state: absent tasks: - name: Manage users user: name: \"{{ item.key }}\" group: \"{{ item.value.group }}\" state: \"{{ item.value.state }}\" loop: \"{{ users | dict2items }}\" !!! Note Many things can be done with the loops. You will discover the possibilities offered by loops when your use of Ansible pushes you to use them in a more complex way. Exercices Display the content of the service variable from the previous exercise using a loop. !!! Note You will have to transform your `service` variable, which is a dictionary, to a list with the help of the jinja filter `list` as this: ``` {{ service.values() | list }} ``` Conditionals !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html). The when statement is very useful in many cases: not performing certain actions on certain types of servers, if a file or a user does not exist, etc. !!! Note Behind the `when` statement the variables do not need double braces (they are in fact Jinja2 expressions...). - name: \"Reboot only Debian servers\" reboot: when: ansible_os_family == \"Debian\" Conditions can be grouped with parentheses: - name: \"Reboot only CentOS version 6 and Debian version 7\" reboot: when: (ansible_distribution == \"CentOS\" and ansible_distribution_major_version == \"6\") or (ansible_distribution == \"Debian\" and ansible_distribution_major_version == \"7\") The conditions corresponding to a logical AND can be provided as a list: - name: \"Reboot only CentOS version 6\" reboot: when: - ansible_distribution == \"CentOS\" - ansible_distribution_major_version == \"6\" You can test the value of a boolean and verify that it is true: - name: check if directory exists stat: path: /home/ansible register: directory - ansible.builtin.debug: var: directory - ansible.builtin.debug: msg: The directory exists when: - directory.stat.exists - directory.stat.isdir You can also test that it is not true: when: - file.stat.exists - not file.stat.isdir You will probably have to test that a variable exists to avoid execution errors: when: myboolean is defined and myboolean Exercices Print the value of service.web only when type equals to web . Managing changes: the handlers !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_handlers.html). Handlers allow to launch operations, like restarting a service, when changes occur. A module, being idempotent, a playbook can detect that there has been a significant change on a remote system, and thus trigger an operation in reaction to this change. A notification is sent at the end of a playbook task block, and the reaction operation will be triggered only once even if several tasks send the same notification. For example, several tasks may indicate that the httpd service needs to be restarted due to a change in its configuration files. But the service will only be restarted once to avoid multiple unnecessary starts. - name: template configuration file template: src: template-site.j2 dest: /etc/httpd/sites-availables/test-site.conf notify: - restart memcached - restart httpd A handler is a kind of task referenced by a unique global name: It is activated by one or more notifiers. It does not start immediately, but waits until all tasks are complete to run. Example of handlers: handlers: - name: restart memcached systemd: name: memcached state: restarted - name: restart httpd systemd: name: httpd state: restarted Since version 2.2 of Ansible, handlers can listen directly as well: handlers: - name: restart memcached systemd: name: memcached state: restarted listen: \"web services restart\" - name: restart apache systemd: name: apache state: restarted listen: \"web services restart\" tasks: - name: restart everything command: echo \"this task will restart the web services\" notify: \"web services restart\" Asynchronous tasks !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html). By default, SSH connections to hosts remain open during the execution of various playbook tasks on all nodes. This can cause some problems, especially: if the execution time of the task is longer than the SSH connection timeout if the connection is interrupted during the action (server reboot for example) In this case, you will have to switch to asynchronous mode and specify a maximum execution time as well as the frequency (by default 10s) with which you will check the host status. By specifying a poll value of 0, Ansible will execute the task and continue without worrying about the result. Here's an example using asynchronous tasks, which allows you to restart a server and wait for port 22 to be reachable again: # Wait 2s and launch the reboot - name: Reboot system shell: sleep 2 && shutdown -r now \"Ansible reboot triggered\" async: 1 poll: 0 ignore_errors: true become: true changed_when: False # Wait the server is available - name: Waiting for server to restart (10 mins max) wait_for: host: \"{{ inventory_hostname }}\" port: 22 delay: 30 state: started timeout: 600 delegate_to: localhost You can also decide to launch a long-running task and forget it (fire and forget) because the execution does not matter in the playbook. Exercise results Write a playbook play-vars.yml that print the distribution name of the target with its major version, using global variables. --- - hosts: ansible_clients tasks: - name: Print globales variables debug: msg: \"The distribution is {{ ansible_distribution }} version {{ ansible_distribution_major_version }}\" $ ansible-playbook play-vars.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print globales variables] ************************************************************************ ok: [192.168.1.11] => { \"msg\": \"The distribution is Rocky version 8\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Write a playbook using the following dictionary to display the services that will be installed: service: web: name: apache rpm: httpd db: name: mariadb rpm: mariadb-server The default type should be \"web\". --- - hosts: ansible_clients vars: type: web service: web: name: apache rpm: httpd db: name: mariadb rpm: mariadb-server tasks: - name: Print a specific entry of a dictionary debug: msg: \"The {{ service[type]['name'] }} will be installed with the packages {{ service[type].rpm }}\" $ ansible-playbook display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a specific entry of a dictionnaire] ******************************************************** ok: [192.168.1.11] => { \"msg\": \"The apache will be installed with the packages httpd\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Override the type variable using the command line: ansible-playbook --extra-vars \"type=db\" display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a specific entry of a dictionary] ******************************************************** ok: [192.168.1.11] => { \"msg\": \"The mariadb will be installed with the packages mariadb-server\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Externalize variables in a vars.yml file type: web service: web: name: apache rpm: httpd db: name: mariadb rpm: mariadb-server --- - hosts: ansible_clients vars_files: - vars.yml tasks: - name: Print a specific entry of a dictionary debug: msg: \"The {{ service[type]['name'] }} will be installed with the packages {{ service[type].rpm }}\" Display the content of the service variable from the previous exercise using a loop. !!! Note You will have to transform your `service` variable, which is a dictionary, to an item or a list with the help of the jinja filters `dict2items` or `list` as this: ``` {{ service | dict2items }} ``` ``` {{ service.values() | list }} ``` With dict2items : --- - hosts: ansible_clients vars_files: - vars.yml tasks: - name: Print a dictionary variable with a loop debug: msg: \"{{item.key }} | The {{ item.value.name }} will be installed with the packages {{ item.value.rpm }}\" loop: \"{{ service | dict2items }}\" $ ansible-playbook display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a dictionary variable with a loop] ******************************************************** ok: [192.168.1.11] => (item={'key': 'web', 'value': {'name': 'apache', 'rpm': 'httpd'}}) => { \"msg\": \"web | The apache will be installed with the packages httpd\" } ok: [192.168.1.11] => (item={'key': 'db', 'value': {'name': 'mariadb', 'rpm': 'mariadb-server'}}) => { \"msg\": \"db | The mariadb will be installed with the packages mariadb-server\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 With list : --- - hosts: ansible_clients vars_files: - vars.yml tasks: - name: Print a dictionary variable with a loop debug: msg: \"The {{ item.name }} will be installed with the packages {{ item.rpm }}\" loop: \"{{ service.values() | list}}\" ~ $ ansible-playbook display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a dictionary variable with a loop] ******************************************************** ok: [192.168.1.11] => (item={'name': 'apache', 'rpm': 'httpd'}) => { \"msg\": \"The apache will be installed with the packages httpd\" } ok: [192.168.1.11] => (item={'name': 'mariadb', 'rpm': 'mariadb-server'}) => { \"msg\": \"The mariadb will be installed with the packages mariadb-server\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Print the value of service.web only when type equals to web . --- - hosts: ansible_clients vars_files: - vars.yml tasks: - name: Print a dictionary variable debug: msg: \"The {{ service.web.name }} will be installed with the packages {{ service.web.rpm }}\" when: type == \"web\" - name: Print a dictionary variable debug: msg: \"The {{ service.db.name }} will be installed with the packages {{ service.db.rpm }}\" when: type == \"db\" $ ansible-playbook display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a dictionary variable] ******************************************************************** ok: [192.168.1.11] => { \"msg\": \"The apache will be installed with the packages httpd\" } TASK [Print a dictionary variable] ******************************************************************** skipping: [192.168.1.11] PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 $ ansible-playbook --extra-vars \"type=db\" display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a dictionary variable] ******************************************************************** skipping: [192.168.1.11] TASK [Print a dictionary variable] ******************************************************************** ok: [192.168.1.11] => { \"msg\": \"The mariadb will be installed with the packages mariadb-server\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0","title":"Ansible Intermediate"},{"location":"books/learning_ansible/02-advanced/#ansible-intermediate","text":"In this chapter you will continue to learn how to work with Ansible. Objectives : In this chapter you will learn how to: :heavy_check_mark: work with variables; :heavy_check_mark: use loops; :heavy_check_mark: manage state changes and react to them; :heavy_check_mark: manage asynchronous tasks. :checkered_flag: ansible , module , playbook Knowledge : :star: :star: :star: Complexity : :star: :star: Reading time : 30 minutes In the previous chapter, you learned how to install Ansible, use it on the command line, or how to write playbooks to promote the re-usability of your code. In this chapter, we can start to discover some more advanced notions of how to use Ansible, and discover some interesting tasks that you will use very regularly.","title":"Ansible Intermediate"},{"location":"books/learning_ansible/02-advanced/#the-variables","text":"!!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html). Under Ansible, there are different types of primitive variables: strings, integers, booleans. These variables can be organized as: dictionaries, lists. A variable can be defined in different places, like in a playbook, in a role or from the command line for example. For example, from a playbook: --- - hosts: apache1 vars: port_http: 80 service: debian: apache2 rhel: httpd or from the command line: $ ansible-playbook deploy-http.yml --extra-vars \"service=httpd\" Once defined, a variable can be used by calling it between double braces: {{ port_http }} for a simple value, {{ service['rhel'] }} or {{ service.rhel }} for a dictionary. For example: - name: make sure apache is started ansible.builtin.systemd: name: \"{{ service['rhel'] }}\" state: started Of course, it is also possible to access the global variables (the facts ) of Ansible (OS type, IP addresses, VM name, etc.).","title":"The variables"},{"location":"books/learning_ansible/02-advanced/#outsourcing-variables","text":"Variables can be included in a file external to the playbook, in which case this file must be defined in the playbook with the vars_files directive: --- - hosts: apache1 vars_files: - myvariables.yml The myvariables.yml file: --- port_http: 80 ansible.builtin.systemd:: debian: apache2 rhel: httpd It can also be added dynamically with the use of the module include_vars : - name: Include secrets. ansible.builtin.include_vars: file: vault.yml","title":"Outsourcing variables"},{"location":"books/learning_ansible/02-advanced/#display-a-variable","text":"To display a variable, you have to activate the debug module as follows: - ansible.builtin.debug: var: \"{{ service['debian'] }}\" You can also use the variable inside a text: - ansible.builtin.debug: msg: \"Print a variable in a message : {{ service['debian'] }}\"","title":"Display a variable"},{"location":"books/learning_ansible/02-advanced/#save-the-return-of-a-task","text":"To save the return of a task and to be able to access it later, you have to use the keyword register inside the task itself. Use of a stored variable: - name: /home content shell: ls /home register: homes - name: Print the first directory name ansible.builtin.debug: var: homes.stdout_lines[0] - name: Print the first directory name ansible.builtin.debug: var: homes.stdout_lines[1] !!! Note The variable `homes.stdout_lines` is a list of variables of type string, a way to organize variables that we had not yet encountered. The strings that make up the stored variable can be accessed via the stdout value (which allows you to do things like homes.stdout.find(\"core\") != -1 ), to exploit them using a loop (see loop ), or simply by their indices as seen in the previous example.","title":"Save the return of a task"},{"location":"books/learning_ansible/02-advanced/#exercices","text":"Write a playbook play-vars.yml that prints the distribution name of the target with its major version, using global variables. Write a playbook using the following dictionary to display the services that will be installed: service: web: name: apache rpm: httpd db: name: mariadb rpm: mariadb-server The default type should be \"web\". Override the type variable using the command line Externalize variables in a vars.yml file","title":"Exercices"},{"location":"books/learning_ansible/02-advanced/#loop-management","text":"With the help of loop, you can iterate a task over a list, a hash, or dictionary for example. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html). Simple example of use, creation of 4 users: - name: add users user: name: \"{{ item }}\" state: present groups: \"users\" loop: - antoine - patrick - steven - xavier At each iteration of the loop, the value of the list used is stored in the item variable, accessible in the loop code. Of course, a list can be defined in an external file: users: - antoine - patrick - steven - xavier and be used inside the task like this (after having include the vars file): - name: add users user: name: \"{{ item }}\" state: present groups: \"users\" loop: \"{{ users }}\" We can use the example seen during the study of stored variables to improve it. Use of a stored variable: - name: /home content shell: ls /home register: homes - name: Print the directories name ansible.builtin.debug: msg: \"Directory => {{ item }}\" loop: \"{{ homes.stdout_lines }}\" A dictionary can also be used in a loop. In this case, you will have to transform the dictionary into an item with what is called a jinja filter (jinja is the templating engine used by Ansible): | dict2items . In the loop, it becomes possible to use item.key which corresponds to the dictionary key, and item.value which corresponds to the values of the key. Let's see this through a concrete example, showing the management of the system users: --- - hosts: rocky8 become: true become_user: root vars: users: antoine: group: users state: present steven: group: users state: absent tasks: - name: Manage users user: name: \"{{ item.key }}\" group: \"{{ item.value.group }}\" state: \"{{ item.value.state }}\" loop: \"{{ users | dict2items }}\" !!! Note Many things can be done with the loops. You will discover the possibilities offered by loops when your use of Ansible pushes you to use them in a more complex way.","title":"Loop management"},{"location":"books/learning_ansible/02-advanced/#exercices_1","text":"Display the content of the service variable from the previous exercise using a loop. !!! Note You will have to transform your `service` variable, which is a dictionary, to a list with the help of the jinja filter `list` as this: ``` {{ service.values() | list }} ```","title":"Exercices"},{"location":"books/learning_ansible/02-advanced/#conditionals","text":"!!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html). The when statement is very useful in many cases: not performing certain actions on certain types of servers, if a file or a user does not exist, etc. !!! Note Behind the `when` statement the variables do not need double braces (they are in fact Jinja2 expressions...). - name: \"Reboot only Debian servers\" reboot: when: ansible_os_family == \"Debian\" Conditions can be grouped with parentheses: - name: \"Reboot only CentOS version 6 and Debian version 7\" reboot: when: (ansible_distribution == \"CentOS\" and ansible_distribution_major_version == \"6\") or (ansible_distribution == \"Debian\" and ansible_distribution_major_version == \"7\") The conditions corresponding to a logical AND can be provided as a list: - name: \"Reboot only CentOS version 6\" reboot: when: - ansible_distribution == \"CentOS\" - ansible_distribution_major_version == \"6\" You can test the value of a boolean and verify that it is true: - name: check if directory exists stat: path: /home/ansible register: directory - ansible.builtin.debug: var: directory - ansible.builtin.debug: msg: The directory exists when: - directory.stat.exists - directory.stat.isdir You can also test that it is not true: when: - file.stat.exists - not file.stat.isdir You will probably have to test that a variable exists to avoid execution errors: when: myboolean is defined and myboolean","title":"Conditionals"},{"location":"books/learning_ansible/02-advanced/#exercices_2","text":"Print the value of service.web only when type equals to web .","title":"Exercices"},{"location":"books/learning_ansible/02-advanced/#managing-changes-the-handlers","text":"!!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_handlers.html). Handlers allow to launch operations, like restarting a service, when changes occur. A module, being idempotent, a playbook can detect that there has been a significant change on a remote system, and thus trigger an operation in reaction to this change. A notification is sent at the end of a playbook task block, and the reaction operation will be triggered only once even if several tasks send the same notification. For example, several tasks may indicate that the httpd service needs to be restarted due to a change in its configuration files. But the service will only be restarted once to avoid multiple unnecessary starts. - name: template configuration file template: src: template-site.j2 dest: /etc/httpd/sites-availables/test-site.conf notify: - restart memcached - restart httpd A handler is a kind of task referenced by a unique global name: It is activated by one or more notifiers. It does not start immediately, but waits until all tasks are complete to run. Example of handlers: handlers: - name: restart memcached systemd: name: memcached state: restarted - name: restart httpd systemd: name: httpd state: restarted Since version 2.2 of Ansible, handlers can listen directly as well: handlers: - name: restart memcached systemd: name: memcached state: restarted listen: \"web services restart\" - name: restart apache systemd: name: apache state: restarted listen: \"web services restart\" tasks: - name: restart everything command: echo \"this task will restart the web services\" notify: \"web services restart\"","title":"Managing changes: the handlers"},{"location":"books/learning_ansible/02-advanced/#asynchronous-tasks","text":"!!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html). By default, SSH connections to hosts remain open during the execution of various playbook tasks on all nodes. This can cause some problems, especially: if the execution time of the task is longer than the SSH connection timeout if the connection is interrupted during the action (server reboot for example) In this case, you will have to switch to asynchronous mode and specify a maximum execution time as well as the frequency (by default 10s) with which you will check the host status. By specifying a poll value of 0, Ansible will execute the task and continue without worrying about the result. Here's an example using asynchronous tasks, which allows you to restart a server and wait for port 22 to be reachable again: # Wait 2s and launch the reboot - name: Reboot system shell: sleep 2 && shutdown -r now \"Ansible reboot triggered\" async: 1 poll: 0 ignore_errors: true become: true changed_when: False # Wait the server is available - name: Waiting for server to restart (10 mins max) wait_for: host: \"{{ inventory_hostname }}\" port: 22 delay: 30 state: started timeout: 600 delegate_to: localhost You can also decide to launch a long-running task and forget it (fire and forget) because the execution does not matter in the playbook.","title":"Asynchronous tasks"},{"location":"books/learning_ansible/02-advanced/#exercise-results","text":"Write a playbook play-vars.yml that print the distribution name of the target with its major version, using global variables. --- - hosts: ansible_clients tasks: - name: Print globales variables debug: msg: \"The distribution is {{ ansible_distribution }} version {{ ansible_distribution_major_version }}\" $ ansible-playbook play-vars.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print globales variables] ************************************************************************ ok: [192.168.1.11] => { \"msg\": \"The distribution is Rocky version 8\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Write a playbook using the following dictionary to display the services that will be installed: service: web: name: apache rpm: httpd db: name: mariadb rpm: mariadb-server The default type should be \"web\". --- - hosts: ansible_clients vars: type: web service: web: name: apache rpm: httpd db: name: mariadb rpm: mariadb-server tasks: - name: Print a specific entry of a dictionary debug: msg: \"The {{ service[type]['name'] }} will be installed with the packages {{ service[type].rpm }}\" $ ansible-playbook display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a specific entry of a dictionnaire] ******************************************************** ok: [192.168.1.11] => { \"msg\": \"The apache will be installed with the packages httpd\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Override the type variable using the command line: ansible-playbook --extra-vars \"type=db\" display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a specific entry of a dictionary] ******************************************************** ok: [192.168.1.11] => { \"msg\": \"The mariadb will be installed with the packages mariadb-server\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Externalize variables in a vars.yml file type: web service: web: name: apache rpm: httpd db: name: mariadb rpm: mariadb-server --- - hosts: ansible_clients vars_files: - vars.yml tasks: - name: Print a specific entry of a dictionary debug: msg: \"The {{ service[type]['name'] }} will be installed with the packages {{ service[type].rpm }}\" Display the content of the service variable from the previous exercise using a loop. !!! Note You will have to transform your `service` variable, which is a dictionary, to an item or a list with the help of the jinja filters `dict2items` or `list` as this: ``` {{ service | dict2items }} ``` ``` {{ service.values() | list }} ``` With dict2items : --- - hosts: ansible_clients vars_files: - vars.yml tasks: - name: Print a dictionary variable with a loop debug: msg: \"{{item.key }} | The {{ item.value.name }} will be installed with the packages {{ item.value.rpm }}\" loop: \"{{ service | dict2items }}\" $ ansible-playbook display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a dictionary variable with a loop] ******************************************************** ok: [192.168.1.11] => (item={'key': 'web', 'value': {'name': 'apache', 'rpm': 'httpd'}}) => { \"msg\": \"web | The apache will be installed with the packages httpd\" } ok: [192.168.1.11] => (item={'key': 'db', 'value': {'name': 'mariadb', 'rpm': 'mariadb-server'}}) => { \"msg\": \"db | The mariadb will be installed with the packages mariadb-server\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 With list : --- - hosts: ansible_clients vars_files: - vars.yml tasks: - name: Print a dictionary variable with a loop debug: msg: \"The {{ item.name }} will be installed with the packages {{ item.rpm }}\" loop: \"{{ service.values() | list}}\" ~ $ ansible-playbook display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a dictionary variable with a loop] ******************************************************** ok: [192.168.1.11] => (item={'name': 'apache', 'rpm': 'httpd'}) => { \"msg\": \"The apache will be installed with the packages httpd\" } ok: [192.168.1.11] => (item={'name': 'mariadb', 'rpm': 'mariadb-server'}) => { \"msg\": \"The mariadb will be installed with the packages mariadb-server\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Print the value of service.web only when type equals to web . --- - hosts: ansible_clients vars_files: - vars.yml tasks: - name: Print a dictionary variable debug: msg: \"The {{ service.web.name }} will be installed with the packages {{ service.web.rpm }}\" when: type == \"web\" - name: Print a dictionary variable debug: msg: \"The {{ service.db.name }} will be installed with the packages {{ service.db.rpm }}\" when: type == \"db\" $ ansible-playbook display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a dictionary variable] ******************************************************************** ok: [192.168.1.11] => { \"msg\": \"The apache will be installed with the packages httpd\" } TASK [Print a dictionary variable] ******************************************************************** skipping: [192.168.1.11] PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 $ ansible-playbook --extra-vars \"type=db\" display-dict.yml PLAY [ansible_clients] ********************************************************************************* TASK [Gathering Facts] ********************************************************************************* ok: [192.168.1.11] TASK [Print a dictionary variable] ******************************************************************** skipping: [192.168.1.11] TASK [Print a dictionary variable] ******************************************************************** ok: [192.168.1.11] => { \"msg\": \"The mariadb will be installed with the packages mariadb-server\" } PLAY RECAP ********************************************************************************************* 192.168.1.11 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0","title":"Exercise results"},{"location":"books/learning_ansible/03-working-with-files/","text":"Ansible - Management of Files In this chapter you will learn how to manage files with Ansible. Objectives : In this chapter you will learn how to: :heavy_check_mark: modify the content of file; :heavy_check_mark: upload files to the targeted servers; :heavy_check_mark: retrieve files from the targeted servers. :checkered_flag: ansible , module , files Knowledge : :star: :star: Complexity : :star: Reading time : 20 minutes Depending on your needs, you will have to use different Ansible modules to modify the system configuration files. ini_file module When you want to modify an INI file (section between [] then key=value pairs), the easiest way is to use the ini_file module. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/community/general/ini_file_module.html). The module requires: The value of the section The name of the option The new value Example of use: - name: change value on inifile community.general.ini_file: dest: /path/to/file.ini section: SECTIONNAME option: OPTIONNAME value: NEWVALUE lineinfile module To ensure that a line is present in a file, or when a single line in a file needs to be added or modified, use the linefile module. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/lineinfile_module.html). In this case, the line to be modified in a file will be found using a regexp. For example, to ensure that the line starting with SELINUX= in the /etc/selinux/config file contains the value enforcing : - ansible.builtin.lineinfile: path: /etc/selinux/config regexp: '^SELINUX=' line: 'SELINUX=enforcing' copy module When a file has to be copied from the Ansible server to one or more hosts, it is better to use the copy module. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/copy_module.html). Here we are copying myflile.conf from one location to another: - ansible.builtin.copy: src: /data/ansible/sources/myfile.conf dest: /etc/myfile.conf owner: root group: root mode: 0644 fetch module When a file has to be copied from a remote server to the local server, it is best to use the fetch module. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/fetch_module.html). This module does the opposite of the copy module: - ansible.builtin.fetch: src: /etc/myfile.conf dest: /data/ansible/backup/myfile-{{ inventory_hostname }}.conf flat: yes template module Ansible and its template module use the Jinja2 template system (http://jinja.pocoo.org/docs/) to generate files on target hosts. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html). For example: - ansible.builtin.template: src: /data/ansible/templates/monfichier.j2 dest: /etc/myfile.conf owner: root group: root mode: 0644 It is possible to add a validation step if the targeted service allows it (for example apache with the command apachectl -t ): - template: src: /data/ansible/templates/vhost.j2 dest: /etc/httpd/sites-available/vhost.conf owner: root group: root mode: 0644 validate: '/usr/sbin/apachectl -t' get_url module To upload files from a web site or ftp to one or more hosts, use the get_url module: - get_url: url: http://site.com/archive.zip dest: /tmp/archive.zip mode: 0640 checksum: sha256:f772bd36185515581aa9a2e4b38fb97940ff28764900ba708e68286121770e9a By providing a checksum of the file, the file will not be re-downloaded if it is already present at the destination location and its checksum matches the value provided.","title":"File Management"},{"location":"books/learning_ansible/03-working-with-files/#ansible-management-of-files","text":"In this chapter you will learn how to manage files with Ansible. Objectives : In this chapter you will learn how to: :heavy_check_mark: modify the content of file; :heavy_check_mark: upload files to the targeted servers; :heavy_check_mark: retrieve files from the targeted servers. :checkered_flag: ansible , module , files Knowledge : :star: :star: Complexity : :star: Reading time : 20 minutes Depending on your needs, you will have to use different Ansible modules to modify the system configuration files.","title":"Ansible - Management of Files"},{"location":"books/learning_ansible/03-working-with-files/#ini_file-module","text":"When you want to modify an INI file (section between [] then key=value pairs), the easiest way is to use the ini_file module. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/community/general/ini_file_module.html). The module requires: The value of the section The name of the option The new value Example of use: - name: change value on inifile community.general.ini_file: dest: /path/to/file.ini section: SECTIONNAME option: OPTIONNAME value: NEWVALUE","title":"ini_file module"},{"location":"books/learning_ansible/03-working-with-files/#lineinfile-module","text":"To ensure that a line is present in a file, or when a single line in a file needs to be added or modified, use the linefile module. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/lineinfile_module.html). In this case, the line to be modified in a file will be found using a regexp. For example, to ensure that the line starting with SELINUX= in the /etc/selinux/config file contains the value enforcing : - ansible.builtin.lineinfile: path: /etc/selinux/config regexp: '^SELINUX=' line: 'SELINUX=enforcing'","title":"lineinfile module"},{"location":"books/learning_ansible/03-working-with-files/#copy-module","text":"When a file has to be copied from the Ansible server to one or more hosts, it is better to use the copy module. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/copy_module.html). Here we are copying myflile.conf from one location to another: - ansible.builtin.copy: src: /data/ansible/sources/myfile.conf dest: /etc/myfile.conf owner: root group: root mode: 0644","title":"copy module"},{"location":"books/learning_ansible/03-working-with-files/#fetch-module","text":"When a file has to be copied from a remote server to the local server, it is best to use the fetch module. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/fetch_module.html). This module does the opposite of the copy module: - ansible.builtin.fetch: src: /etc/myfile.conf dest: /data/ansible/backup/myfile-{{ inventory_hostname }}.conf flat: yes","title":"fetch module"},{"location":"books/learning_ansible/03-working-with-files/#template-module","text":"Ansible and its template module use the Jinja2 template system (http://jinja.pocoo.org/docs/) to generate files on target hosts. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html). For example: - ansible.builtin.template: src: /data/ansible/templates/monfichier.j2 dest: /etc/myfile.conf owner: root group: root mode: 0644 It is possible to add a validation step if the targeted service allows it (for example apache with the command apachectl -t ): - template: src: /data/ansible/templates/vhost.j2 dest: /etc/httpd/sites-available/vhost.conf owner: root group: root mode: 0644 validate: '/usr/sbin/apachectl -t'","title":"template module"},{"location":"books/learning_ansible/03-working-with-files/#get_url-module","text":"To upload files from a web site or ftp to one or more hosts, use the get_url module: - get_url: url: http://site.com/archive.zip dest: /tmp/archive.zip mode: 0640 checksum: sha256:f772bd36185515581aa9a2e4b38fb97940ff28764900ba708e68286121770e9a By providing a checksum of the file, the file will not be re-downloaded if it is already present at the destination location and its checksum matches the value provided.","title":"get_url module"},{"location":"books/learning_ansible/04-ansible-galaxy/","text":"Ansible Galaxy: Collections and Roles In this chapter you will learn how to use, install, and manage Ansible roles and collections. Objectives : In this chapter you will learn how to: :heavy_check_mark: install and manage collections; :heavy_check_mark: install and manage roles;. :checkered_flag: ansible , ansible-galaxy , roles , collections Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 40 minutes Ansible Galaxy provides Ansible Roles and Collections from the Ansible Community. The elements provided can be referenced in the playbooks and used out of the box ansible-galaxy command The ansible-galaxy command manages roles and collections using galaxy.ansible.com . To manage roles: ansible-galaxy role [import|init|install|login|remove|...] Sub-commands Observations install installs a role. remove remove one or more roles. list display the name and the version of installed roles. info display information about a role. init generate a skeleton of a new role. import import a role from the galaxy web site. Requires a login. To manage collections: ansible-galaxy collection [import|init|install|login|remove|...] Sub-commands Observations init generate a skeleton of a new collection. install installs a collection. list display the name and the version of installed collections. Ansible Roles An Ansible role is a unit that promotes the reusability of playbooks. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html) Installing useful Roles In order to highlight the interest of using roles, I suggest you to use the alemorvan/patchmanagement role, which will allow you to perform a lot of tasks (pre-update or post-update for example) during your update process, in only a few lines of code. You can check the code in the github repo of the role here . Install the role. This needs only one command: ansible-galaxy role install alemorvan.patchmanagement Create a playbook to include the role: - name: Start a Patch Management hosts: ansible_clients vars: pm_before_update_tasks_file: custom_tasks/pm_before_update_tasks_file.yml pm_after_update_tasks_file: custom_tasks/pm_after_update_tasks_file.yml tasks: - name: \"Include patchmanagement\" include_role: name: \"alemorvan.patchmanagement\" With this role, you can add your own tasks for all your inventory or for only your targeted node. Let's create tasks that will be run before and after the update process: Create the custom_tasks folder: mkdir custom_tasks Create the custom_tasks/pm_before_update_tasks_file.yml (feel free to change the name and the content of this file) --- - name: sample task before the update process debug: msg: \"This is a sample tasks, feel free to add your own test task\" Create the custom_tasks/pm_after_update_tasks_file.yml (feel free to change the name and the content of this file) --- - name: sample task after the update process debug: msg: \"This is a sample tasks, feel free to add your own test task\" And launch your first Patch Management: ansible-playbook patchmanagement.yml PLAY [Start a Patch Management] ************************************************************************* TASK [Gathering Facts] ********************************************************************************** ok: [192.168.1.11] TASK [Include patchmanagement] ************************************************************************** TASK [alemorvan.patchmanagement : MAIN | Linux Patch Management Job] ************************************ ok: [192.168.1.11] => { \"msg\": \"Start 192 patch management\" } ... TASK [alemorvan.patchmanagement : sample task before the update process] ******************************** ok: [192.168.1.11] => { \"msg\": \"This is a sample tasks, feel free to add your own test task\" } ... TASK [alemorvan.patchmanagement : MAIN | We can now patch] ********************************************** included: /home/ansible/.ansible/roles/alemorvan.patchmanagement/tasks/patch.yml for 192.168.1.11 TASK [alemorvan.patchmanagement : PATCH | Tasks depends on distribution] ******************************** ok: [192.168.1.11] => { \"ansible_distribution\": \"Rocky\" } TASK [alemorvan.patchmanagement : PATCH | Include tasks for CentOS & RedHat tasks] ********************** included: /home/ansible/.ansible/roles/alemorvan.patchmanagement/tasks/linux_tasks/redhat_centos.yml for 192.168.1.11 TASK [alemorvan.patchmanagement : RHEL CENTOS | yum clean all] ****************************************** changed: [192.168.1.11] TASK [alemorvan.patchmanagement : RHEL CENTOS | Ensure yum-utils is installed] ************************** ok: [192.168.1.11] TASK [alemorvan.patchmanagement : RHEL CENTOS | Remove old kernels] ************************************* skipping: [192.168.1.11] TASK [alemorvan.patchmanagement : RHEL CENTOS | Update rpm package with yum] **************************** ok: [192.168.1.11] TASK [alemorvan.patchmanagement : PATCH | Inlude tasks for Debian & Ubuntu tasks] *********************** skipping: [192.168.1.11] TASK [alemorvan.patchmanagement : MAIN | We can now reboot] ********************************************* included: /home/ansible/.ansible/roles/alemorvan.patchmanagement/tasks/reboot.yml for 192.168.1.11 TASK [alemorvan.patchmanagement : REBOOT | Reboot triggered] ******************************************** ok: [192.168.1.11] TASK [alemorvan.patchmanagement : REBOOT | Ensure we are not in rescue mode] **************************** ok: [192.168.1.11] ... TASK [alemorvan.patchmanagement : FACTS | Insert fact file] ********************************************* ok: [192.168.1.11] TASK [alemorvan.patchmanagement : FACTS | Save date of last PM] ***************************************** ok: [192.168.1.11] ... TASK [alemorvan.patchmanagement : sample task after the update process] ********************************* ok: [192.168.1.11] => { \"msg\": \"This is a sample tasks, feel free to add your own test task\" } PLAY RECAP ********************************************************************************************** 192.168.1.11 : ok=31 changed=1 unreachable=0 failed=0 skipped=4 rescued=0 ignored=0 Pretty easy for such a complex process, isn't it? This is just one example of what can be done using roles made available by the community. Have a look at galaxy.ansible.com to discover the roles that could be useful for you! You can also create your own roles for your own needs and publish them on the Internet if you feel like it. This is what we will briefly cover in the next chapter. Introduction to Role development A role skeleton, serving as a starting point for custom role development, can be generated by the ansible-galaxy command: $ ansible-galaxy role init rocky8 - Role rocky8 was created successfully The command will generate the following tree structure to contain the rocky8 role: tree rocky8/ rocky8/ \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 templates \u251c\u2500\u2500 tests \u2502 \u251c\u2500\u2500 inventory \u2502 \u2514\u2500\u2500 test.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 main.yml 8 directories, 8 files Roles allow you to do away with the need to include files. There is no need to specify file paths or include directives in playbooks. You just have to specify a task, and Ansible takes care of the inclusions. The structure of a role is fairly obvious to understand. Variables are simply stored either in vars/main.yml if the variables are not to be overridden, or in default/main.yml if you want to leave the possibility of overriding the variable content from outside your role. The handlers, files, and templates needed for your code are stored in handlers/main.yml , files and templates respectively. All that remains is to define the code for your role's tasks in tasks/main.yml . Once all this is working well, you can use this role in your playbooks. You will be able to use your role without worrying about the technical aspect of its tasks, while customizing its operation with variables. Practical work: create a first simple role Let's implement this with a \"go anywhere\" role that will create a default user and install software packages. This role can be systematically applied to all your servers. Variables We will create a rockstar user on all of our servers. As we don't want this user to be overridden, let's define it in the vars/main.yml : --- rocky8_default_group: name: rockstar gid: 1100 rocky8_default_user: name: rockstar uid: 1100 group: rockstar We can now use those variables inside our tasks/main.yml without any inclusion. --- - name: Create default group group: name: \"{{ rocky8_default_group.name }}\" gid: \"{{ rocky8_default_group.gid }}\" - name: Create default user user: name: \"{{ rocky8_default_user.name }}\" uid: \"{{ rocky8_default_user.uid }}\" group: \"{{ rocky8_default_user.group }}\" To test your new role, let's create a test-role.yml playbook in the same directory as your role: --- - name: Test my role hosts: localhost roles: - role: rocky8 become: true become_user: root and launch it: ansible-playbook test-role.yml PLAY [Test my role] ************************************************************************************ TASK [Gathering Facts] ********************************************************************************* ok: [localhost] TASK [rocky8 : Create default group] ******************************************************************* changed: [localhost] TASK [rocky8 : Create default user] ******************************************************************** changed: [localhost] PLAY RECAP ********************************************************************************************* localhost : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Congratulations! You are now able to create great things with a playbook of only a few lines. Let's see the use of default variables. Create a list of packages to install by default on your servers and an empty list of packages to uninstall. Edit the defaults/main.yml files and add those two lists: rocky8_default_packages: - tree - vim rocky8_remove_packages: [] and use them in your tasks/main.yml : - name: Install default packages (can be overridden) package: name: \"{{ rocky8_default_packages }}\" state: present - name: \"Uninstall default packages (can be overridden) {{ rocky8_remove_packages }}\" package: name: \"{{ rocky8_remove_packages }}\" state: absent Test your role with the help of the playbook previously created: ansible-playbook test-role.yml PLAY [Test my role] ************************************************************************************ TASK [Gathering Facts] ********************************************************************************* ok: [localhost] TASK [rocky8 : Create default group] ******************************************************************* ok: [localhost] TASK [rocky8 : Create default user] ******************************************************************** ok: [localhost] TASK [rocky8 : Install default packages (can be overridden)] ******************************************** ok: [localhost] TASK [rocky8 : Uninstall default packages (can be overridden) []] *************************************** ok: [localhost] PLAY RECAP ********************************************************************************************* localhost : ok=5 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 You can now override the rocky8_remove_packages in your playbook and uninstall for example cockpit : --- - name: Test my role hosts: localhost vars: rocky8_remove_packages: - cockpit roles: - role: rocky8 become: true become_user: root ansible-playbook test-role.yml PLAY [Test my role] ************************************************************************************ TASK [Gathering Facts] ********************************************************************************* ok: [localhost] TASK [rocky8 : Create default group] ******************************************************************* ok: [localhost] TASK [rocky8 : Create default user] ******************************************************************** ok: [localhost] TASK [rocky8 : Install default packages (can be overridden)] ******************************************** ok: [localhost] TASK [rocky8 : Uninstall default packages (can be overridden) ['cockpit']] ****************************** changed: [localhost] PLAY RECAP ********************************************************************************************* localhost : ok=5 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Obviously, there is no limit to how much you can improve your role. Imagine that for one of your servers, you need a package that is in the list of those to be uninstalled. You could then, for example, create a new list that can be overridden and then remove from the list of packages to be uninstalled those in the list of specific packages to be installed by using the jinja difference() filter. - name: \"Uninstall default packages (can be overridden) {{ rocky8_remove_packages }}\" package: name: \"{{ rocky8_remove_packages | difference(rocky8_specifics_packages) }}\" state: absent Ansible Collections Collections are a distribution format for Ansible content that can include playbooks, roles, modules, and plugins. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/collections_using.html) To install or upgrade a collection: ansible-galaxy collection install namespace.collection [--upgrade] You can then use the newly installed collection using its namespace and name before the module's name or role's name: - import_role: name: namespace.collection.rolename - namespace.collection.modulename: option1: value You can find a collection index here . Let's install the community.general collection: ansible-galaxy collection install community.general Starting galaxy collection install process Process install dependency map Starting collection install process Downloading https://galaxy.ansible.com/download/community-general-3.3.2.tar.gz to /home/ansible/.ansible/tmp/ansible-local-51384hsuhf3t5/tmpr_c9qrt1/community-general-3.3.2-f4q9u4dg Installing 'community.general:3.3.2' to '/home/ansible/.ansible/collections/ansible_collections/community/general' community.general:3.3.2 was installed successfully We can now use the newly available module yum_versionlock : - name: Start a Patch Management hosts: ansible_clients become: true become_user: root tasks: - name: Ensure yum-versionlock is installed package: name: python3-dnf-plugin-versionlock state: present - name: Prevent kernel from being updated community.general.yum_versionlock: state: present name: kernel register: locks - name: Display locks debug: var: locks.meta.packages ansible-playbook versionlock.yml PLAY [Start a Patch Management] ************************************************************************* TASK [Gathering Facts] ********************************************************************************** ok: [192.168.1.11] TASK [Ensure yum-versionlock is installed] ************************************************************** changed: [192.168.1.11] TASK [Prevent kernel from being updated] **************************************************************** changed: [192.168.1.11] TASK [Display locks] ************************************************************************************ ok: [192.168.1.11] => { \"locks.meta.packages\": [ \"kernel\" ] } PLAY RECAP ********************************************************************************************** 192.168.1.11 : ok=4 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Creating your own collection As with roles, you are able to create your own collection with the help of the ansible-galaxy command: ansible-galaxy collection init rocky8.rockstarcollection - Collection rocky8.rockstarcollection was created successfully tree rocky8/rockstarcollection/ rocky8/rockstarcollection/ \u251c\u2500\u2500 docs \u251c\u2500\u2500 galaxy.yml \u251c\u2500\u2500 plugins \u2502 \u2514\u2500\u2500 README.md \u251c\u2500\u2500 README.md \u2514\u2500\u2500 roles You can then store your own plugins or roles inside this new collection.","title":"Ansible Galaxy"},{"location":"books/learning_ansible/04-ansible-galaxy/#ansible-galaxy-collections-and-roles","text":"In this chapter you will learn how to use, install, and manage Ansible roles and collections. Objectives : In this chapter you will learn how to: :heavy_check_mark: install and manage collections; :heavy_check_mark: install and manage roles;. :checkered_flag: ansible , ansible-galaxy , roles , collections Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 40 minutes Ansible Galaxy provides Ansible Roles and Collections from the Ansible Community. The elements provided can be referenced in the playbooks and used out of the box","title":"Ansible Galaxy: Collections and Roles"},{"location":"books/learning_ansible/04-ansible-galaxy/#ansible-galaxy-command","text":"The ansible-galaxy command manages roles and collections using galaxy.ansible.com . To manage roles: ansible-galaxy role [import|init|install|login|remove|...] Sub-commands Observations install installs a role. remove remove one or more roles. list display the name and the version of installed roles. info display information about a role. init generate a skeleton of a new role. import import a role from the galaxy web site. Requires a login. To manage collections: ansible-galaxy collection [import|init|install|login|remove|...] Sub-commands Observations init generate a skeleton of a new collection. install installs a collection. list display the name and the version of installed collections.","title":"ansible-galaxy command"},{"location":"books/learning_ansible/04-ansible-galaxy/#ansible-roles","text":"An Ansible role is a unit that promotes the reusability of playbooks. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html)","title":"Ansible Roles"},{"location":"books/learning_ansible/04-ansible-galaxy/#installing-useful-roles","text":"In order to highlight the interest of using roles, I suggest you to use the alemorvan/patchmanagement role, which will allow you to perform a lot of tasks (pre-update or post-update for example) during your update process, in only a few lines of code. You can check the code in the github repo of the role here . Install the role. This needs only one command: ansible-galaxy role install alemorvan.patchmanagement Create a playbook to include the role: - name: Start a Patch Management hosts: ansible_clients vars: pm_before_update_tasks_file: custom_tasks/pm_before_update_tasks_file.yml pm_after_update_tasks_file: custom_tasks/pm_after_update_tasks_file.yml tasks: - name: \"Include patchmanagement\" include_role: name: \"alemorvan.patchmanagement\" With this role, you can add your own tasks for all your inventory or for only your targeted node. Let's create tasks that will be run before and after the update process: Create the custom_tasks folder: mkdir custom_tasks Create the custom_tasks/pm_before_update_tasks_file.yml (feel free to change the name and the content of this file) --- - name: sample task before the update process debug: msg: \"This is a sample tasks, feel free to add your own test task\" Create the custom_tasks/pm_after_update_tasks_file.yml (feel free to change the name and the content of this file) --- - name: sample task after the update process debug: msg: \"This is a sample tasks, feel free to add your own test task\" And launch your first Patch Management: ansible-playbook patchmanagement.yml PLAY [Start a Patch Management] ************************************************************************* TASK [Gathering Facts] ********************************************************************************** ok: [192.168.1.11] TASK [Include patchmanagement] ************************************************************************** TASK [alemorvan.patchmanagement : MAIN | Linux Patch Management Job] ************************************ ok: [192.168.1.11] => { \"msg\": \"Start 192 patch management\" } ... TASK [alemorvan.patchmanagement : sample task before the update process] ******************************** ok: [192.168.1.11] => { \"msg\": \"This is a sample tasks, feel free to add your own test task\" } ... TASK [alemorvan.patchmanagement : MAIN | We can now patch] ********************************************** included: /home/ansible/.ansible/roles/alemorvan.patchmanagement/tasks/patch.yml for 192.168.1.11 TASK [alemorvan.patchmanagement : PATCH | Tasks depends on distribution] ******************************** ok: [192.168.1.11] => { \"ansible_distribution\": \"Rocky\" } TASK [alemorvan.patchmanagement : PATCH | Include tasks for CentOS & RedHat tasks] ********************** included: /home/ansible/.ansible/roles/alemorvan.patchmanagement/tasks/linux_tasks/redhat_centos.yml for 192.168.1.11 TASK [alemorvan.patchmanagement : RHEL CENTOS | yum clean all] ****************************************** changed: [192.168.1.11] TASK [alemorvan.patchmanagement : RHEL CENTOS | Ensure yum-utils is installed] ************************** ok: [192.168.1.11] TASK [alemorvan.patchmanagement : RHEL CENTOS | Remove old kernels] ************************************* skipping: [192.168.1.11] TASK [alemorvan.patchmanagement : RHEL CENTOS | Update rpm package with yum] **************************** ok: [192.168.1.11] TASK [alemorvan.patchmanagement : PATCH | Inlude tasks for Debian & Ubuntu tasks] *********************** skipping: [192.168.1.11] TASK [alemorvan.patchmanagement : MAIN | We can now reboot] ********************************************* included: /home/ansible/.ansible/roles/alemorvan.patchmanagement/tasks/reboot.yml for 192.168.1.11 TASK [alemorvan.patchmanagement : REBOOT | Reboot triggered] ******************************************** ok: [192.168.1.11] TASK [alemorvan.patchmanagement : REBOOT | Ensure we are not in rescue mode] **************************** ok: [192.168.1.11] ... TASK [alemorvan.patchmanagement : FACTS | Insert fact file] ********************************************* ok: [192.168.1.11] TASK [alemorvan.patchmanagement : FACTS | Save date of last PM] ***************************************** ok: [192.168.1.11] ... TASK [alemorvan.patchmanagement : sample task after the update process] ********************************* ok: [192.168.1.11] => { \"msg\": \"This is a sample tasks, feel free to add your own test task\" } PLAY RECAP ********************************************************************************************** 192.168.1.11 : ok=31 changed=1 unreachable=0 failed=0 skipped=4 rescued=0 ignored=0 Pretty easy for such a complex process, isn't it? This is just one example of what can be done using roles made available by the community. Have a look at galaxy.ansible.com to discover the roles that could be useful for you! You can also create your own roles for your own needs and publish them on the Internet if you feel like it. This is what we will briefly cover in the next chapter.","title":"Installing useful Roles"},{"location":"books/learning_ansible/04-ansible-galaxy/#introduction-to-role-development","text":"A role skeleton, serving as a starting point for custom role development, can be generated by the ansible-galaxy command: $ ansible-galaxy role init rocky8 - Role rocky8 was created successfully The command will generate the following tree structure to contain the rocky8 role: tree rocky8/ rocky8/ \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 files \u251c\u2500\u2500 handlers \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 meta \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 templates \u251c\u2500\u2500 tests \u2502 \u251c\u2500\u2500 inventory \u2502 \u2514\u2500\u2500 test.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 main.yml 8 directories, 8 files Roles allow you to do away with the need to include files. There is no need to specify file paths or include directives in playbooks. You just have to specify a task, and Ansible takes care of the inclusions. The structure of a role is fairly obvious to understand. Variables are simply stored either in vars/main.yml if the variables are not to be overridden, or in default/main.yml if you want to leave the possibility of overriding the variable content from outside your role. The handlers, files, and templates needed for your code are stored in handlers/main.yml , files and templates respectively. All that remains is to define the code for your role's tasks in tasks/main.yml . Once all this is working well, you can use this role in your playbooks. You will be able to use your role without worrying about the technical aspect of its tasks, while customizing its operation with variables.","title":"Introduction to Role development"},{"location":"books/learning_ansible/04-ansible-galaxy/#practical-work-create-a-first-simple-role","text":"Let's implement this with a \"go anywhere\" role that will create a default user and install software packages. This role can be systematically applied to all your servers.","title":"Practical work: create a first simple role"},{"location":"books/learning_ansible/04-ansible-galaxy/#variables","text":"We will create a rockstar user on all of our servers. As we don't want this user to be overridden, let's define it in the vars/main.yml : --- rocky8_default_group: name: rockstar gid: 1100 rocky8_default_user: name: rockstar uid: 1100 group: rockstar We can now use those variables inside our tasks/main.yml without any inclusion. --- - name: Create default group group: name: \"{{ rocky8_default_group.name }}\" gid: \"{{ rocky8_default_group.gid }}\" - name: Create default user user: name: \"{{ rocky8_default_user.name }}\" uid: \"{{ rocky8_default_user.uid }}\" group: \"{{ rocky8_default_user.group }}\" To test your new role, let's create a test-role.yml playbook in the same directory as your role: --- - name: Test my role hosts: localhost roles: - role: rocky8 become: true become_user: root and launch it: ansible-playbook test-role.yml PLAY [Test my role] ************************************************************************************ TASK [Gathering Facts] ********************************************************************************* ok: [localhost] TASK [rocky8 : Create default group] ******************************************************************* changed: [localhost] TASK [rocky8 : Create default user] ******************************************************************** changed: [localhost] PLAY RECAP ********************************************************************************************* localhost : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Congratulations! You are now able to create great things with a playbook of only a few lines. Let's see the use of default variables. Create a list of packages to install by default on your servers and an empty list of packages to uninstall. Edit the defaults/main.yml files and add those two lists: rocky8_default_packages: - tree - vim rocky8_remove_packages: [] and use them in your tasks/main.yml : - name: Install default packages (can be overridden) package: name: \"{{ rocky8_default_packages }}\" state: present - name: \"Uninstall default packages (can be overridden) {{ rocky8_remove_packages }}\" package: name: \"{{ rocky8_remove_packages }}\" state: absent Test your role with the help of the playbook previously created: ansible-playbook test-role.yml PLAY [Test my role] ************************************************************************************ TASK [Gathering Facts] ********************************************************************************* ok: [localhost] TASK [rocky8 : Create default group] ******************************************************************* ok: [localhost] TASK [rocky8 : Create default user] ******************************************************************** ok: [localhost] TASK [rocky8 : Install default packages (can be overridden)] ******************************************** ok: [localhost] TASK [rocky8 : Uninstall default packages (can be overridden) []] *************************************** ok: [localhost] PLAY RECAP ********************************************************************************************* localhost : ok=5 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 You can now override the rocky8_remove_packages in your playbook and uninstall for example cockpit : --- - name: Test my role hosts: localhost vars: rocky8_remove_packages: - cockpit roles: - role: rocky8 become: true become_user: root ansible-playbook test-role.yml PLAY [Test my role] ************************************************************************************ TASK [Gathering Facts] ********************************************************************************* ok: [localhost] TASK [rocky8 : Create default group] ******************************************************************* ok: [localhost] TASK [rocky8 : Create default user] ******************************************************************** ok: [localhost] TASK [rocky8 : Install default packages (can be overridden)] ******************************************** ok: [localhost] TASK [rocky8 : Uninstall default packages (can be overridden) ['cockpit']] ****************************** changed: [localhost] PLAY RECAP ********************************************************************************************* localhost : ok=5 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Obviously, there is no limit to how much you can improve your role. Imagine that for one of your servers, you need a package that is in the list of those to be uninstalled. You could then, for example, create a new list that can be overridden and then remove from the list of packages to be uninstalled those in the list of specific packages to be installed by using the jinja difference() filter. - name: \"Uninstall default packages (can be overridden) {{ rocky8_remove_packages }}\" package: name: \"{{ rocky8_remove_packages | difference(rocky8_specifics_packages) }}\" state: absent","title":"Variables"},{"location":"books/learning_ansible/04-ansible-galaxy/#ansible-collections","text":"Collections are a distribution format for Ansible content that can include playbooks, roles, modules, and plugins. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/collections_using.html) To install or upgrade a collection: ansible-galaxy collection install namespace.collection [--upgrade] You can then use the newly installed collection using its namespace and name before the module's name or role's name: - import_role: name: namespace.collection.rolename - namespace.collection.modulename: option1: value You can find a collection index here . Let's install the community.general collection: ansible-galaxy collection install community.general Starting galaxy collection install process Process install dependency map Starting collection install process Downloading https://galaxy.ansible.com/download/community-general-3.3.2.tar.gz to /home/ansible/.ansible/tmp/ansible-local-51384hsuhf3t5/tmpr_c9qrt1/community-general-3.3.2-f4q9u4dg Installing 'community.general:3.3.2' to '/home/ansible/.ansible/collections/ansible_collections/community/general' community.general:3.3.2 was installed successfully We can now use the newly available module yum_versionlock : - name: Start a Patch Management hosts: ansible_clients become: true become_user: root tasks: - name: Ensure yum-versionlock is installed package: name: python3-dnf-plugin-versionlock state: present - name: Prevent kernel from being updated community.general.yum_versionlock: state: present name: kernel register: locks - name: Display locks debug: var: locks.meta.packages ansible-playbook versionlock.yml PLAY [Start a Patch Management] ************************************************************************* TASK [Gathering Facts] ********************************************************************************** ok: [192.168.1.11] TASK [Ensure yum-versionlock is installed] ************************************************************** changed: [192.168.1.11] TASK [Prevent kernel from being updated] **************************************************************** changed: [192.168.1.11] TASK [Display locks] ************************************************************************************ ok: [192.168.1.11] => { \"locks.meta.packages\": [ \"kernel\" ] } PLAY RECAP ********************************************************************************************** 192.168.1.11 : ok=4 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0","title":"Ansible Collections"},{"location":"books/learning_ansible/04-ansible-galaxy/#creating-your-own-collection","text":"As with roles, you are able to create your own collection with the help of the ansible-galaxy command: ansible-galaxy collection init rocky8.rockstarcollection - Collection rocky8.rockstarcollection was created successfully tree rocky8/rockstarcollection/ rocky8/rockstarcollection/ \u251c\u2500\u2500 docs \u251c\u2500\u2500 galaxy.yml \u251c\u2500\u2500 plugins \u2502 \u2514\u2500\u2500 README.md \u251c\u2500\u2500 README.md \u2514\u2500\u2500 roles You can then store your own plugins or roles inside this new collection.","title":"Creating your own collection"},{"location":"books/learning_ansible/05-deployments/","text":"Ansible Deployments with Ansistrano In this chapter you will learn how to deploy applications with the Ansible role Ansistrano . Objectives : In this chapter you will learn how to: :heavy_check_mark: Implement Ansistrano; :heavy_check_mark: Configure Ansistrano; :heavy_check_mark: Use shared folders and files between deployed versions; :heavy_check_mark: Deploying different versions of a site from git; :heavy_check_mark: React between deployment steps. :checkered_flag: ansible , ansistrano , roles , deployments Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 40 minutes Ansistrano is an Ansible role to easily deploy PHP, Python, etc. applications. It is based on the functionality of Capistrano . Introduction Ansistrano requires the following to run: Ansible on the deployment machine, rsync or git on the client machine. It can download source code from rsync , git , scp , http , S3 , ... !!! Note For our deployment example, we will use the `git` protocol. Ansistrano deploys applications by following these 5 steps: Setup : create the directory structure to host the releases; Update Code : downloading the new release to the targets; Symlink Shared and Symlink : after deploying the new release, the current symbolic link is modified to point to this new release; Clean Up : to do some clean up (remove old versions). The skeleton of a deployment with Ansistrano looks like this: /var/www/site/ \u251c\u2500\u2500 current -> ./releases/20210718100000Z \u251c\u2500\u2500 releases \u2502 \u2514\u2500\u2500 20210718100000Z \u2502 \u251c\u2500\u2500 css -> ../../shared/css/ \u2502 \u251c\u2500\u2500 img -> ../../shared/img/ \u2502 \u2514\u2500\u2500 REVISION \u251c\u2500\u2500 repo \u2514\u2500\u2500 shared \u251c\u2500\u2500 css/ \u2514\u2500\u2500 img/ You can find all the Ansistrano documentation on its Github repository . Labs You will continue to work on your 2 servers: The management server: Ansible is already installed. You will have to install the ansistrano.deploy role. The managed server: You will need to install Apache and deploy the client site. Deploying the Web server For more efficiency, we will use the geerlingguy.apache role to configure the server: $ ansible-galaxy role install geerlingguy.apache Starting galaxy role install process - downloading role 'apache', owned by geerlingguy - downloading role from https://github.com/geerlingguy/ansible-role-apache/archive/3.1.4.tar.gz - extracting geerlingguy.apache to /home/ansible/.ansible/roles/geerlingguy.apache - geerlingguy.apache (3.1.4) was installed successfully We will probably need to open some firewall rules, so we will also install the collection ansible.posix to work with its module firewalld : $ ansible-galaxy collection install ansible.posix Starting galaxy collection install process Process install dependency map Starting collection install process Downloading https://galaxy.ansible.com/download/ansible-posix-1.2.0.tar.gz to /home/ansible/.ansible/tmp/ansible-local-519039bp65pwn/tmpsvuj1fw5/ansible-posix-1.2.0-bhjbfdpw Installing 'ansible.posix:1.2.0' to '/home/ansible/.ansible/collections/ansible_collections/ansible/posix' ansible.posix:1.2.0 was installed successfully Once the role and the collection are installed, we can create the first part of our playbook, which will: Install Apache, Create a target folder for our vhost , Create a default vhost , Open the firewall, Start or restart Apache. Technical considerations: We will deploy our site to the /var/www/site/ folder. As we will see later, ansistrano will create a current symbolic link to the current release folder. The source code to be deployed contains a html folder which the vhost should point to. Its DirectoryIndex is index.htm . The deployment is done by git , the package will be installed. !!! Note The target of our vhost will therefore be: `/var/www/site/current/html`. Our playbook to configure the server: playbook-config-server.yml --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" apache_global_vhost_settings: | DirectoryIndex index.php index.htm apache_vhosts: - servername: \"website\" documentroot: \"{{ dest }}current/html\" tasks: - name: create directory for website file: path: /var/www/site/ state: directory mode: 0755 - name: install git package: name: git state: latest - name: permit traffic in default zone for http service ansible.posix.firewalld: service: http permanent: yes state: enabled immediate: yes roles: - { role: geerlingguy.apache } The playbook can be applied to the server: $ ansible-playbook playbook-config-server.yml Note the execution of the following tasks: TASK [geerlingguy.apache : Ensure Apache is installed on RHEL.] **************** TASK [geerlingguy.apache : Configure Apache.] ********************************** TASK [geerlingguy.apache : Add apache vhosts configuration.] ******************* TASK [geerlingguy.apache : Ensure Apache has selected state and enabled on boot.] *** TASK [permit traffic in default zone for http service] ************************* RUNNING HANDLER [geerlingguy.apache : restart apache] ************************** The geerlingguy.apache role makes our job much easier by taking care of the installation and configuration of Apache. You can check that everything is working by using curl : $ curl -I http://192.168.1.11 HTTP/1.1 404 Not Found Date: Mon, 05 Jul 2021 23:30:02 GMT Server: Apache/2.4.37 (rocky) OpenSSL/1.1.1g Content-Type: text/html; charset=iso-8859-1 !!! Note We have not yet deployed any code, so it is normal for `curl` to return a `404` HTTP code. But we can already confirm that the `httpd` service is working and that the firewall is open. Deploying the software Now that our server is configured, we can deploy the application. For this, we will use the ansistrano.deploy role in a second playbook dedicated to application deployment (for more readability). $ ansible-galaxy role install ansistrano.deploy Starting galaxy role install process - downloading role 'deploy', owned by ansistrano - downloading role from https://github.com/ansistrano/deploy/archive/3.10.0.tar.gz - extracting ansistrano.deploy to /home/ansible/.ansible/roles/ansistrano.deploy - ansistrano.deploy (3.10.0) was installed successfully The sources of the software can be found in the github repository . We will create a playbook playbook-deploy.yml to manage our deployment: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" roles: - { role: ansistrano.deploy } $ ansible-playbook playbook-deploy.yml PLAY [ansible_clients] ********************************************************* TASK [ansistrano.deploy : ANSISTRANO | Ensure deployment base path exists] ***** TASK [ansistrano.deploy : ANSISTRANO | Ensure releases folder exists] TASK [ansistrano.deploy : ANSISTRANO | Ensure shared elements folder exists] TASK [ansistrano.deploy : ANSISTRANO | Ensure shared paths exists] TASK [ansistrano.deploy : ANSISTRANO | Ensure basedir shared files exists] TASK [ansistrano.deploy : ANSISTRANO | Get release version] ******************** TASK [ansistrano.deploy : ANSISTRANO | Get release path] TASK [ansistrano.deploy : ANSISTRANO | GIT | Register ansistrano_git_result variable] TASK [ansistrano.deploy : ANSISTRANO | GIT | Set git_real_repo_tree] TASK [ansistrano.deploy : ANSISTRANO | GIT | Create release folder] TASK [ansistrano.deploy : ANSISTRANO | GIT | Sync repo subtree[\"\"] to release path] TASK [ansistrano.deploy : ANSISTRANO | Copy git released version into REVISION file] TASK [ansistrano.deploy : ANSISTRANO | Ensure shared paths targets are absent] TASK [ansistrano.deploy : ANSISTRANO | Create softlinks for shared paths and files] TASK [ansistrano.deploy : ANSISTRANO | Ensure .rsync-filter is absent] TASK [ansistrano.deploy : ANSISTRANO | Setup .rsync-filter with shared-folders] TASK [ansistrano.deploy : ANSISTRANO | Get current folder] TASK [ansistrano.deploy : ANSISTRANO | Remove current folder if it's a directory] TASK [ansistrano.deploy : ANSISTRANO | Change softlink to new release] TASK [ansistrano.deploy : ANSISTRANO | Clean up releases] PLAY RECAP ******************************************************************************************************************************************************************************************************** 192.168.1.11 : ok=25 changed=8 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0 So many things done with only 11 lines of code! $ curl http://192.168.1.11 <html> <head> <title>Demo Ansible</title> </head> <body> <h1>Version Master</h1> </body> <html> Checking on the server You can now connect by ssh to your client machine. Make a tree on the /var/www/site/ directory: $ tree /var/www/site/ /var/www/site \u251c\u2500\u2500 current -> ./releases/20210722155312Z \u251c\u2500\u2500 releases \u2502 \u2514\u2500\u2500 20210722155312Z \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u251c\u2500\u2500 repo \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared Please note: the current symlink to the release ./releases/20210722155312Z the presence of a directory shared the presence of the git repos in ./repo/ From the Ansible server, restart the deployment 3 times, then check on the client. $ tree /var/www/site/ var/www/site \u251c\u2500\u2500 current -> ./releases/20210722160048Z \u251c\u2500\u2500 releases \u2502 \u251c\u2500\u2500 20210722155312Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160032Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160040Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u2514\u2500\u2500 20210722160048Z \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u251c\u2500\u2500 repo \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared Please note: ansistrano kept the 4 last releases, the current link linked now to the lastest release Limit the number of releases The ansistrano_keep_releases variable is used to specify the number of releases to keep. Using the ansistrano_keep_releases variable, keep only 3 releases of the project. Check. --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 roles: - { role: ansistrano.deploy } --- $ ansible-playbook -i hosts playbook-deploy.yml On the client machine: $ tree /var/www/site/ /var/www/site \u251c\u2500\u2500 current -> ./releases/20210722160318Z \u251c\u2500\u2500 releases \u2502 \u251c\u2500\u2500 20210722160040Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160048Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u2514\u2500\u2500 20210722160318Z \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u251c\u2500\u2500 repo \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared Using shared_paths and shared_files --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"logs\" roles: - { role: ansistrano.deploy } On the client machine, create the file logs in the shared directory: sudo touch /var/www/site/shared/logs Then execute the playbook: TASK [ansistrano.deploy : ANSISTRANO | Ensure shared paths targets are absent] ******************************************************* ok: [192.168.10.11] => (item=img) ok: [192.168.10.11] => (item=css) ok: [192.168.10.11] => (item=logs/log) TASK [ansistrano.deploy : ANSISTRANO | Create softlinks for shared paths and files] ************************************************** changed: [192.168.10.11] => (item=img) changed: [192.168.10.11] => (item=css) changed: [192.168.10.11] => (item=logs) On the client machine: $ tree -F /var/www/site/ /var/www/site/ \u251c\u2500\u2500 current -> ./releases/20210722160631Z/ \u251c\u2500\u2500 releases/ \u2502 \u251c\u2500\u2500 20210722160048Z/ \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html/ \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160318Z/ \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html/ \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u2514\u2500\u2500 20210722160631Z/ \u2502 \u251c\u2500\u2500 REVISION \u2502 \u251c\u2500\u2500 css -> ../../shared/css/ \u2502 \u251c\u2500\u2500 html/ \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 img -> ../../shared/img/ \u2502 \u2514\u2500\u2500 logs -> ../../shared/logs \u251c\u2500\u2500 repo/ \u2502 \u2514\u2500\u2500 html/ \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared/ \u251c\u2500\u2500 css/ \u251c\u2500\u2500 img/ \u2514\u2500\u2500 logs Please note that the last release contains 3 links: css , img , and logs from /var/www/site/releases/css to the ../../shared/css/ directory. from /var/www/site/releases/img to the ../../shared/img/ directory. from /var/www/site/releases/logs to the ../../shared/logs file. Therefore, the files contained in these 2 folders and the logs file are always accessible via the following paths: /var/www/site/current/css/ , /var/www/site/current/img/ , /var/www/site/current/logs , but above all they will be kept from one release to the next. Use a sub-directory of the repository for deployment In our case, the repository contains a html folder, which contains the site files. To avoid this extra level of directory, use the ansistrano_git_repo_tree variable by specifying the path of the sub-directory to use. Don't forget to modify the Apache configuration to take into account this change! Change the playbook for the server configuration playbook-config-server.yml --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" apache_global_vhost_settings: | DirectoryIndex index.php index.htm apache_vhosts: - servername: \"website\" documentroot: \"{{ dest }}current/\" # <1> tasks: - name: create directory for website file: path: /var/www/site/ state: directory mode: 0755 - name: install git package: name: git state: latest roles: - { role: geerlingguy.apache } <1> Modify this line Change the playbook for the deployment playbook-deploy.yml --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"log\" ansistrano_git_repo_tree: 'html' # <1> roles: - { role: ansistrano.deploy } <1> Modify this line Don't forget to run both of the playbooks Check on the client machine: $ tree -F /var/www/site/ /var/www/site/ \u251c\u2500\u2500 current -> ./releases/20210722161542Z/ \u251c\u2500\u2500 releases/ \u2502 \u251c\u2500\u2500 20210722160318Z/ \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html/ \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160631Z/ \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u251c\u2500\u2500 css -> ../../shared/css/ \u2502 \u2502 \u251c\u2500\u2500 html/ \u2502 \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u2502 \u251c\u2500\u2500 img -> ../../shared/img/ \u2502 \u2502 \u2514\u2500\u2500 logs -> ../../shared/logs \u2502 \u2514\u2500\u2500 20210722161542Z/ \u2502 \u251c\u2500\u2500 REVISION \u2502 \u251c\u2500\u2500 css -> ../../shared/css/ \u2502 \u251c\u2500\u2500 img -> ../../shared/img/ \u2502 \u251c\u2500\u2500 index.htm \u2502 \u2514\u2500\u2500 logs -> ../../shared/logs \u251c\u2500\u2500 repo/ \u2502 \u2514\u2500\u2500 html/ \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared/ \u251c\u2500\u2500 css/ \u251c\u2500\u2500 img/ \u2514\u2500\u2500 logs <1> Please note the absence of html Managing git branch or tags The ansistrano_git_branch variable is used to specify a branch or tag to deploy. Deploy the releases/v1.1.0 branch: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"log\" ansistrano_git_repo_tree: 'html' ansistrano_git_branch: 'releases/v1.1.0' roles: - { role: ansistrano.deploy } !!! Note You can have fun, during the deployment, refreshing your browser, to see in 'live' the change. $ curl http://192.168.1.11 <html> <head> <title>Demo Ansible</title> </head> <body> <h1>Version 1.0.1</h1> </body> <html> Deploy the v2.0.0 tag: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"log\" ansistrano_git_repo_tree: 'html' ansistrano_git_branch: 'v2.0.0' roles: - { role: ansistrano.deploy } $ curl http://192.168.1.11 <html> <head> <title>Demo Ansible</title> </head> <body> <h1>Version 2.0.0</h1> </body> <html> Actions between deployment steps A deployment with Ansistrano respects the following steps: Setup Update Code Symlink Shared Symlink Clean Up It is possible to intervene before and after each of these steps. A playbook can be included through the variables provided for this purpose: ansistrano_before_<task>_tasks_file or ansistrano_after_<task>_tasks_file Easy example: send an email (or whatever you want like Slack notification) at the beginning of the deployment: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"logs\" ansistrano_git_repo_tree: 'html' ansistrano_git_branch: 'v2.0.0' ansistrano_before_setup_tasks_file: \"{{ playbook_dir }}/deploy/before-setup-tasks.yml\" roles: - { role: ansistrano.deploy } Create the file deploy/before-setup-tasks.yml : --- - name: Send a mail mail: subject: Starting deployment on {{ ansible_hostname }}. delegate_to: localhost TASK [ansistrano.deploy : include] ************************************************************************************* included: /home/ansible/deploy/before-setup-tasks.yml for 192.168.10.11 TASK [ansistrano.deploy : Send a mail] ************************************************************************************* ok: [192.168.10.11 -> localhost] [root] # mailx Heirloom Mail version 12.5 7/5/10. Type ? for help. \"/var/spool/mail/root\": 1 message 1 new >N 1 root@localhost.local Tue Aug 21 14:41 28/946 \"Starting deployment on localhost.\" You will probably have to restart some services at the end of the deployment, to flush caches for example. Let's restart Apache at the end of the deployment: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"logs\" ansistrano_git_repo_tree: 'html' ansistrano_git_branch: 'v2.0.0' ansistrano_before_setup_tasks_file: \"{{ playbook_dir }}/deploy/before-setup-tasks.yml\" ansistrano_after_symlink_tasks_file: \"{{ playbook_dir }}/deploy/after-symlink-tasks.yml\" roles: - { role: ansistrano.deploy } Create the file deploy/after-symlink-tasks.yml : --- - name: restart apache systemd: name: httpd state: restarted TASK [ansistrano.deploy : include] ************************************************************************************* included: /home/ansible/deploy/after-symlink-tasks.yml for 192.168.10.11 TASK [ansistrano.deploy : restart apache] ************************************************************************************** changed: [192.168.10.11] As you have seen during this chapter, Ansible can greatly improve the life of the system administrator. Very intelligent roles like Ansistrano are \"must haves\" that quickly become indispensable. Using Ansistrano, ensures that good deployment practices are respected, reduces the time needed to put a system into production, and avoids the risk of potential human errors. The machine works fast, well, and rarely makes mistakes!","title":"Deploy With Ansistrano"},{"location":"books/learning_ansible/05-deployments/#ansible-deployments-with-ansistrano","text":"In this chapter you will learn how to deploy applications with the Ansible role Ansistrano . Objectives : In this chapter you will learn how to: :heavy_check_mark: Implement Ansistrano; :heavy_check_mark: Configure Ansistrano; :heavy_check_mark: Use shared folders and files between deployed versions; :heavy_check_mark: Deploying different versions of a site from git; :heavy_check_mark: React between deployment steps. :checkered_flag: ansible , ansistrano , roles , deployments Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 40 minutes Ansistrano is an Ansible role to easily deploy PHP, Python, etc. applications. It is based on the functionality of Capistrano .","title":"Ansible Deployments with Ansistrano"},{"location":"books/learning_ansible/05-deployments/#introduction","text":"Ansistrano requires the following to run: Ansible on the deployment machine, rsync or git on the client machine. It can download source code from rsync , git , scp , http , S3 , ... !!! Note For our deployment example, we will use the `git` protocol. Ansistrano deploys applications by following these 5 steps: Setup : create the directory structure to host the releases; Update Code : downloading the new release to the targets; Symlink Shared and Symlink : after deploying the new release, the current symbolic link is modified to point to this new release; Clean Up : to do some clean up (remove old versions). The skeleton of a deployment with Ansistrano looks like this: /var/www/site/ \u251c\u2500\u2500 current -> ./releases/20210718100000Z \u251c\u2500\u2500 releases \u2502 \u2514\u2500\u2500 20210718100000Z \u2502 \u251c\u2500\u2500 css -> ../../shared/css/ \u2502 \u251c\u2500\u2500 img -> ../../shared/img/ \u2502 \u2514\u2500\u2500 REVISION \u251c\u2500\u2500 repo \u2514\u2500\u2500 shared \u251c\u2500\u2500 css/ \u2514\u2500\u2500 img/ You can find all the Ansistrano documentation on its Github repository .","title":"Introduction"},{"location":"books/learning_ansible/05-deployments/#labs","text":"You will continue to work on your 2 servers: The management server: Ansible is already installed. You will have to install the ansistrano.deploy role. The managed server: You will need to install Apache and deploy the client site.","title":"Labs"},{"location":"books/learning_ansible/05-deployments/#deploying-the-web-server","text":"For more efficiency, we will use the geerlingguy.apache role to configure the server: $ ansible-galaxy role install geerlingguy.apache Starting galaxy role install process - downloading role 'apache', owned by geerlingguy - downloading role from https://github.com/geerlingguy/ansible-role-apache/archive/3.1.4.tar.gz - extracting geerlingguy.apache to /home/ansible/.ansible/roles/geerlingguy.apache - geerlingguy.apache (3.1.4) was installed successfully We will probably need to open some firewall rules, so we will also install the collection ansible.posix to work with its module firewalld : $ ansible-galaxy collection install ansible.posix Starting galaxy collection install process Process install dependency map Starting collection install process Downloading https://galaxy.ansible.com/download/ansible-posix-1.2.0.tar.gz to /home/ansible/.ansible/tmp/ansible-local-519039bp65pwn/tmpsvuj1fw5/ansible-posix-1.2.0-bhjbfdpw Installing 'ansible.posix:1.2.0' to '/home/ansible/.ansible/collections/ansible_collections/ansible/posix' ansible.posix:1.2.0 was installed successfully Once the role and the collection are installed, we can create the first part of our playbook, which will: Install Apache, Create a target folder for our vhost , Create a default vhost , Open the firewall, Start or restart Apache. Technical considerations: We will deploy our site to the /var/www/site/ folder. As we will see later, ansistrano will create a current symbolic link to the current release folder. The source code to be deployed contains a html folder which the vhost should point to. Its DirectoryIndex is index.htm . The deployment is done by git , the package will be installed. !!! Note The target of our vhost will therefore be: `/var/www/site/current/html`. Our playbook to configure the server: playbook-config-server.yml --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" apache_global_vhost_settings: | DirectoryIndex index.php index.htm apache_vhosts: - servername: \"website\" documentroot: \"{{ dest }}current/html\" tasks: - name: create directory for website file: path: /var/www/site/ state: directory mode: 0755 - name: install git package: name: git state: latest - name: permit traffic in default zone for http service ansible.posix.firewalld: service: http permanent: yes state: enabled immediate: yes roles: - { role: geerlingguy.apache } The playbook can be applied to the server: $ ansible-playbook playbook-config-server.yml Note the execution of the following tasks: TASK [geerlingguy.apache : Ensure Apache is installed on RHEL.] **************** TASK [geerlingguy.apache : Configure Apache.] ********************************** TASK [geerlingguy.apache : Add apache vhosts configuration.] ******************* TASK [geerlingguy.apache : Ensure Apache has selected state and enabled on boot.] *** TASK [permit traffic in default zone for http service] ************************* RUNNING HANDLER [geerlingguy.apache : restart apache] ************************** The geerlingguy.apache role makes our job much easier by taking care of the installation and configuration of Apache. You can check that everything is working by using curl : $ curl -I http://192.168.1.11 HTTP/1.1 404 Not Found Date: Mon, 05 Jul 2021 23:30:02 GMT Server: Apache/2.4.37 (rocky) OpenSSL/1.1.1g Content-Type: text/html; charset=iso-8859-1 !!! Note We have not yet deployed any code, so it is normal for `curl` to return a `404` HTTP code. But we can already confirm that the `httpd` service is working and that the firewall is open.","title":"Deploying the Web server"},{"location":"books/learning_ansible/05-deployments/#deploying-the-software","text":"Now that our server is configured, we can deploy the application. For this, we will use the ansistrano.deploy role in a second playbook dedicated to application deployment (for more readability). $ ansible-galaxy role install ansistrano.deploy Starting galaxy role install process - downloading role 'deploy', owned by ansistrano - downloading role from https://github.com/ansistrano/deploy/archive/3.10.0.tar.gz - extracting ansistrano.deploy to /home/ansible/.ansible/roles/ansistrano.deploy - ansistrano.deploy (3.10.0) was installed successfully The sources of the software can be found in the github repository . We will create a playbook playbook-deploy.yml to manage our deployment: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" roles: - { role: ansistrano.deploy } $ ansible-playbook playbook-deploy.yml PLAY [ansible_clients] ********************************************************* TASK [ansistrano.deploy : ANSISTRANO | Ensure deployment base path exists] ***** TASK [ansistrano.deploy : ANSISTRANO | Ensure releases folder exists] TASK [ansistrano.deploy : ANSISTRANO | Ensure shared elements folder exists] TASK [ansistrano.deploy : ANSISTRANO | Ensure shared paths exists] TASK [ansistrano.deploy : ANSISTRANO | Ensure basedir shared files exists] TASK [ansistrano.deploy : ANSISTRANO | Get release version] ******************** TASK [ansistrano.deploy : ANSISTRANO | Get release path] TASK [ansistrano.deploy : ANSISTRANO | GIT | Register ansistrano_git_result variable] TASK [ansistrano.deploy : ANSISTRANO | GIT | Set git_real_repo_tree] TASK [ansistrano.deploy : ANSISTRANO | GIT | Create release folder] TASK [ansistrano.deploy : ANSISTRANO | GIT | Sync repo subtree[\"\"] to release path] TASK [ansistrano.deploy : ANSISTRANO | Copy git released version into REVISION file] TASK [ansistrano.deploy : ANSISTRANO | Ensure shared paths targets are absent] TASK [ansistrano.deploy : ANSISTRANO | Create softlinks for shared paths and files] TASK [ansistrano.deploy : ANSISTRANO | Ensure .rsync-filter is absent] TASK [ansistrano.deploy : ANSISTRANO | Setup .rsync-filter with shared-folders] TASK [ansistrano.deploy : ANSISTRANO | Get current folder] TASK [ansistrano.deploy : ANSISTRANO | Remove current folder if it's a directory] TASK [ansistrano.deploy : ANSISTRANO | Change softlink to new release] TASK [ansistrano.deploy : ANSISTRANO | Clean up releases] PLAY RECAP ******************************************************************************************************************************************************************************************************** 192.168.1.11 : ok=25 changed=8 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0 So many things done with only 11 lines of code! $ curl http://192.168.1.11 <html> <head> <title>Demo Ansible</title> </head> <body> <h1>Version Master</h1> </body> <html>","title":"Deploying the software"},{"location":"books/learning_ansible/05-deployments/#checking-on-the-server","text":"You can now connect by ssh to your client machine. Make a tree on the /var/www/site/ directory: $ tree /var/www/site/ /var/www/site \u251c\u2500\u2500 current -> ./releases/20210722155312Z \u251c\u2500\u2500 releases \u2502 \u2514\u2500\u2500 20210722155312Z \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u251c\u2500\u2500 repo \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared Please note: the current symlink to the release ./releases/20210722155312Z the presence of a directory shared the presence of the git repos in ./repo/ From the Ansible server, restart the deployment 3 times, then check on the client. $ tree /var/www/site/ var/www/site \u251c\u2500\u2500 current -> ./releases/20210722160048Z \u251c\u2500\u2500 releases \u2502 \u251c\u2500\u2500 20210722155312Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160032Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160040Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u2514\u2500\u2500 20210722160048Z \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u251c\u2500\u2500 repo \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared Please note: ansistrano kept the 4 last releases, the current link linked now to the lastest release","title":"Checking on the server"},{"location":"books/learning_ansible/05-deployments/#limit-the-number-of-releases","text":"The ansistrano_keep_releases variable is used to specify the number of releases to keep. Using the ansistrano_keep_releases variable, keep only 3 releases of the project. Check. --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 roles: - { role: ansistrano.deploy } --- $ ansible-playbook -i hosts playbook-deploy.yml On the client machine: $ tree /var/www/site/ /var/www/site \u251c\u2500\u2500 current -> ./releases/20210722160318Z \u251c\u2500\u2500 releases \u2502 \u251c\u2500\u2500 20210722160040Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160048Z \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u2514\u2500\u2500 20210722160318Z \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u251c\u2500\u2500 repo \u2502 \u2514\u2500\u2500 html \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared","title":"Limit the number of releases"},{"location":"books/learning_ansible/05-deployments/#using-shared_paths-and-shared_files","text":"--- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"logs\" roles: - { role: ansistrano.deploy } On the client machine, create the file logs in the shared directory: sudo touch /var/www/site/shared/logs Then execute the playbook: TASK [ansistrano.deploy : ANSISTRANO | Ensure shared paths targets are absent] ******************************************************* ok: [192.168.10.11] => (item=img) ok: [192.168.10.11] => (item=css) ok: [192.168.10.11] => (item=logs/log) TASK [ansistrano.deploy : ANSISTRANO | Create softlinks for shared paths and files] ************************************************** changed: [192.168.10.11] => (item=img) changed: [192.168.10.11] => (item=css) changed: [192.168.10.11] => (item=logs) On the client machine: $ tree -F /var/www/site/ /var/www/site/ \u251c\u2500\u2500 current -> ./releases/20210722160631Z/ \u251c\u2500\u2500 releases/ \u2502 \u251c\u2500\u2500 20210722160048Z/ \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html/ \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160318Z/ \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html/ \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u2514\u2500\u2500 20210722160631Z/ \u2502 \u251c\u2500\u2500 REVISION \u2502 \u251c\u2500\u2500 css -> ../../shared/css/ \u2502 \u251c\u2500\u2500 html/ \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 img -> ../../shared/img/ \u2502 \u2514\u2500\u2500 logs -> ../../shared/logs \u251c\u2500\u2500 repo/ \u2502 \u2514\u2500\u2500 html/ \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared/ \u251c\u2500\u2500 css/ \u251c\u2500\u2500 img/ \u2514\u2500\u2500 logs Please note that the last release contains 3 links: css , img , and logs from /var/www/site/releases/css to the ../../shared/css/ directory. from /var/www/site/releases/img to the ../../shared/img/ directory. from /var/www/site/releases/logs to the ../../shared/logs file. Therefore, the files contained in these 2 folders and the logs file are always accessible via the following paths: /var/www/site/current/css/ , /var/www/site/current/img/ , /var/www/site/current/logs , but above all they will be kept from one release to the next.","title":"Using shared_paths and shared_files"},{"location":"books/learning_ansible/05-deployments/#use-a-sub-directory-of-the-repository-for-deployment","text":"In our case, the repository contains a html folder, which contains the site files. To avoid this extra level of directory, use the ansistrano_git_repo_tree variable by specifying the path of the sub-directory to use. Don't forget to modify the Apache configuration to take into account this change! Change the playbook for the server configuration playbook-config-server.yml --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" apache_global_vhost_settings: | DirectoryIndex index.php index.htm apache_vhosts: - servername: \"website\" documentroot: \"{{ dest }}current/\" # <1> tasks: - name: create directory for website file: path: /var/www/site/ state: directory mode: 0755 - name: install git package: name: git state: latest roles: - { role: geerlingguy.apache } <1> Modify this line Change the playbook for the deployment playbook-deploy.yml --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"log\" ansistrano_git_repo_tree: 'html' # <1> roles: - { role: ansistrano.deploy } <1> Modify this line Don't forget to run both of the playbooks Check on the client machine: $ tree -F /var/www/site/ /var/www/site/ \u251c\u2500\u2500 current -> ./releases/20210722161542Z/ \u251c\u2500\u2500 releases/ \u2502 \u251c\u2500\u2500 20210722160318Z/ \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u2514\u2500\u2500 html/ \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u251c\u2500\u2500 20210722160631Z/ \u2502 \u2502 \u251c\u2500\u2500 REVISION \u2502 \u2502 \u251c\u2500\u2500 css -> ../../shared/css/ \u2502 \u2502 \u251c\u2500\u2500 html/ \u2502 \u2502 \u2502 \u2514\u2500\u2500 index.htm \u2502 \u2502 \u251c\u2500\u2500 img -> ../../shared/img/ \u2502 \u2502 \u2514\u2500\u2500 logs -> ../../shared/logs \u2502 \u2514\u2500\u2500 20210722161542Z/ \u2502 \u251c\u2500\u2500 REVISION \u2502 \u251c\u2500\u2500 css -> ../../shared/css/ \u2502 \u251c\u2500\u2500 img -> ../../shared/img/ \u2502 \u251c\u2500\u2500 index.htm \u2502 \u2514\u2500\u2500 logs -> ../../shared/logs \u251c\u2500\u2500 repo/ \u2502 \u2514\u2500\u2500 html/ \u2502 \u2514\u2500\u2500 index.htm \u2514\u2500\u2500 shared/ \u251c\u2500\u2500 css/ \u251c\u2500\u2500 img/ \u2514\u2500\u2500 logs <1> Please note the absence of html","title":"Use a sub-directory of the repository for deployment"},{"location":"books/learning_ansible/05-deployments/#managing-git-branch-or-tags","text":"The ansistrano_git_branch variable is used to specify a branch or tag to deploy. Deploy the releases/v1.1.0 branch: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"log\" ansistrano_git_repo_tree: 'html' ansistrano_git_branch: 'releases/v1.1.0' roles: - { role: ansistrano.deploy } !!! Note You can have fun, during the deployment, refreshing your browser, to see in 'live' the change. $ curl http://192.168.1.11 <html> <head> <title>Demo Ansible</title> </head> <body> <h1>Version 1.0.1</h1> </body> <html> Deploy the v2.0.0 tag: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"log\" ansistrano_git_repo_tree: 'html' ansistrano_git_branch: 'v2.0.0' roles: - { role: ansistrano.deploy } $ curl http://192.168.1.11 <html> <head> <title>Demo Ansible</title> </head> <body> <h1>Version 2.0.0</h1> </body> <html>","title":"Managing git branch or tags"},{"location":"books/learning_ansible/05-deployments/#actions-between-deployment-steps","text":"A deployment with Ansistrano respects the following steps: Setup Update Code Symlink Shared Symlink Clean Up It is possible to intervene before and after each of these steps. A playbook can be included through the variables provided for this purpose: ansistrano_before_<task>_tasks_file or ansistrano_after_<task>_tasks_file Easy example: send an email (or whatever you want like Slack notification) at the beginning of the deployment: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"logs\" ansistrano_git_repo_tree: 'html' ansistrano_git_branch: 'v2.0.0' ansistrano_before_setup_tasks_file: \"{{ playbook_dir }}/deploy/before-setup-tasks.yml\" roles: - { role: ansistrano.deploy } Create the file deploy/before-setup-tasks.yml : --- - name: Send a mail mail: subject: Starting deployment on {{ ansible_hostname }}. delegate_to: localhost TASK [ansistrano.deploy : include] ************************************************************************************* included: /home/ansible/deploy/before-setup-tasks.yml for 192.168.10.11 TASK [ansistrano.deploy : Send a mail] ************************************************************************************* ok: [192.168.10.11 -> localhost] [root] # mailx Heirloom Mail version 12.5 7/5/10. Type ? for help. \"/var/spool/mail/root\": 1 message 1 new >N 1 root@localhost.local Tue Aug 21 14:41 28/946 \"Starting deployment on localhost.\" You will probably have to restart some services at the end of the deployment, to flush caches for example. Let's restart Apache at the end of the deployment: --- - hosts: ansible_clients become: yes become_user: root vars: dest: \"/var/www/site/\" ansistrano_deploy_via: \"git\" ansistrano_git_repo: https://github.com/alemorvan/demo-ansible.git ansistrano_deploy_to: \"{{ dest }}\" ansistrano_keep_releases: 3 ansistrano_shared_paths: - \"img\" - \"css\" ansistrano_shared_files: - \"logs\" ansistrano_git_repo_tree: 'html' ansistrano_git_branch: 'v2.0.0' ansistrano_before_setup_tasks_file: \"{{ playbook_dir }}/deploy/before-setup-tasks.yml\" ansistrano_after_symlink_tasks_file: \"{{ playbook_dir }}/deploy/after-symlink-tasks.yml\" roles: - { role: ansistrano.deploy } Create the file deploy/after-symlink-tasks.yml : --- - name: restart apache systemd: name: httpd state: restarted TASK [ansistrano.deploy : include] ************************************************************************************* included: /home/ansible/deploy/after-symlink-tasks.yml for 192.168.10.11 TASK [ansistrano.deploy : restart apache] ************************************************************************************** changed: [192.168.10.11] As you have seen during this chapter, Ansible can greatly improve the life of the system administrator. Very intelligent roles like Ansistrano are \"must haves\" that quickly become indispensable. Using Ansistrano, ensures that good deployment practices are respected, reduces the time needed to put a system into production, and avoids the risk of potential human errors. The machine works fast, well, and rarely makes mistakes!","title":"Actions between deployment steps"},{"location":"books/learning_ansible/06-large-scale-infrastructure/","text":"Ansible - Large Scale infrastructure In this chapter you will learn how to scale your configuration management system. Objectives : In this chapter you will learn how to: :heavy_check_mark: Organize your code for large infrastructure; :heavy_check_mark: Apply all or part of your configuration management to a group of nodes; :checkered_flag: ansible , config management , scale Knowledge : :star: :star: :star: Complexity : :star: :star: :star: :star: Reading time : 30 minutes We have seen in the previous chapters how to organize our code in the form of roles but also how to use some roles for the management of updates (patch management) or the deployment of code. What about configuration management? How to manage the configuration of tens, hundreds, or even thousands of virtual machines with Ansible? The advent of the cloud has changed the traditional methods a bit. The VM is configured at deployment. If its configuration is no longer compliant, it is destroyed and replaced by a new one. The organization of the configuration management system presented in this chapter will respond to these two ways of consuming IT: \"one-shot\" use or regular \"re-configuration\" of a fleet. However, be careful: using Ansible to ensure park compliance requires changing work habits. It is no longer possible to manually modify the configuration of a service manager without seeing these modifications overwritten the next time Ansible is run. !!! Note What we are going to set up below is not Ansible's favorite terrain. Technologies like Puppet or Salt will do much better. Let's remember that Ansible is a Swiss army knife of automation and is agentless, which explains the differences in performance. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/sample_setup.html) Variables storage The first thing we have to discuss is the separation between data and Ansible code. As the code gets larger and more complex, it will be more and more complicated to modify the variables it contains. To ensure the maintenance of your site, the most important thing is correctly separating the variables from the Ansible code. We haven't discussed it here yet, but you should know that Ansible can automatically load the variables it finds in specific folders depending on the inventory name of the managed node, or its member groups. The Ansible documentation suggests that we organize our code as below: inventories/ production/ hosts # inventory file for production servers group_vars/ group1.yml # here we assign variables to particular groups group2.yml host_vars/ hostname1.yml # here we assign variables to particular systems hostname2.yml If the targeted node is hostname1 of group1 , the variables contained in the hostname1.yml and group1.yml files will be automatically loaded. It's a nice way to store all the data for all your roles in the same place. In this way, the inventory file of your server becomes its identity card. It contains all the variables that differ from the default variables for your server. From the point of view of centralization of variables, it becomes essential to organize the naming of its variables in the roles by prefixing them, for example, with the name of the role. It is also recommended to use flat variable names rather than dictionaries. For example, if you want to make the PermitRootLogin value in the sshd_config file a variable, a good variable name could be sshd_config_permitrootlogin (instead of sshd.config.permitrootlogin which could also be a good variable name). About Ansible tags The use of Ansible tags allows you to execute or skip a part of the tasks in your code. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html) For example, let's modify our users creation task: - name: add users user: name: \"{{ item }}\" state: present groups: \"users\" loop: - antoine - patrick - steven - xavier tags: users You can now play only the tasks with the tag users with the ansible-playbook option --tags : ansible-playbook -i inventories/production/hosts --tags users site.yml You can also use the --skip-tags option. About the directory layout Let's focus on a proposal for the organization of files and directories necessary for the proper functioning of a CMS (Content Management System). Our starting point will be the site.yml file. This file is a bit like the orchestra conductor of the CMS since it will only include the necessary roles for the target nodes if needed: --- - name: \"Config Management for {{ target }}\" hosts: \"{{ target }}\" roles: - role: roles/functionality1 - role: roles/functionality2 Of course, those roles must be created under the roles directory at the same level as the site.yml file. I like to manage my global vars inside a vars/global_vars.yml , even if I could store them inside a file located at inventories/production/group_vars/all.yml --- - name: \"Config Management for {{ target }}\" hosts: \"{{ target }}\" vars_files: - vars/global_vars.yml roles: - role: roles/functionality1 - role: roles/functionality2 I also like to keep the possibility of disabling a functionality. So I include my roles with a condition and a default value like this: --- - name: \"Config Management for {{ target }}\" hosts: \"{{ target }}\" vars_files: - vars/global_vars.yml roles: - role: roles/functionality1 when: - enable_functionality1|default(true) - role: roles/functionality2 when: - enable_functionality2|default(false) Don't forget to use the tags: - name: \"Config Management for {{ target }}\" hosts: \"{{ target }}\" vars_files: - vars/global_vars.yml roles: - role: roles/functionality1 when: - enable_functionality1|default(true) tags: - functionality1 - role: roles/functionality2 when: - enable_functionality2|default(false) tags: - functionality2 You should get something like this: $ tree cms cms \u251c\u2500\u2500 inventories \u2502 \u2514\u2500\u2500 production \u2502 \u251c\u2500\u2500 group_vars \u2502 \u2502 \u2514\u2500\u2500 plateform.yml \u2502 \u251c\u2500\u2500 hosts \u2502 \u2514\u2500\u2500 host_vars \u2502 \u251c\u2500\u2500 client1.yml \u2502 \u2514\u2500\u2500 client2.yml \u251c\u2500\u2500 roles \u2502 \u251c\u2500\u2500 functionality1 \u2502 \u2502 \u251c\u2500\u2500 defaults \u2502 \u2502 \u2502 \u2514\u2500\u2500 main.yml \u2502 \u2502 \u2514\u2500\u2500 tasks \u2502 \u2502 \u2514\u2500\u2500 main.yml \u2502 \u2514\u2500\u2500 functionality2 \u2502 \u251c\u2500\u2500 defaults \u2502 \u2502 \u2514\u2500\u2500 main.yml \u2502 \u2514\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 site.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 global_vars.yml !!! Note You are free to develop your roles within a collection Tests Let's launch the playbook and run some tests: $ ansible-playbook -i inventories/production/hosts -e \"target=client1\" site.yml PLAY [Config Management for client1] **************************************************************************** TASK [Gathering Facts] ****************************************************************************************** ok: [client1] TASK [roles/functionality1 : Task in functionality 1] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 1\" } TASK [roles/functionality2 : Task in functionality 2] ********************************************************* skipping: [client1] PLAY RECAP ****************************************************************************************************** client1 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 As you can see, by default, only the tasks of the functionality1 role are played. Let's activate in the inventory the functionality2 for our targeted node and rerun the playbook: $ vim inventories/production/host_vars/client1.yml --- enable_functionality2: true $ ansible-playbook -i inventories/production/hosts -e \"target=client1\" site.yml PLAY [Config Management for client1] **************************************************************************** TASK [Gathering Facts] ****************************************************************************************** ok: [client1] TASK [roles/functionality1 : Task in functionality 1] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 1\" } TASK [roles/functionality2 : Task in functionality 2] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 2\" } PLAY RECAP ****************************************************************************************************** client1 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Try to apply only functionality2 : $ ansible-playbook -i inventories/production/hosts -e \"target=client1\" --tags functionality2 site.yml PLAY [Config Management for client1] **************************************************************************** TASK [Gathering Facts] ****************************************************************************************** ok: [client1] TASK [roles/functionality2 : Task in functionality 2] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 2\" } PLAY RECAP ****************************************************************************************************** client1 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Let's run on the whole inventory: $ ansible-playbook -i inventories/production/hosts -e \"target=plateform\" site.yml PLAY [Config Management for plateform] ************************************************************************** TASK [Gathering Facts] ****************************************************************************************** ok: [client1] ok: [client2] TASK [roles/functionality1 : Task in functionality 1] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 1\" } ok: [client2] => { \"msg\": \"You are in functionality 1\" } TASK [roles/functionality2 : Task in functionality 2] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 2\" } skipping: [client2] PLAY RECAP ****************************************************************************************************** client1 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 client2 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 As you can see, functionality2 is only played on the client1 . Benefits By following the advice given in the Ansible documentation, you will quickly obtain a: easily maintainable source code even if it contains a large number of roles a relatively fast, repeatable compliance system that you can apply partially or completely can be adapted on a case-by-case basis and by servers the specifics of your information system are separated from the code, easily audit-able, and centralized in the inventory files of your configuration management.","title":"Large Scale infrastructure"},{"location":"books/learning_ansible/06-large-scale-infrastructure/#ansible-large-scale-infrastructure","text":"In this chapter you will learn how to scale your configuration management system. Objectives : In this chapter you will learn how to: :heavy_check_mark: Organize your code for large infrastructure; :heavy_check_mark: Apply all or part of your configuration management to a group of nodes; :checkered_flag: ansible , config management , scale Knowledge : :star: :star: :star: Complexity : :star: :star: :star: :star: Reading time : 30 minutes We have seen in the previous chapters how to organize our code in the form of roles but also how to use some roles for the management of updates (patch management) or the deployment of code. What about configuration management? How to manage the configuration of tens, hundreds, or even thousands of virtual machines with Ansible? The advent of the cloud has changed the traditional methods a bit. The VM is configured at deployment. If its configuration is no longer compliant, it is destroyed and replaced by a new one. The organization of the configuration management system presented in this chapter will respond to these two ways of consuming IT: \"one-shot\" use or regular \"re-configuration\" of a fleet. However, be careful: using Ansible to ensure park compliance requires changing work habits. It is no longer possible to manually modify the configuration of a service manager without seeing these modifications overwritten the next time Ansible is run. !!! Note What we are going to set up below is not Ansible's favorite terrain. Technologies like Puppet or Salt will do much better. Let's remember that Ansible is a Swiss army knife of automation and is agentless, which explains the differences in performance. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/sample_setup.html)","title":"Ansible - Large Scale infrastructure"},{"location":"books/learning_ansible/06-large-scale-infrastructure/#variables-storage","text":"The first thing we have to discuss is the separation between data and Ansible code. As the code gets larger and more complex, it will be more and more complicated to modify the variables it contains. To ensure the maintenance of your site, the most important thing is correctly separating the variables from the Ansible code. We haven't discussed it here yet, but you should know that Ansible can automatically load the variables it finds in specific folders depending on the inventory name of the managed node, or its member groups. The Ansible documentation suggests that we organize our code as below: inventories/ production/ hosts # inventory file for production servers group_vars/ group1.yml # here we assign variables to particular groups group2.yml host_vars/ hostname1.yml # here we assign variables to particular systems hostname2.yml If the targeted node is hostname1 of group1 , the variables contained in the hostname1.yml and group1.yml files will be automatically loaded. It's a nice way to store all the data for all your roles in the same place. In this way, the inventory file of your server becomes its identity card. It contains all the variables that differ from the default variables for your server. From the point of view of centralization of variables, it becomes essential to organize the naming of its variables in the roles by prefixing them, for example, with the name of the role. It is also recommended to use flat variable names rather than dictionaries. For example, if you want to make the PermitRootLogin value in the sshd_config file a variable, a good variable name could be sshd_config_permitrootlogin (instead of sshd.config.permitrootlogin which could also be a good variable name).","title":"Variables storage"},{"location":"books/learning_ansible/06-large-scale-infrastructure/#about-ansible-tags","text":"The use of Ansible tags allows you to execute or skip a part of the tasks in your code. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html) For example, let's modify our users creation task: - name: add users user: name: \"{{ item }}\" state: present groups: \"users\" loop: - antoine - patrick - steven - xavier tags: users You can now play only the tasks with the tag users with the ansible-playbook option --tags : ansible-playbook -i inventories/production/hosts --tags users site.yml You can also use the --skip-tags option.","title":"About Ansible tags"},{"location":"books/learning_ansible/06-large-scale-infrastructure/#about-the-directory-layout","text":"Let's focus on a proposal for the organization of files and directories necessary for the proper functioning of a CMS (Content Management System). Our starting point will be the site.yml file. This file is a bit like the orchestra conductor of the CMS since it will only include the necessary roles for the target nodes if needed: --- - name: \"Config Management for {{ target }}\" hosts: \"{{ target }}\" roles: - role: roles/functionality1 - role: roles/functionality2 Of course, those roles must be created under the roles directory at the same level as the site.yml file. I like to manage my global vars inside a vars/global_vars.yml , even if I could store them inside a file located at inventories/production/group_vars/all.yml --- - name: \"Config Management for {{ target }}\" hosts: \"{{ target }}\" vars_files: - vars/global_vars.yml roles: - role: roles/functionality1 - role: roles/functionality2 I also like to keep the possibility of disabling a functionality. So I include my roles with a condition and a default value like this: --- - name: \"Config Management for {{ target }}\" hosts: \"{{ target }}\" vars_files: - vars/global_vars.yml roles: - role: roles/functionality1 when: - enable_functionality1|default(true) - role: roles/functionality2 when: - enable_functionality2|default(false) Don't forget to use the tags: - name: \"Config Management for {{ target }}\" hosts: \"{{ target }}\" vars_files: - vars/global_vars.yml roles: - role: roles/functionality1 when: - enable_functionality1|default(true) tags: - functionality1 - role: roles/functionality2 when: - enable_functionality2|default(false) tags: - functionality2 You should get something like this: $ tree cms cms \u251c\u2500\u2500 inventories \u2502 \u2514\u2500\u2500 production \u2502 \u251c\u2500\u2500 group_vars \u2502 \u2502 \u2514\u2500\u2500 plateform.yml \u2502 \u251c\u2500\u2500 hosts \u2502 \u2514\u2500\u2500 host_vars \u2502 \u251c\u2500\u2500 client1.yml \u2502 \u2514\u2500\u2500 client2.yml \u251c\u2500\u2500 roles \u2502 \u251c\u2500\u2500 functionality1 \u2502 \u2502 \u251c\u2500\u2500 defaults \u2502 \u2502 \u2502 \u2514\u2500\u2500 main.yml \u2502 \u2502 \u2514\u2500\u2500 tasks \u2502 \u2502 \u2514\u2500\u2500 main.yml \u2502 \u2514\u2500\u2500 functionality2 \u2502 \u251c\u2500\u2500 defaults \u2502 \u2502 \u2514\u2500\u2500 main.yml \u2502 \u2514\u2500\u2500 tasks \u2502 \u2514\u2500\u2500 main.yml \u251c\u2500\u2500 site.yml \u2514\u2500\u2500 vars \u2514\u2500\u2500 global_vars.yml !!! Note You are free to develop your roles within a collection","title":"About the directory layout"},{"location":"books/learning_ansible/06-large-scale-infrastructure/#tests","text":"Let's launch the playbook and run some tests: $ ansible-playbook -i inventories/production/hosts -e \"target=client1\" site.yml PLAY [Config Management for client1] **************************************************************************** TASK [Gathering Facts] ****************************************************************************************** ok: [client1] TASK [roles/functionality1 : Task in functionality 1] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 1\" } TASK [roles/functionality2 : Task in functionality 2] ********************************************************* skipping: [client1] PLAY RECAP ****************************************************************************************************** client1 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 As you can see, by default, only the tasks of the functionality1 role are played. Let's activate in the inventory the functionality2 for our targeted node and rerun the playbook: $ vim inventories/production/host_vars/client1.yml --- enable_functionality2: true $ ansible-playbook -i inventories/production/hosts -e \"target=client1\" site.yml PLAY [Config Management for client1] **************************************************************************** TASK [Gathering Facts] ****************************************************************************************** ok: [client1] TASK [roles/functionality1 : Task in functionality 1] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 1\" } TASK [roles/functionality2 : Task in functionality 2] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 2\" } PLAY RECAP ****************************************************************************************************** client1 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Try to apply only functionality2 : $ ansible-playbook -i inventories/production/hosts -e \"target=client1\" --tags functionality2 site.yml PLAY [Config Management for client1] **************************************************************************** TASK [Gathering Facts] ****************************************************************************************** ok: [client1] TASK [roles/functionality2 : Task in functionality 2] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 2\" } PLAY RECAP ****************************************************************************************************** client1 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Let's run on the whole inventory: $ ansible-playbook -i inventories/production/hosts -e \"target=plateform\" site.yml PLAY [Config Management for plateform] ************************************************************************** TASK [Gathering Facts] ****************************************************************************************** ok: [client1] ok: [client2] TASK [roles/functionality1 : Task in functionality 1] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 1\" } ok: [client2] => { \"msg\": \"You are in functionality 1\" } TASK [roles/functionality2 : Task in functionality 2] ********************************************************* ok: [client1] => { \"msg\": \"You are in functionality 2\" } skipping: [client2] PLAY RECAP ****************************************************************************************************** client1 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 client2 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 As you can see, functionality2 is only played on the client1 .","title":"Tests"},{"location":"books/learning_ansible/06-large-scale-infrastructure/#benefits","text":"By following the advice given in the Ansible documentation, you will quickly obtain a: easily maintainable source code even if it contains a large number of roles a relatively fast, repeatable compliance system that you can apply partially or completely can be adapted on a case-by-case basis and by servers the specifics of your information system are separated from the code, easily audit-able, and centralized in the inventory files of your configuration management.","title":"Benefits"},{"location":"books/learning_ansible/07-working-with-filters/","text":"Ansible - Working with filters In this chapter you will learn how to transform data with jinja filters. Objectives : In this chapter you will learn how to: :heavy_check_mark: Transform data structures as dictionnaries or lists; :heavy_check_mark: Transform variables; :checkered_flag: ansible , jinja , filters Knowledge : :star: :star: :star: Complexity : :star: :star: :star: :star: Reading time : 20 minutes We have already had the opportunity, during the previous chapters, to use the jinja filters. These filters, written in python, allow us to manipulate and transform our ansible variables. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html). Throughout this chapter, we will use the following playbook to test the different filters presented: - name: Manipulating the data hosts: localhost gather_facts: false vars: zero: 0 zero_string: \"0\" non_zero: 4 true_booleen: True true_non_booleen: \"True\" false_boolean: False false_non_boolean: \"False\" whatever: \"It's false!\" user_name: antoine my_dictionary: key1: value1 key2: value2 my_simple_list: - value_list_1 - value_list_2 - value_list_3 my_simple_list_2: - value_list_3 - value_list_4 - value_list_5 my_list: - element: element1 value: value1 - element: element2 value: value2 tasks: - name: Print an integer debug: var: zero !!! Note The following is a non-exhaustive list of filters that you are most likely to encounter or need. Fortunately, there are many others. You could even write your own! The playbook will be played as follows: ansible-playbook play-filter.yml Converting data Data can be converted from one type to another. To know the type of a data (the type in python language), you have to use the type_debug filter. Example: - name: Display the type of a variable debug: var: true_boolean|type_debug which gives us: TASK [Display the type of a variable] ****************************************************************** ok: [localhost] => { \"true_boolean|type_debug\": \"bool\" } It is possible to transform an integer into a string: - name: Transforming a variable type debug: var: zero|string TASK [Transforming a variable type] *************************************************************** ok: [localhost] => { \"zero|string\": \"0\" } Transform a string into an integer: - name: Transforming a variable type debug: var: zero_string|int or a variable into a boolean: - name: Display an integer as a boolean debug: var: non_zero | bool - name: Display a string as a boolean debug: var: true_non_boolean | bool - name: Display a string as a boolean debug: var: false_non_boolean | bool - name: Display a string as a boolean debug: var: whatever | bool A character string can be transformed into upper or lower case: - name: Lowercase a string of characters debug: var: whatever | lower - name: Upercase a string of characters debug: var: whatever | upper which gives us: TASK [Lowercase a string of characters] ***************************************************** ok: [localhost] => { \"whatever | lower\": \"it's false!\" } TASK [Upercase a string of characters] ***************************************************** ok: [localhost] => { \"whatever | upper\": \"IT'S FALSE!\" } The replace filter allows you to replace characters by others. Here we remove spaces or even replace a word: - name: Replace a character in a string debug: var: whatever | replace(\" \", \"\") - name: Replace a word in a string debug: var: whatever | replace(\"false\", \"true\") which gives us: TASK [Replace a character in a string] ***************************************************** ok: [localhost] => { \"whatever | replace(\\\" \\\", \\\"\\\")\": \"It'sfalse!\" } TASK [Replace a word in a string] ***************************************************** ok: [localhost] => { \"whatever | replace(\\\"false\\\", \\\"true\\\")\": \"It's true !\" } The split filter splits a string into a list based on a character: - name: Cutting a string of characters debug: var: whatever | split(\" \", \"\") TASK [Cutting a string of characters] ***************************************************** ok: [localhost] => { \"whatever | split(\\\" \\\")\": [ \"It's\", \"false!\" ] } Join the elements of a list It is frequent to have to join the different elements in a single string. We can then specify a character or a string to insert between each element. - name: Joining elements of a list debug: var: my_simple_list|join(\",\") - name: Joining elements of a list debug: var: my_simple_list|join(\" | \") which gives us: TASK [Joining elements of a list] ***************************************************************** ok: [localhost] => { \"my_simple_list|join(\\\",\\\")\": \"value_list_1,value_list_2,value_list_3\" } TASK [Joining elements of a list] ***************************************************************** ok: [localhost] => { \"my_simple_list|join(\\\" | \\\")\": \"value_list_1 | value_list_2 | value_list_3\" } Transforming dictionaries into lists (and vice versa) The filters dict2items and itemstodict , a bit more complex to implement, are frequently used, especially in loops. Note that it is possible to specify the name of the key and of the value to use in the transformation. - name: Display a dictionary debug: var: my_dictionary - name: Transforming a dictionary into a list debug: var: my_dictionary | dict2items - name: Transforming a dictionary into a list debug: var: my_dictionary | dict2items(key_name='key', value_name='value') - name: Transforming a list into a dictionary debug: var: my_list | items2dict(key_name='element', value_name='value') TASK [Display a dictionary] ************************************************************************* ok: [localhost] => { \"my_dictionary\": { \"key1\": \"value1\", \"key2\": \"value2\" } } TASK [Transforming a dictionary into a list] ************************************************************* ok: [localhost] => { \"my_dictionary | dict2items\": [ { \"key\": \"key1\", \"value\": \"value1\" }, { \"key\": \"key2\", \"value\": \"value2\" } ] } TASK [Transforming a dictionary into a list] ************************************************************* ok: [localhost] => { \"my_dictionary | dict2items (key_name = 'key', value_name = 'value')\": [ { \"key\": \"key1\", \"value\": \"value1\" }, { \"key\": \"key2\", \"value\": \"value2\" } ] } TASK [Transforming a list into a dictionary] ************************************************************ ok: [localhost] => { \"my_list | items2dict(key_name='element', value_name='value')\": { \"element1\": \"value1\", \"element2\": \"value2\" } } Working with lists It is possible to merge or filter data from one or more lists: - name: Merger of two lists debug: var: my_simple_list | union(my_simple_list_2) ok: [localhost] => { \"my_simple_list | union(my_simple_list_2)\": [ \"value_list_1\", \"value_list_2\", \"value_list_3\", \"value_list_4\", \"value_list_5\" ] } To keep only the intersection of the 2 lists (the values present in the 2 lists): - name: Merger of two lists debug: var: my_simple_list | intersect(my_simple_list_2) TASK [Merger of two lists] ******************************************************************************* ok: [localhost] => { \"my_simple_list | intersect(my_simple_list_2)\": [ \"value_list_3\" ] } Or on the contrary keep only the difference (the values that do not exist in the second list): - name: Merger of two lists debug: var: my_simple_list | difference(my_simple_list_2) TASK [Merger of two lists] ******************************************************************************* ok: [localhost] => { \"my_simple_list | difference(my_simple_list_2)\": [ \"value_list_1\", \"value_list_2\", ] } If your list contains non-unique values, it is also possible to filter them with the unique filter. - name: Unique value in a list debug: var: my_simple_list | unique Transformation json/yaml You may have to import json data (from an API for example) or export data in yaml or json. - name: Display a variable in yaml debug: var: my_list | to_nice_yaml(indent=4) - name: Display a variable in json debug: var: my_list | to_nice_json(indent=4) TASK [Display a variable in yaml] ******************************************************************** ok: [localhost] => { \"my_list | to_nice_yaml(indent=4)\": \"- element: element1\\n value: value1\\n- element: element2\\n value: value2\\n\" } TASK [Display a variable in json] ******************************************************************** ok: [localhost] => { \"my_list | to_nice_json(indent=4)\": \"[\\n {\\n \\\"element\\\": \\\"element1\\\",\\n \\\"value\\\": \\\"value1\\\"\\n },\\n {\\n \\\"element\\\": \\\"element2\\\",\\n \\\"value\\\": \\\"value2\\\"\\n }\\n]\" } Default values, optional variables, protect variables You will quickly be confronted with errors in the execution of your playbooks if you do not provide default values for your variables, or if you do not protect them. The value of a variable can be substituted for another one if it does not exist with the default filter: - name: Default value debug: var: variablethatdoesnotexists | default(whatever) TASK [Default value] ******************************************************************************** ok: [localhost] => { \"variablethatdoesnotexists | default(whatever)\": \"It's false!\" } Note the presence of the apostrophe ' which should be protected, for example, if you were using the shell module: - name: Default value debug: var: variablethatdoesnotexists | default(whatever| quote) TASK [Default value] ******************************************************************************** ok: [localhost] => { \"variablethatdoesnotexists | default(whatever|quote)\": \"'It'\\\"'\\\"'s false!'\" } Finally, an optional variable in a module can be ignored if it does not exist with the keyword omit in the default filter, which will save you an error at runtime. - name: Add a new user ansible.builtin.user: name: \"{{ user_name }}\" comment: \"{{ user_comment | default(omit) }}\" Associate a value according to another one ( ternary ) Sometimes you need to use a condition to assign a value to a variable, in which case it is common to go through a set_fact step. This can be avoided by using the ternary filter: - name: Default value debug: var: (user_name == 'antoine') | ternary('admin', 'normal_user') TASK [Default value] ******************************************************************************** ok: [localhost] => { \"(user_name == 'antoine') | ternary('admin', 'normal_user')\": \"admin\" } Some other filters {{ 10000 | random }} : as its name indicates, gives a random value. {{ my_simple_list | first }} : extracts the first element of the list. {{ my_simple_list | length }} : gives the length (of a list or a string). {{ ip_list | ansible.netcommon.ipv4 }} : only displays v4 IPs. Without dwelling on this, if you need, there are many filters dedicated to the network. {{ user_password | password_hash('sha512') }} : generates a hashed password in sha512.","title":"Working With Filters"},{"location":"books/learning_ansible/07-working-with-filters/#ansible-working-with-filters","text":"In this chapter you will learn how to transform data with jinja filters. Objectives : In this chapter you will learn how to: :heavy_check_mark: Transform data structures as dictionnaries or lists; :heavy_check_mark: Transform variables; :checkered_flag: ansible , jinja , filters Knowledge : :star: :star: :star: Complexity : :star: :star: :star: :star: Reading time : 20 minutes We have already had the opportunity, during the previous chapters, to use the jinja filters. These filters, written in python, allow us to manipulate and transform our ansible variables. !!! Note More information can be [found here](https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html). Throughout this chapter, we will use the following playbook to test the different filters presented: - name: Manipulating the data hosts: localhost gather_facts: false vars: zero: 0 zero_string: \"0\" non_zero: 4 true_booleen: True true_non_booleen: \"True\" false_boolean: False false_non_boolean: \"False\" whatever: \"It's false!\" user_name: antoine my_dictionary: key1: value1 key2: value2 my_simple_list: - value_list_1 - value_list_2 - value_list_3 my_simple_list_2: - value_list_3 - value_list_4 - value_list_5 my_list: - element: element1 value: value1 - element: element2 value: value2 tasks: - name: Print an integer debug: var: zero !!! Note The following is a non-exhaustive list of filters that you are most likely to encounter or need. Fortunately, there are many others. You could even write your own! The playbook will be played as follows: ansible-playbook play-filter.yml","title":"Ansible - Working with filters"},{"location":"books/learning_ansible/07-working-with-filters/#converting-data","text":"Data can be converted from one type to another. To know the type of a data (the type in python language), you have to use the type_debug filter. Example: - name: Display the type of a variable debug: var: true_boolean|type_debug which gives us: TASK [Display the type of a variable] ****************************************************************** ok: [localhost] => { \"true_boolean|type_debug\": \"bool\" } It is possible to transform an integer into a string: - name: Transforming a variable type debug: var: zero|string TASK [Transforming a variable type] *************************************************************** ok: [localhost] => { \"zero|string\": \"0\" } Transform a string into an integer: - name: Transforming a variable type debug: var: zero_string|int or a variable into a boolean: - name: Display an integer as a boolean debug: var: non_zero | bool - name: Display a string as a boolean debug: var: true_non_boolean | bool - name: Display a string as a boolean debug: var: false_non_boolean | bool - name: Display a string as a boolean debug: var: whatever | bool A character string can be transformed into upper or lower case: - name: Lowercase a string of characters debug: var: whatever | lower - name: Upercase a string of characters debug: var: whatever | upper which gives us: TASK [Lowercase a string of characters] ***************************************************** ok: [localhost] => { \"whatever | lower\": \"it's false!\" } TASK [Upercase a string of characters] ***************************************************** ok: [localhost] => { \"whatever | upper\": \"IT'S FALSE!\" } The replace filter allows you to replace characters by others. Here we remove spaces or even replace a word: - name: Replace a character in a string debug: var: whatever | replace(\" \", \"\") - name: Replace a word in a string debug: var: whatever | replace(\"false\", \"true\") which gives us: TASK [Replace a character in a string] ***************************************************** ok: [localhost] => { \"whatever | replace(\\\" \\\", \\\"\\\")\": \"It'sfalse!\" } TASK [Replace a word in a string] ***************************************************** ok: [localhost] => { \"whatever | replace(\\\"false\\\", \\\"true\\\")\": \"It's true !\" } The split filter splits a string into a list based on a character: - name: Cutting a string of characters debug: var: whatever | split(\" \", \"\") TASK [Cutting a string of characters] ***************************************************** ok: [localhost] => { \"whatever | split(\\\" \\\")\": [ \"It's\", \"false!\" ] }","title":"Converting data"},{"location":"books/learning_ansible/07-working-with-filters/#join-the-elements-of-a-list","text":"It is frequent to have to join the different elements in a single string. We can then specify a character or a string to insert between each element. - name: Joining elements of a list debug: var: my_simple_list|join(\",\") - name: Joining elements of a list debug: var: my_simple_list|join(\" | \") which gives us: TASK [Joining elements of a list] ***************************************************************** ok: [localhost] => { \"my_simple_list|join(\\\",\\\")\": \"value_list_1,value_list_2,value_list_3\" } TASK [Joining elements of a list] ***************************************************************** ok: [localhost] => { \"my_simple_list|join(\\\" | \\\")\": \"value_list_1 | value_list_2 | value_list_3\" }","title":"Join the elements of a list"},{"location":"books/learning_ansible/07-working-with-filters/#transforming-dictionaries-into-lists-and-vice-versa","text":"The filters dict2items and itemstodict , a bit more complex to implement, are frequently used, especially in loops. Note that it is possible to specify the name of the key and of the value to use in the transformation. - name: Display a dictionary debug: var: my_dictionary - name: Transforming a dictionary into a list debug: var: my_dictionary | dict2items - name: Transforming a dictionary into a list debug: var: my_dictionary | dict2items(key_name='key', value_name='value') - name: Transforming a list into a dictionary debug: var: my_list | items2dict(key_name='element', value_name='value') TASK [Display a dictionary] ************************************************************************* ok: [localhost] => { \"my_dictionary\": { \"key1\": \"value1\", \"key2\": \"value2\" } } TASK [Transforming a dictionary into a list] ************************************************************* ok: [localhost] => { \"my_dictionary | dict2items\": [ { \"key\": \"key1\", \"value\": \"value1\" }, { \"key\": \"key2\", \"value\": \"value2\" } ] } TASK [Transforming a dictionary into a list] ************************************************************* ok: [localhost] => { \"my_dictionary | dict2items (key_name = 'key', value_name = 'value')\": [ { \"key\": \"key1\", \"value\": \"value1\" }, { \"key\": \"key2\", \"value\": \"value2\" } ] } TASK [Transforming a list into a dictionary] ************************************************************ ok: [localhost] => { \"my_list | items2dict(key_name='element', value_name='value')\": { \"element1\": \"value1\", \"element2\": \"value2\" } }","title":"Transforming dictionaries into lists (and vice versa)"},{"location":"books/learning_ansible/07-working-with-filters/#working-with-lists","text":"It is possible to merge or filter data from one or more lists: - name: Merger of two lists debug: var: my_simple_list | union(my_simple_list_2) ok: [localhost] => { \"my_simple_list | union(my_simple_list_2)\": [ \"value_list_1\", \"value_list_2\", \"value_list_3\", \"value_list_4\", \"value_list_5\" ] } To keep only the intersection of the 2 lists (the values present in the 2 lists): - name: Merger of two lists debug: var: my_simple_list | intersect(my_simple_list_2) TASK [Merger of two lists] ******************************************************************************* ok: [localhost] => { \"my_simple_list | intersect(my_simple_list_2)\": [ \"value_list_3\" ] } Or on the contrary keep only the difference (the values that do not exist in the second list): - name: Merger of two lists debug: var: my_simple_list | difference(my_simple_list_2) TASK [Merger of two lists] ******************************************************************************* ok: [localhost] => { \"my_simple_list | difference(my_simple_list_2)\": [ \"value_list_1\", \"value_list_2\", ] } If your list contains non-unique values, it is also possible to filter them with the unique filter. - name: Unique value in a list debug: var: my_simple_list | unique","title":"Working with lists"},{"location":"books/learning_ansible/07-working-with-filters/#transformation-jsonyaml","text":"You may have to import json data (from an API for example) or export data in yaml or json. - name: Display a variable in yaml debug: var: my_list | to_nice_yaml(indent=4) - name: Display a variable in json debug: var: my_list | to_nice_json(indent=4) TASK [Display a variable in yaml] ******************************************************************** ok: [localhost] => { \"my_list | to_nice_yaml(indent=4)\": \"- element: element1\\n value: value1\\n- element: element2\\n value: value2\\n\" } TASK [Display a variable in json] ******************************************************************** ok: [localhost] => { \"my_list | to_nice_json(indent=4)\": \"[\\n {\\n \\\"element\\\": \\\"element1\\\",\\n \\\"value\\\": \\\"value1\\\"\\n },\\n {\\n \\\"element\\\": \\\"element2\\\",\\n \\\"value\\\": \\\"value2\\\"\\n }\\n]\" }","title":"Transformation json/yaml"},{"location":"books/learning_ansible/07-working-with-filters/#default-values-optional-variables-protect-variables","text":"You will quickly be confronted with errors in the execution of your playbooks if you do not provide default values for your variables, or if you do not protect them. The value of a variable can be substituted for another one if it does not exist with the default filter: - name: Default value debug: var: variablethatdoesnotexists | default(whatever) TASK [Default value] ******************************************************************************** ok: [localhost] => { \"variablethatdoesnotexists | default(whatever)\": \"It's false!\" } Note the presence of the apostrophe ' which should be protected, for example, if you were using the shell module: - name: Default value debug: var: variablethatdoesnotexists | default(whatever| quote) TASK [Default value] ******************************************************************************** ok: [localhost] => { \"variablethatdoesnotexists | default(whatever|quote)\": \"'It'\\\"'\\\"'s false!'\" } Finally, an optional variable in a module can be ignored if it does not exist with the keyword omit in the default filter, which will save you an error at runtime. - name: Add a new user ansible.builtin.user: name: \"{{ user_name }}\" comment: \"{{ user_comment | default(omit) }}\"","title":"Default values, optional variables, protect variables"},{"location":"books/learning_ansible/07-working-with-filters/#associate-a-value-according-to-another-one-ternary","text":"Sometimes you need to use a condition to assign a value to a variable, in which case it is common to go through a set_fact step. This can be avoided by using the ternary filter: - name: Default value debug: var: (user_name == 'antoine') | ternary('admin', 'normal_user') TASK [Default value] ******************************************************************************** ok: [localhost] => { \"(user_name == 'antoine') | ternary('admin', 'normal_user')\": \"admin\" }","title":"Associate a value according to another one (ternary)"},{"location":"books/learning_ansible/07-working-with-filters/#some-other-filters","text":"{{ 10000 | random }} : as its name indicates, gives a random value. {{ my_simple_list | first }} : extracts the first element of the list. {{ my_simple_list | length }} : gives the length (of a list or a string). {{ ip_list | ansible.netcommon.ipv4 }} : only displays v4 IPs. Without dwelling on this, if you need, there are many filters dedicated to the network. {{ user_password | password_hash('sha512') }} : generates a hashed password in sha512.","title":"Some other filters"},{"location":"books/learning_ansible/08-management-server-optimizations/","text":"Management server optimizations In this chapter, we will review the configuration options that may be of interest to optimize our Ansible management server. The ansible.cfg configuration file Some interesting configuration options to comment on: forks : by default to 5, it is the number of processes that Ansible will launch in parallel to communicate with remote hosts. The higher this number is, the more clients Ansible will be able to manage at the same time, and thus speed up processing. The value you can set is dependent on the CPU/RAM limits of your management server. Note that the default value, 5 , is very small, the Ansible documentation states that many users set it to 50, even 500 or more. gathering : this variable changes the policy for collecting facts. By default, the value is implicit , which implies that facts will be collected systematically. Switching this variable to smart allows for collection facts only when they have not already been collected. Coupled with a facts cache (see below), this option can greatly increase performance. host_key_checking : Be careful with your server security! However, if you are in control of your environment, it can be interesting to disable the key control of remote servers and save some time at the connection. You can also, on remote servers, disable the use of the DNS of the SSH server (in /etc/ssh/sshd_config , option UseDNS no ), this option wastes time at the connection and is, most of the time, only used in the connection logs. ansible_managed : This variable, containing Ansible managed by default, is typically used in file templates that are deployed on remote servers. It allows you to specify to an administrator that the file is managed automatically and that any changes they make to it will potentially be lost. It can be interesting to let the administrators have a more complete messages. Be careful though, if you change this variable, it may cause daemons to restart (via the handlers associated with the templates). ssh_args = -C -o ControlMaster=auto -o ControlPersist=300s -o PreferredAuthentications=publickey : specify the ssh connection options. By disabling all authentication methods other than public key, you can save a lot of time. You can also increase the ControlPersist to improve performance (the documentation suggests that a value equivalent to 30 minutes may be appropriate). The connection to a client will stay open longer and can be reused when reconnecting to the same server, which is a significant time saving. control_path_dir : Specify the path to the connection sockets. If this path is too long, it can cause problems. Consider changing it to something short, such as /tmp/.cp . pipelining : Setting this value to True increases performance by reducing the number of SSH connections needed when running remote modules. You must first make sure that the requiretty option is disabled in the sudoers options (see documentation). Caching the facts Gathering facts is a process that can take some time. It can be interesting to disable this gathering for playbooks that don't need it (via gather_facts option) or to keep these facts in memory in a cache for a certain period of time (for example 24H). These facts can be easily stored in a redis database: sudo yum install redis sudo systemctl start redis sudo systemctl enable redis sudo pip3 install redis Don't forget to modify the ansible configuration: fact_caching = redis fact_caching_timeout = 86400 fact_caching_connection = localhost:6379:0 To check the correct operation, it is enough to request the redis server: redis-cli 127.0.0.1:6379> keys * 127.0.0.1:6379> get ansible_facts_SERVERNAME Using Vault The various passwords and secrets cannot be stored in clear text with the Ansible source code, either locally on the management server or on a possible source code manager. Ansible proposes using an encryption manager: ansible-vault . The principle is to encrypt a variable or a whole file with the ansible-vault command. Ansible will be able to decrypt this file at runtime by retrieving the encryption key from the file (for example) /etc/ansible/ansible.cfg . The latter can also be a python script or other. Edit the /etc/ansible/ansible.cfg file: #vault_password_file = /path/to/vault_password_file vault_password_file = /etc/ansible/vault_pass Store the password in this file /etc/ansible/vault_pass and assign necessary restrictive rights: mysecretpassword You can then encrypt your files with the command: ansible-vault encrypt myfile.yml A file encrypted by ansible-vault can be easily recognized by its header: $ANSIBLE_VAULT;1.1;AES256 35376532343663353330613133663834626136316234323964333735363333396136613266383966 6664322261633261356566383438393738386165333966660a343032663233343762633936313630 34373230124561663766306134656235386233323964336239336661653433663036633334366661 6434656630306261650a313364636261393931313739363931336664386536333766326264633330 6334 Once a file is encrypted, it can still be edited with the command: ansible-vault edit myfile.yml You can also deport your password storage to any password manager. For example, to retrieve a password that would be stored in the rundeck vault: #!/usr/bin/env python # -*- coding: utf-8 -*- import urllib.request import io import ssl def get_password(): ''' :return: Vault password :return_type: str ''' ctx = ssl.create_default_context() ctx.check_hostname = False ctx.verify_mode = ssl.CERT_NONE url = 'https://rundeck.rockylinux.org/api/11/storage/keys/ansible/vault' req = urllib.request.Request(url, headers={ 'Accept': '*/*', 'X-Rundeck-Auth-Token': '****token-rundeck****' }) response = urllib.request.urlopen(req, context=ctx) return response.read().decode('utf-8') if __name__ == '__main__': print(get_password()) Working with Windows servers It will be necessary to install on the management server several packages: Via the package manager: sudo dnf install python38-devel krb5-devel krb5-libs krb5-workstation and configure the /etc/krb5.conf file to specify the correct realms : [realms] ROCKYLINUX.ORG = { kdc = dc1.rockylinux.org kdc = dc2.rockylinux.org } [domain_realm] .rockylinux.org = ROCKYLINUX.ORG Via the python package manager: pip3 install pywinrm pip3 install pywinrm[credssp] pip3 install kerberos requests-kerberos Working with IP modules Network modules usually require the netaddr python module: sudo pip3 install netaddr Generating a CMDB A tool, ansible-cmdb has been developed to generate a CMDB from ansible. pip3 install ansible-cmdb The facts must be exported by ansible with the following command: ansible --become --become-user=root -o -m setup --tree /var/www/ansible/cmdb/out/ You can then generate a global json file: ansible-cmdb -t json /var/www/ansible/cmdb/out/linux > /var/www/ansible/cmdb/cmdb-linux.json If you prefer a web interface: ansible-cmdb -t html_fancy_split /var/www/ansible/cmdb/out/","title":"Management server optimizations"},{"location":"books/learning_ansible/08-management-server-optimizations/#management-server-optimizations","text":"In this chapter, we will review the configuration options that may be of interest to optimize our Ansible management server.","title":"Management server optimizations"},{"location":"books/learning_ansible/08-management-server-optimizations/#the-ansiblecfg-configuration-file","text":"Some interesting configuration options to comment on: forks : by default to 5, it is the number of processes that Ansible will launch in parallel to communicate with remote hosts. The higher this number is, the more clients Ansible will be able to manage at the same time, and thus speed up processing. The value you can set is dependent on the CPU/RAM limits of your management server. Note that the default value, 5 , is very small, the Ansible documentation states that many users set it to 50, even 500 or more. gathering : this variable changes the policy for collecting facts. By default, the value is implicit , which implies that facts will be collected systematically. Switching this variable to smart allows for collection facts only when they have not already been collected. Coupled with a facts cache (see below), this option can greatly increase performance. host_key_checking : Be careful with your server security! However, if you are in control of your environment, it can be interesting to disable the key control of remote servers and save some time at the connection. You can also, on remote servers, disable the use of the DNS of the SSH server (in /etc/ssh/sshd_config , option UseDNS no ), this option wastes time at the connection and is, most of the time, only used in the connection logs. ansible_managed : This variable, containing Ansible managed by default, is typically used in file templates that are deployed on remote servers. It allows you to specify to an administrator that the file is managed automatically and that any changes they make to it will potentially be lost. It can be interesting to let the administrators have a more complete messages. Be careful though, if you change this variable, it may cause daemons to restart (via the handlers associated with the templates). ssh_args = -C -o ControlMaster=auto -o ControlPersist=300s -o PreferredAuthentications=publickey : specify the ssh connection options. By disabling all authentication methods other than public key, you can save a lot of time. You can also increase the ControlPersist to improve performance (the documentation suggests that a value equivalent to 30 minutes may be appropriate). The connection to a client will stay open longer and can be reused when reconnecting to the same server, which is a significant time saving. control_path_dir : Specify the path to the connection sockets. If this path is too long, it can cause problems. Consider changing it to something short, such as /tmp/.cp . pipelining : Setting this value to True increases performance by reducing the number of SSH connections needed when running remote modules. You must first make sure that the requiretty option is disabled in the sudoers options (see documentation).","title":"The ansible.cfg configuration file"},{"location":"books/learning_ansible/08-management-server-optimizations/#caching-the-facts","text":"Gathering facts is a process that can take some time. It can be interesting to disable this gathering for playbooks that don't need it (via gather_facts option) or to keep these facts in memory in a cache for a certain period of time (for example 24H). These facts can be easily stored in a redis database: sudo yum install redis sudo systemctl start redis sudo systemctl enable redis sudo pip3 install redis Don't forget to modify the ansible configuration: fact_caching = redis fact_caching_timeout = 86400 fact_caching_connection = localhost:6379:0 To check the correct operation, it is enough to request the redis server: redis-cli 127.0.0.1:6379> keys * 127.0.0.1:6379> get ansible_facts_SERVERNAME","title":"Caching the facts"},{"location":"books/learning_ansible/08-management-server-optimizations/#using-vault","text":"The various passwords and secrets cannot be stored in clear text with the Ansible source code, either locally on the management server or on a possible source code manager. Ansible proposes using an encryption manager: ansible-vault . The principle is to encrypt a variable or a whole file with the ansible-vault command. Ansible will be able to decrypt this file at runtime by retrieving the encryption key from the file (for example) /etc/ansible/ansible.cfg . The latter can also be a python script or other. Edit the /etc/ansible/ansible.cfg file: #vault_password_file = /path/to/vault_password_file vault_password_file = /etc/ansible/vault_pass Store the password in this file /etc/ansible/vault_pass and assign necessary restrictive rights: mysecretpassword You can then encrypt your files with the command: ansible-vault encrypt myfile.yml A file encrypted by ansible-vault can be easily recognized by its header: $ANSIBLE_VAULT;1.1;AES256 35376532343663353330613133663834626136316234323964333735363333396136613266383966 6664322261633261356566383438393738386165333966660a343032663233343762633936313630 34373230124561663766306134656235386233323964336239336661653433663036633334366661 6434656630306261650a313364636261393931313739363931336664386536333766326264633330 6334 Once a file is encrypted, it can still be edited with the command: ansible-vault edit myfile.yml You can also deport your password storage to any password manager. For example, to retrieve a password that would be stored in the rundeck vault: #!/usr/bin/env python # -*- coding: utf-8 -*- import urllib.request import io import ssl def get_password(): ''' :return: Vault password :return_type: str ''' ctx = ssl.create_default_context() ctx.check_hostname = False ctx.verify_mode = ssl.CERT_NONE url = 'https://rundeck.rockylinux.org/api/11/storage/keys/ansible/vault' req = urllib.request.Request(url, headers={ 'Accept': '*/*', 'X-Rundeck-Auth-Token': '****token-rundeck****' }) response = urllib.request.urlopen(req, context=ctx) return response.read().decode('utf-8') if __name__ == '__main__': print(get_password())","title":"Using Vault"},{"location":"books/learning_ansible/08-management-server-optimizations/#working-with-windows-servers","text":"It will be necessary to install on the management server several packages: Via the package manager: sudo dnf install python38-devel krb5-devel krb5-libs krb5-workstation and configure the /etc/krb5.conf file to specify the correct realms : [realms] ROCKYLINUX.ORG = { kdc = dc1.rockylinux.org kdc = dc2.rockylinux.org } [domain_realm] .rockylinux.org = ROCKYLINUX.ORG Via the python package manager: pip3 install pywinrm pip3 install pywinrm[credssp] pip3 install kerberos requests-kerberos","title":"Working with Windows servers"},{"location":"books/learning_ansible/08-management-server-optimizations/#working-with-ip-modules","text":"Network modules usually require the netaddr python module: sudo pip3 install netaddr","title":"Working with IP modules"},{"location":"books/learning_ansible/08-management-server-optimizations/#generating-a-cmdb","text":"A tool, ansible-cmdb has been developed to generate a CMDB from ansible. pip3 install ansible-cmdb The facts must be exported by ansible with the following command: ansible --become --become-user=root -o -m setup --tree /var/www/ansible/cmdb/out/ You can then generate a global json file: ansible-cmdb -t json /var/www/ansible/cmdb/out/linux > /var/www/ansible/cmdb/cmdb-linux.json If you prefer a web interface: ansible-cmdb -t html_fancy_split /var/www/ansible/cmdb/out/","title":"Generating a CMDB"},{"location":"books/learning_bash/00-toc/","tags":["education","bash scripting","bash"],"text":"Learning Bash with Rocky In this section, you will learn more about Bash scripting, an exercise that every administrator will have to perform one day or another. Generalities The shell is the command interpreter of Linux. It is a binary that is not part of the kernel, but forms an additional layer, hence its name \"shell\". It parses the commands entered by the user and then executes them by the system. There are several shells, all of which share some common features. The user is free to use the one that suits him/her best. Some examples are: the Bourne-Again shell ( bash ), the Korn shell ( ksh ), the C shell ( csh ), etc. bash is present by default in most (all) Linux distributions. It is characterized by its practical and user-friendly features. The shell is also a basic programming language which, thanks to some dedicated commands, allows: the use of variables , conditional execution of commands, the repetition of commands. Shell scripts have the advantage that they can be created quickly and reliably , without compiling or installing additional commands. A shell script is just a text file without any embellishments (bold, italics, etc.). !!! NOTE Although the shell is a \"basic\" programming language, it is still very powerful and sometimes faster than badly compiled code. To write a shell script, you just have to put all the necessary commands in a single text file. By making this file executable the shell reads it sequentially, and executes the commands in it one by one. It is also possible to execute it by passing the name of the script as an argument to the bash binary. When the shell encounters an error, it displays a message to identify the problem but continues to execute the script. But there are mechanisms to stop the execution of a script when an error occurs. Command-specific errors are also displayed on the screen or inside files. What is a good script? It is: reliable : its operation is flawless even in case of misuse; commented : its code is annotated to facilitate the rereading and future evolution; readable : the code is indented appropriately, the commands are spaced out, ... portable : the code runs on any Linux system, dependency management, rights management, etc.","title":"Learning bash with Rocky"},{"location":"books/learning_bash/00-toc/#learning-bash-with-rocky","text":"In this section, you will learn more about Bash scripting, an exercise that every administrator will have to perform one day or another.","title":"Learning Bash with Rocky"},{"location":"books/learning_bash/00-toc/#generalities","text":"The shell is the command interpreter of Linux. It is a binary that is not part of the kernel, but forms an additional layer, hence its name \"shell\". It parses the commands entered by the user and then executes them by the system. There are several shells, all of which share some common features. The user is free to use the one that suits him/her best. Some examples are: the Bourne-Again shell ( bash ), the Korn shell ( ksh ), the C shell ( csh ), etc. bash is present by default in most (all) Linux distributions. It is characterized by its practical and user-friendly features. The shell is also a basic programming language which, thanks to some dedicated commands, allows: the use of variables , conditional execution of commands, the repetition of commands. Shell scripts have the advantage that they can be created quickly and reliably , without compiling or installing additional commands. A shell script is just a text file without any embellishments (bold, italics, etc.). !!! NOTE Although the shell is a \"basic\" programming language, it is still very powerful and sometimes faster than badly compiled code. To write a shell script, you just have to put all the necessary commands in a single text file. By making this file executable the shell reads it sequentially, and executes the commands in it one by one. It is also possible to execute it by passing the name of the script as an argument to the bash binary. When the shell encounters an error, it displays a message to identify the problem but continues to execute the script. But there are mechanisms to stop the execution of a script when an error occurs. Command-specific errors are also displayed on the screen or inside files. What is a good script? It is: reliable : its operation is flawless even in case of misuse; commented : its code is annotated to facilitate the rereading and future evolution; readable : the code is indented appropriately, the commands are spaced out, ... portable : the code runs on any Linux system, dependency management, rights management, etc.","title":"Generalities"},{"location":"books/learning_bash/01-first-script/","tags":["education","bash scripting","bash"],"text":"Bash - First script In this chapter you will learn how to write your first script in bash. Objectives : In this chapter you will learn how to: :heavy_check_mark: Write your first script in bash; :heavy_check_mark: Execute your first script; :heavy_check_mark: Specify which shell to use with the so-called shebang; :checkered_flag: linux , script , bash Knowledge : :star: Complexity : :star: Reading time : 10 minutes My first script To start writing a shell script, it is convenient to use a text editor that supports syntax highlighting. vim , for example, is a good tool for this. The name of the script should respect some rules: no names of existing commands; only alphanumeric characters, i.e. no accented characters or spaces; extension .sh to indicate that it is a shell script. !!! note The author uses the \"$\" throughout these lessons to indicate the user's command-prompt. #!/usr/bin/env bash # # Author : Rocky Documentation Team # Date: March 2022 # Version 1.0.0: Displays the text \"Hello world!\" # # Displays a text on the screen : echo \"Hello world!\" To be able to run this script, as an argument to bash: $ bash hello-world.sh Hello world ! Or, more simply, after having given it the right to execute: $ chmod u+x ./hello-world.sh $ ./hello-world.sh Hello world ! !!! note To execute the script, it needs to be called with `./` before its name when you are in the directory where the script resides. If not in that directory, you will need to call it with the entire path to the script, OR place it in a directory that is within your PATH environment variable: (Examples: `/usr/local/sbin`, `/usr/local/bin`, etc.) The interpreter will refuse to execute a script present in the current directory without indicating a path (here with `./` before it). The `chmod` command is to be passed only once on a newly created script. The first line to be written in any script is to indicate the name of the shell binary to be used to execute it. If you want to use the ksh shell or the interpreted language python , you would replace the line: #!/usr/bin/env bash with : #!/usr/bin/env ksh or with : #!/usr/bin/env python This first line is called the shebang . It starts with the characters #! followed by the path to the binary of the command interpreter to use. !!! hint \"About the shebang\" You may have encountered the \"shebang\" in a script that you've looked at that does not contain the \"env\" section and simply contains the interpreter to use. (Example: `#!/bin/bash`). The author's method is considered to be the recommended and proper way to format the \"shebang\". Why is the author's method recommended? Because it increases the portability of the script. If for some reason the interpreter lived in an entirely different directory, the interpreter would **still** be found if you used the author's method. Throughout the writing process, you should think about proofreading the script, using comments in particular: a general presentation, at the beginning, to indicate the purpose of the script, its author, its version, its use, etc. during the text to help understand the actions. Comments can be placed on a separate line or at the end of a line containing a command. Example: # This program displays the date date # This line is the line that displays the date!","title":"Bash - First script"},{"location":"books/learning_bash/01-first-script/#bash-first-script","text":"In this chapter you will learn how to write your first script in bash. Objectives : In this chapter you will learn how to: :heavy_check_mark: Write your first script in bash; :heavy_check_mark: Execute your first script; :heavy_check_mark: Specify which shell to use with the so-called shebang; :checkered_flag: linux , script , bash Knowledge : :star: Complexity : :star: Reading time : 10 minutes","title":"Bash - First script"},{"location":"books/learning_bash/01-first-script/#my-first-script","text":"To start writing a shell script, it is convenient to use a text editor that supports syntax highlighting. vim , for example, is a good tool for this. The name of the script should respect some rules: no names of existing commands; only alphanumeric characters, i.e. no accented characters or spaces; extension .sh to indicate that it is a shell script. !!! note The author uses the \"$\" throughout these lessons to indicate the user's command-prompt. #!/usr/bin/env bash # # Author : Rocky Documentation Team # Date: March 2022 # Version 1.0.0: Displays the text \"Hello world!\" # # Displays a text on the screen : echo \"Hello world!\" To be able to run this script, as an argument to bash: $ bash hello-world.sh Hello world ! Or, more simply, after having given it the right to execute: $ chmod u+x ./hello-world.sh $ ./hello-world.sh Hello world ! !!! note To execute the script, it needs to be called with `./` before its name when you are in the directory where the script resides. If not in that directory, you will need to call it with the entire path to the script, OR place it in a directory that is within your PATH environment variable: (Examples: `/usr/local/sbin`, `/usr/local/bin`, etc.) The interpreter will refuse to execute a script present in the current directory without indicating a path (here with `./` before it). The `chmod` command is to be passed only once on a newly created script. The first line to be written in any script is to indicate the name of the shell binary to be used to execute it. If you want to use the ksh shell or the interpreted language python , you would replace the line: #!/usr/bin/env bash with : #!/usr/bin/env ksh or with : #!/usr/bin/env python This first line is called the shebang . It starts with the characters #! followed by the path to the binary of the command interpreter to use. !!! hint \"About the shebang\" You may have encountered the \"shebang\" in a script that you've looked at that does not contain the \"env\" section and simply contains the interpreter to use. (Example: `#!/bin/bash`). The author's method is considered to be the recommended and proper way to format the \"shebang\". Why is the author's method recommended? Because it increases the portability of the script. If for some reason the interpreter lived in an entirely different directory, the interpreter would **still** be found if you used the author's method. Throughout the writing process, you should think about proofreading the script, using comments in particular: a general presentation, at the beginning, to indicate the purpose of the script, its author, its version, its use, etc. during the text to help understand the actions. Comments can be placed on a separate line or at the end of a line containing a command. Example: # This program displays the date date # This line is the line that displays the date!","title":"My first script"},{"location":"books/learning_bash/02-using-variables/","tags":["education","bash scripting","bash"],"text":"Bash - Using Variables In this chapter you will learn how to use variables in your bash scripts. Objectives : In this chapter you will learn how to: :heavy_check_mark: Store information for later use; :heavy_check_mark: Delete and lock variables; :heavy_check_mark: Use environment variables; :heavy_check_mark: Substitute commands; :checkered_flag: linux , script , bash , variable Knowledge : :star: :star: Complexity : :star: Reading time : 10 minutes Storing information for later use As in any programming language, the shell script uses variables. They are used to store information in memory to be reused as needed during the script. A variable is created when it receives its content. It remains valid until the end of the execution of the script or at the explicit request of the script author. Since the script is executed sequentially from start to finish, it is impossible to call a variable before it is created. The content of a variable can be changed during the script, as the variable continues to exist until the script ends. If the content is deleted, the variable remains active but contains nothing. The notion of a variable type in a shell script is possible but is very rarely used. The content of a variable is always a character or a string. #!/usr/bin/env bash # # Author : Rocky Documentation Team # Date: March 2022 # Version 1.0.0: Save in /root the files passwd, shadow, group, and gshadow # # Global variables FILE1=/etc/passwd FILE2=/etc/shadow FILE3=/etc/group FILE4=/etc/gshadow # Destination folder DESTINATION=/root # Clear the screen clear # Launch the backup echo \"Starting the backup of $FILE1, $FILE2, $FILE3, $FILE4 to $DESTINATION:\" cp $FILE1 $FILE2 $FILE3 $FILE4 $DESTINATION echo \"Backup ended!\" This script makes use of variables. The name of a variable must start with a letter but can contain any sequence of letters or numbers. Except for the underscore \"_\", special characters cannot be used. By convention, variables created by a user have a name in lower case. This name must be chosen with care so as not to be too evasive or too complicated. However, a variable can be named with upper case letters, as in this case, if it is a global variable that should not be modified by the program. The character = assigns content to a variable: variable=value rep_name=\"/home\" There is no space before or after the = sign. Once the variable is created, it can be used by prefixing it with a dollar $. file=file_name touch $file It is strongly recommended to protect variables with quotes, as in this example below: file=file name touch $file touch \"$file\" As the content of the variable contains a space, the first touch will create 2 files while the second touch will create a file whose name will contain a space. To isolate the name of the variable from the rest of the text, you must use quotes or braces: file=file_name touch \"$file\"1 touch ${file}1 The systematic use of braces is recommended. The use of apostrophes inhibits the interpretation of special characters. message=\"Hello\" echo \"This is the content of the variable message: $message\" Here is the content of the variable message: Hello echo 'Here is the content of the variable message: $message' Here is the content of the variable message: $message Delete and lock variables The unset command allows for the deletion of a variable. Example: name=\"NAME\" firstname=\"Firstname\" echo \"$name $firstname\" NAME Firstname unset firstname echo \"$name $firstname\" NAME The readonly or typeset -r command locks a variable. Example: name=\"NAME\" readonly name name=\"OTHER NAME\" bash: name: read-only variable unset name bash: name: read-only variable !!! Note A `set -u` at the beginning of the script will stop the execution of the script if undeclared variables are used. Use environment variables Environment variables and system variables are variables used by the system for its operation. By convention these are named with capital letters. Like all variables, they can be displayed when a script is executed. Even if this is strongly discouraged, they can also be modified. The env command displays all the environment variables used. The set command displays all used system variables. Among the dozens of environment variables, several are of interest to be used in a shell script: Variables Observations HOSTNAME Host name of the machine. USER , USERNAME and LOGNAME Name of the user connected to the session. PATH Path to find the commands. PWD Current directory, updated each time the cd command is executed. HOME Login directory. $$ Process id of the script execution. $? Return code of the last command executed. The export command allows you to export a variable. A variable is only valid in the environment of the shell script process. In order for the child processes of the script to know the variables and their contents, they must be exported. The modification of a variable exported in a child process cannot be traced back to the parent process. !!! note Without any option, the `export` command displays the name and values of the exported variables in the environment. Substitute commands It is possible to store the result of a command in a variable. !!! Note This operation is only valid for commands that return a message at the end of their execution. The syntax for sub-executing a command is as follows: variable=`command` variable=$(command) # Preferred syntax Example: $ day=`date +%d` $ homedir=$(pwd) With everything we've just seen, our backup script might look like this: #!/usr/bin/env bash # # Author : Rocky Documentation Team # Date: March 2022 # Version 1.0.0: Save in /root the files passwd, shadow, group, and gshadow # Version 1.0.1: Adding what we learned about variables # # Global variables FILE1=/etc/passwd FILE2=/etc/shadow FILE3=/etc/group FILE4=/etc/gshadow # Destination folder DESTINATION=/root ## Readonly variables readonly FILE1 FILE2 FILE3 FILE4 DESTINATION # A folder name with the day's number dir=\"backup-$(date +%j)\" # Clear the screen clear # Launch the backup echo \"****************************************************************\" echo \" Backup Script - Backup on ${HOSTNAME} \" echo \"****************************************************************\" echo \"The backup will be made in the folder ${dir}.\" echo \"Creating the directory...\" mkdir -p ${DESTINATION}/${dir} echo \"Starting the backup of ${FILE1}, ${FILE2}, ${FILE3}, ${FILE4} to ${DESTINATION}/${dir}:\" cp ${FILE1} ${FILE2} ${FILE3} ${FILE4} ${DESTINATION}/${dir} echo \"Backup ended!\" # The backup is noted in the system event log: logger \"Backup of system files by ${USER} on ${HOSTNAME} in the folder ${DESTINATION}/${dir}.\" Running our backup script: $ sudo ./backup.sh will give us: **************************************************************** Backup Script - Backup on desktop **************************************************************** The backup will be made in the folder backup-088. Creating the directory... Starting the backup of /etc/passwd, /etc/shadow, /etc/group, /etc/gshadow to /root/backup-088: Backup ended!","title":"Bash - Using Variables"},{"location":"books/learning_bash/02-using-variables/#bash-using-variables","text":"In this chapter you will learn how to use variables in your bash scripts. Objectives : In this chapter you will learn how to: :heavy_check_mark: Store information for later use; :heavy_check_mark: Delete and lock variables; :heavy_check_mark: Use environment variables; :heavy_check_mark: Substitute commands; :checkered_flag: linux , script , bash , variable Knowledge : :star: :star: Complexity : :star: Reading time : 10 minutes","title":"Bash - Using Variables"},{"location":"books/learning_bash/02-using-variables/#storing-information-for-later-use","text":"As in any programming language, the shell script uses variables. They are used to store information in memory to be reused as needed during the script. A variable is created when it receives its content. It remains valid until the end of the execution of the script or at the explicit request of the script author. Since the script is executed sequentially from start to finish, it is impossible to call a variable before it is created. The content of a variable can be changed during the script, as the variable continues to exist until the script ends. If the content is deleted, the variable remains active but contains nothing. The notion of a variable type in a shell script is possible but is very rarely used. The content of a variable is always a character or a string. #!/usr/bin/env bash # # Author : Rocky Documentation Team # Date: March 2022 # Version 1.0.0: Save in /root the files passwd, shadow, group, and gshadow # # Global variables FILE1=/etc/passwd FILE2=/etc/shadow FILE3=/etc/group FILE4=/etc/gshadow # Destination folder DESTINATION=/root # Clear the screen clear # Launch the backup echo \"Starting the backup of $FILE1, $FILE2, $FILE3, $FILE4 to $DESTINATION:\" cp $FILE1 $FILE2 $FILE3 $FILE4 $DESTINATION echo \"Backup ended!\" This script makes use of variables. The name of a variable must start with a letter but can contain any sequence of letters or numbers. Except for the underscore \"_\", special characters cannot be used. By convention, variables created by a user have a name in lower case. This name must be chosen with care so as not to be too evasive or too complicated. However, a variable can be named with upper case letters, as in this case, if it is a global variable that should not be modified by the program. The character = assigns content to a variable: variable=value rep_name=\"/home\" There is no space before or after the = sign. Once the variable is created, it can be used by prefixing it with a dollar $. file=file_name touch $file It is strongly recommended to protect variables with quotes, as in this example below: file=file name touch $file touch \"$file\" As the content of the variable contains a space, the first touch will create 2 files while the second touch will create a file whose name will contain a space. To isolate the name of the variable from the rest of the text, you must use quotes or braces: file=file_name touch \"$file\"1 touch ${file}1 The systematic use of braces is recommended. The use of apostrophes inhibits the interpretation of special characters. message=\"Hello\" echo \"This is the content of the variable message: $message\" Here is the content of the variable message: Hello echo 'Here is the content of the variable message: $message' Here is the content of the variable message: $message","title":"Storing information for later use"},{"location":"books/learning_bash/02-using-variables/#delete-and-lock-variables","text":"The unset command allows for the deletion of a variable. Example: name=\"NAME\" firstname=\"Firstname\" echo \"$name $firstname\" NAME Firstname unset firstname echo \"$name $firstname\" NAME The readonly or typeset -r command locks a variable. Example: name=\"NAME\" readonly name name=\"OTHER NAME\" bash: name: read-only variable unset name bash: name: read-only variable !!! Note A `set -u` at the beginning of the script will stop the execution of the script if undeclared variables are used.","title":"Delete and lock variables"},{"location":"books/learning_bash/02-using-variables/#use-environment-variables","text":"Environment variables and system variables are variables used by the system for its operation. By convention these are named with capital letters. Like all variables, they can be displayed when a script is executed. Even if this is strongly discouraged, they can also be modified. The env command displays all the environment variables used. The set command displays all used system variables. Among the dozens of environment variables, several are of interest to be used in a shell script: Variables Observations HOSTNAME Host name of the machine. USER , USERNAME and LOGNAME Name of the user connected to the session. PATH Path to find the commands. PWD Current directory, updated each time the cd command is executed. HOME Login directory. $$ Process id of the script execution. $? Return code of the last command executed. The export command allows you to export a variable. A variable is only valid in the environment of the shell script process. In order for the child processes of the script to know the variables and their contents, they must be exported. The modification of a variable exported in a child process cannot be traced back to the parent process. !!! note Without any option, the `export` command displays the name and values of the exported variables in the environment.","title":"Use environment variables"},{"location":"books/learning_bash/02-using-variables/#substitute-commands","text":"It is possible to store the result of a command in a variable. !!! Note This operation is only valid for commands that return a message at the end of their execution. The syntax for sub-executing a command is as follows: variable=`command` variable=$(command) # Preferred syntax Example: $ day=`date +%d` $ homedir=$(pwd) With everything we've just seen, our backup script might look like this: #!/usr/bin/env bash # # Author : Rocky Documentation Team # Date: March 2022 # Version 1.0.0: Save in /root the files passwd, shadow, group, and gshadow # Version 1.0.1: Adding what we learned about variables # # Global variables FILE1=/etc/passwd FILE2=/etc/shadow FILE3=/etc/group FILE4=/etc/gshadow # Destination folder DESTINATION=/root ## Readonly variables readonly FILE1 FILE2 FILE3 FILE4 DESTINATION # A folder name with the day's number dir=\"backup-$(date +%j)\" # Clear the screen clear # Launch the backup echo \"****************************************************************\" echo \" Backup Script - Backup on ${HOSTNAME} \" echo \"****************************************************************\" echo \"The backup will be made in the folder ${dir}.\" echo \"Creating the directory...\" mkdir -p ${DESTINATION}/${dir} echo \"Starting the backup of ${FILE1}, ${FILE2}, ${FILE3}, ${FILE4} to ${DESTINATION}/${dir}:\" cp ${FILE1} ${FILE2} ${FILE3} ${FILE4} ${DESTINATION}/${dir} echo \"Backup ended!\" # The backup is noted in the system event log: logger \"Backup of system files by ${USER} on ${HOSTNAME} in the folder ${DESTINATION}/${dir}.\" Running our backup script: $ sudo ./backup.sh will give us: **************************************************************** Backup Script - Backup on desktop **************************************************************** The backup will be made in the folder backup-088. Creating the directory... Starting the backup of /etc/passwd, /etc/shadow, /etc/group, /etc/gshadow to /root/backup-088: Backup ended!","title":"Substitute commands"},{"location":"books/learning_bash/03-data-entry-and-manipulations/","tags":["education","bash scripting","bash"],"text":"Bash - Data entry and manipulations In this chapter you will learn how to make your scripts interact with users and manipulate the data. Objectives : In this chapter you will learn how to: :heavy_check_mark: read input from a user; :heavy_check_mark: manipulate data entries; :heavy_check_mark: use arguments inside a script; :heavy_check_mark: manage positional variables; :checkered_flag: linux , script , bash , variable Knowledge : :star: :star: Complexity : :star: :star: Reading time : 10 minutes Depending on the purpose of the script, it may be necessary to send it information when it is launched or during its execution. This information, not known when the script is written, can be extracted from files or entered by the user. It is also possible to send this information in the form of arguments when the script command is entered. This is the way many Linux commands work. The read command The read command allows you to enter a character string and store it in a variable. Syntax of the read command: read [-n X] [-p] [-s] [variable] The first example below, prompts you for two variable inputs: \"name\" and \"firstname\", but since there is no prompt, you would have to know ahead of time that this was the case. In the case of this particular entry, each variable input would be separated by a space. The second example prompts for the variable \"name\" with the prompt text included: read name firstname read -p \"Please type your name: \" name Option Observation -p Displays a prompt message. -n Limit the number of characters to be entered. -s Hides the input. When using the -n option, the shell automatically validates the input after the specified number of characters. The user does not have to press the ENTER key. read -n5 name The read command allows you to interrupt the execution of the script while the user enters information. The user's input is broken down into words assigned to one or more predefined variables. The words are strings of characters separated by the field separator. The end of the input is determined by pressing the ENTER key. Once the input is validated, each word will be stored in the predefined variable. The division of the words is defined by the field separator character. This separator is stored in the system variable IFS ( Internal Field Separator ). set | grep IFS IFS=$' \\t\\n' By default, the IFS contains the space, tab and line feed. When used without specifying a variable, this command simply pauses the script. The script continues its execution when the input is validated. This is used to pause a script when debugging or to prompt the user to press ENTER to continue. echo -n \"Press [ENTER] to continue...\" read The cut command The cut command allows you to isolate a column in a file or in a stream. Syntax of the cut command: cut [-cx] [-dy] [-fz] file Example of use of the cut command: cut -d: -f1 /etc/passwd Option Observation -c Specifies the sequence numbers of the characters to be selected. -d Specifies the field separator. -f Specifies the order number of the columns to select. The main interest of this command will be its association with a stream, for example the grep command and the | pipe. The grep command works \"vertically\" (isolation of one line from all the lines in the file). The combination of the two commands allows for the isolation of a specific field in the file . Example: grep \"^root:\" /etc/passwd | cut -d: -f3 0 !!! NOTE Configuration files with a single structure using the same field separator are ideal targets for this combination of commands. The tr command The tr command allows you to convert a string. Syntax of the tr command: tr [-csd] string1 string2 Option Observation -c All characters not specified in the first string are converted to the characters of the second string. -d Deletes the specified character. -s Reduce the specified character to a single unit. An example of using the tr command follows. If you use grep to return root's passwd file entry, you would get this: grep root /etc/passwd returns: root:x:0:0:root:/root:/bin/bash Now let's use tr command and the reduce the \"o's\" in the line: grep root /etc/passwd | tr -s \"o\" which returns this: rot:x:0:0:rot:/rot:/bin/bash Extract the name and path of a file The basename command allows you to extract the name of the file from a path. The dirname command allows you to extract the parent path of a file. Examples: echo $FILE=/usr/bin/passwd basename $FILE Which would result in \"passwd\" dirname $FILE Which would result in: \"/usr/bin\" Arguments of a script The request to enter information with the read command interrupts the execution of the script as long as the user does not enter any information. This method, although very user-friendly, has its limits if the script is scheduled to run at night. To overcome this problem, it is possible to inject the desired information via arguments. Many Linux commands work on this principle. This way of doing things has the advantage that once the script is executed, it will not need any human intervention to finish. Its major disadvantage is that the user will have to be warned about the syntax of the script to avoid errors. The arguments are filled in when the script command is entered. They are separated by a space. ./script argument1 argument2 Once executed, the script saves the entered arguments in predefined variables: positional variables . These variables can be used in the script like any other variable, except that they cannot be assigned. Unused positional variables exist but are empty. Positional variables are always defined in the same way: Variable Observation $0 contains the name of the script as entered. $1 to $9 contain the values of the 1st to 9th argument ${x} contains the value of the argument x , greater than 9. $# contains the number of arguments passed. $* or $@ contains in one variable all the arguments passed. Example: #!/usr/bin/env bash # # Author : Damien dit LeDub # Date : september 2019 # Version 1.0.0 : Display the value of the positional arguments # From 1 to 3 # The field separator will be \",\" or space # Important to see the difference in $* and $@ IFS=\", \" # Display a text on the screen: echo \"The number of arguments (\\$#) = $#\" echo \"The name of the script (\\$0) = $0\" echo \"The 1st argument (\\$1) = $1\" echo \"The 2nd argument (\\$2) = $2\" echo \"The 3rd argument (\\$3) = $3\" echo \"All separated by IFS (\\$*) = $*\" echo \"All without separation (\\$@) = $@\" This will give: $ ./arguments.sh one two \"tree four\" The number of arguments ($#) = 3 The name of the script ($0) = ./arguments.sh The 1st argument ($1) = one The 2nd argument ($2) = two The 3rd argument ($3) = tree four All separated by IFS ($*) = one,two,tree four All without separation ($@) = one two tree four !!! warning Beware of the difference between `$@` and `$*`. It is in the argument storage format: * `$*` : Contains the arguments in the format `\"$1 $2 $3 ...\"` * `$@` : Contains arguments in the format `\"$1\" \"$2\" \"$3\" ...` It is by modifying the `IFS` environment variable that the difference is visible. The shift command The shift command allows you to shift positional variables. Let's modify our previous example to illustrate the impact of the shift command on positional variables: #!/usr/bin/env bash # # Author : Damien dit LeDub # Date : september 2019 # Version 1.0.0 : Display the value of the positional arguments # From 1 to 3 # The field separator will be \",\" or space # Important to see the difference in $* and $@ IFS=\", \" # Display a text on the screen: echo \"The number of arguments (\\$#) = $#\" echo \"The 1st argument (\\$1) = $1\" echo \"The 2nd argument (\\$2) = $2\" echo \"The 3rd argument (\\$3) = $3\" echo \"All separated by IFS (\\$*) = $*\" echo \"All without separation (\\$@) = $@\" shift 2 echo \"\" echo \"-------- SHIFT 2 ----------------\" echo \"\" echo \"The number of arguments (\\$#) = $#\" echo \"The 1st argument (\\$1) = $1\" echo \"The 2nd argument (\\$2) = $2\" echo \"The 3rd argument (\\$3) = $3\" echo \"All separated by IFS (\\$*) = $*\" echo \"All without separation (\\$@) = $@\" This will give: ./arguments.sh one two \"tree four\" The number of arguments ($#) = 3 The 1st argument ($1) = one The 2nd argument ($2) = two The 3rd argument ($3) = tree four All separated by IFS ($*) = one,two,tree four All without separation ($@) = one two tree four -------- SHIFT 2 ---------------- The number of arguments ($#) = 1 The 1st argument ($1) = tree four The 2nd argument ($2) = The 3rd argument ($3) = All separated by IFS ($*) = tree four All without separation ($@) = tree four As you can see, the shift command has shifted the place of the arguments \"to the left\", removing the first 2. !!! WARNING When using the `shift` command, the `$#` and `$*` variables are modified accordingly. The set command The set command splits a string into positional variables. Syntax of the set command: set [value] [$variable] Example: $ set one two three $ echo $1 $2 $3 $# one two three 3 $ variable=\"four five six\" $ set $variable $ echo $1 $2 $3 $# four five six 3 You can now use positional variables as seen before.","title":"Bash - Data entry and manipulations"},{"location":"books/learning_bash/03-data-entry-and-manipulations/#bash-data-entry-and-manipulations","text":"In this chapter you will learn how to make your scripts interact with users and manipulate the data. Objectives : In this chapter you will learn how to: :heavy_check_mark: read input from a user; :heavy_check_mark: manipulate data entries; :heavy_check_mark: use arguments inside a script; :heavy_check_mark: manage positional variables; :checkered_flag: linux , script , bash , variable Knowledge : :star: :star: Complexity : :star: :star: Reading time : 10 minutes Depending on the purpose of the script, it may be necessary to send it information when it is launched or during its execution. This information, not known when the script is written, can be extracted from files or entered by the user. It is also possible to send this information in the form of arguments when the script command is entered. This is the way many Linux commands work.","title":"Bash - Data entry and manipulations"},{"location":"books/learning_bash/03-data-entry-and-manipulations/#the-read-command","text":"The read command allows you to enter a character string and store it in a variable. Syntax of the read command: read [-n X] [-p] [-s] [variable] The first example below, prompts you for two variable inputs: \"name\" and \"firstname\", but since there is no prompt, you would have to know ahead of time that this was the case. In the case of this particular entry, each variable input would be separated by a space. The second example prompts for the variable \"name\" with the prompt text included: read name firstname read -p \"Please type your name: \" name Option Observation -p Displays a prompt message. -n Limit the number of characters to be entered. -s Hides the input. When using the -n option, the shell automatically validates the input after the specified number of characters. The user does not have to press the ENTER key. read -n5 name The read command allows you to interrupt the execution of the script while the user enters information. The user's input is broken down into words assigned to one or more predefined variables. The words are strings of characters separated by the field separator. The end of the input is determined by pressing the ENTER key. Once the input is validated, each word will be stored in the predefined variable. The division of the words is defined by the field separator character. This separator is stored in the system variable IFS ( Internal Field Separator ). set | grep IFS IFS=$' \\t\\n' By default, the IFS contains the space, tab and line feed. When used without specifying a variable, this command simply pauses the script. The script continues its execution when the input is validated. This is used to pause a script when debugging or to prompt the user to press ENTER to continue. echo -n \"Press [ENTER] to continue...\" read","title":"The read command"},{"location":"books/learning_bash/03-data-entry-and-manipulations/#the-cut-command","text":"The cut command allows you to isolate a column in a file or in a stream. Syntax of the cut command: cut [-cx] [-dy] [-fz] file Example of use of the cut command: cut -d: -f1 /etc/passwd Option Observation -c Specifies the sequence numbers of the characters to be selected. -d Specifies the field separator. -f Specifies the order number of the columns to select. The main interest of this command will be its association with a stream, for example the grep command and the | pipe. The grep command works \"vertically\" (isolation of one line from all the lines in the file). The combination of the two commands allows for the isolation of a specific field in the file . Example: grep \"^root:\" /etc/passwd | cut -d: -f3 0 !!! NOTE Configuration files with a single structure using the same field separator are ideal targets for this combination of commands.","title":"The cut command"},{"location":"books/learning_bash/03-data-entry-and-manipulations/#the-tr-command","text":"The tr command allows you to convert a string. Syntax of the tr command: tr [-csd] string1 string2 Option Observation -c All characters not specified in the first string are converted to the characters of the second string. -d Deletes the specified character. -s Reduce the specified character to a single unit. An example of using the tr command follows. If you use grep to return root's passwd file entry, you would get this: grep root /etc/passwd returns: root:x:0:0:root:/root:/bin/bash Now let's use tr command and the reduce the \"o's\" in the line: grep root /etc/passwd | tr -s \"o\" which returns this: rot:x:0:0:rot:/rot:/bin/bash","title":"The tr command"},{"location":"books/learning_bash/03-data-entry-and-manipulations/#extract-the-name-and-path-of-a-file","text":"The basename command allows you to extract the name of the file from a path. The dirname command allows you to extract the parent path of a file. Examples: echo $FILE=/usr/bin/passwd basename $FILE Which would result in \"passwd\" dirname $FILE Which would result in: \"/usr/bin\"","title":"Extract the name and path of a file"},{"location":"books/learning_bash/03-data-entry-and-manipulations/#arguments-of-a-script","text":"The request to enter information with the read command interrupts the execution of the script as long as the user does not enter any information. This method, although very user-friendly, has its limits if the script is scheduled to run at night. To overcome this problem, it is possible to inject the desired information via arguments. Many Linux commands work on this principle. This way of doing things has the advantage that once the script is executed, it will not need any human intervention to finish. Its major disadvantage is that the user will have to be warned about the syntax of the script to avoid errors. The arguments are filled in when the script command is entered. They are separated by a space. ./script argument1 argument2 Once executed, the script saves the entered arguments in predefined variables: positional variables . These variables can be used in the script like any other variable, except that they cannot be assigned. Unused positional variables exist but are empty. Positional variables are always defined in the same way: Variable Observation $0 contains the name of the script as entered. $1 to $9 contain the values of the 1st to 9th argument ${x} contains the value of the argument x , greater than 9. $# contains the number of arguments passed. $* or $@ contains in one variable all the arguments passed. Example: #!/usr/bin/env bash # # Author : Damien dit LeDub # Date : september 2019 # Version 1.0.0 : Display the value of the positional arguments # From 1 to 3 # The field separator will be \",\" or space # Important to see the difference in $* and $@ IFS=\", \" # Display a text on the screen: echo \"The number of arguments (\\$#) = $#\" echo \"The name of the script (\\$0) = $0\" echo \"The 1st argument (\\$1) = $1\" echo \"The 2nd argument (\\$2) = $2\" echo \"The 3rd argument (\\$3) = $3\" echo \"All separated by IFS (\\$*) = $*\" echo \"All without separation (\\$@) = $@\" This will give: $ ./arguments.sh one two \"tree four\" The number of arguments ($#) = 3 The name of the script ($0) = ./arguments.sh The 1st argument ($1) = one The 2nd argument ($2) = two The 3rd argument ($3) = tree four All separated by IFS ($*) = one,two,tree four All without separation ($@) = one two tree four !!! warning Beware of the difference between `$@` and `$*`. It is in the argument storage format: * `$*` : Contains the arguments in the format `\"$1 $2 $3 ...\"` * `$@` : Contains arguments in the format `\"$1\" \"$2\" \"$3\" ...` It is by modifying the `IFS` environment variable that the difference is visible.","title":"Arguments of a script"},{"location":"books/learning_bash/03-data-entry-and-manipulations/#the-shift-command","text":"The shift command allows you to shift positional variables. Let's modify our previous example to illustrate the impact of the shift command on positional variables: #!/usr/bin/env bash # # Author : Damien dit LeDub # Date : september 2019 # Version 1.0.0 : Display the value of the positional arguments # From 1 to 3 # The field separator will be \",\" or space # Important to see the difference in $* and $@ IFS=\", \" # Display a text on the screen: echo \"The number of arguments (\\$#) = $#\" echo \"The 1st argument (\\$1) = $1\" echo \"The 2nd argument (\\$2) = $2\" echo \"The 3rd argument (\\$3) = $3\" echo \"All separated by IFS (\\$*) = $*\" echo \"All without separation (\\$@) = $@\" shift 2 echo \"\" echo \"-------- SHIFT 2 ----------------\" echo \"\" echo \"The number of arguments (\\$#) = $#\" echo \"The 1st argument (\\$1) = $1\" echo \"The 2nd argument (\\$2) = $2\" echo \"The 3rd argument (\\$3) = $3\" echo \"All separated by IFS (\\$*) = $*\" echo \"All without separation (\\$@) = $@\" This will give: ./arguments.sh one two \"tree four\" The number of arguments ($#) = 3 The 1st argument ($1) = one The 2nd argument ($2) = two The 3rd argument ($3) = tree four All separated by IFS ($*) = one,two,tree four All without separation ($@) = one two tree four -------- SHIFT 2 ---------------- The number of arguments ($#) = 1 The 1st argument ($1) = tree four The 2nd argument ($2) = The 3rd argument ($3) = All separated by IFS ($*) = tree four All without separation ($@) = tree four As you can see, the shift command has shifted the place of the arguments \"to the left\", removing the first 2. !!! WARNING When using the `shift` command, the `$#` and `$*` variables are modified accordingly.","title":"The shift command"},{"location":"books/learning_bash/03-data-entry-and-manipulations/#the-set-command","text":"The set command splits a string into positional variables. Syntax of the set command: set [value] [$variable] Example: $ set one two three $ echo $1 $2 $3 $# one two three 3 $ variable=\"four five six\" $ set $variable $ echo $1 $2 $3 $# four five six 3 You can now use positional variables as seen before.","title":"The set command"},{"location":"books/learning_bash/04-check-your-knowledge/","tags":["education","bash scripting","bash"],"text":"Bash - Check your knowledge :heavy_check_mark: Among these 4 shells, which one does not exist: [ ] Bash [ ] Ksh [ ] Tsh [ ] Csh :heavy_check_mark: What is the correct syntax to assign a content to a variable: [ ] variable:=value [ ] variable := value [ ] variable = value [ ] variable=value :heavy_check_mark: How to store the return of a command in a variable: [ ] file=$(ls) [ ] file= ls`` [ ] file:=$ls [ ] file = $(ls) [ ] file=${ls} :heavy_check_mark: The read command allows you to read the contents of a file: [ ] True [ ] False :heavy_check_mark: Which of the following is the correct syntax for the command cut : [ ] cut -f: -D1 /etc/passwd [ ] cut -d: -f1 /etc/passwd [ ] cut -d1 -f: /etc/passwd [ ] cut -c \":\" -f 3 /etc/passwd :heavy_check_mark: Which command is used to shift positional variables: [ ] left [ ] shift [ ] set [ ] array :heavy_check_mark: Which command transforms a string into positional variables: [ ] left [ ] shift [ ] set [ ] array","title":"Bash - Check your knowledge"},{"location":"books/learning_bash/04-check-your-knowledge/#bash-check-your-knowledge","text":":heavy_check_mark: Among these 4 shells, which one does not exist: [ ] Bash [ ] Ksh [ ] Tsh [ ] Csh :heavy_check_mark: What is the correct syntax to assign a content to a variable: [ ] variable:=value [ ] variable := value [ ] variable = value [ ] variable=value :heavy_check_mark: How to store the return of a command in a variable: [ ] file=$(ls) [ ] file= ls`` [ ] file:=$ls [ ] file = $(ls) [ ] file=${ls} :heavy_check_mark: The read command allows you to read the contents of a file: [ ] True [ ] False :heavy_check_mark: Which of the following is the correct syntax for the command cut : [ ] cut -f: -D1 /etc/passwd [ ] cut -d: -f1 /etc/passwd [ ] cut -d1 -f: /etc/passwd [ ] cut -c \":\" -f 3 /etc/passwd :heavy_check_mark: Which command is used to shift positional variables: [ ] left [ ] shift [ ] set [ ] array :heavy_check_mark: Which command transforms a string into positional variables: [ ] left [ ] shift [ ] set [ ] array","title":"Bash - Check your knowledge"},{"location":"books/learning_bash/05-tests/","tags":["education","bash scripting","bash"],"text":"Bash - Tests Objectives : In this chapter you will learn how to: :heavy_check_mark: work with the return code; :heavy_check_mark: test files and compare them; :heavy_check_mark: test variables, strings and integers; :heavy_check_mark: perform an operation with numeric integers; :checkered_flag: linux , script , bash , variable Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 10 minutes Upon completion, all commands executed by the shell return a return code (also called status or exit code ). If the command ran correctly, the convention is that the status code will be zero . If the command encountered a problem during its execution, its status code will have a non-zero value . There are many reasons for this: lack of access rights, missing file, incorrect input, etc. You should refer to the manual of the man command to know the different values of the return code provided by the developers. The return code is not visible directly, but is stored in a special variable: $? . mkdir directory echo $? 0 mkdir /directory mkdir: unable to create directory echo $? 1 command_that_does_not_exist command_that_does_not_exist: command not found echo $? 127 !!! note The display of the contents of the `$?` variable with the `echo` command is done immediately after the command you want to evaluate because this variable is updated after each execution of a command, a command line or a script. !!! tip Since the value of `$?` changes after each command execution, it is better to put its value in a variable that will be used afterwards, for a test or to display a message. ``` ls no_file ls: cannot access 'no_file': No such file or directory result=$? echo $? 0 echo $result 2 ``` It is also possible to create return codes in a script. To do so, you just need to add a numeric argument to the exit command. bash # to avoid being disconnected after the \"exit 2 exit 123 echo $? 123 In addition to the correct execution of a command, the shell offers the possibility to run tests on many patterns: Files : existence, type, rights, comparison; Strings : length, comparison; Numeric integers : value, comparison. The result of the test: $?=0 : the test was correctly executed and is true; $?=1 : the test was correctly executed and is false; $?=2 : the test was not correctly executed. Testing the type of a file Syntax of the test command for a file: test [-d|-e|-f|-L] file or: [ -d|-e|-f|-L file ] !!! NOTE Note that there is a space after the `[` and before the `]`. Options of the test command on files: Option Observation -e Tests if the file exists -f Tests if the file exists and is of normal type -d Checks if the file exists and is of type directory -L Checks if the file exists and is of type symbolic link -b Checks if the file exists and is of special type block mode -c Checks if the file exists and is of special type character mode -p Checks if the file exists and is of type tube -S Checks if the file exists and is of type socket -t Checks if the file exists and is of type terminal -r Checks if the file exists and is readable -w Checks if the file exists and is writable -x Checks if the file exists and is executable -g Checks if the file exists and has a set SGID -u Checks if the file exists and has a set SUID -s Tests if the file exists and is non-empty (size > 0 bytes) Example: test -e /etc/passwd echo $? 0 [ -w /etc/passwd ] echo $? 1 An internal command to some shells (including bash) that is more modern, and provides more features than the external command test , has been created. [[ -s /etc/passwd ]] echo $? 1 !!! NOTE We will therefore use the internal command for the rest of this chapter. Compare two files It is also possible to compare two files: [[ file1 -nt|-ot|-ef file2 ]] Option Observation -nt Tests if the first file is newer than the second -ot Tests if the first file is older than the second -ef Tests if the first file is a physical link of the second Testing variables It is possible to test variables: [[ -z|-n $variable ]] Option Observation -z Tests if the variable is empty -n Tests if the variable is not empty Testing strings It is also possible to compare two strings: [[ string1 =|!=|<|> string2 ]] Example: [[ \"$var\" = \"Rocky rocks!\" ]] echo $? 0 Option Observation = Tests if the first string is equal to the second != Tests if the first string is different from the second one < Tests if the first string is before the second in ASCII order > Tests if the first string is after the second in ASCII order Comparison of integer numbers Syntax for testing integers: [[ \"num1\" -eq|-ne|-gt|-lt \"num2\" ]] Example: var=1 [[ \"$var\" -eq \"1\" ]] echo $? 0 var=2 [[ \"$var\" -eq \"1\" ]] echo $? 1 Option Observation -eq Test if the first number is equal to the second -ne Test if the first number is different from the second -gt Test if the first number is greater than the second -lt Test if the first number is less than the second !!! Note Since numeric values are treated by the shell as regular characters (or strings), a test on a character can return the same result whether it is treated as a numeric or not. ``` test \"1\" = \"1\" echo $? 0 test \"1\" -eq \"1\" echo $? 0 ``` But the result of the test will not have the same meaning: * In the first case, it will mean that the two characters have the same value in the ASCII table. * In the second case, it will mean that the two numbers are equal. Combined tests The combination of tests allows you to perform several tests in one command. It is possible to test the same argument (file, string or numeric) several times or different arguments. [ option1 argument1 [-a|-o] option2 argument 2 ] ls -lad /etc drwxr-xr-x 142 root root 12288 sept. 20 09:25 /etc [ -d /etc -a -x /etc ] echo $? 0 Option Observation -a AND: The test will be true if all patterns are true. -o OR: The test will be true if at least one pattern is true. With the internal command, it is better to use this syntax: [[ -d \"/etc\" && -x \"/etc\" ]] Tests can be grouped with parentheses ( ) to give them priority. (TEST1 -a TEST2) -a TEST3 The ! character is used to perform the reverse test of the one requested by the option: test -e /file # true if file exists ! test -e /file # true if file does not exist Numerical operations The expr command performs an operation with numeric integers. expr num1 [+] [-] [\\*] [/] [%] num2 Example: expr 2 + 2 4 !!! Warning Be careful to surround the operation sign with a space. You will get an error message if you forget. In the case of a multiplication, the wildcard character `*` is preceded by `\\` to avoid a wrong interpretation. Option Observation + Addition - Subtraction \\* Multiplication / Division quotient % Modulo of the division The typeset command The typeset -i command declares a variable as an integer. Example: typeset -i var1 var1=1+1 var2=1+1 echo $var1 2 echo $var2 1+1 The let command The let command tests if a character is numeric. Example: var1=\"10\" var2=\"AA\" let $var1 echo $? 0 let $var2 echo $? 1 !!! Warning The `let` command does not return a consistent return code when it evaluates the numeric `0`. ``` let 0 echo $? 1 ``` The let command also allows you to perform mathematical operations: let var=5+5 echo $var 10 let can be substituted by $(( )) . echo $((5+2)) 7 echo $((5*2)) 10 var=$((5*3)) echo $var 15","title":"Bash - Tests"},{"location":"books/learning_bash/05-tests/#bash-tests","text":"Objectives : In this chapter you will learn how to: :heavy_check_mark: work with the return code; :heavy_check_mark: test files and compare them; :heavy_check_mark: test variables, strings and integers; :heavy_check_mark: perform an operation with numeric integers; :checkered_flag: linux , script , bash , variable Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 10 minutes Upon completion, all commands executed by the shell return a return code (also called status or exit code ). If the command ran correctly, the convention is that the status code will be zero . If the command encountered a problem during its execution, its status code will have a non-zero value . There are many reasons for this: lack of access rights, missing file, incorrect input, etc. You should refer to the manual of the man command to know the different values of the return code provided by the developers. The return code is not visible directly, but is stored in a special variable: $? . mkdir directory echo $? 0 mkdir /directory mkdir: unable to create directory echo $? 1 command_that_does_not_exist command_that_does_not_exist: command not found echo $? 127 !!! note The display of the contents of the `$?` variable with the `echo` command is done immediately after the command you want to evaluate because this variable is updated after each execution of a command, a command line or a script. !!! tip Since the value of `$?` changes after each command execution, it is better to put its value in a variable that will be used afterwards, for a test or to display a message. ``` ls no_file ls: cannot access 'no_file': No such file or directory result=$? echo $? 0 echo $result 2 ``` It is also possible to create return codes in a script. To do so, you just need to add a numeric argument to the exit command. bash # to avoid being disconnected after the \"exit 2 exit 123 echo $? 123 In addition to the correct execution of a command, the shell offers the possibility to run tests on many patterns: Files : existence, type, rights, comparison; Strings : length, comparison; Numeric integers : value, comparison. The result of the test: $?=0 : the test was correctly executed and is true; $?=1 : the test was correctly executed and is false; $?=2 : the test was not correctly executed.","title":"Bash - Tests"},{"location":"books/learning_bash/05-tests/#testing-the-type-of-a-file","text":"Syntax of the test command for a file: test [-d|-e|-f|-L] file or: [ -d|-e|-f|-L file ] !!! NOTE Note that there is a space after the `[` and before the `]`. Options of the test command on files: Option Observation -e Tests if the file exists -f Tests if the file exists and is of normal type -d Checks if the file exists and is of type directory -L Checks if the file exists and is of type symbolic link -b Checks if the file exists and is of special type block mode -c Checks if the file exists and is of special type character mode -p Checks if the file exists and is of type tube -S Checks if the file exists and is of type socket -t Checks if the file exists and is of type terminal -r Checks if the file exists and is readable -w Checks if the file exists and is writable -x Checks if the file exists and is executable -g Checks if the file exists and has a set SGID -u Checks if the file exists and has a set SUID -s Tests if the file exists and is non-empty (size > 0 bytes) Example: test -e /etc/passwd echo $? 0 [ -w /etc/passwd ] echo $? 1 An internal command to some shells (including bash) that is more modern, and provides more features than the external command test , has been created. [[ -s /etc/passwd ]] echo $? 1 !!! NOTE We will therefore use the internal command for the rest of this chapter.","title":"Testing the type of a file"},{"location":"books/learning_bash/05-tests/#compare-two-files","text":"It is also possible to compare two files: [[ file1 -nt|-ot|-ef file2 ]] Option Observation -nt Tests if the first file is newer than the second -ot Tests if the first file is older than the second -ef Tests if the first file is a physical link of the second","title":"Compare two files"},{"location":"books/learning_bash/05-tests/#testing-variables","text":"It is possible to test variables: [[ -z|-n $variable ]] Option Observation -z Tests if the variable is empty -n Tests if the variable is not empty","title":"Testing variables"},{"location":"books/learning_bash/05-tests/#testing-strings","text":"It is also possible to compare two strings: [[ string1 =|!=|<|> string2 ]] Example: [[ \"$var\" = \"Rocky rocks!\" ]] echo $? 0 Option Observation = Tests if the first string is equal to the second != Tests if the first string is different from the second one < Tests if the first string is before the second in ASCII order > Tests if the first string is after the second in ASCII order","title":"Testing strings"},{"location":"books/learning_bash/05-tests/#comparison-of-integer-numbers","text":"Syntax for testing integers: [[ \"num1\" -eq|-ne|-gt|-lt \"num2\" ]] Example: var=1 [[ \"$var\" -eq \"1\" ]] echo $? 0 var=2 [[ \"$var\" -eq \"1\" ]] echo $? 1 Option Observation -eq Test if the first number is equal to the second -ne Test if the first number is different from the second -gt Test if the first number is greater than the second -lt Test if the first number is less than the second !!! Note Since numeric values are treated by the shell as regular characters (or strings), a test on a character can return the same result whether it is treated as a numeric or not. ``` test \"1\" = \"1\" echo $? 0 test \"1\" -eq \"1\" echo $? 0 ``` But the result of the test will not have the same meaning: * In the first case, it will mean that the two characters have the same value in the ASCII table. * In the second case, it will mean that the two numbers are equal.","title":"Comparison of integer numbers"},{"location":"books/learning_bash/05-tests/#combined-tests","text":"The combination of tests allows you to perform several tests in one command. It is possible to test the same argument (file, string or numeric) several times or different arguments. [ option1 argument1 [-a|-o] option2 argument 2 ] ls -lad /etc drwxr-xr-x 142 root root 12288 sept. 20 09:25 /etc [ -d /etc -a -x /etc ] echo $? 0 Option Observation -a AND: The test will be true if all patterns are true. -o OR: The test will be true if at least one pattern is true. With the internal command, it is better to use this syntax: [[ -d \"/etc\" && -x \"/etc\" ]] Tests can be grouped with parentheses ( ) to give them priority. (TEST1 -a TEST2) -a TEST3 The ! character is used to perform the reverse test of the one requested by the option: test -e /file # true if file exists ! test -e /file # true if file does not exist","title":"Combined tests"},{"location":"books/learning_bash/05-tests/#numerical-operations","text":"The expr command performs an operation with numeric integers. expr num1 [+] [-] [\\*] [/] [%] num2 Example: expr 2 + 2 4 !!! Warning Be careful to surround the operation sign with a space. You will get an error message if you forget. In the case of a multiplication, the wildcard character `*` is preceded by `\\` to avoid a wrong interpretation. Option Observation + Addition - Subtraction \\* Multiplication / Division quotient % Modulo of the division","title":"Numerical operations"},{"location":"books/learning_bash/05-tests/#the-typeset-command","text":"The typeset -i command declares a variable as an integer. Example: typeset -i var1 var1=1+1 var2=1+1 echo $var1 2 echo $var2 1+1","title":"The typeset command"},{"location":"books/learning_bash/05-tests/#the-let-command","text":"The let command tests if a character is numeric. Example: var1=\"10\" var2=\"AA\" let $var1 echo $? 0 let $var2 echo $? 1 !!! Warning The `let` command does not return a consistent return code when it evaluates the numeric `0`. ``` let 0 echo $? 1 ``` The let command also allows you to perform mathematical operations: let var=5+5 echo $var 10 let can be substituted by $(( )) . echo $((5+2)) 7 echo $((5*2)) 10 var=$((5*3)) echo $var 15","title":"The let command"},{"location":"books/learning_bash/06-conditional-structures/","tags":["education","bash scripting","bash"],"text":"Bash - Conditional structures if and case Objectives : In this chapter you will learn how to: :heavy_check_mark: use the conditional syntax if ; :heavy_check_mark: use the conditional syntax case ; :checkered_flag: linux , script , bash , conditional structures Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 20 minutes Conditional structures If the $? variable is used to know the result of a test or the execution of a command, it can only be displayed and has no effect on the execution of a script. But we can use it in a condition. If the test is good then I do this action otherwise I do this other action. Syntax of the conditional alternative if : if command then command if $?=0 else command if $?!=0 fi The command placed after the word if can be any command since it is its return code ( $? ) that will be evaluated. It is often convenient to use the test command to define several actions depending on the result of this test (file exists, variable not empty, write rights set). Using a classical command ( mkdir , tar , ...) allows you to define the actions to be performed in case of success, or the error messages to be displayed in case of failure. Examples: if [[ -e /etc/passwd ]] then echo \"The file exists\" else echo \"The file does not exist\" fi if mkdir rep then cd rep fi If the else block starts with a new if structure, you can merge the else and if with elif as shown below: [...] else if [[ -e /etc/ ]] [...] [...] # is equivalent to elif [[ -e /etc ]] [...] !!! Note \"Summary\" The structure `if` / `then` / `else` / `fi` evaluates the command placed after if: * If the return code of this command is `0` (`true`) the shell will execute the commands placed after `then`; * If the return code is different from `0` (`false`) the shell will execute the commands placed after `else`. The `else` block is optional. There is often a need to perform some actions only if the evaluation of the command is true and to do nothing if it is false. The word `fi` closes the structure. When there is only one command to execute in the then block, it is possible to use a simpler syntax. The command to execute if $? is true is placed after && while the command to execute if $? is false is placed after || (optional). Example: [[ -e /etc/passwd ]] && echo \"The file exists\" || echo \"The file does not exist\" mkdir dir && echo \"The directory is created\". It is also possible to evaluate and replace a variable with a lighter structure than if . This syntax implements the braces: Displays a replacement value if the variable is empty: ${variable:-value} Displays a replacement value if the variable is not empty: ${variable:+value} Assigns a new value to the variable if it is empty: ${variable:=value} Examples: name=\"\" echo ${name:-linux} linux echo $name echo ${name:=linux} linux echo $name linux echo ${name:+tux} tux echo $name linux !!! hint When deciding on the use of `if`, `then`, `else`, `fi` OR the use of the simpler syntax examples described, keep in mind the readability of your script. If no one is going to use the script but yourself, then you can use what works best for you. If someone else might need to review, debug, or trace through the script that you create, either use the more self documenting form (`if`,`then`, etc) or make sure that you document your script thoroughly so that the simpler syntax is actually understood by those who may need to modify and use the script. Documenting the script is *always* a good thing to do anyway, as noted several times earlier in these lessons. Alternative conditional: structure case A succession of if structures can quickly become heavy and complex. When it concerns the evaluation of the same variable, it is possible to use a conditional structure with several branches. The values of the variable can be specified or belong to a list of possibilities. Wildcards can be used . The structure case ... in / esac evaluates the variable placed after case and compares it with the defined values. At the first equality found, the commands placed between ) and ;; are executed. The variable evaluated and the values proposed can be strings or results of sub-executions of commands. Placed at the end of the structure, the choice * indicates the actions to be executed for all the values that have not been previously tested. Syntax of the conditional alternative case: case $variable in value1) commands if $variable = value1 ;; value2) commands if $variable = value2 ;; [..] *) commands for all values of $variable != of value1 and value2 ;; esac When the value is subject to variation, it is advisable to use wildcards [] to specify the possibilities: [Yy][Ee][Ss]) echo \"yes\" ;; The character | also allows you to specify a value or another: \"yes\" | \"YES\") echo \"yes\" ;;","title":"Bash - Conditional structures if and case"},{"location":"books/learning_bash/06-conditional-structures/#bash-conditional-structures-if-and-case","text":"Objectives : In this chapter you will learn how to: :heavy_check_mark: use the conditional syntax if ; :heavy_check_mark: use the conditional syntax case ; :checkered_flag: linux , script , bash , conditional structures Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 20 minutes","title":"Bash - Conditional structures if and case"},{"location":"books/learning_bash/06-conditional-structures/#conditional-structures","text":"If the $? variable is used to know the result of a test or the execution of a command, it can only be displayed and has no effect on the execution of a script. But we can use it in a condition. If the test is good then I do this action otherwise I do this other action. Syntax of the conditional alternative if : if command then command if $?=0 else command if $?!=0 fi The command placed after the word if can be any command since it is its return code ( $? ) that will be evaluated. It is often convenient to use the test command to define several actions depending on the result of this test (file exists, variable not empty, write rights set). Using a classical command ( mkdir , tar , ...) allows you to define the actions to be performed in case of success, or the error messages to be displayed in case of failure. Examples: if [[ -e /etc/passwd ]] then echo \"The file exists\" else echo \"The file does not exist\" fi if mkdir rep then cd rep fi If the else block starts with a new if structure, you can merge the else and if with elif as shown below: [...] else if [[ -e /etc/ ]] [...] [...] # is equivalent to elif [[ -e /etc ]] [...] !!! Note \"Summary\" The structure `if` / `then` / `else` / `fi` evaluates the command placed after if: * If the return code of this command is `0` (`true`) the shell will execute the commands placed after `then`; * If the return code is different from `0` (`false`) the shell will execute the commands placed after `else`. The `else` block is optional. There is often a need to perform some actions only if the evaluation of the command is true and to do nothing if it is false. The word `fi` closes the structure. When there is only one command to execute in the then block, it is possible to use a simpler syntax. The command to execute if $? is true is placed after && while the command to execute if $? is false is placed after || (optional). Example: [[ -e /etc/passwd ]] && echo \"The file exists\" || echo \"The file does not exist\" mkdir dir && echo \"The directory is created\". It is also possible to evaluate and replace a variable with a lighter structure than if . This syntax implements the braces: Displays a replacement value if the variable is empty: ${variable:-value} Displays a replacement value if the variable is not empty: ${variable:+value} Assigns a new value to the variable if it is empty: ${variable:=value} Examples: name=\"\" echo ${name:-linux} linux echo $name echo ${name:=linux} linux echo $name linux echo ${name:+tux} tux echo $name linux !!! hint When deciding on the use of `if`, `then`, `else`, `fi` OR the use of the simpler syntax examples described, keep in mind the readability of your script. If no one is going to use the script but yourself, then you can use what works best for you. If someone else might need to review, debug, or trace through the script that you create, either use the more self documenting form (`if`,`then`, etc) or make sure that you document your script thoroughly so that the simpler syntax is actually understood by those who may need to modify and use the script. Documenting the script is *always* a good thing to do anyway, as noted several times earlier in these lessons.","title":"Conditional structures"},{"location":"books/learning_bash/06-conditional-structures/#alternative-conditional-structure-case","text":"A succession of if structures can quickly become heavy and complex. When it concerns the evaluation of the same variable, it is possible to use a conditional structure with several branches. The values of the variable can be specified or belong to a list of possibilities. Wildcards can be used . The structure case ... in / esac evaluates the variable placed after case and compares it with the defined values. At the first equality found, the commands placed between ) and ;; are executed. The variable evaluated and the values proposed can be strings or results of sub-executions of commands. Placed at the end of the structure, the choice * indicates the actions to be executed for all the values that have not been previously tested. Syntax of the conditional alternative case: case $variable in value1) commands if $variable = value1 ;; value2) commands if $variable = value2 ;; [..] *) commands for all values of $variable != of value1 and value2 ;; esac When the value is subject to variation, it is advisable to use wildcards [] to specify the possibilities: [Yy][Ee][Ss]) echo \"yes\" ;; The character | also allows you to specify a value or another: \"yes\" | \"YES\") echo \"yes\" ;;","title":"Alternative conditional: structure case"},{"location":"books/learning_bash/07-loops/","tags":["education","bash scripting","bash"],"text":"Bash - Loops Objectives : In this chapter you will learn how to: :heavy_check_mark: use loops; :checkered_flag: linux , script , bash , loops Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 20 minutes The bash shell allows for the use of loops . These structures allow for the execution of a block of commands several times (from 0 to infinity) according to a statically defined value, dynamically or on condition: while until for select Whatever the loop used, the commands to be repeated are placed between the words do and done . The while conditional loop structure The while / do / done structure evaluates the command placed after while . If this command is true ( $? = 0 ), the commands placed between do and done are executed. The script then returns to the beginning to evaluate the command again. When the evaluated command is false ( $? != 0 ), the shell resumes the execution of the script at the first command after done. Syntax of the conditional loop structure while : while command do command if $? = 0 done Example using the while conditional structure: while [[ -e /etc/passwd ]] do echo \"The file exists\" done If the evaluated command does not vary, the loop will be infinite and the shell will never execute the commands placed after the script. This can be intentional, but it can also be an error. So you have to be very careful with the commands that manage the loop and find a way to get out of it . To get out of a while loop, you have to make sure that the command being evaluated is no longer true, which is not always possible. There are commands that allow you to change the behavior of a loop: exit break continue The exit command The exit command ends the execution of the script. Syntax of the exit command : exit [n] Example using the exit command : bash # to avoid being disconnected after the \"exit 1 exit 1 echo $? 1 The exit command ends the script immediately. It is possible to specify the return code of the script by giving it as an argument (from 0 to 255 ). If no argument is given, the return code of the last command of the script will be passed to the $? variable. The break / continue commands The break command allows you to interrupt the loop by going to the first command after done . The continue command allows you to restart the loop by going back to the first command after done . while [[ -d / ]] \ue0b2 INT \u2718 \ue0b2 17s \uf252 do echo \"Do you want to continue? (yes/no)\" read ans [[ $ans = \"yes\" ]] && continue [[ $ans = \"no\" ]] && break done The true / false commands The true command always returns true while the false command always returns false . true echo $? 0 false echo $? 1 Used as a condition of a loop, they allow for either an execution of an infinite loop or the deactivation of this loop. Example: while true do echo \"Do you want to continue? (yes/no)\" read ans [[ $ans = \"yes\" ]] && continue [[ $ans = \"no\" ]] && break done The until conditional loop structure The until / do / done structure evaluates the command placed after until . If this command is false ( $? != 0 ), the commands placed between do and done are executed. The script then returns to the beginning to evaluate the command again. When the evaluated command is true ( $? = 0 ), the shell resumes the execution of the script at the first command after done . Syntax of the conditional loop structure until : until command do command if $? != 0 done Example of the use of the conditional structure until : until [[ -e test_until ]] do echo \"The file does not exist\" touch test_until done The alternative choice structure select The structure select / do / done allows for the display of a menu with several choices and an input request. Each item in the list has a numbered choice. When you enter a choice, the value chosen is assigned to the variable placed after select (created for this purpose). It then executes the commands placed between do and done with this value. The variable PS3 contains the invitation to enter the choice; The variable REPLY will return the number of the choice. A break command is needed to exit the loop. !!! Note The `select` structure is very useful for small and simple menus. To customize a more complete display, the `echo` and `read` commands must be used in a `while` loop. Syntax of the conditional loop structure select : PS3=\"Your choice:\" select variable in var1 var2 var3 do commands done Example of the use of the conditional structure select : PS3=\"Your choice: \" select choice in coffee tea chocolate do echo \"You have chosen the $REPLY: $choice\" done If this script is run, it shows something like this: 1) Coffee 2) Tea 3) Chocolate Your choice : 2 You have chosen choice 2: Tea Your choice: The loop structure on a list of values for The for / do / done structure assigns the first element of the list to the variable placed after for (created on this occasion). It then executes the commands placed between do and done with this value. The script then returns to the beginning to assign the next element of the list to the working variable. When the last element has been used, the shell resumes execution at the first command after done . Syntax of the loop structure on list of values for : for variable in list do commands done Example of using the conditional structure for : for file in /home /etc/passwd /root/fic.txt do file $file done Any command producing a list of values can be placed after the in using a sub-execution. With the variable IFS containing $' \\t\\n' , the for loop will take each word of the result of this command as a list of elements to loop on. With the IFS variable containing $'\\t\\n' (i.e. without spaces), the for loop will take each line of the result of this command. This can be the files in a directory. In this case, the variable will take as a value each of the words of the file names present: for file in $(ls -d /tmp/*) do echo $file done It can be a file. In this case, the variable will take as a value each word contained in the file browsed, from the beginning to the end: cat my_file.txt first line second line third line for LINE in $(cat my_file.txt); do echo $LINE; done first line second line third line line To read a file line by line, you must modify the value of the IFS environment variable. IFS=$'\\t\\n' for LINE in $(cat my_file.txt); do echo $LINE; done first line second line third line","title":"Bash - Loops"},{"location":"books/learning_bash/07-loops/#bash-loops","text":"Objectives : In this chapter you will learn how to: :heavy_check_mark: use loops; :checkered_flag: linux , script , bash , loops Knowledge : :star: :star: Complexity : :star: :star: :star: Reading time : 20 minutes The bash shell allows for the use of loops . These structures allow for the execution of a block of commands several times (from 0 to infinity) according to a statically defined value, dynamically or on condition: while until for select Whatever the loop used, the commands to be repeated are placed between the words do and done .","title":"Bash - Loops"},{"location":"books/learning_bash/07-loops/#the-while-conditional-loop-structure","text":"The while / do / done structure evaluates the command placed after while . If this command is true ( $? = 0 ), the commands placed between do and done are executed. The script then returns to the beginning to evaluate the command again. When the evaluated command is false ( $? != 0 ), the shell resumes the execution of the script at the first command after done. Syntax of the conditional loop structure while : while command do command if $? = 0 done Example using the while conditional structure: while [[ -e /etc/passwd ]] do echo \"The file exists\" done If the evaluated command does not vary, the loop will be infinite and the shell will never execute the commands placed after the script. This can be intentional, but it can also be an error. So you have to be very careful with the commands that manage the loop and find a way to get out of it . To get out of a while loop, you have to make sure that the command being evaluated is no longer true, which is not always possible. There are commands that allow you to change the behavior of a loop: exit break continue","title":"The while conditional loop structure"},{"location":"books/learning_bash/07-loops/#the-exit-command","text":"The exit command ends the execution of the script. Syntax of the exit command : exit [n] Example using the exit command : bash # to avoid being disconnected after the \"exit 1 exit 1 echo $? 1 The exit command ends the script immediately. It is possible to specify the return code of the script by giving it as an argument (from 0 to 255 ). If no argument is given, the return code of the last command of the script will be passed to the $? variable.","title":"The exit command"},{"location":"books/learning_bash/07-loops/#the-break-continue-commands","text":"The break command allows you to interrupt the loop by going to the first command after done . The continue command allows you to restart the loop by going back to the first command after done . while [[ -d / ]] \ue0b2 INT \u2718 \ue0b2 17s \uf252 do echo \"Do you want to continue? (yes/no)\" read ans [[ $ans = \"yes\" ]] && continue [[ $ans = \"no\" ]] && break done","title":"The break / continue commands"},{"location":"books/learning_bash/07-loops/#the-true-false-commands","text":"The true command always returns true while the false command always returns false . true echo $? 0 false echo $? 1 Used as a condition of a loop, they allow for either an execution of an infinite loop or the deactivation of this loop. Example: while true do echo \"Do you want to continue? (yes/no)\" read ans [[ $ans = \"yes\" ]] && continue [[ $ans = \"no\" ]] && break done","title":"The true / false commands"},{"location":"books/learning_bash/07-loops/#the-until-conditional-loop-structure","text":"The until / do / done structure evaluates the command placed after until . If this command is false ( $? != 0 ), the commands placed between do and done are executed. The script then returns to the beginning to evaluate the command again. When the evaluated command is true ( $? = 0 ), the shell resumes the execution of the script at the first command after done . Syntax of the conditional loop structure until : until command do command if $? != 0 done Example of the use of the conditional structure until : until [[ -e test_until ]] do echo \"The file does not exist\" touch test_until done","title":"The until conditional loop structure"},{"location":"books/learning_bash/07-loops/#the-alternative-choice-structure-select","text":"The structure select / do / done allows for the display of a menu with several choices and an input request. Each item in the list has a numbered choice. When you enter a choice, the value chosen is assigned to the variable placed after select (created for this purpose). It then executes the commands placed between do and done with this value. The variable PS3 contains the invitation to enter the choice; The variable REPLY will return the number of the choice. A break command is needed to exit the loop. !!! Note The `select` structure is very useful for small and simple menus. To customize a more complete display, the `echo` and `read` commands must be used in a `while` loop. Syntax of the conditional loop structure select : PS3=\"Your choice:\" select variable in var1 var2 var3 do commands done Example of the use of the conditional structure select : PS3=\"Your choice: \" select choice in coffee tea chocolate do echo \"You have chosen the $REPLY: $choice\" done If this script is run, it shows something like this: 1) Coffee 2) Tea 3) Chocolate Your choice : 2 You have chosen choice 2: Tea Your choice:","title":"The alternative choice structure select"},{"location":"books/learning_bash/07-loops/#the-loop-structure-on-a-list-of-values-for","text":"The for / do / done structure assigns the first element of the list to the variable placed after for (created on this occasion). It then executes the commands placed between do and done with this value. The script then returns to the beginning to assign the next element of the list to the working variable. When the last element has been used, the shell resumes execution at the first command after done . Syntax of the loop structure on list of values for : for variable in list do commands done Example of using the conditional structure for : for file in /home /etc/passwd /root/fic.txt do file $file done Any command producing a list of values can be placed after the in using a sub-execution. With the variable IFS containing $' \\t\\n' , the for loop will take each word of the result of this command as a list of elements to loop on. With the IFS variable containing $'\\t\\n' (i.e. without spaces), the for loop will take each line of the result of this command. This can be the files in a directory. In this case, the variable will take as a value each of the words of the file names present: for file in $(ls -d /tmp/*) do echo $file done It can be a file. In this case, the variable will take as a value each word contained in the file browsed, from the beginning to the end: cat my_file.txt first line second line third line for LINE in $(cat my_file.txt); do echo $LINE; done first line second line third line line To read a file line by line, you must modify the value of the IFS environment variable. IFS=$'\\t\\n' for LINE in $(cat my_file.txt); do echo $LINE; done first line second line third line","title":"The loop structure on a list of values for"},{"location":"books/learning_bash/08-check-your-knowledge/","tags":["education","bash scripting","bash"],"text":"Bash - Check your knowledge :heavy_check_mark: Every order must return a return code at the end of its execution: [ ] True [ ] False :heavy_check_mark: A return code of 0 indicates an execution error: [ ] True [ ] False :heavy_check_mark: The return code is stored in the variable $@ : [ ] True [ ] False :heavy_check_mark: The test command allows you to: [ ] Test the type of a file [ ] Test a variable [ ] Compare numbers [ ] Compare the content of 2 files :heavy_check_mark: The command expr : [ ] Concatenates 2 strings of characters [ ] Performs mathematical operations [ ] Display text on the screen :heavy_check_mark: Does the syntax of the conditional structure below seem correct to you? Explain why. if command command if $?=0 else command if $?!=0 fi [ ] True [ ] False :heavy_check_mark: What does the following syntax mean: ${variable:=value} [ ] Displays a replacement value if the variable is empty [ ] Display a replacement value if the variable is not empty [ ] Assigns a new value to the variable if it is empty :heavy_check_mark: Does the syntax of the conditional alternative structure below seem correct to you? Explain why. case $variable in value1) commands if $variable = value1 value2) commands if $variable = value2 *) commands for all values of $variable != of value1 and value2 ;; esac [ ] True [ ] False :heavy_check_mark: Which of the following is not a structure for looping? [ ] while [ ] until [ ] loop [ ] for","title":"Bash - Check your knowledge"},{"location":"books/learning_bash/08-check-your-knowledge/#bash-check-your-knowledge","text":":heavy_check_mark: Every order must return a return code at the end of its execution: [ ] True [ ] False :heavy_check_mark: A return code of 0 indicates an execution error: [ ] True [ ] False :heavy_check_mark: The return code is stored in the variable $@ : [ ] True [ ] False :heavy_check_mark: The test command allows you to: [ ] Test the type of a file [ ] Test a variable [ ] Compare numbers [ ] Compare the content of 2 files :heavy_check_mark: The command expr : [ ] Concatenates 2 strings of characters [ ] Performs mathematical operations [ ] Display text on the screen :heavy_check_mark: Does the syntax of the conditional structure below seem correct to you? Explain why. if command command if $?=0 else command if $?!=0 fi [ ] True [ ] False :heavy_check_mark: What does the following syntax mean: ${variable:=value} [ ] Displays a replacement value if the variable is empty [ ] Display a replacement value if the variable is not empty [ ] Assigns a new value to the variable if it is empty :heavy_check_mark: Does the syntax of the conditional alternative structure below seem correct to you? Explain why. case $variable in value1) commands if $variable = value1 value2) commands if $variable = value2 *) commands for all values of $variable != of value1 and value2 ;; esac [ ] True [ ] False :heavy_check_mark: Which of the following is not a structure for looping? [ ] while [ ] until [ ] loop [ ] for","title":"Bash - Check your knowledge"},{"location":"books/learning_bash/appendix/02-variables-logs/","tags":["bash scripting","bash","variables example"],"text":"Using Variables - A Practical Application With Logs Introduction In lesson two, \"Bash - Using Variables\", you've seen some ways to use variables and learned a lot about what variables can be used for. This is just one practical example of using variables within your bash scripts. Information When a system administrator has to deal with log files, there are sometimes different formats that come into play. Let's say that you want to get some information out of the dnf.log ( /var/log/dnf.log ). Let's take a quick look at what that log file looks like using tail /var/log/dnf.log : 2022-05-04T09:02:18-0400 DEBUG extras: using metadata from Thu 28 Apr 2022 04:25:35 PM EDT. 2022-05-04T09:02:18-0400 DEBUG repo: using cache for: powertools 2022-05-04T09:02:18-0400 DEBUG powertools: using metadata from Thu 28 Apr 2022 04:25:36 PM EDT. 2022-05-04T09:02:18-0400 DEBUG repo: using cache for: epel 2022-05-04T09:02:18-0400 DEBUG epel: using metadata from Tue 03 May 2022 11:55:16 AM EDT. 2022-05-04T09:02:18-0400 DEBUG repo: using cache for: epel-modular 2022-05-04T09:02:18-0400 DEBUG epel-modular: using metadata from Sun 17 Apr 2022 07:09:16 PM EDT. 2022-05-04T09:02:18-0400 INFO Last metadata expiration check: 3:07:06 ago on Wed 04 May 2022 05:55:12 AM EDT. 2022-05-04T09:02:18-0400 DDEBUG timer: sack setup: 512 ms 2022-05-04T09:02:18-0400 DDEBUG Cleaning up. Now take a look at the messages log file tail /var/log/messages : May 4 08:47:19 localhost systemd[1]: Starting dnf makecache... May 4 08:47:19 localhost dnf[108937]: Metadata cache refreshed recently. May 4 08:47:19 localhost systemd[1]: dnf-makecache.service: Succeeded. May 4 08:47:19 localhost systemd[1]: Started dnf makecache. May 4 08:51:59 localhost NetworkManager[981]: <info> [1651668719.5310] dhcp4 (eno1): state changed extended -> extended, address=192.168.1.141 May 4 08:51:59 localhost dbus-daemon[843]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.freedesktop.nm-dispatcher.service' requested by ':1.10' (uid=0 pid=981 comm=\"/usr/sbin/NetworkManager --no-daemon \" label=\"system_u:system_r:NetworkManager_t:s0\") May 4 08:51:59 localhost systemd[1]: Starting Network Manager Script Dispatcher Service... May 4 08:51:59 localhost dbus-daemon[843]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher' May 4 08:51:59 localhost systemd[1]: Started Network Manager Script Dispatcher Service. May 4 08:52:09 localhost systemd[1]: NetworkManager-dispatcher.service: Succeeded. And finally let's take a look at the output of the date command: Wed May 4 09:47:00 EDT 2022 Findings and Goals What we can see here is that the two log files, dnf.log and messages display the date in entirely different ways. If we wanted to grab the information from the messages log in a bash script using date we could do so without much trouble, but getting the same information out of the dnf.log would take some doing. Let's say that as a system administrator, you need to review the dnf.log daily to make sure that nothing was introduced to the system that you weren't aware of or that might cause problems. You want this information to be grabbed from the dnf.log file by date and then emailed to you daily. You will use a cron job to automate this, but first we need to get a script that will do what we want it to do. Script To accomplish what we want, we are going to use a variable in our script called \"today\" that will format the date according to the date displayed in the dnf.log . To get the correct date format, we are using the +%F which will get us the yyyy-mm-dd format we are looking for. Since all we are concerned with is the day, not the times or any other information, that's all we will need to get the correct information out of the dnf.log . Try just this much of the script: #!/usr/bin/env bash # script to grab dnf.log data and send it to administrator daily today=`date +%F` echo $today Here we are using the echo command to see if we have been successful with our date formatting. When you run the script, you should get an output with today's date that looks something like this: 2022-05-04 If so then great, we can remove our \"debug\" line and continue. Let's add another variable called \"logfile\" that we will set to /var/log/dnf.log and then let's see if we can grep that using our \"today\" variable. For now, let's just let it run to standard output: !/usr/bin/env bash # script to grab dnf.log data and send it to administrator daily today=`date +%F` logfile=/var/log/dnf.log /bin/grep $today $logfile The dnf.log has a lot of information in it every day, so we are not posting that to the screen here, but you should see output that has only today's data in it. Give the script a try and if it works, then we can move on to the next step. After we've checked the output, the next step is that we want to do a pipe redirect to send the information to email. !!! hint You need `mailx` and a mail daemon such as `postfix` installed to accomplish this next step. There's also some configuration that will *probably* be necessary for you to receive email from your server to your companies email address. Don't worry about those steps at this point, because you can check the `maillog` to see if the attempt was made and then work from there to get email from your server to your email address working. That's not something that this document is going to deal with. For now do: ``` dnf install mailx postfix systemctl enable --now postfix ``` #!/usr/bin/env bash # script to grab dnf.log data and send it to administrator daily today=`date +%F` logfile=/var/log/dnf.log /bin/grep $today $logfile | /bin/mail -s \"DNF logfile data for $today\" systemadministrator@domain.ext Let's take a look at the additions to the script here. We've added a pipe | to redirect output to /bin/mail set the subject of the email ( -s ) with what is in double quotes and set the recipient to be \"systemadministrator@domain.ext\". Replace that last bit with your email address and then try running the script again. As noted, you probably won't get the email without some changes to your Postfix mail setup, but you should see the attempt in /var/log/maillog . Next Steps The next thing you need to do is to get sending email from your server working. You can take a look at Postfix for Reporting to get you started on that front. We also need to automate this script to run daily, to do that we will use cron . There are multiple references here: cron , anacron , and cronie . For more information on date formatting, check out man date or this link .","title":"Variables - Use With Logs"},{"location":"books/learning_bash/appendix/02-variables-logs/#using-variables-a-practical-application-with-logs","text":"","title":"Using Variables - A Practical Application With Logs"},{"location":"books/learning_bash/appendix/02-variables-logs/#introduction","text":"In lesson two, \"Bash - Using Variables\", you've seen some ways to use variables and learned a lot about what variables can be used for. This is just one practical example of using variables within your bash scripts.","title":"Introduction"},{"location":"books/learning_bash/appendix/02-variables-logs/#information","text":"When a system administrator has to deal with log files, there are sometimes different formats that come into play. Let's say that you want to get some information out of the dnf.log ( /var/log/dnf.log ). Let's take a quick look at what that log file looks like using tail /var/log/dnf.log : 2022-05-04T09:02:18-0400 DEBUG extras: using metadata from Thu 28 Apr 2022 04:25:35 PM EDT. 2022-05-04T09:02:18-0400 DEBUG repo: using cache for: powertools 2022-05-04T09:02:18-0400 DEBUG powertools: using metadata from Thu 28 Apr 2022 04:25:36 PM EDT. 2022-05-04T09:02:18-0400 DEBUG repo: using cache for: epel 2022-05-04T09:02:18-0400 DEBUG epel: using metadata from Tue 03 May 2022 11:55:16 AM EDT. 2022-05-04T09:02:18-0400 DEBUG repo: using cache for: epel-modular 2022-05-04T09:02:18-0400 DEBUG epel-modular: using metadata from Sun 17 Apr 2022 07:09:16 PM EDT. 2022-05-04T09:02:18-0400 INFO Last metadata expiration check: 3:07:06 ago on Wed 04 May 2022 05:55:12 AM EDT. 2022-05-04T09:02:18-0400 DDEBUG timer: sack setup: 512 ms 2022-05-04T09:02:18-0400 DDEBUG Cleaning up. Now take a look at the messages log file tail /var/log/messages : May 4 08:47:19 localhost systemd[1]: Starting dnf makecache... May 4 08:47:19 localhost dnf[108937]: Metadata cache refreshed recently. May 4 08:47:19 localhost systemd[1]: dnf-makecache.service: Succeeded. May 4 08:47:19 localhost systemd[1]: Started dnf makecache. May 4 08:51:59 localhost NetworkManager[981]: <info> [1651668719.5310] dhcp4 (eno1): state changed extended -> extended, address=192.168.1.141 May 4 08:51:59 localhost dbus-daemon[843]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.freedesktop.nm-dispatcher.service' requested by ':1.10' (uid=0 pid=981 comm=\"/usr/sbin/NetworkManager --no-daemon \" label=\"system_u:system_r:NetworkManager_t:s0\") May 4 08:51:59 localhost systemd[1]: Starting Network Manager Script Dispatcher Service... May 4 08:51:59 localhost dbus-daemon[843]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher' May 4 08:51:59 localhost systemd[1]: Started Network Manager Script Dispatcher Service. May 4 08:52:09 localhost systemd[1]: NetworkManager-dispatcher.service: Succeeded. And finally let's take a look at the output of the date command: Wed May 4 09:47:00 EDT 2022","title":"Information"},{"location":"books/learning_bash/appendix/02-variables-logs/#findings-and-goals","text":"What we can see here is that the two log files, dnf.log and messages display the date in entirely different ways. If we wanted to grab the information from the messages log in a bash script using date we could do so without much trouble, but getting the same information out of the dnf.log would take some doing. Let's say that as a system administrator, you need to review the dnf.log daily to make sure that nothing was introduced to the system that you weren't aware of or that might cause problems. You want this information to be grabbed from the dnf.log file by date and then emailed to you daily. You will use a cron job to automate this, but first we need to get a script that will do what we want it to do.","title":"Findings and Goals"},{"location":"books/learning_bash/appendix/02-variables-logs/#script","text":"To accomplish what we want, we are going to use a variable in our script called \"today\" that will format the date according to the date displayed in the dnf.log . To get the correct date format, we are using the +%F which will get us the yyyy-mm-dd format we are looking for. Since all we are concerned with is the day, not the times or any other information, that's all we will need to get the correct information out of the dnf.log . Try just this much of the script: #!/usr/bin/env bash # script to grab dnf.log data and send it to administrator daily today=`date +%F` echo $today Here we are using the echo command to see if we have been successful with our date formatting. When you run the script, you should get an output with today's date that looks something like this: 2022-05-04 If so then great, we can remove our \"debug\" line and continue. Let's add another variable called \"logfile\" that we will set to /var/log/dnf.log and then let's see if we can grep that using our \"today\" variable. For now, let's just let it run to standard output: !/usr/bin/env bash # script to grab dnf.log data and send it to administrator daily today=`date +%F` logfile=/var/log/dnf.log /bin/grep $today $logfile The dnf.log has a lot of information in it every day, so we are not posting that to the screen here, but you should see output that has only today's data in it. Give the script a try and if it works, then we can move on to the next step. After we've checked the output, the next step is that we want to do a pipe redirect to send the information to email. !!! hint You need `mailx` and a mail daemon such as `postfix` installed to accomplish this next step. There's also some configuration that will *probably* be necessary for you to receive email from your server to your companies email address. Don't worry about those steps at this point, because you can check the `maillog` to see if the attempt was made and then work from there to get email from your server to your email address working. That's not something that this document is going to deal with. For now do: ``` dnf install mailx postfix systemctl enable --now postfix ``` #!/usr/bin/env bash # script to grab dnf.log data and send it to administrator daily today=`date +%F` logfile=/var/log/dnf.log /bin/grep $today $logfile | /bin/mail -s \"DNF logfile data for $today\" systemadministrator@domain.ext Let's take a look at the additions to the script here. We've added a pipe | to redirect output to /bin/mail set the subject of the email ( -s ) with what is in double quotes and set the recipient to be \"systemadministrator@domain.ext\". Replace that last bit with your email address and then try running the script again. As noted, you probably won't get the email without some changes to your Postfix mail setup, but you should see the attempt in /var/log/maillog .","title":"Script"},{"location":"books/learning_bash/appendix/02-variables-logs/#next-steps","text":"The next thing you need to do is to get sending email from your server working. You can take a look at Postfix for Reporting to get you started on that front. We also need to automate this script to run daily, to do that we will use cron . There are multiple references here: cron , anacron , and cronie . For more information on date formatting, check out man date or this link .","title":"Next Steps"},{"location":"books/learning_rsync/01_rsync_overview/","text":"Backup Brief What is a backup? Backup refers to the duplication of data in the file system or database. In the event of an error or disaster, the effective data of the system can be restored in a timely manner and normal operation. What are the backup methods? Full backup: refers to a one-time copy of all files, folders or data in the hard disk or database. (Pros: the best, can recover data faster. Disadvantages: take up a larger hard disk space.) Incremental backup: refers to the backup of the data updated after the last full backup or incremental backup. The process is like this, such as a full backup on the first day; a backup of the newly added data on the second day, as opposed to a full backup; on the third day, a backup of the newly added data on the basis of the second day, relative to the next day, and so on. Differential backup: Refers to the backup of the changed files after the full backup. For example, a full backup on the first day; a backup of the new data on the second day; a backup of the new data from the second day to the third day on the third day; and a backup of all the new data from the second day to the fourth day on the fourth day, and so on. Selective backup: Refers to backing up a part of the system. Cold backup: refers to the backup when the system is in shutdown or maintenance state. The backed up data is exactly the same as the data in the system during this period. Hot backup: Refers to the backup when the system is in normal operation. As the data in the system is updated at any time, the backed-up data has a certain lag relative to the real data of the system. Remote backup: refers to backing up data in another geographic location to avoid data loss and service interruption caused by fire, natural disasters, theft, etc. rsync in brief On a server, I backed up the first partition to the second partition, which is commonly known as \"Local backup.\" The specific backup tools are tar , dd , dump , cp , etc. can be achieved. Although the data is backed up on this server, if the hardware fails to boot up properly, the data will not be retrieved. In order to solve this problem with the local backup, we introduced another kind of backup --- \"remote backup\". Some people will say, can't I just use the tar or cp command on the first server and send it to the second server via scp or sftp ? In a production environment, the amount of data is relatively large. First of all, tar or cp consumes a lot of time and occupies system performance. Transmission via scp or sftp also occupies a lot of network bandwidth, which is not allowed in the actual production environment. Secondly, these commands or tools need to be manually entered by the administrator and need to be combined with the crontab of the scheduled task. However, the time set by crontab is not easy to grasp, and it is not appropriate for data to be backed up if the time is too short or too long. Therefore, there needs to be a data backup in the production environment which needs to meet the following requirements: Backups transmitted over the network Real-time data file synchronization Less occupancy of system resources and higher efficiency rsync appears to meet the above needs. It uses the GNU open source license agreement. It is a fast incremental backup tool. The latest version is 3.2.3 (2020-08-06). You can visit the Official website for more information. In terms of platform support, most Unix-like systems are supported, whether it is GNU/Linux or BSD. In addition, there are related rsync under the Windows platform, such as cwRsync. The original rsync was maintained by the Australian programmer Andrew Tridgell (shown in Figure 1 below), and now it has been maintained by Wayne Davison (shown in Figure 2 below) ) For maintenance, you can go to github project address to get the information you want. !!! note \"Attention!\" **rsync itself is only an incremental backup tool and does not have the function of real-time data synchronization (it needs to be supplemented by other programs). In addition, synchronization is one-way. If you want to realize two-way synchronization, you need to cooperate with other tools.** Basic Principles and Features How does rsync achieve efficient one-way data synchronization backup? The core of rsync is its Checksum algorithm . If you are interested, you can go to How Rsync works and The rsync algorithm for more information, This section is beyond the author's competence and will not be covered too much. The characteristics of rsync are: The entire directory can be updated recursively; Can selectively retain file synchronization attributes, such as hard link, soft link, owner, group, corresponding permissions, modification time, etc., and can retain some of the attributes; Support two protocols for transmission, one is ssh protocol, the other is rsync protocol","title":"rsync brief description"},{"location":"books/learning_rsync/01_rsync_overview/#backup-brief","text":"What is a backup? Backup refers to the duplication of data in the file system or database. In the event of an error or disaster, the effective data of the system can be restored in a timely manner and normal operation. What are the backup methods? Full backup: refers to a one-time copy of all files, folders or data in the hard disk or database. (Pros: the best, can recover data faster. Disadvantages: take up a larger hard disk space.) Incremental backup: refers to the backup of the data updated after the last full backup or incremental backup. The process is like this, such as a full backup on the first day; a backup of the newly added data on the second day, as opposed to a full backup; on the third day, a backup of the newly added data on the basis of the second day, relative to the next day, and so on. Differential backup: Refers to the backup of the changed files after the full backup. For example, a full backup on the first day; a backup of the new data on the second day; a backup of the new data from the second day to the third day on the third day; and a backup of all the new data from the second day to the fourth day on the fourth day, and so on. Selective backup: Refers to backing up a part of the system. Cold backup: refers to the backup when the system is in shutdown or maintenance state. The backed up data is exactly the same as the data in the system during this period. Hot backup: Refers to the backup when the system is in normal operation. As the data in the system is updated at any time, the backed-up data has a certain lag relative to the real data of the system. Remote backup: refers to backing up data in another geographic location to avoid data loss and service interruption caused by fire, natural disasters, theft, etc.","title":"Backup Brief"},{"location":"books/learning_rsync/01_rsync_overview/#rsync-in-brief","text":"On a server, I backed up the first partition to the second partition, which is commonly known as \"Local backup.\" The specific backup tools are tar , dd , dump , cp , etc. can be achieved. Although the data is backed up on this server, if the hardware fails to boot up properly, the data will not be retrieved. In order to solve this problem with the local backup, we introduced another kind of backup --- \"remote backup\". Some people will say, can't I just use the tar or cp command on the first server and send it to the second server via scp or sftp ? In a production environment, the amount of data is relatively large. First of all, tar or cp consumes a lot of time and occupies system performance. Transmission via scp or sftp also occupies a lot of network bandwidth, which is not allowed in the actual production environment. Secondly, these commands or tools need to be manually entered by the administrator and need to be combined with the crontab of the scheduled task. However, the time set by crontab is not easy to grasp, and it is not appropriate for data to be backed up if the time is too short or too long. Therefore, there needs to be a data backup in the production environment which needs to meet the following requirements: Backups transmitted over the network Real-time data file synchronization Less occupancy of system resources and higher efficiency rsync appears to meet the above needs. It uses the GNU open source license agreement. It is a fast incremental backup tool. The latest version is 3.2.3 (2020-08-06). You can visit the Official website for more information. In terms of platform support, most Unix-like systems are supported, whether it is GNU/Linux or BSD. In addition, there are related rsync under the Windows platform, such as cwRsync. The original rsync was maintained by the Australian programmer Andrew Tridgell (shown in Figure 1 below), and now it has been maintained by Wayne Davison (shown in Figure 2 below) ) For maintenance, you can go to github project address to get the information you want. !!! note \"Attention!\" **rsync itself is only an incremental backup tool and does not have the function of real-time data synchronization (it needs to be supplemented by other programs). In addition, synchronization is one-way. If you want to realize two-way synchronization, you need to cooperate with other tools.**","title":"rsync in brief"},{"location":"books/learning_rsync/01_rsync_overview/#basic-principles-and-features","text":"How does rsync achieve efficient one-way data synchronization backup? The core of rsync is its Checksum algorithm . If you are interested, you can go to How Rsync works and The rsync algorithm for more information, This section is beyond the author's competence and will not be covered too much. The characteristics of rsync are: The entire directory can be updated recursively; Can selectively retain file synchronization attributes, such as hard link, soft link, owner, group, corresponding permissions, modification time, etc., and can retain some of the attributes; Support two protocols for transmission, one is ssh protocol, the other is rsync protocol","title":"Basic Principles and Features"},{"location":"books/learning_rsync/02_rsync_demo01/","text":"Preface rsync needs to perform user authentication before data synchronization. There are two protocol methods for authentication: SSH protocol and rsync protocol (the default port of rsync protocol is 873) SSH protocol verification login method: use SSH protocol as the basis for user identity authentication (that is, use the system user and password of GNU/Linux itself for verification), and then perform data synchronization. rsync protocol verification login method: use rsync protocol for user identity authentication (non-GNU/Linux system users, similar to vsftpd virtual users), and then perform data synchronization. Before the specific demonstration of rsync synchronization, you need to use the rsync command. In Rocky Linux 8, the rsync rpm package is installed by default, and the version is 3.1.3-12, as follows: [root@Rocky ~]# rpm -qa|grep rsync rsync-3.1.3-12.el8.x86_64 Basic format: rsync [options] original location target location Commonly used options: -a: archive mode, recursive and preserves the attributes of the file object, which is equivalent to -rlptgoD (without -H, -A, -X) -v: Display detailed information about the synchronization process -z: compress when transferring files -H: Keep hard link files -A: retain ACL permissions -X: retain chattr permissions -r: Recursive mode, including all files in the directory and subdirectories -l: still reserved for symbolic link files -p: Permission to retain file attributes -t: time to retain file attributes -g: retain the group belonging to the file attribute (only for super users) -o: retain the owner of the file attributes (only for super users) -D: Keep device files and other special files The author's personal use: rsync -avz original location target location Environment Description Item Description Rocky Linux 8(Server) 192.168.100.4/24 Fedora 34(client) 192.168.100.5/24 You can use Fedora 34 to upload and download graph LR; RockyLinux8-->|pull/download|Fedora34; Fedora34-->|push/upload|RockyLinux8; You can also use Rocky Linux 8 to upload and download graph LR; RockyLinux8-->|push/upload|Fedora34; Fedora34-->|pull/download|RockyLinux8; Demonstration based on SSH protocol !!! tip \"Attention!\" Here, both Rocky Linux 8 and Fedora 34 use the root user to log in. Fedora 34 is the client and Rocky Linux 8 is the server. pull/download Since it is based on the SSH protocol, we first create a user in the server: [root@Rocky ~]# useradd testrsync [root@Rocky ~]# passwd testrsync On the client side, we pull/download it, and the file on the server is /rsync/aabbcc [root@fedora ~]# rsync -avz testrsync@192.168.100.4:/rsync/aabbcc /root testrsync@192.168.100.4 ' s password: receiving incremental file list aabbcc sent 43 bytes received 85 bytes 51.20 bytes/sec total size is 0 speedup is 0.00 [root@fedora ~]# cd [root@fedora ~]# ls aabbcc The transfer was successful. !!! tip \"Attention\" If the server's SSH port is not the default 22, you can specify the port in a similar way---`rsync -avz -e 'ssh -p [port]' `. push/upload [root@fedora ~]# touch fedora [root@fedora ~]# rsync -avz /root/* testrsync@192.168.100.4:/rsync/ testrsync@192.168.100.4 ' s password: sending incremental file list anaconda-ks.cfg fedora rsync: mkstemp \" /rsync/.anaconda-ks.cfg.KWf7JF \" failed: Permission denied (13) rsync: mkstemp \" /rsync/.fedora.fL3zPC \" failed: Permission denied (13) sent 760 bytes received 211 bytes 277.43 bytes/sec total size is 883 speedup is 0.91 rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1330) [sender = 3.2.3] Prompt permission denied, how to deal with it? First check the permissions of the /rsync/ directory. Obviously, there is no \"w\" permission. We can use setfacl to give permission: [root@Rocky ~ ] # ls -ld /rsync/ drwxr-xr-x 2 root root 4096 November 2 15:05 /rsync/ [root@Rocky ~ ] # setfacl -mu:testrsync:rwx /rsync/ [root@Rocky ~ ] # getfacl /rsync/ getfacl: Removing leading ' / ' from absolute path names # file: rsync/ # owner: root # group: root user::rwx user:testrsync:rwx group::rx mask::rwx other::rx Try again, success! [root@fedora ~ ] # rsync -avz /root/* testrsync@192.168.100.4:/rsync/ testrsync@192.168.100.4 ' s password: sending incremental file list anaconda-ks.cfg fedora sent 760 bytes received 54 bytes 180.89 bytes/sec total size is 883 speedup is 1.08","title":"rsync demo 01"},{"location":"books/learning_rsync/02_rsync_demo01/#preface","text":"rsync needs to perform user authentication before data synchronization. There are two protocol methods for authentication: SSH protocol and rsync protocol (the default port of rsync protocol is 873) SSH protocol verification login method: use SSH protocol as the basis for user identity authentication (that is, use the system user and password of GNU/Linux itself for verification), and then perform data synchronization. rsync protocol verification login method: use rsync protocol for user identity authentication (non-GNU/Linux system users, similar to vsftpd virtual users), and then perform data synchronization. Before the specific demonstration of rsync synchronization, you need to use the rsync command. In Rocky Linux 8, the rsync rpm package is installed by default, and the version is 3.1.3-12, as follows: [root@Rocky ~]# rpm -qa|grep rsync rsync-3.1.3-12.el8.x86_64 Basic format: rsync [options] original location target location Commonly used options: -a: archive mode, recursive and preserves the attributes of the file object, which is equivalent to -rlptgoD (without -H, -A, -X) -v: Display detailed information about the synchronization process -z: compress when transferring files -H: Keep hard link files -A: retain ACL permissions -X: retain chattr permissions -r: Recursive mode, including all files in the directory and subdirectories -l: still reserved for symbolic link files -p: Permission to retain file attributes -t: time to retain file attributes -g: retain the group belonging to the file attribute (only for super users) -o: retain the owner of the file attributes (only for super users) -D: Keep device files and other special files The author's personal use: rsync -avz original location target location","title":"Preface"},{"location":"books/learning_rsync/02_rsync_demo01/#environment-description","text":"Item Description Rocky Linux 8(Server) 192.168.100.4/24 Fedora 34(client) 192.168.100.5/24 You can use Fedora 34 to upload and download graph LR; RockyLinux8-->|pull/download|Fedora34; Fedora34-->|push/upload|RockyLinux8; You can also use Rocky Linux 8 to upload and download graph LR; RockyLinux8-->|push/upload|Fedora34; Fedora34-->|pull/download|RockyLinux8;","title":"Environment Description"},{"location":"books/learning_rsync/02_rsync_demo01/#demonstration-based-on-ssh-protocol","text":"!!! tip \"Attention!\" Here, both Rocky Linux 8 and Fedora 34 use the root user to log in. Fedora 34 is the client and Rocky Linux 8 is the server.","title":"Demonstration based on SSH protocol"},{"location":"books/learning_rsync/02_rsync_demo01/#pulldownload","text":"Since it is based on the SSH protocol, we first create a user in the server: [root@Rocky ~]# useradd testrsync [root@Rocky ~]# passwd testrsync On the client side, we pull/download it, and the file on the server is /rsync/aabbcc [root@fedora ~]# rsync -avz testrsync@192.168.100.4:/rsync/aabbcc /root testrsync@192.168.100.4 ' s password: receiving incremental file list aabbcc sent 43 bytes received 85 bytes 51.20 bytes/sec total size is 0 speedup is 0.00 [root@fedora ~]# cd [root@fedora ~]# ls aabbcc The transfer was successful. !!! tip \"Attention\" If the server's SSH port is not the default 22, you can specify the port in a similar way---`rsync -avz -e 'ssh -p [port]' `.","title":"pull/download"},{"location":"books/learning_rsync/02_rsync_demo01/#pushupload","text":"[root@fedora ~]# touch fedora [root@fedora ~]# rsync -avz /root/* testrsync@192.168.100.4:/rsync/ testrsync@192.168.100.4 ' s password: sending incremental file list anaconda-ks.cfg fedora rsync: mkstemp \" /rsync/.anaconda-ks.cfg.KWf7JF \" failed: Permission denied (13) rsync: mkstemp \" /rsync/.fedora.fL3zPC \" failed: Permission denied (13) sent 760 bytes received 211 bytes 277.43 bytes/sec total size is 883 speedup is 0.91 rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1330) [sender = 3.2.3] Prompt permission denied, how to deal with it? First check the permissions of the /rsync/ directory. Obviously, there is no \"w\" permission. We can use setfacl to give permission: [root@Rocky ~ ] # ls -ld /rsync/ drwxr-xr-x 2 root root 4096 November 2 15:05 /rsync/ [root@Rocky ~ ] # setfacl -mu:testrsync:rwx /rsync/ [root@Rocky ~ ] # getfacl /rsync/ getfacl: Removing leading ' / ' from absolute path names # file: rsync/ # owner: root # group: root user::rwx user:testrsync:rwx group::rx mask::rwx other::rx Try again, success! [root@fedora ~ ] # rsync -avz /root/* testrsync@192.168.100.4:/rsync/ testrsync@192.168.100.4 ' s password: sending incremental file list anaconda-ks.cfg fedora sent 760 bytes received 54 bytes 180.89 bytes/sec total size is 883 speedup is 1.08","title":"push/upload"},{"location":"books/learning_rsync/03_rsync_demo02/","text":"Demonstration based on rsync protocol In vsftpd, there are virtual users (impersonated users customized by the administrator) because it is not safe to use anonymous users and local users. We know that a server based on the SSH protocol must ensure that there is a system of users. When there are many synchronization requirements, it may be necessary to create many users. This obviously does not meet the GNU/Linux operation and maintenance standards (the more users, the more insecure), in rsync, for security reasons, there is an rsync protocol authentication login method. How \u200b\u200bto do it? Just write the corresponding parameters and values \u200b\u200bin the configuration file. In Rocky Linux 8, you need to manually create the file /etc/rsyncd.conf . [root@Rocky ~]# touch /etc/rsyncd.conf [root@Rocky ~]# vim /etc/rsyncd.conf Some parameters and values \u200b\u200bof this file are as follows, here has more parameter descriptions: Item Description address = 192.168.100.4 The IP address that rsync listens on by default port = 873 rsync default listening port pid file = /var/run/rsyncd.pid File location of process pid log file = /var/log/rsyncd.log File location of the log [share] Share name comment = rsync Remarks or description information path = /rsync/ The system path location where it is located read only = yes yes means read only, no means read and write dont compress = *.gz *.gz2 *.zip Which file types do not compress it auth users = li Enable virtual users and define what a virtual user is called. Need to create it yourself secrets file = /etc/rsyncd_users.db Used to specify the location of the virtual user's password file, which must end in .db. The content format of the file is \"Username: Password\", one per line !!! tip \"Attention!\" The permission of the password file must be <font color=red>600</font> Write some file content to /etc/rsyncd.conf , and write the user name and password to /etc/rsyncd_users.db, the permission is 600 [root@Rocky ~]# cat /etc/rsyncd.conf address = 192.168.100.4 port = 873 pid file = /var/run/rsyncd.pid log file = /var/log/rsyncd.log [share] comment = rsync path = /rsync/ read only = yes dont compress = *.gz *.bz2 *.zip auth users = li secrets file = /etc/rsyncd_users.db [root@Rocky ~]# ll /etc/rsyncd_users.db -rw------- 1 root root 9 November 2 16:16 /etc/rsyncd_users.db [root@Rocky ~]# cat /etc/rsyncd_users.db li:13579 You may need to dnf -y install rsync-daemon before you can start the service: systemctl start rsyncd.service [root@Rocky ~]# systemctl start rsyncd.service [root@Rocky ~]# netstat -tulnp Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 691/sshd tcp 0 0 192.168.100.4:873 0.0.0.0:* LISTEN 4607/rsync tcp6 0 0 :::22 :::* LISTEN 691/sshd udp 0 0 127.0.0.1:323 0.0.0.0:* 671/chronyd udp6 0 0 ::1:323 :::* 671/chronyd pull/download Create a file in the server for verification: [root@Rocky]# touch /rsync/rsynctest.txt The client does the following: [root@fedora ~]# rsync -avz li@192.168.100.4::share /root Password: receiving incremental file list ./ rsynctest.txt sent 52 bytes received 195 bytes 7.16 bytes/sec total size is 883 speedup is 3.57 [root@fedora ~]# ls aabbcc anaconda-ks.cfg fedora rsynctest.txt success! In addition to the above writing based on the rsync protocol, you can also write like this: rsync://li@10.1.2.84/share push/upload [root@fedora ~]# touch /root/fedora.txt [root@fedora ~]# rsync -avz /root/* li@192.168.100.4::share Password: sending incremental file list rsync: [sender] read error: Connection reset by peer (104) rsync error: error in socket IO (code 10) at io.c(784) [sender = 3.2.3] You are prompted that the reading error is related to the \"read only = yes\" of the server . Change it to \"no\" and restart the service [root@Rocky ~]# systemctl restart rsyncd.service Try again, prompting you permission denied: [root@fedora ~]# rsync -avz /root/* li@192.168.100.4::share Password: sending incremental file list fedora.txt rsync: mkstemp \" /.fedora.txt.hxzBIQ \" (in share) failed: Permission denied (13) sent 206 bytes received 118 bytes 92.57 bytes/sec total size is 883 speedup is 2.73 rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1330) [sender = 3.2.3] Our virtual user here is li , which is mapped to the system user nobody by default. Of course, you can change it to other system users. In other words, nobody does not have write permission to the /rsync/ directory. Of course, we can use [root@Rocky ~]# setfacl -mu:nobody:rwx /rsync/ , try again, and succeed. [root@fedora ~]# rsync -avz /root/* li@192.168.100.4::share Password: sending incremental file list fedora.txt sent 206 bytes received 35 bytes 96.40 bytes/sec total size is 883 speedup is 3.66","title":"rsync demo 02"},{"location":"books/learning_rsync/03_rsync_demo02/#demonstration-based-on-rsync-protocol","text":"In vsftpd, there are virtual users (impersonated users customized by the administrator) because it is not safe to use anonymous users and local users. We know that a server based on the SSH protocol must ensure that there is a system of users. When there are many synchronization requirements, it may be necessary to create many users. This obviously does not meet the GNU/Linux operation and maintenance standards (the more users, the more insecure), in rsync, for security reasons, there is an rsync protocol authentication login method. How \u200b\u200bto do it? Just write the corresponding parameters and values \u200b\u200bin the configuration file. In Rocky Linux 8, you need to manually create the file /etc/rsyncd.conf . [root@Rocky ~]# touch /etc/rsyncd.conf [root@Rocky ~]# vim /etc/rsyncd.conf Some parameters and values \u200b\u200bof this file are as follows, here has more parameter descriptions: Item Description address = 192.168.100.4 The IP address that rsync listens on by default port = 873 rsync default listening port pid file = /var/run/rsyncd.pid File location of process pid log file = /var/log/rsyncd.log File location of the log [share] Share name comment = rsync Remarks or description information path = /rsync/ The system path location where it is located read only = yes yes means read only, no means read and write dont compress = *.gz *.gz2 *.zip Which file types do not compress it auth users = li Enable virtual users and define what a virtual user is called. Need to create it yourself secrets file = /etc/rsyncd_users.db Used to specify the location of the virtual user's password file, which must end in .db. The content format of the file is \"Username: Password\", one per line !!! tip \"Attention!\" The permission of the password file must be <font color=red>600</font> Write some file content to /etc/rsyncd.conf , and write the user name and password to /etc/rsyncd_users.db, the permission is 600 [root@Rocky ~]# cat /etc/rsyncd.conf address = 192.168.100.4 port = 873 pid file = /var/run/rsyncd.pid log file = /var/log/rsyncd.log [share] comment = rsync path = /rsync/ read only = yes dont compress = *.gz *.bz2 *.zip auth users = li secrets file = /etc/rsyncd_users.db [root@Rocky ~]# ll /etc/rsyncd_users.db -rw------- 1 root root 9 November 2 16:16 /etc/rsyncd_users.db [root@Rocky ~]# cat /etc/rsyncd_users.db li:13579 You may need to dnf -y install rsync-daemon before you can start the service: systemctl start rsyncd.service [root@Rocky ~]# systemctl start rsyncd.service [root@Rocky ~]# netstat -tulnp Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 691/sshd tcp 0 0 192.168.100.4:873 0.0.0.0:* LISTEN 4607/rsync tcp6 0 0 :::22 :::* LISTEN 691/sshd udp 0 0 127.0.0.1:323 0.0.0.0:* 671/chronyd udp6 0 0 ::1:323 :::* 671/chronyd","title":"Demonstration based on rsync protocol"},{"location":"books/learning_rsync/03_rsync_demo02/#pulldownload","text":"Create a file in the server for verification: [root@Rocky]# touch /rsync/rsynctest.txt The client does the following: [root@fedora ~]# rsync -avz li@192.168.100.4::share /root Password: receiving incremental file list ./ rsynctest.txt sent 52 bytes received 195 bytes 7.16 bytes/sec total size is 883 speedup is 3.57 [root@fedora ~]# ls aabbcc anaconda-ks.cfg fedora rsynctest.txt success! In addition to the above writing based on the rsync protocol, you can also write like this: rsync://li@10.1.2.84/share","title":"pull/download"},{"location":"books/learning_rsync/03_rsync_demo02/#pushupload","text":"[root@fedora ~]# touch /root/fedora.txt [root@fedora ~]# rsync -avz /root/* li@192.168.100.4::share Password: sending incremental file list rsync: [sender] read error: Connection reset by peer (104) rsync error: error in socket IO (code 10) at io.c(784) [sender = 3.2.3] You are prompted that the reading error is related to the \"read only = yes\" of the server . Change it to \"no\" and restart the service [root@Rocky ~]# systemctl restart rsyncd.service Try again, prompting you permission denied: [root@fedora ~]# rsync -avz /root/* li@192.168.100.4::share Password: sending incremental file list fedora.txt rsync: mkstemp \" /.fedora.txt.hxzBIQ \" (in share) failed: Permission denied (13) sent 206 bytes received 118 bytes 92.57 bytes/sec total size is 883 speedup is 2.73 rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1330) [sender = 3.2.3] Our virtual user here is li , which is mapped to the system user nobody by default. Of course, you can change it to other system users. In other words, nobody does not have write permission to the /rsync/ directory. Of course, we can use [root@Rocky ~]# setfacl -mu:nobody:rwx /rsync/ , try again, and succeed. [root@fedora ~]# rsync -avz /root/* li@192.168.100.4::share Password: sending incremental file list fedora.txt sent 206 bytes received 35 bytes 96.40 bytes/sec total size is 883 speedup is 3.66","title":"push/upload"},{"location":"books/learning_rsync/04_rsync_configure/","text":"/etc/rsyncd.conf In the previous article rsync demo 02 we introduced some basic parameters. This article is to supplement other parameters. Parameters Description fake super = yes yes means that you do not need the daemon to run as root to store the complete attributes of the file. uid = gid = Two parameters are used to specify the user and group used to transfer files when running the rsync daemon as root. The default is nobody use chroot = yes Whether the root directory needs to be locked before transmission, yes yes, no no. In order to increase security, rsync defaults to yes. max connections = 4 The maximum number of connections allowed, the default value is 0, which means that there is no restriction lock file = /var/run/rsyncd.lock The specified lock file, which is associated with the \"max connections\" parameter exclude = lost+found/ Exclude directories that do not need to be transferred transfer logging = yes Whether to enable ftp-like log format to record rsync uploads and downloads timeout = 900 Specify the timeout period. If no data is transmitted within the specified time, rsync will exit directly. The unit is seconds, the default value is 0 means never time out ignore nonreadable = yes Whether to ignore files to which the user does not have access rights motd file = /etc/rsyncd/rsyncd.motd Used to specify the path of the message file. By default, there is no motd file. This message is the welcome message displayed when the user logs in. hosts allow = 10.1.1.1/24 Used to specify which IP or network segment clients are allowed to access. You can fill in the ip, network segment, host name, host under the domain, and separate multiples with spaces. Allow everyone to access by default hosts deny = 10.1.1.20 Which ip or network segment clients specified by the user are not allowed to access. If hosts allow and hosts deny have the same matching result, the client cannot access eventually. If the client's address is neither in the hosts allow nor in the hosts deny, the client is allowed to access. By default, there is no such parameter auth users = li Enable virtual users, multiple users are separated by commas in English state syslog facility = daemon Define the level of system log. These values \u200b\u200bcan be filled in: auth, authpriv, cron, daemon, ftp, kern, lpr, mail, news, security, syslog, user, uucp, local0, local1, local2 local3, local4, local5, local6 and local7. The default value is daemon Recommended configuration","title":"rsync configuration file"},{"location":"books/learning_rsync/04_rsync_configure/#etcrsyncdconf","text":"In the previous article rsync demo 02 we introduced some basic parameters. This article is to supplement other parameters. Parameters Description fake super = yes yes means that you do not need the daemon to run as root to store the complete attributes of the file. uid = gid = Two parameters are used to specify the user and group used to transfer files when running the rsync daemon as root. The default is nobody use chroot = yes Whether the root directory needs to be locked before transmission, yes yes, no no. In order to increase security, rsync defaults to yes. max connections = 4 The maximum number of connections allowed, the default value is 0, which means that there is no restriction lock file = /var/run/rsyncd.lock The specified lock file, which is associated with the \"max connections\" parameter exclude = lost+found/ Exclude directories that do not need to be transferred transfer logging = yes Whether to enable ftp-like log format to record rsync uploads and downloads timeout = 900 Specify the timeout period. If no data is transmitted within the specified time, rsync will exit directly. The unit is seconds, the default value is 0 means never time out ignore nonreadable = yes Whether to ignore files to which the user does not have access rights motd file = /etc/rsyncd/rsyncd.motd Used to specify the path of the message file. By default, there is no motd file. This message is the welcome message displayed when the user logs in. hosts allow = 10.1.1.1/24 Used to specify which IP or network segment clients are allowed to access. You can fill in the ip, network segment, host name, host under the domain, and separate multiples with spaces. Allow everyone to access by default hosts deny = 10.1.1.20 Which ip or network segment clients specified by the user are not allowed to access. If hosts allow and hosts deny have the same matching result, the client cannot access eventually. If the client's address is neither in the hosts allow nor in the hosts deny, the client is allowed to access. By default, there is no such parameter auth users = li Enable virtual users, multiple users are separated by commas in English state syslog facility = daemon Define the level of system log. These values \u200b\u200bcan be filled in: auth, authpriv, cron, daemon, ftp, kern, lpr, mail, news, security, syslog, user, uucp, local0, local1, local2 local3, local4, local5, local6 and local7. The default value is daemon","title":"/etc/rsyncd.conf"},{"location":"books/learning_rsync/04_rsync_configure/#recommended-configuration","text":"","title":"Recommended configuration"},{"location":"books/learning_rsync/05_rsync_authentication-free_login/","text":"Foreword From rsync Brief Description we know that rsync is an incremental synchronization tool. Every time the rsync command is executed, data can be synchronized once, but data cannot be synchronized in real time. How to do it? With inotify-tools, this program tool can realize one-way real-time synchronization. Since it is real-time data synchronization, the prerequisite is to log in without password authentication. Regardless of whether it is rsync protocol or SSH protocol, both can achieve password-free authentication login. SSH protocol password-free authentication login First, generate a public key and private key pair on the client, and keep pressing Enter after typing the command. The key pair is saved in the /root/.ssh/ directory [root@fedora ~]# ssh-keygen -t rsa -b 2048 Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa Your public key has been saved in /root/.ssh/id_rsa.pub The key fingerprint is: SHA256: TDA3tWeRhQIqzTORLaqy18nKnQOFNDhoAsNqRLo1TMg root@fedora The key's randomart image is: +---[RSA 2048]----+ |O+. +o+o. .+. | |BEo oo*....o. | |*o+o..*.. ..o | |.+..o. = o | |o o S | |. o | | o +. | |....=. | | .o.o. | +----[SHA256]-----+ Then, use the scp command to upload the public key file to the server. For example, I upload this public key to the user testrsync [root@fedora ~]# scp -P 22 /root/.ssh/id_rsa.pub root@192.168.100.4:/home/testrsync/ [root@Rocky ~]# cat /home/testrsync/id_rsa.pub >> /home/testrsync/.ssh/authorized_keys Try to log in without secret authentication, success! [root@fedora ~]# ssh -p 22 testrsync@192.168.100.4 Last login: Tue Nov 2 21:42:44 2021 from 192.168.100.5 [testrsync@Rocky ~]$ !!! tip \"Attention!\" The server configuration file **/etc/ssh/sshd_config** should be opened <font color=red>PubkeyAuthentication yes</font> rsync protocol password-free authentication login On the client side, the rsync service prepares an environment variable for the system- RSYNC_PASSWORD , which is empty by default, as shown below: [root@fedora ~]# echo \"$RSYNC_PASSWORD\" [root@fedora ~]# If you want to achieve password-free authentication login, you only need to assign a value to this variable. The value assigned is the password previously set for the virtual user li . At the same time, declare this variable as a global variable. [root@Rocky ~]# cat /etc/rsyncd_users.db li:13579 [root@fedora ~]# export RSYNC_PASSWORD=13579 Try it, success! No new files appear here, so the list of transferred files is not displayed. [root@fedora ~]# rsync -avz li@192.168.100.4::share /root/ receiving incremental file list ./ sent 30 bytes received 193 bytes 148.67 bytes/sec total size is 883 speedup is 3.96 !!! tip \"tip!\" You can write this variable into **/etc/profile** to make it take effect permanently. The content is: `export RSYNC_PASSWORD=13579`","title":"rsync password-free authentication login"},{"location":"books/learning_rsync/05_rsync_authentication-free_login/#foreword","text":"From rsync Brief Description we know that rsync is an incremental synchronization tool. Every time the rsync command is executed, data can be synchronized once, but data cannot be synchronized in real time. How to do it? With inotify-tools, this program tool can realize one-way real-time synchronization. Since it is real-time data synchronization, the prerequisite is to log in without password authentication. Regardless of whether it is rsync protocol or SSH protocol, both can achieve password-free authentication login.","title":"Foreword"},{"location":"books/learning_rsync/05_rsync_authentication-free_login/#ssh-protocol-password-free-authentication-login","text":"First, generate a public key and private key pair on the client, and keep pressing Enter after typing the command. The key pair is saved in the /root/.ssh/ directory [root@fedora ~]# ssh-keygen -t rsa -b 2048 Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa Your public key has been saved in /root/.ssh/id_rsa.pub The key fingerprint is: SHA256: TDA3tWeRhQIqzTORLaqy18nKnQOFNDhoAsNqRLo1TMg root@fedora The key's randomart image is: +---[RSA 2048]----+ |O+. +o+o. .+. | |BEo oo*....o. | |*o+o..*.. ..o | |.+..o. = o | |o o S | |. o | | o +. | |....=. | | .o.o. | +----[SHA256]-----+ Then, use the scp command to upload the public key file to the server. For example, I upload this public key to the user testrsync [root@fedora ~]# scp -P 22 /root/.ssh/id_rsa.pub root@192.168.100.4:/home/testrsync/ [root@Rocky ~]# cat /home/testrsync/id_rsa.pub >> /home/testrsync/.ssh/authorized_keys Try to log in without secret authentication, success! [root@fedora ~]# ssh -p 22 testrsync@192.168.100.4 Last login: Tue Nov 2 21:42:44 2021 from 192.168.100.5 [testrsync@Rocky ~]$ !!! tip \"Attention!\" The server configuration file **/etc/ssh/sshd_config** should be opened <font color=red>PubkeyAuthentication yes</font>","title":"SSH protocol password-free authentication login"},{"location":"books/learning_rsync/05_rsync_authentication-free_login/#rsync-protocol-password-free-authentication-login","text":"On the client side, the rsync service prepares an environment variable for the system- RSYNC_PASSWORD , which is empty by default, as shown below: [root@fedora ~]# echo \"$RSYNC_PASSWORD\" [root@fedora ~]# If you want to achieve password-free authentication login, you only need to assign a value to this variable. The value assigned is the password previously set for the virtual user li . At the same time, declare this variable as a global variable. [root@Rocky ~]# cat /etc/rsyncd_users.db li:13579 [root@fedora ~]# export RSYNC_PASSWORD=13579 Try it, success! No new files appear here, so the list of transferred files is not displayed. [root@fedora ~]# rsync -avz li@192.168.100.4::share /root/ receiving incremental file list ./ sent 30 bytes received 193 bytes 148.67 bytes/sec total size is 883 speedup is 3.96 !!! tip \"tip!\" You can write this variable into **/etc/profile** to make it take effect permanently. The content is: `export RSYNC_PASSWORD=13579`","title":"rsync protocol password-free authentication login"},{"location":"books/learning_rsync/06_rsync_inotify/","text":"Compile and install Perform the following operations in the server. In your environment, some dependent packages may be missing. Install them by using: dnf -y install autoconf automake libtool [root@Rocky ~]# wget -c https://github.com/inotify-tools/inotify-tools/archive/refs/tags/3.21.9.6.tar.gz [root@Rocky ~]# tar -zvxf 3.21.9.6.tar.gz -C /usr/local/src/ [root@Rocky ~]# cd /usr/local/src/inotify-tools-3.21.9.6/ [root@Rocky /usr/local/src/inotify-tools-3.21.9.6]# ./autogen.sh && \\ ./configure --prefix=/usr/local/inotify-tools && \\ make && \\ make install ... [root@Rocky ~]# ls /usr/local/inotify-tools/bin/ inotifywait inotifywatch Append the environment variable PATH, write it to the configuration file and let it take effect permanently. [root@Rocky ~]# vim /etc/profile ... PATH=$PATH:/usr/local/inotify-tools/bin/ [root@Rocky ~]# . /etc/profile Why not use the inotify-tools RPM package of the EPEL repository? And the way to use source code to compile and install? The author personally believes that remote data transmission is a matter of efficiency, especially in a production environment, where there are a large number of files to be synchronized and a single file is particularly large. In addition, the new version will have some bug fixes and function expansions, and perhaps the transmission efficiency of the new version will be higher, so I recommend installing inotify-tools by source code. Of course, this is the author's personal suggestion, not every user must follow. Kernel parameter adjustment You can adjust the kernel parameters according to the needs of the production environment. By default, there are three files in /proc/sys/fs/inotity/ [root@Rocky ~]# cd /proc/sys/fs/inotify/ [root@Rocky /proc/sys/fs/inotify]# cat max_queued_events ;cat max_user_instances ;cat max_user_watches 16384 128 28014 max_queued_events-maximum monitor queue size, default 16384 max_user_instances-the maximum number of monitoring instances, the default is 128 max_user_watches-the maximum number of files monitored per instance, the default is 8192 Write some parameters and values \u200b\u200bto /etc/sysctl.conf , examples are as follows. Then use sysctl -p to make the files take effect fs.inotify.max_queued_events = 16384 fs.inotify.max_user_instances = 1024 fs.inotify.max_user_watches = 1048576 Related commands The inotify-tools tool has two commands, namely: * inotifywait -For continuous monitoring, real-time output results. It is generally used with the rsync incremental backup tool. Because it is a file system monitoring, it can be used with a script. We will introduce the specific script writing later. * inotifywatch -for short-term monitoring, output results after the task is completed. inotifywait mainly has the following options: -m means continuous monitoring -r Recursive monitoring -q Simplify output information -e specifies the event type of monitoring data, multiple event types are separated by commas in English status The event types are as follows: Event Type Description access Access to the contents of a file or directory modify The contents of the file or directory are written attrib The attributes of the file or directory are modified close_write File or directory is opened in writable mode and then closed close_nowrite File or directory is closed after being opened in read-only mode close Regardless of the read/write mode, the file or directory is closed open File or directory is opened moved_to A file or directory is moved to the monitored directory moved_from A file or directory is moved from the monitored directory move There are files or directories that are moved to or removed from the monitoring directory move_self The monitored file or directory has been moved create There are files or directories created in the monitored directory delete A file or directory in the monitored directory is deleted delete_self File or directory and delete unmount File system containing unmounted files or directories Example: [root@Rocky ~]# inotifywait -mrq -e create,delete /rsync/ Demonstration of inotifywait command Type the command in the first terminal pts/0, and the window is locked after pressing Enter, indicating that it is monitoring [root@Rocky ~]# inotifywait -mrq -e create,delete /rsync/ In the second terminal pts/1, go to the /rsync/ directory and create a file. [root@Rocky ~]# cd /rsync/ [root@Rocky /rsync]# touch inotify Back to the first terminal pts/0, the output information is as follows: [root@Rocky ~]# inotifywait -mrq -e create,delete /rsync/ /rsync/ CREATE inotify Combination of inotifywait and rsync !!! tip \"Attention!\" We are operating in Rocky Linux 8 server, using SSH protocol for demonstration. For the password-free authentication login of the SSH protocol, please refer to rsync password-free authentication login , which is not described here. An example of the content of a bash script is as follows. You can add different options after the command according to your needs to meet your needs. For example, you can also add --delete after the rsync command. #!/bin/bash a=\"/usr/local/inotify-tools/bin/inotifywait -mrq -e modify,move,create,delete /rsync/\" b=\"/usr/bin/rsync -avz /rsync/* testfedora@192.168.100.5:/home/testfedora/\" $a | while read directory event file do $b &>> /tmp/rsync.log done [root@Rocky ~]# chmod +x rsync_inotify.sh [root@Rocky ~]# bash /root/rsync_inotify.sh & !!! tip \"emphasize again!\" When using the SSH protocol for data synchronization transmission, if the SSH service port of the target machine is not 22, you can use a method similar to this\u2014\u2014 `b=\"/usr/bin/rsync -avz -e 'ssh -p [port-number]' /rsync/* testfedora@192.168.100.5:/home/testfedora/\"` !!! tip \"Attention!\" If you want to start this script at boot `[root@Rocky ~]# echo \"bash /root/rsync_inotify.sh &\" >> /etc/rc.local` `[root@Rocky ~]# chmod +x /etc/rc.local` If you are using the rsync protocol for synchronization, you need to configure the rsync service of the target machine, please refer to rsync demo 02 , rsync configuration file , rsync free Secret authentication login","title":"inotify-tools installation and use"},{"location":"books/learning_rsync/06_rsync_inotify/#compile-and-install","text":"Perform the following operations in the server. In your environment, some dependent packages may be missing. Install them by using: dnf -y install autoconf automake libtool [root@Rocky ~]# wget -c https://github.com/inotify-tools/inotify-tools/archive/refs/tags/3.21.9.6.tar.gz [root@Rocky ~]# tar -zvxf 3.21.9.6.tar.gz -C /usr/local/src/ [root@Rocky ~]# cd /usr/local/src/inotify-tools-3.21.9.6/ [root@Rocky /usr/local/src/inotify-tools-3.21.9.6]# ./autogen.sh && \\ ./configure --prefix=/usr/local/inotify-tools && \\ make && \\ make install ... [root@Rocky ~]# ls /usr/local/inotify-tools/bin/ inotifywait inotifywatch Append the environment variable PATH, write it to the configuration file and let it take effect permanently. [root@Rocky ~]# vim /etc/profile ... PATH=$PATH:/usr/local/inotify-tools/bin/ [root@Rocky ~]# . /etc/profile Why not use the inotify-tools RPM package of the EPEL repository? And the way to use source code to compile and install? The author personally believes that remote data transmission is a matter of efficiency, especially in a production environment, where there are a large number of files to be synchronized and a single file is particularly large. In addition, the new version will have some bug fixes and function expansions, and perhaps the transmission efficiency of the new version will be higher, so I recommend installing inotify-tools by source code. Of course, this is the author's personal suggestion, not every user must follow.","title":"Compile and install"},{"location":"books/learning_rsync/06_rsync_inotify/#kernel-parameter-adjustment","text":"You can adjust the kernel parameters according to the needs of the production environment. By default, there are three files in /proc/sys/fs/inotity/ [root@Rocky ~]# cd /proc/sys/fs/inotify/ [root@Rocky /proc/sys/fs/inotify]# cat max_queued_events ;cat max_user_instances ;cat max_user_watches 16384 128 28014 max_queued_events-maximum monitor queue size, default 16384 max_user_instances-the maximum number of monitoring instances, the default is 128 max_user_watches-the maximum number of files monitored per instance, the default is 8192 Write some parameters and values \u200b\u200bto /etc/sysctl.conf , examples are as follows. Then use sysctl -p to make the files take effect fs.inotify.max_queued_events = 16384 fs.inotify.max_user_instances = 1024 fs.inotify.max_user_watches = 1048576","title":"Kernel parameter adjustment"},{"location":"books/learning_rsync/06_rsync_inotify/#related-commands","text":"The inotify-tools tool has two commands, namely: * inotifywait -For continuous monitoring, real-time output results. It is generally used with the rsync incremental backup tool. Because it is a file system monitoring, it can be used with a script. We will introduce the specific script writing later. * inotifywatch -for short-term monitoring, output results after the task is completed. inotifywait mainly has the following options: -m means continuous monitoring -r Recursive monitoring -q Simplify output information -e specifies the event type of monitoring data, multiple event types are separated by commas in English status The event types are as follows: Event Type Description access Access to the contents of a file or directory modify The contents of the file or directory are written attrib The attributes of the file or directory are modified close_write File or directory is opened in writable mode and then closed close_nowrite File or directory is closed after being opened in read-only mode close Regardless of the read/write mode, the file or directory is closed open File or directory is opened moved_to A file or directory is moved to the monitored directory moved_from A file or directory is moved from the monitored directory move There are files or directories that are moved to or removed from the monitoring directory move_self The monitored file or directory has been moved create There are files or directories created in the monitored directory delete A file or directory in the monitored directory is deleted delete_self File or directory and delete unmount File system containing unmounted files or directories Example: [root@Rocky ~]# inotifywait -mrq -e create,delete /rsync/","title":"Related commands"},{"location":"books/learning_rsync/06_rsync_inotify/#demonstration-of-inotifywait-command","text":"Type the command in the first terminal pts/0, and the window is locked after pressing Enter, indicating that it is monitoring [root@Rocky ~]# inotifywait -mrq -e create,delete /rsync/ In the second terminal pts/1, go to the /rsync/ directory and create a file. [root@Rocky ~]# cd /rsync/ [root@Rocky /rsync]# touch inotify Back to the first terminal pts/0, the output information is as follows: [root@Rocky ~]# inotifywait -mrq -e create,delete /rsync/ /rsync/ CREATE inotify","title":"Demonstration of inotifywait command"},{"location":"books/learning_rsync/06_rsync_inotify/#combination-of-inotifywait-and-rsync","text":"!!! tip \"Attention!\" We are operating in Rocky Linux 8 server, using SSH protocol for demonstration. For the password-free authentication login of the SSH protocol, please refer to rsync password-free authentication login , which is not described here. An example of the content of a bash script is as follows. You can add different options after the command according to your needs to meet your needs. For example, you can also add --delete after the rsync command. #!/bin/bash a=\"/usr/local/inotify-tools/bin/inotifywait -mrq -e modify,move,create,delete /rsync/\" b=\"/usr/bin/rsync -avz /rsync/* testfedora@192.168.100.5:/home/testfedora/\" $a | while read directory event file do $b &>> /tmp/rsync.log done [root@Rocky ~]# chmod +x rsync_inotify.sh [root@Rocky ~]# bash /root/rsync_inotify.sh & !!! tip \"emphasize again!\" When using the SSH protocol for data synchronization transmission, if the SSH service port of the target machine is not 22, you can use a method similar to this\u2014\u2014 `b=\"/usr/bin/rsync -avz -e 'ssh -p [port-number]' /rsync/* testfedora@192.168.100.5:/home/testfedora/\"` !!! tip \"Attention!\" If you want to start this script at boot `[root@Rocky ~]# echo \"bash /root/rsync_inotify.sh &\" >> /etc/rc.local` `[root@Rocky ~]# chmod +x /etc/rc.local` If you are using the rsync protocol for synchronization, you need to configure the rsync service of the target machine, please refer to rsync demo 02 , rsync configuration file , rsync free Secret authentication login","title":"Combination of  inotifywait and rsync"},{"location":"books/learning_rsync/07_rsync_unison_use/","text":"Brief As we mentioned earlier, one-way synchronization uses rsync + inotify-tools. In some special usage scenarios, two-way synchronization may be required, which requires inotify-tools + unison. Environmental preparation Both Rocky Linux 8 and Fedora 34 require source code compilation and installation inotify-tools , which is not specifically expanded here. Both machines must be password-free login authentication, here we use the SSH protocol for ocaml uses v4.12.0, unison uses v2.51.4. After the environment is ready, it can be verified: [root@Rocky ~]# inotifywa inotifywait inotifywatch [root@Rocky ~]# ssh -p 22 testrsync@192.168.100.5 Last login: Thu Nov 4 13:13:42 2021 from 192.168.100.4 [testrsync@fedora ~]$ [root@fedora ~]# inotifywa inotifywait inotifywatch [root@fedora ~]# ssh -p 22 testrsync@192.168.100.4 Last login: Wed Nov 3 22:07:18 2021 from 192.168.100.5 [testrsync@Rocky ~]$ !!! tip \"Attention\" The configuration files of the two machines **/etc/ssh/sshd_config** should be opened <font color=red>PubkeyAuthentication yes</font> Rocky Linux 8 install unison Ocaml is a programming language, and the bottom layer of unison depends on it. [root@Rocky ~]# wget -c https://github.com/ocaml/ocaml/archive/refs/tags/4.12.0.tar.gz [root@Rocky ~]# tar -zvxf 4.12.0.tar.gz -C /usr/local/src/ [root@Rocky ~]# cd /usr/local/src/ocaml-4.12.0 [root@Rocky /usr/local/src/ocaml-4.12.0]# ./configure --prefix=/usr/local/ocaml && make world opt && make install ... [root@Rocky ~]# ls /usr/local/ocaml/ bin lib man [root@Rocky ~]# echo PATH=$PATH:/usr/local/ocaml/bin >> /etc/profile [root@Rocky ~]# . /etc/profile [root@Rocky ~]# wget -c https://github.com/bcpierce00/unison/archive/refs/tags/v2.51.4.tar.gz [root@Rocky ~]# tar -zvxf v2.51.4.tar.gz -C /usr/local/src/ [root@Rocky ~]# cd /usr/local/src/unison-2.51.4/ [root@Rocky /usr/local/src/unison-2.51.4]# make UISTYLE=txt ... [root@Rocky /usr/local/src/unison-2.51.4]# ls src/unison src/unison [root@Rocky /usr/local/src/unison-2.51.4] cp -p src/unison /usr/local/bin Fedora 34 install unison The same operation. [root@fedora ~]# wget -c https://github.com/ocaml/ocaml/archive/refs/tags/4.12.0.tar.gz [root@feodora ~]# tar -zvxf 4.12.0.tar.gz -C /usr/local/src/ [root@fedora ~]# cd /usr/local/src/ocaml-4.12.0 [root@fedora /usr/local/src/ocaml-4.12.0]# ./configure --prefix=/usr/local/ocaml && make world opt && make install ... [root@fedora ~]# ls /usr/local/ocaml/ bin lib man [root@fedora ~]# echo PATH=$PATH:/usr/local/ocaml/bin >> /etc/profile [root@fedora ~]#. /etc/profile [root@fedora ~]# wget -c https://github.com/bcpierce00/unison/archive/refs/tags/v2.51.4.tar.gz [root@fedora ~]# tar -zvxf v2.51.4.tar.gz -C /usr/local/src/ [root@fedora ~]# cd /usr/local/src/unison-2.51.4/ [root@fedora /usr/local/src/unison-2.51.4]# make UISTYLE=txt ... [root@fedora /usr/local/src/unison-2.51.4]# ls src/unison src/unison [root@fedora /usr/local/src/unison-2.51.4]# cp -p src/unison /usr/local/bin Demo Our requirement is-Rocky Linux 8's /dir1/ directory is automatically synchronized to Fedora 34's /dir2/ directory; at the same time, Fedora 34's /dir2/ directory is automatically synchronized to Rocky Linux 8's /dir1/ directory Configure Rcoky Linux 8 [root@Rocky ~]# mkdir /dir1 [root@Rocky ~]# setfacl -m u:testrsync:rwx /dir1/ [root@Rocky ~]# vim /root/unison1.sh #!/bin/bash a=\"/usr/local/inotify-tools/bin/inotifywait -mrq -e create,delete,modify,move /dir1/\" b=\"/usr/local/bin/unison -batch /dir1/ ssh://testrsync@192.168.100.5//dir2\" $a | while read directory event file do $b &>> /tmp/unison1.log done [root@Rocky ~]# chmod +x /root/unison1.sh [root@Rocky ~]# bash /root/unison1.sh & [root@Rocky ~]# jobs -l Configure Fedora 34 [root@fedora ~]# mkdir /dir2 [root@fedora ~]# setfacl -m u:testrsync:rwx /dir2/ [root@fedora ~]# vim /root/unison2.sh #!/bin/bash a=\"/usr/local/inotify-tools/bin/inotifywait -mrq -e create,delete,modify,move /dir2/\" b=\"/usr/local/bin/unison -batch /dir2/ ssh://testrsync@192.168.100.4//dir1\" $a | while read directory event file do $b &>> /tmp/unison2.log done [root@fedora ~]# chmod +x /root/unison2.sh [root@fedora ~]# bash /root/unison2.sh & [root@fedora ~]# jobs -l !!! tip \"Attention!\" For two-way synchronization, the scripts of both machines must be started, otherwise an error will be reported. !!! tip \"Attention!\" If you want to start this script at boot `[root@Rocky ~]# echo \"bash /root/unison1.sh &\" >> /etc/rc.local` `[root@Rocky ~]# chmod +x /etc/rc.local` !!! tip \"Attention!\" If you want to stop the corresponding process of this script, you can find it in the `htop` command and then **kill**","title":"Use unison"},{"location":"books/learning_rsync/07_rsync_unison_use/#brief","text":"As we mentioned earlier, one-way synchronization uses rsync + inotify-tools. In some special usage scenarios, two-way synchronization may be required, which requires inotify-tools + unison.","title":"Brief"},{"location":"books/learning_rsync/07_rsync_unison_use/#environmental-preparation","text":"Both Rocky Linux 8 and Fedora 34 require source code compilation and installation inotify-tools , which is not specifically expanded here. Both machines must be password-free login authentication, here we use the SSH protocol for ocaml uses v4.12.0, unison uses v2.51.4. After the environment is ready, it can be verified: [root@Rocky ~]# inotifywa inotifywait inotifywatch [root@Rocky ~]# ssh -p 22 testrsync@192.168.100.5 Last login: Thu Nov 4 13:13:42 2021 from 192.168.100.4 [testrsync@fedora ~]$ [root@fedora ~]# inotifywa inotifywait inotifywatch [root@fedora ~]# ssh -p 22 testrsync@192.168.100.4 Last login: Wed Nov 3 22:07:18 2021 from 192.168.100.5 [testrsync@Rocky ~]$ !!! tip \"Attention\" The configuration files of the two machines **/etc/ssh/sshd_config** should be opened <font color=red>PubkeyAuthentication yes</font>","title":"Environmental preparation"},{"location":"books/learning_rsync/07_rsync_unison_use/#rocky-linux-8-install-unison","text":"Ocaml is a programming language, and the bottom layer of unison depends on it. [root@Rocky ~]# wget -c https://github.com/ocaml/ocaml/archive/refs/tags/4.12.0.tar.gz [root@Rocky ~]# tar -zvxf 4.12.0.tar.gz -C /usr/local/src/ [root@Rocky ~]# cd /usr/local/src/ocaml-4.12.0 [root@Rocky /usr/local/src/ocaml-4.12.0]# ./configure --prefix=/usr/local/ocaml && make world opt && make install ... [root@Rocky ~]# ls /usr/local/ocaml/ bin lib man [root@Rocky ~]# echo PATH=$PATH:/usr/local/ocaml/bin >> /etc/profile [root@Rocky ~]# . /etc/profile [root@Rocky ~]# wget -c https://github.com/bcpierce00/unison/archive/refs/tags/v2.51.4.tar.gz [root@Rocky ~]# tar -zvxf v2.51.4.tar.gz -C /usr/local/src/ [root@Rocky ~]# cd /usr/local/src/unison-2.51.4/ [root@Rocky /usr/local/src/unison-2.51.4]# make UISTYLE=txt ... [root@Rocky /usr/local/src/unison-2.51.4]# ls src/unison src/unison [root@Rocky /usr/local/src/unison-2.51.4] cp -p src/unison /usr/local/bin","title":"Rocky Linux 8 install unison"},{"location":"books/learning_rsync/07_rsync_unison_use/#fedora-34-install-unison","text":"The same operation. [root@fedora ~]# wget -c https://github.com/ocaml/ocaml/archive/refs/tags/4.12.0.tar.gz [root@feodora ~]# tar -zvxf 4.12.0.tar.gz -C /usr/local/src/ [root@fedora ~]# cd /usr/local/src/ocaml-4.12.0 [root@fedora /usr/local/src/ocaml-4.12.0]# ./configure --prefix=/usr/local/ocaml && make world opt && make install ... [root@fedora ~]# ls /usr/local/ocaml/ bin lib man [root@fedora ~]# echo PATH=$PATH:/usr/local/ocaml/bin >> /etc/profile [root@fedora ~]#. /etc/profile [root@fedora ~]# wget -c https://github.com/bcpierce00/unison/archive/refs/tags/v2.51.4.tar.gz [root@fedora ~]# tar -zvxf v2.51.4.tar.gz -C /usr/local/src/ [root@fedora ~]# cd /usr/local/src/unison-2.51.4/ [root@fedora /usr/local/src/unison-2.51.4]# make UISTYLE=txt ... [root@fedora /usr/local/src/unison-2.51.4]# ls src/unison src/unison [root@fedora /usr/local/src/unison-2.51.4]# cp -p src/unison /usr/local/bin","title":"Fedora 34 install unison"},{"location":"books/learning_rsync/07_rsync_unison_use/#demo","text":"Our requirement is-Rocky Linux 8's /dir1/ directory is automatically synchronized to Fedora 34's /dir2/ directory; at the same time, Fedora 34's /dir2/ directory is automatically synchronized to Rocky Linux 8's /dir1/ directory","title":"Demo"},{"location":"books/learning_rsync/07_rsync_unison_use/#configure-rcoky-linux-8","text":"[root@Rocky ~]# mkdir /dir1 [root@Rocky ~]# setfacl -m u:testrsync:rwx /dir1/ [root@Rocky ~]# vim /root/unison1.sh #!/bin/bash a=\"/usr/local/inotify-tools/bin/inotifywait -mrq -e create,delete,modify,move /dir1/\" b=\"/usr/local/bin/unison -batch /dir1/ ssh://testrsync@192.168.100.5//dir2\" $a | while read directory event file do $b &>> /tmp/unison1.log done [root@Rocky ~]# chmod +x /root/unison1.sh [root@Rocky ~]# bash /root/unison1.sh & [root@Rocky ~]# jobs -l","title":"Configure Rcoky Linux 8"},{"location":"books/learning_rsync/07_rsync_unison_use/#configure-fedora-34","text":"[root@fedora ~]# mkdir /dir2 [root@fedora ~]# setfacl -m u:testrsync:rwx /dir2/ [root@fedora ~]# vim /root/unison2.sh #!/bin/bash a=\"/usr/local/inotify-tools/bin/inotifywait -mrq -e create,delete,modify,move /dir2/\" b=\"/usr/local/bin/unison -batch /dir2/ ssh://testrsync@192.168.100.4//dir1\" $a | while read directory event file do $b &>> /tmp/unison2.log done [root@fedora ~]# chmod +x /root/unison2.sh [root@fedora ~]# bash /root/unison2.sh & [root@fedora ~]# jobs -l !!! tip \"Attention!\" For two-way synchronization, the scripts of both machines must be started, otherwise an error will be reported. !!! tip \"Attention!\" If you want to start this script at boot `[root@Rocky ~]# echo \"bash /root/unison1.sh &\" >> /etc/rc.local` `[root@Rocky ~]# chmod +x /etc/rc.local` !!! tip \"Attention!\" If you want to stop the corresponding process of this script, you can find it in the `htop` command and then **kill**","title":"Configure Fedora 34"},{"location":"gemstones/","text":"Gemstones Welcome to Gemstones ! I can hear you now: \"What on earth are Gemstones, and how do they fit into Rocky Linux documentation?\" That is a very good question. While Guides contains our normal length how-to documentation and Books contain our longer-form documentation, Gemstones are just little gems of wisdom. Have a favorite bit of Linux code that you use all the time or a favorite command? Maybe you've written a script in bash , python , or other common Linux language, that you would like to share because it helps you in your day-to-day use of Linux? If any of these things are true, Gemstones is the place for your contribution! Criteria Your code, script, or command document should be short. If it is many pages long, then it belongs elsewhere in the documentation. We are looking for a page or possibly two. In order for your \"gemstone\" to be complete, we suggest including: A good description Any reasons why you do things a particular way, in the case of a script A brief conclusion Contribution You can contribute your Gemstone in the same way that you contribute other documentation (see: Guides/Contribution/Contribution Guide ). When you submit a pull request to GitHub, include \"gemstone\" in the commit message. If you don't have or don't want a GitHub account, you can simply submit it to the Mattermost Documentation channel and we will edit and create your Gemstone for you. It couldn't be easier!","title":"Index"},{"location":"gemstones/#gemstones","text":"Welcome to Gemstones ! I can hear you now: \"What on earth are Gemstones, and how do they fit into Rocky Linux documentation?\" That is a very good question. While Guides contains our normal length how-to documentation and Books contain our longer-form documentation, Gemstones are just little gems of wisdom. Have a favorite bit of Linux code that you use all the time or a favorite command? Maybe you've written a script in bash , python , or other common Linux language, that you would like to share because it helps you in your day-to-day use of Linux? If any of these things are true, Gemstones is the place for your contribution!","title":"Gemstones"},{"location":"gemstones/#criteria","text":"Your code, script, or command document should be short. If it is many pages long, then it belongs elsewhere in the documentation. We are looking for a page or possibly two. In order for your \"gemstone\" to be complete, we suggest including: A good description Any reasons why you do things a particular way, in the case of a script A brief conclusion","title":"Criteria"},{"location":"gemstones/#contribution","text":"You can contribute your Gemstone in the same way that you contribute other documentation (see: Guides/Contribution/Contribution Guide ). When you submit a pull request to GitHub, include \"gemstone\" in the commit message. If you don't have or don't want a GitHub account, you can simply submit it to the Mattermost Documentation channel and we will edit and create your Gemstone for you. It couldn't be easier!","title":"Contribution"},{"location":"gemstones/bash_stub/","text":"Bash - Script Stub Where I was previously employed, we had an ace programmer who knew a bunch of languages. He was also the go-to guy when you had questions on how to accomplish something with a script. He finally created a little stub, a files full of scripting examples that you could just strip out and edit as needed. Eventually, I got good enough at these routines that I didn't have to look at the stub, but it was a good learning tool, and something that others may find useful. The Actual Stub The stub is well documented, but keep in mind that this is by no means an exhaustive script! There are a lot more routines that could be added. If you have examples that would fit nicely into this stub, then please feel free to add some changes: #!/bin/sh # By exporting the path, this keeps you from having to enter full paths for commands that exist in those paths: export PATH=\"$PATH:/bin:/usr/bin:/usr/local/bin\" # Determine and save absolute path to program directory. # Attention! In bash, the ' 'represents the string itself; But \" \" is a little different. $, ` `, and \\ represent call variable values, reference commands, and escape characters, respectively # When done will be in same directory as script: PGM=`basename $0` # Name of the program CDIR=`pwd` # Save directory program was run from PDIR=`dirname $0` cd $PDIR PDIR=`pwd` # If a program accepts filenames as arguments, this will put us back where we started. # (Needed so references to files using relative paths work.): cd $CDIR # Use this if script must be run by certain user: runby=\"root\" iam=`/usr/bin/id -un` if [ $iam != \"$runby\" ] then echo \"$PGM : program must be run by user \\\"$runby\\\"\" exit fi # Check for missing parameter. # Display usage message and exit if it is missing: if [ \"$1\" = \"\" ] then echo \"$PGM : parameter 1 is required\" echo \"Usage: $PGM param-one\" exit fi # Prompt for data (in this case a yes/no response that defaults to \"N\"): /bin/echo -n \"Do you wish to continue? [y/N] \" read yn if [ \"$yn\" != \"y\" ] && [ \"$yn\" != \"Y\" ] then echo \"Cancelling...\" exit; fi # If only one copy of your script can run at a time, use this block of code. # Check for lock file. If it doesn't exist create it. # If it does exist, display error message and exit: LOCKF=\"/tmp/${PGM}.lock\" if [ ! -e $LOCKF ] then touch $LOCKF else echo \"$PGM: cannot continue -- lock file exists\" echo echo \"To continue make sure this program is not already running, then delete the\" echo \"lock file:\" echo echo \" rm -f $LOCKF\" echo echo \"Aborting...\" exit 0 fi script_list=`ls customer/*` for script in $script_list do if [ $script != $PGM ] then echo \"./${script}\" fi done # Remove the lock file rm -f $LOCKF Conclusion Scripting is a System Administrator's friend. Being able to quickly do certain tasks in a script streamlines process completion. While by no means an exhaustive set of script routines, this stub offers some common usage examples.","title":"bash - Script Stub"},{"location":"gemstones/bash_stub/#bash-script-stub","text":"Where I was previously employed, we had an ace programmer who knew a bunch of languages. He was also the go-to guy when you had questions on how to accomplish something with a script. He finally created a little stub, a files full of scripting examples that you could just strip out and edit as needed. Eventually, I got good enough at these routines that I didn't have to look at the stub, but it was a good learning tool, and something that others may find useful.","title":"Bash - Script Stub"},{"location":"gemstones/bash_stub/#the-actual-stub","text":"The stub is well documented, but keep in mind that this is by no means an exhaustive script! There are a lot more routines that could be added. If you have examples that would fit nicely into this stub, then please feel free to add some changes: #!/bin/sh # By exporting the path, this keeps you from having to enter full paths for commands that exist in those paths: export PATH=\"$PATH:/bin:/usr/bin:/usr/local/bin\" # Determine and save absolute path to program directory. # Attention! In bash, the ' 'represents the string itself; But \" \" is a little different. $, ` `, and \\ represent call variable values, reference commands, and escape characters, respectively # When done will be in same directory as script: PGM=`basename $0` # Name of the program CDIR=`pwd` # Save directory program was run from PDIR=`dirname $0` cd $PDIR PDIR=`pwd` # If a program accepts filenames as arguments, this will put us back where we started. # (Needed so references to files using relative paths work.): cd $CDIR # Use this if script must be run by certain user: runby=\"root\" iam=`/usr/bin/id -un` if [ $iam != \"$runby\" ] then echo \"$PGM : program must be run by user \\\"$runby\\\"\" exit fi # Check for missing parameter. # Display usage message and exit if it is missing: if [ \"$1\" = \"\" ] then echo \"$PGM : parameter 1 is required\" echo \"Usage: $PGM param-one\" exit fi # Prompt for data (in this case a yes/no response that defaults to \"N\"): /bin/echo -n \"Do you wish to continue? [y/N] \" read yn if [ \"$yn\" != \"y\" ] && [ \"$yn\" != \"Y\" ] then echo \"Cancelling...\" exit; fi # If only one copy of your script can run at a time, use this block of code. # Check for lock file. If it doesn't exist create it. # If it does exist, display error message and exit: LOCKF=\"/tmp/${PGM}.lock\" if [ ! -e $LOCKF ] then touch $LOCKF else echo \"$PGM: cannot continue -- lock file exists\" echo echo \"To continue make sure this program is not already running, then delete the\" echo \"lock file:\" echo echo \" rm -f $LOCKF\" echo echo \"Aborting...\" exit 0 fi script_list=`ls customer/*` for script in $script_list do if [ $script != $PGM ] then echo \"./${script}\" fi done # Remove the lock file rm -f $LOCKF","title":"The Actual Stub"},{"location":"gemstones/bash_stub/#conclusion","text":"Scripting is a System Administrator's friend. Being able to quickly do certain tasks in a script streamlines process completion. While by no means an exhaustive set of script routines, this stub offers some common usage examples.","title":"Conclusion"},{"location":"gemstones/htop/","text":"install htop Every system administrator likes to use some of the more commonly used commands. Today I recommend htop as an alternative to the top command. To use the htop command normally , you need to install it first. # Installation epel source (also called repository) dnf -y install epel-release # Generate cache dnf makecache # Install htop dnf -y install htop Use htop You only need to type htop in the terminal, and the interactive interface is as follows: 0[ ||| 3%] Tasks: 24, 14thr; 1 running 1[ | 1%] Load average: 0.00 0.00 0.05 Mem[ ||||||| 197M/8G] Uptime: 00:31:39 Swap[ 0K/500M] PID USER PRI NI VIRT RES SHR S CPU% MEM% TIME+ Commad(merged) ... F1 Help F2 Setup F3 Search F4 Filter F5 Tree F6 SortBy F7 Nice F8 Nice+ F9 Kill F10 Quit Top Description The top 0 and 1 indicate the number of your CPU cores, and the percentage indicates the occupancy rate of a single core (of course, the total occupancy rate of the CPU can also be displayed) The different colors of the progress bar indicate the percentage of different process types: Color Description Blue Percentage of CPU used by low-priority processes Green Percentage of process CPU owned by ordinary users Red Percentage of CPU used by system processes Orange Percentage of CPU used by IRQ time Magenta Percentage of CPU used by soft IRQ time Gray Percentage of CPU occupied by IO waiting time Cyan Percentage of CPU consumed by Steal time Tasks: 24, 14thr; 1 running, process information. In my example, it means that my current machine has 24 tasks, which are divided into 14 threads, of which only 1 process is in a running state. Mem memory and swap information. Similarly, use different colors to distinguish: Color Description Blue Percentage of memory consumed by the buffer Green Percentage of memory consumed by the memory area Orange Percentage of memory consumed by the cache area Load average, the three values \u200b\u200brespectively represent the average load of the system in the last 1 minute, the last 5 minutes, and the last 15 minutes Uptime, which means the running time after booting Process information description PID-Process ID number USER-the owner of the process PRI-Display the process priority as seen by the Linux kernel NI-displays the process priority of reset by normal user or root super user VIRI-virtual memory being consumed by a process RES-physical memory being consumed by a process SHR-shared memory being consumed by a process S-The current state of the process, there is a special state to pay attention to! That is Z (zombie process). When there are a large number of zombie processes in the machine, it will affect the performance of the machine. CPU%-Percentage of CPU consumed by each process MEM%-Percentage of memory consumed by each process TIME+-shows the running time since the process was started Commad-the command corresponding to the process Shortcut key description In the interactive interface, press the F1 button to see the corresponding shortcut key description. The up, down, left, and right direction keys can scroll through the interactive interface, and space can mark the corresponding process, which is marked in yellow. The N button, the P button, the M button and the T button are respectively PID, CPU%, MEM%, TIME+ is used for sorting. Of course, you can also use the mouse to click to sort in ascending or descending order of a certain field. Other commonly used To manage the process, use the F9 button to send different signals to the process. The list of signals can be found in kill -l . The more commonly used ones are: Signal Description 1 Let the process shut down immediately, and then restart after re-reading the configuration file 9 Used to immediately end the running of the program, used to forcibly terminate the process, similar to the forced end in the windows taskbar 15 The default signal for the kill command. Sometimes if a problem has occurred in the process and the process cannot be terminated normally with this signal, we will try signal 9 End htop is much easier to use than the top that comes with the system, it is more intuitive, and it improves daily use greatly. This is why usually the first thing after installing the operating system the author installs it.","title":"htop-Process Management"},{"location":"gemstones/htop/#install-htop","text":"Every system administrator likes to use some of the more commonly used commands. Today I recommend htop as an alternative to the top command. To use the htop command normally , you need to install it first. # Installation epel source (also called repository) dnf -y install epel-release # Generate cache dnf makecache # Install htop dnf -y install htop","title":"install htop"},{"location":"gemstones/htop/#use-htop","text":"You only need to type htop in the terminal, and the interactive interface is as follows: 0[ ||| 3%] Tasks: 24, 14thr; 1 running 1[ | 1%] Load average: 0.00 0.00 0.05 Mem[ ||||||| 197M/8G] Uptime: 00:31:39 Swap[ 0K/500M] PID USER PRI NI VIRT RES SHR S CPU% MEM% TIME+ Commad(merged) ... F1 Help F2 Setup F3 Search F4 Filter F5 Tree F6 SortBy F7 Nice F8 Nice+ F9 Kill F10 Quit","title":"Use htop"},{"location":"gemstones/htop/#top-description","text":"The top 0 and 1 indicate the number of your CPU cores, and the percentage indicates the occupancy rate of a single core (of course, the total occupancy rate of the CPU can also be displayed) The different colors of the progress bar indicate the percentage of different process types: Color Description Blue Percentage of CPU used by low-priority processes Green Percentage of process CPU owned by ordinary users Red Percentage of CPU used by system processes Orange Percentage of CPU used by IRQ time Magenta Percentage of CPU used by soft IRQ time Gray Percentage of CPU occupied by IO waiting time Cyan Percentage of CPU consumed by Steal time Tasks: 24, 14thr; 1 running, process information. In my example, it means that my current machine has 24 tasks, which are divided into 14 threads, of which only 1 process is in a running state. Mem memory and swap information. Similarly, use different colors to distinguish: Color Description Blue Percentage of memory consumed by the buffer Green Percentage of memory consumed by the memory area Orange Percentage of memory consumed by the cache area Load average, the three values \u200b\u200brespectively represent the average load of the system in the last 1 minute, the last 5 minutes, and the last 15 minutes Uptime, which means the running time after booting","title":"Top Description"},{"location":"gemstones/htop/#process-information-description","text":"PID-Process ID number USER-the owner of the process PRI-Display the process priority as seen by the Linux kernel NI-displays the process priority of reset by normal user or root super user VIRI-virtual memory being consumed by a process RES-physical memory being consumed by a process SHR-shared memory being consumed by a process S-The current state of the process, there is a special state to pay attention to! That is Z (zombie process). When there are a large number of zombie processes in the machine, it will affect the performance of the machine. CPU%-Percentage of CPU consumed by each process MEM%-Percentage of memory consumed by each process TIME+-shows the running time since the process was started Commad-the command corresponding to the process","title":"Process information description"},{"location":"gemstones/htop/#shortcut-key-description","text":"In the interactive interface, press the F1 button to see the corresponding shortcut key description. The up, down, left, and right direction keys can scroll through the interactive interface, and space can mark the corresponding process, which is marked in yellow. The N button, the P button, the M button and the T button are respectively PID, CPU%, MEM%, TIME+ is used for sorting. Of course, you can also use the mouse to click to sort in ascending or descending order of a certain field.","title":"Shortcut key description"},{"location":"gemstones/htop/#other-commonly-used","text":"To manage the process, use the F9 button to send different signals to the process. The list of signals can be found in kill -l . The more commonly used ones are: Signal Description 1 Let the process shut down immediately, and then restart after re-reading the configuration file 9 Used to immediately end the running of the program, used to forcibly terminate the process, similar to the forced end in the windows taskbar 15 The default signal for the kill command. Sometimes if a problem has occurred in the process and the process cannot be terminated normally with this signal, we will try signal 9","title":"Other commonly used"},{"location":"gemstones/htop/#end","text":"htop is much easier to use than the top that comes with the system, it is more intuitive, and it improves daily use greatly. This is why usually the first thing after installing the operating system the author installs it.","title":"End"},{"location":"gemstones/https_rsa_keygen/","text":"https - RSA Key Generation This script has been used by me many times. No matter how often you use the openssl command structure, sometimes you have to refer back to the procedure. This script allows you to automate key generation for a web site using RSA. Note that this script is hard coded with a 2048 bit key length. For those of you who feel strongly that the key length minimum should be 4096 bits, simply change that portion of the script. Just know that you need to weigh the memory and speed that a site needs to load on a device, against the security of the longer key length. Script Name this script anything you like, example: keygen.sh , make the script executable ( chmod +x scriptname ) and place it in a directory that is in your path, example: /usr/local/sbin #!/bin/bash if [ $1 ] then echo \"generating 2048 bit key - you'll need to enter a pass phrase and verify it\" openssl genrsa -des3 -out $1.key.pass 2048 echo \"now we will create a pass-phrase less key for actual use, but you will need to enter your pass phrase a third time\" openssl rsa -in $1.key.pass -out $1.key echo \"next, we will generate the csr\" openssl req -new -key $1.key -out $1.csr #cleanup rm -f $1.key.pass else echo \"requires keyname parameter\" exit fi !!! Note You will enter the pass phrase three times in succession. Brief Description This bash script requires a parameter to be entered ($1) which is the name of the the site without any www, etc. For example, \"mywidget\". The script creates the default key with a password and 2048 bit length (this can be edited, as noted above to a longer 4096 bit length) The password is then immediately removed from the key, the reason is that web server restarts would require that the key password be entered each time, and on reboot, which can be problematic in practice. Next the script creates the CSR (Certificate Signing Request), which can then be used to purchase an SSL certificate from a provider. Finally, the cleanup step removes the previously created key with the password attached. Entering the script name without the parameter generates the error: \"requires keyname parameter\". The positional parameter variable, i.e. $n, is used here. Where $0 represents the command itself and $1 to $9 represent the first to ninth parameters. When the number is greater than 10, you need to use braces, such as ${10}","title":"https - RSA Key Generation"},{"location":"gemstones/https_rsa_keygen/#https-rsa-key-generation","text":"This script has been used by me many times. No matter how often you use the openssl command structure, sometimes you have to refer back to the procedure. This script allows you to automate key generation for a web site using RSA. Note that this script is hard coded with a 2048 bit key length. For those of you who feel strongly that the key length minimum should be 4096 bits, simply change that portion of the script. Just know that you need to weigh the memory and speed that a site needs to load on a device, against the security of the longer key length.","title":"https - RSA Key Generation"},{"location":"gemstones/https_rsa_keygen/#script","text":"Name this script anything you like, example: keygen.sh , make the script executable ( chmod +x scriptname ) and place it in a directory that is in your path, example: /usr/local/sbin #!/bin/bash if [ $1 ] then echo \"generating 2048 bit key - you'll need to enter a pass phrase and verify it\" openssl genrsa -des3 -out $1.key.pass 2048 echo \"now we will create a pass-phrase less key for actual use, but you will need to enter your pass phrase a third time\" openssl rsa -in $1.key.pass -out $1.key echo \"next, we will generate the csr\" openssl req -new -key $1.key -out $1.csr #cleanup rm -f $1.key.pass else echo \"requires keyname parameter\" exit fi !!! Note You will enter the pass phrase three times in succession.","title":"Script"},{"location":"gemstones/https_rsa_keygen/#brief-description","text":"This bash script requires a parameter to be entered ($1) which is the name of the the site without any www, etc. For example, \"mywidget\". The script creates the default key with a password and 2048 bit length (this can be edited, as noted above to a longer 4096 bit length) The password is then immediately removed from the key, the reason is that web server restarts would require that the key password be entered each time, and on reboot, which can be problematic in practice. Next the script creates the CSR (Certificate Signing Request), which can then be used to purchase an SSL certificate from a provider. Finally, the cleanup step removes the previously created key with the password attached. Entering the script name without the parameter generates the error: \"requires keyname parameter\". The positional parameter variable, i.e. $n, is used here. Where $0 represents the command itself and $1 to $9 represent the first to ninth parameters. When the number is greater than 10, you need to use braces, such as ${10}","title":"Brief Description"},{"location":"gemstones/mtr/","text":"mtr Introduction mtr is a network diagnostic tool that can diagnose network problems. It is used to replace the ping and traceroute commands. In terms of performance, the mtr command is faster. Use mtr # Install mtr shell > dnf -y install mtr The common options of the mtr command are as follows. Under normal circumstances, no additional options are required, followed by the host name or IP address directly: Options Description -4 # Use IPv4 only -6 # Use IPv6 only -c COUNT # Number of pings sent -n # Do not resolve the host name -z # Display AS number -b # Display ip and hostname -w # Output a wide range of reports The information exchanged by the terminal is as follows: shell > mtr -c 10 bing.com My traceroutr [v0.92] li(192.168.100.4) 2021-10-20T08:02:05+0800 Keys:Help Display mode Restart Statistics Order of fields quit HOST: li Loss% Snt Last Avg Best Wrst StDev 1. _gateway 0.0% 10 2.0 5.6 2.0 12.9 3.6 2. 10.9.128.1 0.0% 10 13.9 14.8 8.5 20.7 3.9 3. 120.80.175.109 0.0% 10 15.8 15.0 10.0 20.1 3.1 4. 112.89.0.57 20.0% 10 18.9 15.2 11.5 18.9 2.9 5.219.158.8.114 0.0% 10 10.8 14.4 10.6 20.5 3.5 6. 219.158.24.134 0.0% 10 13.1 14.5 11.9 18.9 2.2 7. 219.158.10.30 0.0% 10 14.9 21.2 12.0 29.8 6.9 8. 219.158.33.114 0.0% 10 17.7 17.1 13.0 20.0 2.0 9. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 10. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 11. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 12. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 13. a-0001.a-msedge.net 0.0% 10 18.4 15.7 9.5 19.3 3.1 ... Loss% - packet loss rate Snt - the number of packets sent Last - the delay of the last packet Avg - average delay Best - lowest latency Wrst - Worst time delay StDev - variance (stability) Shortcut keys for interaction p - pause; d - switch display mode; n - turn on/off DNS; r - reset all counters; j - Toggle delay display information; y - switch IP information; q - Quit interaction.","title":"mtr - Network Diagnostics"},{"location":"gemstones/mtr/#mtr-introduction","text":"mtr is a network diagnostic tool that can diagnose network problems. It is used to replace the ping and traceroute commands. In terms of performance, the mtr command is faster.","title":"mtr Introduction"},{"location":"gemstones/mtr/#use-mtr","text":"# Install mtr shell > dnf -y install mtr The common options of the mtr command are as follows. Under normal circumstances, no additional options are required, followed by the host name or IP address directly: Options Description -4 # Use IPv4 only -6 # Use IPv6 only -c COUNT # Number of pings sent -n # Do not resolve the host name -z # Display AS number -b # Display ip and hostname -w # Output a wide range of reports The information exchanged by the terminal is as follows: shell > mtr -c 10 bing.com My traceroutr [v0.92] li(192.168.100.4) 2021-10-20T08:02:05+0800 Keys:Help Display mode Restart Statistics Order of fields quit HOST: li Loss% Snt Last Avg Best Wrst StDev 1. _gateway 0.0% 10 2.0 5.6 2.0 12.9 3.6 2. 10.9.128.1 0.0% 10 13.9 14.8 8.5 20.7 3.9 3. 120.80.175.109 0.0% 10 15.8 15.0 10.0 20.1 3.1 4. 112.89.0.57 20.0% 10 18.9 15.2 11.5 18.9 2.9 5.219.158.8.114 0.0% 10 10.8 14.4 10.6 20.5 3.5 6. 219.158.24.134 0.0% 10 13.1 14.5 11.9 18.9 2.2 7. 219.158.10.30 0.0% 10 14.9 21.2 12.0 29.8 6.9 8. 219.158.33.114 0.0% 10 17.7 17.1 13.0 20.0 2.0 9. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 10. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 11. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 12. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 13. a-0001.a-msedge.net 0.0% 10 18.4 15.7 9.5 19.3 3.1 ... Loss% - packet loss rate Snt - the number of packets sent Last - the delay of the last packet Avg - average delay Best - lowest latency Wrst - Worst time delay StDev - variance (stability)","title":"Use mtr"},{"location":"gemstones/mtr/#shortcut-keys-for-interaction","text":"p - pause; d - switch display mode; n - turn on/off DNS; r - reset all counters; j - Toggle delay display information; y - switch IP information; q - Quit interaction.","title":"Shortcut keys for interaction"},{"location":"gemstones/nmcli/","text":"Modify NetworkManager connection profile autoconnect property First use nmcli to query and display the current value of the autoconnect property for all network connections on a Rocky Linux system. Type: nmcli -f name,autoconnect connection To change the value of a property for a network connection use the modify sub-command with nmcli connection . For example to change the autoconnect property value from no to yes for the ens3 connection profile, type: sudo nmcli con mod ens3 connection.autoconnect yes Commands Explained connection (con) : NetworkManager connection object. modify (mod) : Modify one or more properties of a given connection profile connection.autoconnect : The setting and property (<setting>.<property>) -f, --fields : specify fields to output Notes This tip shows how to modify an existing NetworkManager connection profile. This is useful when the network interface does not automatically get activated after a fresh Rocky Linux installation or system update. The reason for this is often because the value of autoconnect property is set to no . You can use the nmcli command to quickly change the value to yes .","title":"nmcli - set connection autoconnect"},{"location":"gemstones/nmcli/#modify-networkmanager-connection-profile-autoconnect-property","text":"First use nmcli to query and display the current value of the autoconnect property for all network connections on a Rocky Linux system. Type: nmcli -f name,autoconnect connection To change the value of a property for a network connection use the modify sub-command with nmcli connection . For example to change the autoconnect property value from no to yes for the ens3 connection profile, type: sudo nmcli con mod ens3 connection.autoconnect yes","title":"Modify NetworkManager connection profile autoconnect property"},{"location":"gemstones/nmcli/#commands-explained","text":"connection (con) : NetworkManager connection object. modify (mod) : Modify one or more properties of a given connection profile connection.autoconnect : The setting and property (<setting>.<property>) -f, --fields : specify fields to output","title":"Commands Explained"},{"location":"gemstones/nmcli/#notes","text":"This tip shows how to modify an existing NetworkManager connection profile. This is useful when the network interface does not automatically get activated after a fresh Rocky Linux installation or system update. The reason for this is often because the value of autoconnect property is set to no . You can use the nmcli command to quickly change the value to yes .","title":"Notes"},{"location":"gemstones/nmtui/","text":"Introduction For novice users who are new to GNU/Linux for the first time, the first thing to consider is how to connect the machine to the Internet after installing the operating system. This article will tell you how to configure the IP address, subnet mask, gateway and DNS. There are several ways for reference. Whether you are a novice or a familiar, I believe you can quickly get started. nmtui NetworkManager is a standard Linux network configuration tool suite, which supports server and desktop environments. Nowadays, most popular distributions support it. This set of network configuration tools is suitable for Rocky Linux 8 and later versions. If you want to configure network information graphically (i.e. the command line nmtui ), you only need to do this: shell > dnf -y install NetworkManager NetworkManager-tui shell > nmtui NetworkManager TUI Edit a connection Activate a connection Set system hostname Quit \\<OK> You can use the Tab key or the \u2191 \u2193 \u2190 \u2192 key to select the specific If you want to change the network information, please select Edit a connection and then Enter . Select a different network card and select Edit.. to edit. DHCP IPv4 For IPv4, if it is to obtain network information using DHCP way, you only need to select IPv4 CONFIGURATION back <Automatic> , and then run your terminal under systemctl restart NetworkManager.service , large In most cases, it can take effect. In rare cases, you need to switch the network card to take effect. For example, this way- nmcli connection down ens33 , nmcli connection up ens33 Manually fix network information If you want to manually fix all IPv4 network information, you need to select <Manual> after IPv4 CONFIGURATION and add it line by line. For example, I like this: Item Value Addresses 192.168.100.4/24 Gateway 192.168.100.1 DNS servers 8.8.8.8 Then click \\< OK > , return to the terminal interface step by step, and execute systemctl restart NetworkManager.service . Similarly, in rare cases, the network card needs to be switched on and off to take effect. Change the way of configuration files All RHEL distributions, whether upstream or downstream, are configured in the same way. The configuration file of network information is stored in the /etc/sysconfig/network-scripts/ directory, and one network card corresponds to one configuration file. The configuration file has many parameters, as shown in the following table. Notice! The parameters must be capitalized. shell > ls /etc/sysconfig/network-scripts/ ifcfg-ens33 Parameter name Meaning Example DEVICE System logical device name DEVICE=ens33 ONBOOT Whether the network card starts automatically with the system, you can choose yes or no ONBOOT=yes TYPE Network card interface type, usually Ethernet TYPE=Ethernet BOOTPROTO The way to obtain ip, it can be DHCP dynamic acquisition, or static manual configuration using static BOOTPROTO=static IPADDR The ip address of the network card, when BOOTPROTO=static, this parameter will take effect IPADDR=192.168.100.4 HWADDR Hardware address, ie MAC address HWADDR=00:0C:29:84:F6:9C NETMASK Decimal subnet mask NETMASK=255.255.255.0 PREFIX Subnet mask, represented by numbers PREFIX=24 GATEWAY Gateway, if there are multiple network cards, this parameter can only appear once GATEWAY=192.168.100.1 PEERDNS When it is yes, the DNS parameters defined here will modify /etc/resolv.conf; when it is no, /etc/resolv.conf will not be modified. When using DHCP, the default is yes PEERDNS=yes DNS1 The primary DNS is selected, it takes effect only when PEERDNS=no DNS1=8.8.8.8 DNS2 Alternative DNS, only effective when PEERDNS=no DNS2=114.114.114.114 BROWSER_ONLY Whether to allow only browsers BROWSER_ONLY=no USERCTL Whether ordinary users are allowed to control the network card device, yes means allow, no means not allowed USERCTL=no UUID Universal unique identification code, the main function is to identify the hardware, generally speaking, it is not necessary to fill in PROXY_METHOD Proxy method, generally none, can be left blank IPV4_FAILURE_FATAL If it is yes, it means that the device will be disabled after ipv4 configuration fails; if it is no, it means it will not be disabled. IPV4_FAILURE_FATAL=no IPV6INIT Whether to enable IPV6, yes to enable, no not to enable. When IPV6INIT=yes, the two parameters IPV6ADDR and IPV6_DEFAULTGW can also be enabled. The former represents the IPV6 address and the latter represents the designated gateway IPV6INIT=yes IPV6_AUTOCONF Whether to use IPV6 automatic configuration, yes means use; no means not use IPV6_AUTOCONF=yes IPV6_DEFROUTE Whether to give IPV6 the default route IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL After IPV6 configuration fails, whether to disable the device IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE Generate IPV6 address model, optional values \u200b\u200bare stable-privacy and eui64 IPV6_ADDR_GEN_MODE=stable-privacy After the configuration file is modified successfully, remember to restart the network card service systemctl restart NetworkManager.service Recommended configuration for IPV4 TYPE=Ethernet ONBOOT=yes DEVICE=ens33 USERCTL=no IPV4_FAILURE_FATAL=no BROWSER_ONLY=no BOOTPROTO=static PEERDNS=no IPADDR=192.168.100.4 PREFIX=24 GATEWAY=192.168.100.1 DNS1=8.8.8.8 DNS2=114.114.114.114 Recommended configuration for IPV6 TYPE=Ethernet ONBOOT=yes DEVICE=ens33 USERCTL=no BROWSER_ONLY=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no View network information ip a or nmcli device show","title":"nmtui - Network Management Tool"},{"location":"gemstones/nmtui/#introduction","text":"For novice users who are new to GNU/Linux for the first time, the first thing to consider is how to connect the machine to the Internet after installing the operating system. This article will tell you how to configure the IP address, subnet mask, gateway and DNS. There are several ways for reference. Whether you are a novice or a familiar, I believe you can quickly get started.","title":"Introduction"},{"location":"gemstones/nmtui/#nmtui","text":"NetworkManager is a standard Linux network configuration tool suite, which supports server and desktop environments. Nowadays, most popular distributions support it. This set of network configuration tools is suitable for Rocky Linux 8 and later versions. If you want to configure network information graphically (i.e. the command line nmtui ), you only need to do this: shell > dnf -y install NetworkManager NetworkManager-tui shell > nmtui NetworkManager TUI Edit a connection Activate a connection Set system hostname Quit \\<OK> You can use the Tab key or the \u2191 \u2193 \u2190 \u2192 key to select the specific If you want to change the network information, please select Edit a connection and then Enter . Select a different network card and select Edit.. to edit.","title":"nmtui"},{"location":"gemstones/nmtui/#dhcp-ipv4","text":"For IPv4, if it is to obtain network information using DHCP way, you only need to select IPv4 CONFIGURATION back <Automatic> , and then run your terminal under systemctl restart NetworkManager.service , large In most cases, it can take effect. In rare cases, you need to switch the network card to take effect. For example, this way- nmcli connection down ens33 , nmcli connection up ens33","title":"DHCP IPv4"},{"location":"gemstones/nmtui/#manually-fix-network-information","text":"If you want to manually fix all IPv4 network information, you need to select <Manual> after IPv4 CONFIGURATION and add it line by line. For example, I like this: Item Value Addresses 192.168.100.4/24 Gateway 192.168.100.1 DNS servers 8.8.8.8 Then click \\< OK > , return to the terminal interface step by step, and execute systemctl restart NetworkManager.service . Similarly, in rare cases, the network card needs to be switched on and off to take effect.","title":"Manually fix network information"},{"location":"gemstones/nmtui/#change-the-way-of-configuration-files","text":"All RHEL distributions, whether upstream or downstream, are configured in the same way. The configuration file of network information is stored in the /etc/sysconfig/network-scripts/ directory, and one network card corresponds to one configuration file. The configuration file has many parameters, as shown in the following table. Notice! The parameters must be capitalized. shell > ls /etc/sysconfig/network-scripts/ ifcfg-ens33 Parameter name Meaning Example DEVICE System logical device name DEVICE=ens33 ONBOOT Whether the network card starts automatically with the system, you can choose yes or no ONBOOT=yes TYPE Network card interface type, usually Ethernet TYPE=Ethernet BOOTPROTO The way to obtain ip, it can be DHCP dynamic acquisition, or static manual configuration using static BOOTPROTO=static IPADDR The ip address of the network card, when BOOTPROTO=static, this parameter will take effect IPADDR=192.168.100.4 HWADDR Hardware address, ie MAC address HWADDR=00:0C:29:84:F6:9C NETMASK Decimal subnet mask NETMASK=255.255.255.0 PREFIX Subnet mask, represented by numbers PREFIX=24 GATEWAY Gateway, if there are multiple network cards, this parameter can only appear once GATEWAY=192.168.100.1 PEERDNS When it is yes, the DNS parameters defined here will modify /etc/resolv.conf; when it is no, /etc/resolv.conf will not be modified. When using DHCP, the default is yes PEERDNS=yes DNS1 The primary DNS is selected, it takes effect only when PEERDNS=no DNS1=8.8.8.8 DNS2 Alternative DNS, only effective when PEERDNS=no DNS2=114.114.114.114 BROWSER_ONLY Whether to allow only browsers BROWSER_ONLY=no USERCTL Whether ordinary users are allowed to control the network card device, yes means allow, no means not allowed USERCTL=no UUID Universal unique identification code, the main function is to identify the hardware, generally speaking, it is not necessary to fill in PROXY_METHOD Proxy method, generally none, can be left blank IPV4_FAILURE_FATAL If it is yes, it means that the device will be disabled after ipv4 configuration fails; if it is no, it means it will not be disabled. IPV4_FAILURE_FATAL=no IPV6INIT Whether to enable IPV6, yes to enable, no not to enable. When IPV6INIT=yes, the two parameters IPV6ADDR and IPV6_DEFAULTGW can also be enabled. The former represents the IPV6 address and the latter represents the designated gateway IPV6INIT=yes IPV6_AUTOCONF Whether to use IPV6 automatic configuration, yes means use; no means not use IPV6_AUTOCONF=yes IPV6_DEFROUTE Whether to give IPV6 the default route IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL After IPV6 configuration fails, whether to disable the device IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE Generate IPV6 address model, optional values \u200b\u200bare stable-privacy and eui64 IPV6_ADDR_GEN_MODE=stable-privacy After the configuration file is modified successfully, remember to restart the network card service systemctl restart NetworkManager.service","title":"Change the way of configuration files"},{"location":"gemstones/nmtui/#recommended-configuration-for-ipv4","text":"TYPE=Ethernet ONBOOT=yes DEVICE=ens33 USERCTL=no IPV4_FAILURE_FATAL=no BROWSER_ONLY=no BOOTPROTO=static PEERDNS=no IPADDR=192.168.100.4 PREFIX=24 GATEWAY=192.168.100.1 DNS1=8.8.8.8 DNS2=114.114.114.114","title":"Recommended configuration for IPV4"},{"location":"gemstones/nmtui/#recommended-configuration-for-ipv6","text":"TYPE=Ethernet ONBOOT=yes DEVICE=ens33 USERCTL=no BROWSER_ONLY=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no","title":"Recommended configuration for IPV6"},{"location":"gemstones/nmtui/#view-network-information","text":"ip a or nmcli device show","title":"View network information"},{"location":"gemstones/perl_search_replace/","text":"perl Search and Replace Sometimes you need to quickly search and replace strings in a file or group of files. There are many ways to do this, but this method uses perl To search for and replace a particular string across multiple files in a directory, the command would be: perl -pi -w -e 's/search_for/replace_with/g;' ~/Dir_to_search/*.html For a single file that might have multiple instances of the string, you can specify the file: perl -pi -w -e 's/search_for/replace_with/g;' /var/www/htdocs/bigfile.html This command uses vi syntax for search and replace to find any occurrence of a string and replace it with another string across a single or multiple files of a particular type. Useful for replacing html/php link changes embedded in those types of files, and many other things. Options Explained Option Explanation -p places a loop around your script -i edit file in place -w prints out warning messages in case something goes wrong -e allows a single line of code entered on the command line -s specifies search -g specifies to replace globally, in other words all occurrences Conclusion A simple way to replace a string in either one or many files using perl .","title":"Perl - Search and Replace"},{"location":"gemstones/perl_search_replace/#perl-search-and-replace","text":"Sometimes you need to quickly search and replace strings in a file or group of files. There are many ways to do this, but this method uses perl To search for and replace a particular string across multiple files in a directory, the command would be: perl -pi -w -e 's/search_for/replace_with/g;' ~/Dir_to_search/*.html For a single file that might have multiple instances of the string, you can specify the file: perl -pi -w -e 's/search_for/replace_with/g;' /var/www/htdocs/bigfile.html This command uses vi syntax for search and replace to find any occurrence of a string and replace it with another string across a single or multiple files of a particular type. Useful for replacing html/php link changes embedded in those types of files, and many other things.","title":"perl Search and Replace"},{"location":"gemstones/perl_search_replace/#options-explained","text":"Option Explanation -p places a loop around your script -i edit file in place -w prints out warning messages in case something goes wrong -e allows a single line of code entered on the command line -s specifies search -g specifies to replace globally, in other words all occurrences","title":"Options Explained"},{"location":"gemstones/perl_search_replace/#conclusion","text":"A simple way to replace a string in either one or many files using perl .","title":"Conclusion"},{"location":"gemstones/sed_search_replace/","text":"sed - Search and Replace sed is a command that stands for \"stream editor.\" Conventions path : The actual path. Example: /var/www/html/ filename : The actual filename. Example: index.php Using sed Using sed for search and replace is my personal preference because you can use a delimiter of your choice, which makes replacing things like web links with \u201c/\u201d in them very handy. The default examples for in place editing using sed show things like this example: sed -i 's/search_for/replace_with/g' /path/filename But what if you are searching for strings that will contain \"/\" in them? If the forward slash was the only option available as a delimiter, then we would have to escape each forward slash before we could use it in the search. That's where sed excels over other tools, because the delimiter is changeable on-the-fly (no need to specify that you are changing it anywhere). As stated, if we are looking for things with \"/\" in them, we can easily do that by changing the delimiter to \"|\". Here's an example of looking for a link using this method: sed -i 's|search_for/with_slash|replace_string|g' /path/filename You can use any single-byte character for the delimiter with the exception of backslash, newline, and \"s\". For instance, this works too: sed -i 'sasearch_forawith_slashareplace_stringag' /path/filename where \"a\" is the delimiter, and the search and replace still works. For safety, you can specify a backup while searching and replacing, which is handy for making sure the changes you are making with sed are what you really want. This gives you a recovery option from the backup file: sed -i.bak s|search_for|replacea_with|g /path/filename Which will create an unedited version of filename called filename.bak You can also use full quotes instead of single quotes if you like: sed -i \"s|search_for/with_slash|replace_string|g\" /path/filename Options Explained Option Explanation i edit file in place i.ext create a backup with whatever the extension is (ext here) s specifies search g specifies to replace globally, in other words all occurrences Multiple files Unfortunately, sed doesn't have an in-line looping option like perl . To loop through multiple files, you would need to combine your sed command within a script. Here's an example of doing that. First, generate a list of files that your script will use, which can be entered at the command line: find /var/www/html -name \"*.php\" > phpfiles.txt Next, create a script to use this phpfiles.txt : #!/bin/bash for file in `cat phpfiles.txt` do sed -i.bak 's|search_for/with_slash|replace_string|g' $file done The script loops through all of the files created in phpfiles.txt , creates a backup of each file, and executes the search and replace string globally. Once you have verified that your search and replace has completed successfully and your changes are what you want, you can delete all of the backup files. Other reading and examples sed manual page sed additional examples sed & awk O'Reilly Book Conclusion sed is a powerful tools and works very well for search and replace functions, particularly where the delimiter needs to be flexible.","title":"sed - Search and Replace"},{"location":"gemstones/sed_search_replace/#sed-search-and-replace","text":"sed is a command that stands for \"stream editor.\"","title":"sed - Search and Replace"},{"location":"gemstones/sed_search_replace/#conventions","text":"path : The actual path. Example: /var/www/html/ filename : The actual filename. Example: index.php","title":"Conventions"},{"location":"gemstones/sed_search_replace/#using-sed","text":"Using sed for search and replace is my personal preference because you can use a delimiter of your choice, which makes replacing things like web links with \u201c/\u201d in them very handy. The default examples for in place editing using sed show things like this example: sed -i 's/search_for/replace_with/g' /path/filename But what if you are searching for strings that will contain \"/\" in them? If the forward slash was the only option available as a delimiter, then we would have to escape each forward slash before we could use it in the search. That's where sed excels over other tools, because the delimiter is changeable on-the-fly (no need to specify that you are changing it anywhere). As stated, if we are looking for things with \"/\" in them, we can easily do that by changing the delimiter to \"|\". Here's an example of looking for a link using this method: sed -i 's|search_for/with_slash|replace_string|g' /path/filename You can use any single-byte character for the delimiter with the exception of backslash, newline, and \"s\". For instance, this works too: sed -i 'sasearch_forawith_slashareplace_stringag' /path/filename where \"a\" is the delimiter, and the search and replace still works. For safety, you can specify a backup while searching and replacing, which is handy for making sure the changes you are making with sed are what you really want. This gives you a recovery option from the backup file: sed -i.bak s|search_for|replacea_with|g /path/filename Which will create an unedited version of filename called filename.bak You can also use full quotes instead of single quotes if you like: sed -i \"s|search_for/with_slash|replace_string|g\" /path/filename","title":"Using sed"},{"location":"gemstones/sed_search_replace/#options-explained","text":"Option Explanation i edit file in place i.ext create a backup with whatever the extension is (ext here) s specifies search g specifies to replace globally, in other words all occurrences","title":"Options Explained"},{"location":"gemstones/sed_search_replace/#multiple-files","text":"Unfortunately, sed doesn't have an in-line looping option like perl . To loop through multiple files, you would need to combine your sed command within a script. Here's an example of doing that. First, generate a list of files that your script will use, which can be entered at the command line: find /var/www/html -name \"*.php\" > phpfiles.txt Next, create a script to use this phpfiles.txt : #!/bin/bash for file in `cat phpfiles.txt` do sed -i.bak 's|search_for/with_slash|replace_string|g' $file done The script loops through all of the files created in phpfiles.txt , creates a backup of each file, and executes the search and replace string globally. Once you have verified that your search and replace has completed successfully and your changes are what you want, you can delete all of the backup files.","title":"Multiple files"},{"location":"gemstones/sed_search_replace/#other-reading-and-examples","text":"sed manual page sed additional examples sed & awk O'Reilly Book","title":"Other reading and examples"},{"location":"gemstones/sed_search_replace/#conclusion","text":"sed is a powerful tools and works very well for search and replace functions, particularly where the delimiter needs to be flexible.","title":"Conclusion"},{"location":"gemstones/setup_local_repo/","text":"Introduction Sometimes you need to have Rocky repositories local for building virtual machines, lab environments, etc. It can also help save bandwidth if that is a concern. This article will walk you through using rsync to copy Rocky repositories to a local web server. Building a web server is out of the scope of this short article. Requirements A web server Code #!/bin/bash repos_base_dir=\"/web/path\" # Start sync if base repo directory exist if [[ -d \"$repos_base_dir\" ]] ; then # Start Sync rsync -avSHP --progress --delete --exclude-from=/opt/scripts/excludes.txt rsync://ord.mirror.rackspace.com/rocky \"$repos_base_dir\" --delete-excluded # Download Rocky 8 repository key if [[ -e /web/path/RPM-GPG-KEY-rockyofficial ]]; then exit else wget -P $repos_base_dir https://dl.rockylinux.org/pub/rocky/RPM-GPG-KEY-rockyofficial fi fi Breakdown This simple shell script uses rsync to pull repository files from the nearest mirror. It also utilizes the \"exclude\" option which is defined in a text file in the form of keywords that shouldnt be included. Excludes are good if you have limited disk space or just dont want everything for whatever reason. We can use * as a wildcard character. Be careful using */ng as it will exclude anything that matches those characters. An example is below: */source* */debug* */images* */Devel* 8/* 8.4-RC1/* 8.4-RC1 End A simple script that can help save bandwidth or make building out a lab environment a little easier.","title":"Setup Local Rocky Repositories"},{"location":"gemstones/setup_local_repo/#introduction","text":"Sometimes you need to have Rocky repositories local for building virtual machines, lab environments, etc. It can also help save bandwidth if that is a concern. This article will walk you through using rsync to copy Rocky repositories to a local web server. Building a web server is out of the scope of this short article.","title":"Introduction"},{"location":"gemstones/setup_local_repo/#requirements","text":"A web server","title":"Requirements"},{"location":"gemstones/setup_local_repo/#code","text":"#!/bin/bash repos_base_dir=\"/web/path\" # Start sync if base repo directory exist if [[ -d \"$repos_base_dir\" ]] ; then # Start Sync rsync -avSHP --progress --delete --exclude-from=/opt/scripts/excludes.txt rsync://ord.mirror.rackspace.com/rocky \"$repos_base_dir\" --delete-excluded # Download Rocky 8 repository key if [[ -e /web/path/RPM-GPG-KEY-rockyofficial ]]; then exit else wget -P $repos_base_dir https://dl.rockylinux.org/pub/rocky/RPM-GPG-KEY-rockyofficial fi fi","title":"Code"},{"location":"gemstones/setup_local_repo/#breakdown","text":"This simple shell script uses rsync to pull repository files from the nearest mirror. It also utilizes the \"exclude\" option which is defined in a text file in the form of keywords that shouldnt be included. Excludes are good if you have limited disk space or just dont want everything for whatever reason. We can use * as a wildcard character. Be careful using */ng as it will exclude anything that matches those characters. An example is below: */source* */debug* */images* */Devel* 8/* 8.4-RC1/* 8.4-RC1","title":"Breakdown"},{"location":"gemstones/setup_local_repo/#end","text":"A simple script that can help save bandwidth or make building out a lab environment a little easier.","title":"End"},{"location":"gemstones/view_kernel_conf/","tags":["kernel","config","modules","kmod"],"text":"View Current Kernel Configuration The Linux kernel stores running kernel information in two places via special filesystems: ( A summary of them ) The older procfs which mounts /proc (verify via mount -l -t proc ) The newer sysfs which mounts /sys (verify via mount -l -t sysfs ) !!! caution Be cautious if examining the files mentioned here, altering them can change the behavior of the actual running kernel! These two interfaces allow you to view and change the parameters of the currently running kernel. Note that if you do an ls -l on some of these files, they will show as \"0\" length, but if you cat them out they actually contain data; most of them are ASCII and editable, however some are binary, and in either case commands like file or stat will typically just return \"empty file\" or \"0\" for lengths, although they will show you other information. The preferred and standard programs for interacting with these functions are lsmod , modinfo , and sysctl , among others. sysctl -a | grep -i <keyword> lsmod | grep -i <keyword> modinfo <module> See what your currently running \"kernel release\" version is with: uname -r and substitute its return value in commands by using $(uname -r) RHEL and derivative distributions (Fedora, CentOS Stream, Scientific Linux, RockyLinux, Almalinux, et. al.) also store the config used for bootable installed kernels in the /boot directory used by Grub2 as ASCII files: /boot/config-<kernel-release> To check the currently running kernel config for a particular value: cat /boot/config-$(uname -r) | grep -i <keyword> Results will show: \"=m\" if compiled in as a kernel module \"=y\" if compiled statically into the kernel \"is not set\" if that setting was commented out a numeric value a quoted string value Some distributions, like Gentoo and Arch, use the configs kernel module to provide /proc/config.gz by default instead: zcat /proc/config.gz | grep -i <keyword> zgrep <keyword> /proc/config.gz For any distribution, if your running kernel has set both CONFIG_IKCONFIG and CONFIG_IKCONFIG_PROC and if ls -lh /sys/module/configs exists and is executable (searchable in the case of a dir) then you can create /proc/config.gz with this command if it is not present: modprobe configs !!! note \"Enabled Repos\" This document does not currently cover kernel packages that might have come from non-default repos such as: appstream-debug, appstream-source, baseos-debug, baseos-source, or devel The kernel-devel packages install the config file used to compile each installed standard kernel package as an ASCII file in the following location: /usr/src/kernels/<kernel-release>/.config This file is more commonly accessed by a symlinked path provided by the kernel-core packages: /lib/modules/<kernel-release>/build/ -> /usr/src/kernels/<kernel-release>/ If you have kernel-debug-devel packages installed you will also have this directory: /usr/src/kernels/<kernel-release>+debug/ You can look in any of the following for details on the config values used to build an installed kernel: /lib/modules/<kernel-release>/config /lib/modules/<kernel-release>/build/.config /usr/src/kernels/<kernel-release>/.config /usr/src/kernels/<kernel-release>+debug/.config Configured modules for the currently running kernel, whether compiled as builtin (i.e. statically into the kernel itself) or a loadable module, are listed by sub directories named as the module name in: /sys/module/ For each installed kernel-release you can examine these files to see what values were compiled into that kernel, and what version of GCC was used to compile it: cat /lib/modules/$(uname -r)/config | grep -i <keyword> cat /lib/modules/$(uname -r)/build/.config | grep -i <keyword> cat /usr/src/kernels/$(uname -r)/.config | grep -i <keyword> cat /usr/src/kernels/$(uname -r)+debug/.config | grep -i <keyword> ls -lh /sys/module/ | grep -i <keyword> You can check for kernel module dependencies in the file: /lib/modules/<kernel-release>/modules.dep but it is easier to read or parse the output of the \"Used-by\" field in lsmod . Reference: depmod , ls , lsmod , modinfo , modprobe , modules.dep , namespaces , procfs , sysctl , sysfs , uname","title":"View Current Kernel Configuration"},{"location":"gemstones/view_kernel_conf/#view-current-kernel-configuration","text":"The Linux kernel stores running kernel information in two places via special filesystems: ( A summary of them ) The older procfs which mounts /proc (verify via mount -l -t proc ) The newer sysfs which mounts /sys (verify via mount -l -t sysfs ) !!! caution Be cautious if examining the files mentioned here, altering them can change the behavior of the actual running kernel! These two interfaces allow you to view and change the parameters of the currently running kernel. Note that if you do an ls -l on some of these files, they will show as \"0\" length, but if you cat them out they actually contain data; most of them are ASCII and editable, however some are binary, and in either case commands like file or stat will typically just return \"empty file\" or \"0\" for lengths, although they will show you other information. The preferred and standard programs for interacting with these functions are lsmod , modinfo , and sysctl , among others. sysctl -a | grep -i <keyword> lsmod | grep -i <keyword> modinfo <module> See what your currently running \"kernel release\" version is with: uname -r and substitute its return value in commands by using $(uname -r) RHEL and derivative distributions (Fedora, CentOS Stream, Scientific Linux, RockyLinux, Almalinux, et. al.) also store the config used for bootable installed kernels in the /boot directory used by Grub2 as ASCII files: /boot/config-<kernel-release> To check the currently running kernel config for a particular value: cat /boot/config-$(uname -r) | grep -i <keyword> Results will show: \"=m\" if compiled in as a kernel module \"=y\" if compiled statically into the kernel \"is not set\" if that setting was commented out a numeric value a quoted string value Some distributions, like Gentoo and Arch, use the configs kernel module to provide /proc/config.gz by default instead: zcat /proc/config.gz | grep -i <keyword> zgrep <keyword> /proc/config.gz For any distribution, if your running kernel has set both CONFIG_IKCONFIG and CONFIG_IKCONFIG_PROC and if ls -lh /sys/module/configs exists and is executable (searchable in the case of a dir) then you can create /proc/config.gz with this command if it is not present: modprobe configs !!! note \"Enabled Repos\" This document does not currently cover kernel packages that might have come from non-default repos such as: appstream-debug, appstream-source, baseos-debug, baseos-source, or devel The kernel-devel packages install the config file used to compile each installed standard kernel package as an ASCII file in the following location: /usr/src/kernels/<kernel-release>/.config This file is more commonly accessed by a symlinked path provided by the kernel-core packages: /lib/modules/<kernel-release>/build/ -> /usr/src/kernels/<kernel-release>/ If you have kernel-debug-devel packages installed you will also have this directory: /usr/src/kernels/<kernel-release>+debug/ You can look in any of the following for details on the config values used to build an installed kernel: /lib/modules/<kernel-release>/config /lib/modules/<kernel-release>/build/.config /usr/src/kernels/<kernel-release>/.config /usr/src/kernels/<kernel-release>+debug/.config Configured modules for the currently running kernel, whether compiled as builtin (i.e. statically into the kernel itself) or a loadable module, are listed by sub directories named as the module name in: /sys/module/ For each installed kernel-release you can examine these files to see what values were compiled into that kernel, and what version of GCC was used to compile it: cat /lib/modules/$(uname -r)/config | grep -i <keyword> cat /lib/modules/$(uname -r)/build/.config | grep -i <keyword> cat /usr/src/kernels/$(uname -r)/.config | grep -i <keyword> cat /usr/src/kernels/$(uname -r)+debug/.config | grep -i <keyword> ls -lh /sys/module/ | grep -i <keyword> You can check for kernel module dependencies in the file: /lib/modules/<kernel-release>/modules.dep but it is easier to read or parse the output of the \"Used-by\" field in lsmod .","title":"View Current Kernel Configuration"},{"location":"gemstones/view_kernel_conf/#reference","text":"depmod , ls , lsmod , modinfo , modprobe , modules.dep , namespaces , procfs , sysctl , sysfs , uname","title":"Reference:"},{"location":"guides/","text":"Rocky Linux Guides Welcome to the Guides section of the Rocky Linux documentation. You will find a host of \"how-to\" documents, and much more, here. This section is changing all the time. There are also some longer document groups that can be found in \"Books\" as well as future planned educational \"Labs\", each of which may be found in the top menu. Most of the categories do not require any explanation. If you want to find out how to help in the ongoing development of Rocky Linux, join the Mattermost Development channel . For those wishing to be involved in documentation, join the Mattermost Documentation channel and join the discussion to find out more. If you are wanting to dive right in, you can install Rocky Linux now!","title":"Guides Home"},{"location":"guides/#rocky-linux-guides","text":"Welcome to the Guides section of the Rocky Linux documentation. You will find a host of \"how-to\" documents, and much more, here. This section is changing all the time. There are also some longer document groups that can be found in \"Books\" as well as future planned educational \"Labs\", each of which may be found in the top menu. Most of the categories do not require any explanation. If you want to find out how to help in the ongoing development of Rocky Linux, join the Mattermost Development channel . For those wishing to be involved in documentation, join the Mattermost Documentation channel and join the discussion to find out more. If you are wanting to dive right in, you can install Rocky Linux now!","title":"Rocky Linux Guides"},{"location":"guides/custom-linux-kernel/","text":"Overview In this guide, we\u2019ll walk through the process of acquiring a kernel source tree, configuring it, compiling it, and, finally, installing and booting the kernel. The Kernel Most often, when people say Linux , they are usually referring to a \" Linux distribution \" \u2014for example, Rocky Linux and Debian are types of Linux distribution. A distribution comprises everything necessary to get Linux to exist as a functional operating system. Distributions make use of code from various open source projects that are independent of Linux. Linux is The kernel. The kernel literally sits right at the heart of the [operating system] matter. The only thing more fundamental than the kernel is the system hardware itself. Although the kernel is a small part of a complete Linux distribution, it is by far the most critical element. If the kernel fails or crashes, the rest of the system goes with it. The Kernel Source Code The Rocky Linux distribution has the source code for the specific kernel version it supports available in one form or another. These could be in the form of a compiled binary ( .src.rpm), a source RPM ( .srpm), or the like. If you need to download a different (possibly newer) version than the one your specific Rocky Linux distro provides, the first place to look for the source code is at the official kernel web site: www.kernel.org This site maintains a listing of web sites mirroring the kernel source, as well as tons of other open source software, distributions and general-purpose utilities. The list of mirrors is maintained at: mirrors.kernel.org !!! TIP The majority of the downloading, configuring and compiling of the Linux kernel done in the following sections can/should be done as an unprivileged user.However, the final steps that require actual installation or altering of system files and binaries need to be done with elevated privileges. We are able to do most of the work as an unprivileged user because we will be using a special kernel build option, which allows us to specify a custom working or output directory. Specifically, we\u2019ll use the `O=~/build/kernel` option for all applicable invocations of make. Where `~/build/kernel` is equivalent to `/home/$USER/build/kernel` or `$HOME/build/kernel` Kernel versions and naming conventions The web site listing of kernels available will contain folders for v1.0, v2.5, v2.6, v3.0, v3.x, v4.x, v5.x, v6.x and so forth. Before you follow your natural inclination to get the latest version, make sure you understand how the Linux kernel versioning system works. The current convention is to name and number major new kernel releases as \u201cLinux 5.x\u201d (also called the vanilla or mainline kernels). Thus the first of this series will be Linux version 5.0 (same as 5.0.0), the next will be Linux version 5.1 (same as 5.1.0), followed by Linux version 5.2, and so on. Any minor changes or updates within each major release version will be reflected by increments to the third digit. These are commonly referred to as stable point releases. Thus, the next stable point release for the 5.0.0 series kernel will be Linux version 5.0.1, followed by version 5.0.2, and so forth. Another way of stating this is to say, for example, that Linux version 5.0.4 is the fourth stable release based on the Linux 5.0.0 series. Installing prerequisite tools and libraries A common source of failure encountered during the kernel build process may be caused by not having all the requisite software available for compiling and building the mainline Linux Kernel. The missing tools and libraries can be installed using the DNF package manager on a Rocky Linux distro. We\u2019ll take care of this in this section. On a Rocky Linux distro, you can quickly get most of the necessary development tools installed by running this command: ``` sudo dnf -y groupinstall 'C Development Tools and Libraries' ``` Some other libraries, header files and applications that you might need can also be obtained by installing the following packages. Type: ``` sudo dnf -y install \\ ncurses-devel openssl-devel elfutils-libelf-devel python3 ``` Next, we need some other utilities that are only available in some supported 3rd party repositories. One of such repositories is the Powertools repo. Let\u2019s enable that repo on our Rocky system. Type: ``` sudo dnf config-manager --set-enabled powertools ``` Finally, let\u2019s install one of the needed packages from the Powertool repo. Type: ``` sudo dnf -y install dwarves ``` That\u2019s it for the prerequisite packages needed for actual Kernel building! Downloading and unpacking the Linux Kernel The version of the kernel that we are going to build in the following section is version 5.16.9, which is available at: www.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.xz Let\u2019s begin the process. First, use the following curl command to download the needed kernel source into your current working directory. Type: curl -L -o linux-5.16.9.tar.xz \\ https://www.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.xz The kernel source that you will download from the Internet is a file that has been compressed and tarred. Therefore, to use the source, you need to decompress and untar the source file. Make sure you are in the directory that download the Kernel tarball into. Use the tar command to unpack and decompress the file, by running: tar xvJf linux-5.*.tar.xz Building the Kernel In this section, we\u2019re going to review the process of configuring and building a kernel. This is in contrast to macOS or Windows-based operating systems, which come preconfigured and therefore contain support for many features you may or may not want. The Linux design philosophy allows the individual to decide on the important parts of the kernel.This individualized design has the important benefit of letting you thin down the feature list so that Linux can run as efficiently as possible. This is also one of the reasons why it is possible to customize Linux to run in various hardware setups, from low-end systems, to embedded systems, to high-end systems. Two main steps are required in building a kernel: configuring compiling The first step in building the kernel is configuring its features. Usually, your desired feature list will be based on whatever hardware you need to support. This, of course, means that you\u2019ll need a list of that hardware. On a system that is already running Linux, you can run commands like \u2013 lspci, lshw and so on to help show detailed information about the exact hardware setup on your system. On RPM-based distros these utilities are provided by the pciutils .rpm and lshw .rpm packages. Having a better understanding of what constitutes your underlying hardware can help you better determine what you need in your custom kernel. You\u2019re ready to start configuring the kernel. Sanitizing the build environment With a rough idea of the types of hardware and features that our new kernel needs to support, we can begin the actual configuration. But first, some background information. The Linux kernel source tree contains several files named Makefile (a makefile is simply a text file with directives and it also describes the relationships among the files in a program). These makefiles help to glue together the thousands of other files that make up the kernel source. What is more important to us here is that the makefiles also contain targets. The targets are the commands, or directives, that are executed by the make program. !!! Caution \"Caution: Avoid Needless Kernel Upgrades\" Bear in mind that if you have a working system that is stable and well behaved, there is little reason to upgrade the kernel unless one of these conditions holds for you: - A security or bug fix affects your system and must be applied - You need a specific new feature in a stable release In the case of a security fix, decide whether the risk really affects you\u2014for example, if the security issue is found in a device driver that you don\u2019t use, then there may be no reason to upgrade. In the case of a bug fix release, read carefully through the release notes and decide if the bugs really affect you\u2014if you have a stable system, upgrading the kernel with patches you never use may be pointless. On production systems, the kernel shouldn\u2019t simply be upgraded just to have \u201cthe latest kernel\u201d; you should have a truly compelling reason to upgrade. The Makefile in the root of the kernel source tree contains specific targets that can be used in prepping the kernel build environment, configuring the kernel, compiling the kernel, installing the kernel, and so on. Some of the targets are discussed in more detail here: make mrproper \u2003This target cleans up the build environment of any stale files and dependencies that might have been left over from a previous kernel build. All previous kernel configurations will be cleaned (deleted) from the build environment. make clean \u2003This target does not do as thorough a job as the mrproper target. It deletes only most generated files. It does not delete the kernel configuration file (.config). make menuconfig \u2003This target invokes a text-based editor interface with menus, option lists, and text-based dialog boxes for configuring the kernel. make xconfig \u2003This is a GUI based kernel configuration tool/target that relies on the Qt graphical development libraries. These libraries are used by KDE/Plasma-based applications. make gconfig \u2003This is also a GUI based kernel configuration tool/target, but it relies on the GTK+ toolkit. This GTK toolkit is heavily used in the GNOME desktop world. make olddefconfig \u2003This target uses the existing .config file in the current working directory, updates the dependencies, and automatically sets new symbols to their default values. make help \u2003This target will show you all the other possible make targets and also serves as a quick online help system. To configure the kernel in this section, we will use only one of the targets. In particular, we will use the make menuconfig command. The menuconfig kernel config editor is a simple and popular text-based configuration utility that consists of menus, radio button lists, and dialogs. It has a simple and clean interface that can be easily navigated with your keyboard and is almost intuitive to use. We need to change (cd) into the kernel source directory, after which we can begin the kernel configuration. But before beginning the actual kernel configuration, you should clean (prepare) the kernel build environment by using the make mrproper command: > cd linux-5.* > make O=~/build/kernel mrproper Kernel Configuration Next, we will step through the process of configuring a Linux 5.* series kernel. To explore some of the innards of this process, we will enable the support of a specific feature that we\u2019ll pretend is a MUST have feature on the system. Once you understand how this works, you can apply the same procedure to add support for any other new kernel feature that you want. Specifically, we\u2019ll enable support for the NTFS file system into our custom kernel. Most modern Linux distros ship with a kernel configuration file for the running kernel available on the local file system as a compressed or regular file. On our sample Rocky system, this file resides in the /boot directory and is usually named something like config-4.*. The configuration file contains a list of the options and features that were enabled for the particular kernel it represents. A config file similar to this one is what we aim to create through the process of configuring the kernel. The only difference between the file we\u2019ll create and the ready-made one is that we will add further minor customization to ours. !!! TIP Using a known, preexisting config file as a framework for creating our own custom file helps ensure that we don\u2019t waste too much time duplicating the efforts that other people have already put into finding what works and what doesn\u2019t work! The following steps cover how to configure the kernel. We will be using a text-based kernel configuration utility, which will allow you to follow along in your terminal regardless of whether you are using a GUI desktop environment or not. To begin, we\u2019ll copy over and rename the preexisting config file from the /boot directory into our kernel build environment: > cp /boot/config-`uname -r` ~/build/kernel/.config We use uname -r here to help us obtain the configuration file for the running kernel. The uname -r command prints the running kernel\u2019s release. Using it helps ensure that we are getting the exact version we want, just in case other versions are present. !!! NOTE The Linux kernel configuration editor specifically starts up looking for, and ends up generating, a file named .config (pronounced \u201cdot config\u201d) at the root of the kernel source tree. This file is hidden. Launch the graphical kernel configuration utility: ``` make O=~/build/kernel menuconfig ``` A screen similar to this will appear: The kernel configuration screen that appears is divided into roughly three areas. The top part shows various helpful information, keyboard shortcuts, and legends that can help you navigate the application. The main body of the screen shows an expandable tree-structured list of the overall configurable kernel options. You can further drill down into items with arrows in the parent to view and/or configure sub-menu (or child) items. And finally, the bottom of the screen displays the actual actions/options that the user can choose. Next, for demonstration purposes we\u2019ll add support for NTFS into our custom kernel. While at the main configuration screen, use your arrow keys to navigate to and highlight the File systems item. With File systems selected, press enter to view the sub-menu or child items for File systems. In the File Systems section, use your arrow keys to navigate to DOS/FAT/NT Filesystems. Press enter to see the child items for DOS/FAT/NT Filesystems. In the DOS/FAT/NT Filesystems section, navigate to NTFS file system support. Type M (uppercase) to enable support for the NTFS file system via modules. Use the arrow keys to navigate down to NTFS debugging support (NEW) and then press y to include it. Use the arrow keys to navigate down to NTFS write support and then press y to include it. When you are done, the letter M or an asterisk symbol (*) should appear beside each option, like the ones shown here: !!! TIP For each of the configurable options, in the kernel configuration utility, empty angle parentheses, <>, indicates that the feature in question is disabled. The letter M in angle parentheses, <M>, indicates that the feature is to be compiled as a module. And the asterisk symbol in angle parentheses, <*>, indicates that support for the feature will be directly built into the kernel. You can usually toggle through all the possible options using the spacebar on your keyboard. Navigate back to the parent File Systems screen by pressing the esc key twice on your keyboard in the DOS/FAT/NT Filesystems screen.Return to the main kernel configuration screen by pressing esc twice again on your keyboard. Finally, save your changes to the .config file in the root of your kernel source tree and exit the kernel configuration application after saving the file by pressing esc twice again on your keyboard. A dialog box will appear prompting you to save your new configuration. Make sure that Yes is selected and then press enter. After the kernel configuration utility exits, you will be thrown back to your shell\u2014inside the kernel source tree.You are almost ready to build your kernel! We need to complete a few more customizations on our Rocky distro. Type: sed -ri '/CONFIG_SYSTEM_TRUSTED_KEYS/s/=.+/=\"\"/g' ~/build/kernel/.config !!! TIP To view the results of some of the changes you made using the menuconfig tool, use the grep utility to view the .config file that you saved directly. For example to view the effect of the NTFS file system support that we enabled previously, type the following: ``` > grep NTFS ~/build/kernel/.config CONFIG_NTFS_FS=m CONFIG_NTFS_DEBUG=y CONFIG_NTFS_RW=y ``` !!! NOTE \"A Quick Note on Kernel Modules\" Loadable module support is a Linux kernel feature that allows the dynamic loading (or removal) of kernel modules. Kernel modules are pieces of compiled code that can be dynamically inserted into the running kernel, rather than being permanently built into the kernel. Features not often used can thus be enabled, but they won\u2019t occupy any room in memory when they aren\u2019t being used. Thankfully, the Linux kernel can automatically determine what to load and when. Naturally, not every feature is eligible to be compiled as a module. The kernel must know a few things before it can load and unload modules, such as how to access the hard disk and parse through the file system where the loadable modules are stored. Some kernel modules are also commonly referred to as drivers. Compiling the Kernel In the preceding section, we walked through the process of creating a configuration file for the custom kernel that we want to build. In this section, we will perform the actual build of the kernel. But before doing this, we will add one more simple customization to the entire process. The final customization will be to add an extra piece of information used in the final name of our kernel. This will help us be able to differentiate this kernel from any other kernel with the same version number. We will add the tag \u201ccustom\u201d to the kernel version information. This can be done by editing the main Makefile and appending the tag that we want to the EXTRAVERSION variable. The compilation stage of the kernel-building process is by far the easiest, but it also takes the most time. All that is needed at this point is simply to execute the make command, which will then automatically generate and take care of any dependency issues, compile the kernel itself, and compile any features (or drivers) that were enabled as loadable modules. Because of the amount of code that needs to be compiled, be prepared to wait a few minutes, at the very least, depending on the processing power of your system. Let\u2019s dig into the specific steps required to compile your new kernel. First we\u2019ll add an extra piece to the identification string for the kernel we are about to build. While still in the root of the kernel source tree, we\u2019ll use the sed utility edit the Makefile in place. The variable we want to change is close to the top of the file. We want to change the line in the file that looks like this: EXTRAVERSION = To this: EXTRAVERSION = -custom Use the following sed command to make the change. Type: sed -i 's/^EXTRAVERSION.*/EXTRAVERSION = -custom/' Makefile Of course you can also use any text editor that you are comfortable with to make the change. Just remember to save your changes to the file! Pass the kernelversion target to the make command to view the full version of the kernel that you just customized: ``` make O=~/build/kernel kernelversion ``` !!! Tip You can take advantage of all that extra processing power (CPUs, cores and so on) on most modern systems and greatly speed up CPU-intensive operations like compiling the kernel. To do this, you can pass a parameter to the make command that specifies the number of jobs to run simultaneously. The specified number of jobs are then distributed and executed simultaneously on each CPU core. The syntax for the command is: ``` make -j N ``` where N is the number of jobs to run simultaneously. For example, if you have a octa (8) core\u2013capable CPU, you can type: ``` make -j 8 ``` The only command that is needed here to compile the kernel is the make command: ``` make O=~/build/kernel** make[1]: Entering directory '/home/super/build/kernel' SYNC include/config/auto.conf.cmd GEN Makefile HOSTCC scripts/kconfig/conf.o HOSTLD scripts/kconfig/conf GEN Makefile ... \u2026 LD [M] sound/usb/usx2y/snd-usb-usx2y.ko LD [M] sound/x86/snd-hdmi-lpe-audio.ko LD [M] sound/xen/snd_xen_front.ko LD [M] virt/lib/irqbypass.ko make[1]: Leaving directory '/home/super/build/kernel' ``` The end product of this command (that is, the kernel) is sitting pretty and waiting in the path: ~/build/kernel/arch/x86/boot/bzImage Because we compiled portions of the kernel as modules (for example, the NTFS module), we need to install the modules. Type the following: ``` sudo make O=~/build/kernel modules_install ``` On our Rocky system, this command will install all the compiled kernel modules into the /lib/modules/ directory. In this example, this path will translate to /lib/modules/5.16.9-custom/. This is the path from which the kernel will load all loadable modules, as needed. !!! TIP The footprint (size) of the kernel modules installed via \u201cmake modules_install\u201d can end up getting pretty large because the modules include debugging symbols. As a result you could easily end up with a `/lib/modules/5.16.9-custom/` directory that is close to 5GB in size! For this guide we avoid this large size by including the INSTALL_MOD_STRIP=1 option in our make modules_install invocation. You can reduce the total size by orders of magnitude (For example - less than 200 MB!!) by stripping away these debugging symbols. This can be done by including the `INSTALL_MOD_STRIP=1` option to the `make modules_install` command. Installing the Kernel Assuming you have a PC and are working out of the ~/build/kernel/ directory, the compiled kernel that was created in the previous exercise will be located in this path - <kernel-build-dir>/arch/x86/boot/bzImage or, to be precise, in our example ~/build/kernel/arch/x86/boot/bzImage . The corresponding map file for this will be located at ~/build/kernel/System.map. You\u2019ll need both files for the install phase. The System.map file is useful when the kernel is misbehaving and generating \u201cOops\u201d messages. An \u201cOops\u201d is generated on some kernel errors because of kernel bugs or faulty hardware. This error is akin to the Blue Screen of Death (BSOD) in Microsoft Windows. These messages include a lot of detail about the current state of the system, including several hexadecimal numbers. System.map gives Linux a chance to turn those hexadecimal numbers into readable names, making debugging easier. Although this is mostly for the benefit of developers, it can be handy when you\u2019re reporting a problem. Let\u2019s go through the steps required to install the new kernel image. While in the root of your kernel build directory, copy and rename the bzImage file into the /boot directory: ``` sudo cp ~/build/kernel/arch/x86/boot/bzImage \\ /boot/vmlinuz- ``` Here, kernel-version is the version number of the kernel. For the sample kernel we are using in this guide, the filename would be vmlinuz-5.16.9-custom. So here\u2019s the exact command for this example: ``` sudo cp ~/build/kernel/arch/x86/boot/bzImage \\ /boot/vmlinuz-5.16.9-custom ``` !!! Note The decision to name the kernel image vmlinuz-5.16.9-custom is somewhat arbitrary. It\u2019s convenient, because kernel images are commonly referred to as vmlinuz, and the suffix of the version number is useful when you have multiple kernels available or kernels that provide specific functionality (For example vmlinuz-6.50.0-ws). Now that the kernel image is in place, copy over and rename the corresponding System.map file into the /boot directory using the same naming convention: ``` sudo cp -v ~/build/kernel/System.map \\ /boot/System.map-5.16.9-custom ``` With the kernel in place, the System.map file in place, and the modules in place, we are now ready for the final step. The syntax for the command needed is: ``` kernel-install add ``` Here, is the version number (and name) of the kernel. And is the path to the newly compiled kernel image. For our example, type: ``` sudo kernel-install \\ add 5.16.9-custom /boot/vmlinuz-5.16.9-custom ``` The kernel-install command used here is a nifty little shell script. It might not be available in every Linux distribution, but it is available in newer Fedora, RHEL, CentOS distros. This tool automates a lot of the final manual things we\u2019d ordinarily have to do to set up the system to boot the new kernel we just built. In particular, the tool does the following: It creates the appropriate initial RAM file system image (the initramfs image\u2014that is, the /boot/initramfs- .img file). To do this manually on systems where kernel-install is not available, use the mkinitramfs command. It runs the depmod command (which creates a list of module dependencies). It updates the boot loader configuration. For systems running the newer versions of GRUB2, the file will be /boot/grub2/grub.cfg . For EFI based systems /boot/efi/ /fedora/grub.cfg is also updated. And for systems running the legacy versions of GRUB, this will be the /boot/grub/grub.conf or /boot/grub/menu.lst file. And for very new distros that have implemented the new Boot Loader Specification (BLS) a new boot loader entry will be added to the /boot/loader/entries/ directory or any directory pointed to by the variable named \"blsdir\". On our demo EFI based Rocky server running GRUB 2 using BLS, a new boot entry is created in the boot loader file located here: /boot/loader/entries/6fa25ca775f64accb0d3e53f0e4e6e92-5.16.9-custom.conf > sudo cat /boot/loader/entries/6fa25ca775f64accb0d3e53f0e4e6e92-5.16.9-custom.conf title Rocky Linux (5.16.9-custom) 8.5 (Green Obsidian) version 5.16.9-custom linux /vmlinuz-5.16.9-custom initrd /initramfs-5.16.9-custom.img $tuned_initrd options $kernelopts $tuned_params id rocky-20220212013135-5.16.9-custom grub_users $grub_users grub_arg --unrestricted grub_class kernel !!! Note Most distros, have several grub2-* utilities readily available that can be used for performing various GRUB2 and boot loader house keeping tasks. For example you can use the grub2-set-default command to change or set the default kernel to be booted at system startup. Booting the custom Kernel The next stage is to test the new kernel to make sure that the system can indeed boot with it. Assuming you did everything the exact way that the doctor prescribed and that everything worked out exactly as the doctor said it would, you can safely reboot the system and select the new kernel from the boot loader menu during system bootup: ``` sudo reboot ``` After the system boots up, you can use the uname command to find out the name of the current kernel: ``` uname -r 5.16.9-custom ``` You will recall that one of the features that we added to our new kernel is the ability to support the NTFS file system. Make sure that the new kernel does indeed have support for NTFS by displaying information about the NTFS module: [rockstar ~]$ modinfo ntfs filename: /lib/modules/5.16.9-custom/kernel/fs/ntfs/ntfs.ko license: GPL version: 2.1.32 description: NTFS 1.2/3.x driver - Copyright \u2026.. ...<OUTPUT TRUNCATED>... And that\u2019s it !","title":"Building and Installing Custom Linux Kernels"},{"location":"guides/custom-linux-kernel/#overview","text":"In this guide, we\u2019ll walk through the process of acquiring a kernel source tree, configuring it, compiling it, and, finally, installing and booting the kernel.","title":"Overview"},{"location":"guides/custom-linux-kernel/#the-kernel","text":"Most often, when people say Linux , they are usually referring to a \" Linux distribution \" \u2014for example, Rocky Linux and Debian are types of Linux distribution. A distribution comprises everything necessary to get Linux to exist as a functional operating system. Distributions make use of code from various open source projects that are independent of Linux. Linux is The kernel. The kernel literally sits right at the heart of the [operating system] matter. The only thing more fundamental than the kernel is the system hardware itself. Although the kernel is a small part of a complete Linux distribution, it is by far the most critical element. If the kernel fails or crashes, the rest of the system goes with it.","title":"The Kernel"},{"location":"guides/custom-linux-kernel/#the-kernel-source-code","text":"The Rocky Linux distribution has the source code for the specific kernel version it supports available in one form or another. These could be in the form of a compiled binary ( .src.rpm), a source RPM ( .srpm), or the like. If you need to download a different (possibly newer) version than the one your specific Rocky Linux distro provides, the first place to look for the source code is at the official kernel web site: www.kernel.org This site maintains a listing of web sites mirroring the kernel source, as well as tons of other open source software, distributions and general-purpose utilities. The list of mirrors is maintained at: mirrors.kernel.org !!! TIP The majority of the downloading, configuring and compiling of the Linux kernel done in the following sections can/should be done as an unprivileged user.However, the final steps that require actual installation or altering of system files and binaries need to be done with elevated privileges. We are able to do most of the work as an unprivileged user because we will be using a special kernel build option, which allows us to specify a custom working or output directory. Specifically, we\u2019ll use the `O=~/build/kernel` option for all applicable invocations of make. Where `~/build/kernel` is equivalent to `/home/$USER/build/kernel` or `$HOME/build/kernel`","title":"The Kernel Source Code"},{"location":"guides/custom-linux-kernel/#kernel-versions-and-naming-conventions","text":"The web site listing of kernels available will contain folders for v1.0, v2.5, v2.6, v3.0, v3.x, v4.x, v5.x, v6.x and so forth. Before you follow your natural inclination to get the latest version, make sure you understand how the Linux kernel versioning system works. The current convention is to name and number major new kernel releases as \u201cLinux 5.x\u201d (also called the vanilla or mainline kernels). Thus the first of this series will be Linux version 5.0 (same as 5.0.0), the next will be Linux version 5.1 (same as 5.1.0), followed by Linux version 5.2, and so on. Any minor changes or updates within each major release version will be reflected by increments to the third digit. These are commonly referred to as stable point releases. Thus, the next stable point release for the 5.0.0 series kernel will be Linux version 5.0.1, followed by version 5.0.2, and so forth. Another way of stating this is to say, for example, that Linux version 5.0.4 is the fourth stable release based on the Linux 5.0.0 series.","title":"Kernel versions and naming conventions"},{"location":"guides/custom-linux-kernel/#installing-prerequisite-tools-and-libraries","text":"A common source of failure encountered during the kernel build process may be caused by not having all the requisite software available for compiling and building the mainline Linux Kernel. The missing tools and libraries can be installed using the DNF package manager on a Rocky Linux distro. We\u2019ll take care of this in this section. On a Rocky Linux distro, you can quickly get most of the necessary development tools installed by running this command: ``` sudo dnf -y groupinstall 'C Development Tools and Libraries' ``` Some other libraries, header files and applications that you might need can also be obtained by installing the following packages. Type: ``` sudo dnf -y install \\ ncurses-devel openssl-devel elfutils-libelf-devel python3 ``` Next, we need some other utilities that are only available in some supported 3rd party repositories. One of such repositories is the Powertools repo. Let\u2019s enable that repo on our Rocky system. Type: ``` sudo dnf config-manager --set-enabled powertools ``` Finally, let\u2019s install one of the needed packages from the Powertool repo. Type: ``` sudo dnf -y install dwarves ``` That\u2019s it for the prerequisite packages needed for actual Kernel building!","title":"Installing prerequisite tools and libraries"},{"location":"guides/custom-linux-kernel/#downloading-and-unpacking-the-linux-kernel","text":"The version of the kernel that we are going to build in the following section is version 5.16.9, which is available at: www.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.xz Let\u2019s begin the process. First, use the following curl command to download the needed kernel source into your current working directory. Type: curl -L -o linux-5.16.9.tar.xz \\ https://www.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.xz The kernel source that you will download from the Internet is a file that has been compressed and tarred. Therefore, to use the source, you need to decompress and untar the source file. Make sure you are in the directory that download the Kernel tarball into. Use the tar command to unpack and decompress the file, by running: tar xvJf linux-5.*.tar.xz","title":"Downloading and unpacking the Linux Kernel"},{"location":"guides/custom-linux-kernel/#building-the-kernel","text":"In this section, we\u2019re going to review the process of configuring and building a kernel. This is in contrast to macOS or Windows-based operating systems, which come preconfigured and therefore contain support for many features you may or may not want. The Linux design philosophy allows the individual to decide on the important parts of the kernel.This individualized design has the important benefit of letting you thin down the feature list so that Linux can run as efficiently as possible. This is also one of the reasons why it is possible to customize Linux to run in various hardware setups, from low-end systems, to embedded systems, to high-end systems. Two main steps are required in building a kernel: configuring compiling The first step in building the kernel is configuring its features. Usually, your desired feature list will be based on whatever hardware you need to support. This, of course, means that you\u2019ll need a list of that hardware. On a system that is already running Linux, you can run commands like \u2013 lspci, lshw and so on to help show detailed information about the exact hardware setup on your system. On RPM-based distros these utilities are provided by the pciutils .rpm and lshw .rpm packages. Having a better understanding of what constitutes your underlying hardware can help you better determine what you need in your custom kernel. You\u2019re ready to start configuring the kernel.","title":"Building the Kernel"},{"location":"guides/custom-linux-kernel/#sanitizing-the-build-environment","text":"With a rough idea of the types of hardware and features that our new kernel needs to support, we can begin the actual configuration. But first, some background information. The Linux kernel source tree contains several files named Makefile (a makefile is simply a text file with directives and it also describes the relationships among the files in a program). These makefiles help to glue together the thousands of other files that make up the kernel source. What is more important to us here is that the makefiles also contain targets. The targets are the commands, or directives, that are executed by the make program. !!! Caution \"Caution: Avoid Needless Kernel Upgrades\" Bear in mind that if you have a working system that is stable and well behaved, there is little reason to upgrade the kernel unless one of these conditions holds for you: - A security or bug fix affects your system and must be applied - You need a specific new feature in a stable release In the case of a security fix, decide whether the risk really affects you\u2014for example, if the security issue is found in a device driver that you don\u2019t use, then there may be no reason to upgrade. In the case of a bug fix release, read carefully through the release notes and decide if the bugs really affect you\u2014if you have a stable system, upgrading the kernel with patches you never use may be pointless. On production systems, the kernel shouldn\u2019t simply be upgraded just to have \u201cthe latest kernel\u201d; you should have a truly compelling reason to upgrade. The Makefile in the root of the kernel source tree contains specific targets that can be used in prepping the kernel build environment, configuring the kernel, compiling the kernel, installing the kernel, and so on. Some of the targets are discussed in more detail here: make mrproper \u2003This target cleans up the build environment of any stale files and dependencies that might have been left over from a previous kernel build. All previous kernel configurations will be cleaned (deleted) from the build environment. make clean \u2003This target does not do as thorough a job as the mrproper target. It deletes only most generated files. It does not delete the kernel configuration file (.config). make menuconfig \u2003This target invokes a text-based editor interface with menus, option lists, and text-based dialog boxes for configuring the kernel. make xconfig \u2003This is a GUI based kernel configuration tool/target that relies on the Qt graphical development libraries. These libraries are used by KDE/Plasma-based applications. make gconfig \u2003This is also a GUI based kernel configuration tool/target, but it relies on the GTK+ toolkit. This GTK toolkit is heavily used in the GNOME desktop world. make olddefconfig \u2003This target uses the existing .config file in the current working directory, updates the dependencies, and automatically sets new symbols to their default values. make help \u2003This target will show you all the other possible make targets and also serves as a quick online help system. To configure the kernel in this section, we will use only one of the targets. In particular, we will use the make menuconfig command. The menuconfig kernel config editor is a simple and popular text-based configuration utility that consists of menus, radio button lists, and dialogs. It has a simple and clean interface that can be easily navigated with your keyboard and is almost intuitive to use. We need to change (cd) into the kernel source directory, after which we can begin the kernel configuration. But before beginning the actual kernel configuration, you should clean (prepare) the kernel build environment by using the make mrproper command: > cd linux-5.* > make O=~/build/kernel mrproper","title":"Sanitizing the build environment"},{"location":"guides/custom-linux-kernel/#kernel-configuration","text":"Next, we will step through the process of configuring a Linux 5.* series kernel. To explore some of the innards of this process, we will enable the support of a specific feature that we\u2019ll pretend is a MUST have feature on the system. Once you understand how this works, you can apply the same procedure to add support for any other new kernel feature that you want. Specifically, we\u2019ll enable support for the NTFS file system into our custom kernel. Most modern Linux distros ship with a kernel configuration file for the running kernel available on the local file system as a compressed or regular file. On our sample Rocky system, this file resides in the /boot directory and is usually named something like config-4.*. The configuration file contains a list of the options and features that were enabled for the particular kernel it represents. A config file similar to this one is what we aim to create through the process of configuring the kernel. The only difference between the file we\u2019ll create and the ready-made one is that we will add further minor customization to ours. !!! TIP Using a known, preexisting config file as a framework for creating our own custom file helps ensure that we don\u2019t waste too much time duplicating the efforts that other people have already put into finding what works and what doesn\u2019t work! The following steps cover how to configure the kernel. We will be using a text-based kernel configuration utility, which will allow you to follow along in your terminal regardless of whether you are using a GUI desktop environment or not. To begin, we\u2019ll copy over and rename the preexisting config file from the /boot directory into our kernel build environment: > cp /boot/config-`uname -r` ~/build/kernel/.config We use uname -r here to help us obtain the configuration file for the running kernel. The uname -r command prints the running kernel\u2019s release. Using it helps ensure that we are getting the exact version we want, just in case other versions are present. !!! NOTE The Linux kernel configuration editor specifically starts up looking for, and ends up generating, a file named .config (pronounced \u201cdot config\u201d) at the root of the kernel source tree. This file is hidden. Launch the graphical kernel configuration utility: ``` make O=~/build/kernel menuconfig ``` A screen similar to this will appear: The kernel configuration screen that appears is divided into roughly three areas. The top part shows various helpful information, keyboard shortcuts, and legends that can help you navigate the application. The main body of the screen shows an expandable tree-structured list of the overall configurable kernel options. You can further drill down into items with arrows in the parent to view and/or configure sub-menu (or child) items. And finally, the bottom of the screen displays the actual actions/options that the user can choose. Next, for demonstration purposes we\u2019ll add support for NTFS into our custom kernel. While at the main configuration screen, use your arrow keys to navigate to and highlight the File systems item. With File systems selected, press enter to view the sub-menu or child items for File systems. In the File Systems section, use your arrow keys to navigate to DOS/FAT/NT Filesystems. Press enter to see the child items for DOS/FAT/NT Filesystems. In the DOS/FAT/NT Filesystems section, navigate to NTFS file system support. Type M (uppercase) to enable support for the NTFS file system via modules. Use the arrow keys to navigate down to NTFS debugging support (NEW) and then press y to include it. Use the arrow keys to navigate down to NTFS write support and then press y to include it. When you are done, the letter M or an asterisk symbol (*) should appear beside each option, like the ones shown here: !!! TIP For each of the configurable options, in the kernel configuration utility, empty angle parentheses, <>, indicates that the feature in question is disabled. The letter M in angle parentheses, <M>, indicates that the feature is to be compiled as a module. And the asterisk symbol in angle parentheses, <*>, indicates that support for the feature will be directly built into the kernel. You can usually toggle through all the possible options using the spacebar on your keyboard. Navigate back to the parent File Systems screen by pressing the esc key twice on your keyboard in the DOS/FAT/NT Filesystems screen.Return to the main kernel configuration screen by pressing esc twice again on your keyboard. Finally, save your changes to the .config file in the root of your kernel source tree and exit the kernel configuration application after saving the file by pressing esc twice again on your keyboard. A dialog box will appear prompting you to save your new configuration. Make sure that Yes is selected and then press enter. After the kernel configuration utility exits, you will be thrown back to your shell\u2014inside the kernel source tree.You are almost ready to build your kernel! We need to complete a few more customizations on our Rocky distro. Type: sed -ri '/CONFIG_SYSTEM_TRUSTED_KEYS/s/=.+/=\"\"/g' ~/build/kernel/.config !!! TIP To view the results of some of the changes you made using the menuconfig tool, use the grep utility to view the .config file that you saved directly. For example to view the effect of the NTFS file system support that we enabled previously, type the following: ``` > grep NTFS ~/build/kernel/.config CONFIG_NTFS_FS=m CONFIG_NTFS_DEBUG=y CONFIG_NTFS_RW=y ``` !!! NOTE \"A Quick Note on Kernel Modules\" Loadable module support is a Linux kernel feature that allows the dynamic loading (or removal) of kernel modules. Kernel modules are pieces of compiled code that can be dynamically inserted into the running kernel, rather than being permanently built into the kernel. Features not often used can thus be enabled, but they won\u2019t occupy any room in memory when they aren\u2019t being used. Thankfully, the Linux kernel can automatically determine what to load and when. Naturally, not every feature is eligible to be compiled as a module. The kernel must know a few things before it can load and unload modules, such as how to access the hard disk and parse through the file system where the loadable modules are stored. Some kernel modules are also commonly referred to as drivers.","title":"Kernel Configuration"},{"location":"guides/custom-linux-kernel/#compiling-the-kernel","text":"In the preceding section, we walked through the process of creating a configuration file for the custom kernel that we want to build. In this section, we will perform the actual build of the kernel. But before doing this, we will add one more simple customization to the entire process. The final customization will be to add an extra piece of information used in the final name of our kernel. This will help us be able to differentiate this kernel from any other kernel with the same version number. We will add the tag \u201ccustom\u201d to the kernel version information. This can be done by editing the main Makefile and appending the tag that we want to the EXTRAVERSION variable. The compilation stage of the kernel-building process is by far the easiest, but it also takes the most time. All that is needed at this point is simply to execute the make command, which will then automatically generate and take care of any dependency issues, compile the kernel itself, and compile any features (or drivers) that were enabled as loadable modules. Because of the amount of code that needs to be compiled, be prepared to wait a few minutes, at the very least, depending on the processing power of your system. Let\u2019s dig into the specific steps required to compile your new kernel. First we\u2019ll add an extra piece to the identification string for the kernel we are about to build. While still in the root of the kernel source tree, we\u2019ll use the sed utility edit the Makefile in place. The variable we want to change is close to the top of the file. We want to change the line in the file that looks like this: EXTRAVERSION = To this: EXTRAVERSION = -custom Use the following sed command to make the change. Type: sed -i 's/^EXTRAVERSION.*/EXTRAVERSION = -custom/' Makefile Of course you can also use any text editor that you are comfortable with to make the change. Just remember to save your changes to the file! Pass the kernelversion target to the make command to view the full version of the kernel that you just customized: ``` make O=~/build/kernel kernelversion ``` !!! Tip You can take advantage of all that extra processing power (CPUs, cores and so on) on most modern systems and greatly speed up CPU-intensive operations like compiling the kernel. To do this, you can pass a parameter to the make command that specifies the number of jobs to run simultaneously. The specified number of jobs are then distributed and executed simultaneously on each CPU core. The syntax for the command is: ``` make -j N ``` where N is the number of jobs to run simultaneously. For example, if you have a octa (8) core\u2013capable CPU, you can type: ``` make -j 8 ``` The only command that is needed here to compile the kernel is the make command: ``` make O=~/build/kernel** make[1]: Entering directory '/home/super/build/kernel' SYNC include/config/auto.conf.cmd GEN Makefile HOSTCC scripts/kconfig/conf.o HOSTLD scripts/kconfig/conf GEN Makefile ... \u2026 LD [M] sound/usb/usx2y/snd-usb-usx2y.ko LD [M] sound/x86/snd-hdmi-lpe-audio.ko LD [M] sound/xen/snd_xen_front.ko LD [M] virt/lib/irqbypass.ko make[1]: Leaving directory '/home/super/build/kernel' ``` The end product of this command (that is, the kernel) is sitting pretty and waiting in the path: ~/build/kernel/arch/x86/boot/bzImage Because we compiled portions of the kernel as modules (for example, the NTFS module), we need to install the modules. Type the following: ``` sudo make O=~/build/kernel modules_install ``` On our Rocky system, this command will install all the compiled kernel modules into the /lib/modules/ directory. In this example, this path will translate to /lib/modules/5.16.9-custom/. This is the path from which the kernel will load all loadable modules, as needed. !!! TIP The footprint (size) of the kernel modules installed via \u201cmake modules_install\u201d can end up getting pretty large because the modules include debugging symbols. As a result you could easily end up with a `/lib/modules/5.16.9-custom/` directory that is close to 5GB in size! For this guide we avoid this large size by including the INSTALL_MOD_STRIP=1 option in our make modules_install invocation. You can reduce the total size by orders of magnitude (For example - less than 200 MB!!) by stripping away these debugging symbols. This can be done by including the `INSTALL_MOD_STRIP=1` option to the `make modules_install` command.","title":"Compiling the Kernel"},{"location":"guides/custom-linux-kernel/#installing-the-kernel","text":"Assuming you have a PC and are working out of the ~/build/kernel/ directory, the compiled kernel that was created in the previous exercise will be located in this path - <kernel-build-dir>/arch/x86/boot/bzImage or, to be precise, in our example ~/build/kernel/arch/x86/boot/bzImage . The corresponding map file for this will be located at ~/build/kernel/System.map. You\u2019ll need both files for the install phase. The System.map file is useful when the kernel is misbehaving and generating \u201cOops\u201d messages. An \u201cOops\u201d is generated on some kernel errors because of kernel bugs or faulty hardware. This error is akin to the Blue Screen of Death (BSOD) in Microsoft Windows. These messages include a lot of detail about the current state of the system, including several hexadecimal numbers. System.map gives Linux a chance to turn those hexadecimal numbers into readable names, making debugging easier. Although this is mostly for the benefit of developers, it can be handy when you\u2019re reporting a problem. Let\u2019s go through the steps required to install the new kernel image. While in the root of your kernel build directory, copy and rename the bzImage file into the /boot directory: ``` sudo cp ~/build/kernel/arch/x86/boot/bzImage \\ /boot/vmlinuz- ``` Here, kernel-version is the version number of the kernel. For the sample kernel we are using in this guide, the filename would be vmlinuz-5.16.9-custom. So here\u2019s the exact command for this example: ``` sudo cp ~/build/kernel/arch/x86/boot/bzImage \\ /boot/vmlinuz-5.16.9-custom ``` !!! Note The decision to name the kernel image vmlinuz-5.16.9-custom is somewhat arbitrary. It\u2019s convenient, because kernel images are commonly referred to as vmlinuz, and the suffix of the version number is useful when you have multiple kernels available or kernels that provide specific functionality (For example vmlinuz-6.50.0-ws). Now that the kernel image is in place, copy over and rename the corresponding System.map file into the /boot directory using the same naming convention: ``` sudo cp -v ~/build/kernel/System.map \\ /boot/System.map-5.16.9-custom ``` With the kernel in place, the System.map file in place, and the modules in place, we are now ready for the final step. The syntax for the command needed is: ``` kernel-install add ``` Here, is the version number (and name) of the kernel. And is the path to the newly compiled kernel image. For our example, type: ``` sudo kernel-install \\ add 5.16.9-custom /boot/vmlinuz-5.16.9-custom ``` The kernel-install command used here is a nifty little shell script. It might not be available in every Linux distribution, but it is available in newer Fedora, RHEL, CentOS distros. This tool automates a lot of the final manual things we\u2019d ordinarily have to do to set up the system to boot the new kernel we just built. In particular, the tool does the following: It creates the appropriate initial RAM file system image (the initramfs image\u2014that is, the /boot/initramfs- .img file). To do this manually on systems where kernel-install is not available, use the mkinitramfs command. It runs the depmod command (which creates a list of module dependencies). It updates the boot loader configuration. For systems running the newer versions of GRUB2, the file will be /boot/grub2/grub.cfg . For EFI based systems /boot/efi/ /fedora/grub.cfg is also updated. And for systems running the legacy versions of GRUB, this will be the /boot/grub/grub.conf or /boot/grub/menu.lst file. And for very new distros that have implemented the new Boot Loader Specification (BLS) a new boot loader entry will be added to the /boot/loader/entries/ directory or any directory pointed to by the variable named \"blsdir\". On our demo EFI based Rocky server running GRUB 2 using BLS, a new boot entry is created in the boot loader file located here: /boot/loader/entries/6fa25ca775f64accb0d3e53f0e4e6e92-5.16.9-custom.conf > sudo cat /boot/loader/entries/6fa25ca775f64accb0d3e53f0e4e6e92-5.16.9-custom.conf title Rocky Linux (5.16.9-custom) 8.5 (Green Obsidian) version 5.16.9-custom linux /vmlinuz-5.16.9-custom initrd /initramfs-5.16.9-custom.img $tuned_initrd options $kernelopts $tuned_params id rocky-20220212013135-5.16.9-custom grub_users $grub_users grub_arg --unrestricted grub_class kernel !!! Note Most distros, have several grub2-* utilities readily available that can be used for performing various GRUB2 and boot loader house keeping tasks. For example you can use the grub2-set-default command to change or set the default kernel to be booted at system startup.","title":"Installing the Kernel"},{"location":"guides/custom-linux-kernel/#booting-the-custom-kernel","text":"The next stage is to test the new kernel to make sure that the system can indeed boot with it. Assuming you did everything the exact way that the doctor prescribed and that everything worked out exactly as the doctor said it would, you can safely reboot the system and select the new kernel from the boot loader menu during system bootup: ``` sudo reboot ``` After the system boots up, you can use the uname command to find out the name of the current kernel: ``` uname -r 5.16.9-custom ``` You will recall that one of the features that we added to our new kernel is the ability to support the NTFS file system. Make sure that the new kernel does indeed have support for NTFS by displaying information about the NTFS module: [rockstar ~]$ modinfo ntfs filename: /lib/modules/5.16.9-custom/kernel/fs/ntfs/ntfs.ko license: GPL version: 2.1.32 description: NTFS 1.2/3.x driver - Copyright \u2026.. ...<OUTPUT TRUNCATED>... And that\u2019s it !","title":"Booting the custom Kernel"},{"location":"guides/automation/anacron/","text":"anacron- Run commands regularly Prerequisites A machine running Rocky Linux. Know how to use your favorite editor to modify the configuration file (such as vim ) in the command line environment . Understand basic RPM package management Assumption You have understood the basic knowledge of bash, python or other scripting/programming tools, and want to run the script automatically. You are logged in as the root user, or switch to root with su - root Anacron Introduction anacron is used to run commands on a regular basis, and the operating frequency is defined in units of days. It is suitable for computers that do not run 24/7, such as laptops and desktops. Suppose you have a scheduled task (such as a backup script) to be run in the early morning of every day using crontab. When you fall asleep, your desktop/laptop is shut down. Your backup script will not be executed. However, if you use anacron, you can rest assured that the next time you turn on the desktop/laptop, the backup script will be executed. The appearance of anacron is not to replace crontab, but to complement crontab. Their relationship is as follows: anacron configuration file shell > rpm -ql cronie-anacron /etc/anacrontab /etc/cron.hourly/0anacron /usr/lib/.build-id /usr/lib/.build-id/0e /usr/lib/.build-id/0e/6b094fa55505597cb69dc5a6b7f5f30b04d40f /usr/sbin/anacron /usr/share/man/man5/anacrontab.5.gz /usr/share/man/man8/anacron.8.gz /var/spool/anacron /var/spool/anacron/cron.daily /var/spool/anacron/cron.monthly /var/spool/anacron/cron.weekly First check the default configuration file: shell > cat /etc/anacontab # /etc/anacrontab: configuration file for anacron # See anacron(8) and anacrontab(5) for details. SHELL=/bin/sh PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # Default 45 minutes delay for each specified job anacron random increase 0-45 minutes. RANDOM_DELAY=45 # Specify the scope of work time, represented here 3:00 ~ 22:00 START_HOURS_RANGE=3-22 # period in days delay in minutes job-identifier command # Boot every day to check whether the files in the directory /etc/cron.daily be executed in 5 minutes, if not executed today, then to the next 1 5 cron.daily nice run-parts /etc/cron.daily # Every 7 days within 25 minutes if the file check /etc/cron.weekly directory is executed after boot, if not executed within a week, it will be executed next 7 25 cron.weekly nice run-parts /etc/cron.weekly # Whether the files in the directory /etc/cron.monthly 45 minutes checking is performed after every start for a month @monthly 45 cron.monthly nice run-parts /etc/cron.monthly /etc/cron.hourly/ -Through journalctl -u crond.service , you can know that the files put inside are actually called by crond.server, which means that the command will be executed after the first minute of every hour. As follows: shell > cat /etc/cron.d/0hourly # Run the hourly jobs SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root 01 * * * * root run-parts /etc/cron.hourly shell > journalctl -u crond.service - Logs begin at Wed 2021-10-20 19:27:39 CST, end at Wed 2021-10-20 23:32:42 CST. - October 20 19:27:42 li systemd[1]: Started Command Scheduler. October 20 19:27:42 li crond[733]: (CRON) STARTUP (1.5.2) October 20 19:27:42 li crond[733]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 76% if used.) October 20 19:27:42 li crond[733]: (CRON) INFO (running with inotify support) October 20 20:01:01 li CROND[1897]: (root) CMD (run-parts /etc/cron.hourly) October 20 21:01:01 li CROND[1922]: (root) CMD (run-parts /etc/cron.hourly) October 20 22:01:01 li CROND[1947]: (root) CMD (run-parts /etc/cron.hourly) October 20 23:01:01 li CROND[2037]: (root) CMD (run-parts /etc/cron.hourly) For more configuration file information, please Browse the manual page User use In order to make certain files run within these automatically defined times, all you need to do is to copy the script file to the relevant directory and make sure that it has x execution permission (chmod +x) . Therefore, you only need to let the system automatically run the script at one of these scheduled times, which makes the automation task very easy. Let's use cron.daily to illustrate the execution process of /etc/anacrontab: Anacron reads the /var/spool/anacron/cron.daily file, and the content of the file shows the time of the last execution. Compared with the current time, if the difference between the two times exceeds 1 day, the cron.daily job will be executed. This work can only be performed from 03:00-22:00. Check whether a file is executed after 5 minutes after booting. When the first one is executed, it will be randomly delayed for 0\uff5e45 minutes to execute the next one. Use the nice parameter to specify the default priority, and use the run-parts parameter to execute all executable files in the /etc/cron.daily/ directory. Related commands Use the command anacron , commonly used options are: Options Description -f Execute all jobs, ignoring timestamps -u Update the timestamp to the current time without performing any action -T Test the validity of the configuration file /etc/anacrontab For more help information, please Browse the manual page","title":"anacron - Automating commands"},{"location":"guides/automation/anacron/#anacron-run-commands-regularly","text":"","title":"anacron- Run commands regularly"},{"location":"guides/automation/anacron/#prerequisites","text":"A machine running Rocky Linux. Know how to use your favorite editor to modify the configuration file (such as vim ) in the command line environment . Understand basic RPM package management","title":"Prerequisites"},{"location":"guides/automation/anacron/#assumption","text":"You have understood the basic knowledge of bash, python or other scripting/programming tools, and want to run the script automatically. You are logged in as the root user, or switch to root with su - root","title":"Assumption"},{"location":"guides/automation/anacron/#anacron-introduction","text":"anacron is used to run commands on a regular basis, and the operating frequency is defined in units of days. It is suitable for computers that do not run 24/7, such as laptops and desktops. Suppose you have a scheduled task (such as a backup script) to be run in the early morning of every day using crontab. When you fall asleep, your desktop/laptop is shut down. Your backup script will not be executed. However, if you use anacron, you can rest assured that the next time you turn on the desktop/laptop, the backup script will be executed. The appearance of anacron is not to replace crontab, but to complement crontab. Their relationship is as follows:","title":"Anacron Introduction"},{"location":"guides/automation/anacron/#anacron-configuration-file","text":"shell > rpm -ql cronie-anacron /etc/anacrontab /etc/cron.hourly/0anacron /usr/lib/.build-id /usr/lib/.build-id/0e /usr/lib/.build-id/0e/6b094fa55505597cb69dc5a6b7f5f30b04d40f /usr/sbin/anacron /usr/share/man/man5/anacrontab.5.gz /usr/share/man/man8/anacron.8.gz /var/spool/anacron /var/spool/anacron/cron.daily /var/spool/anacron/cron.monthly /var/spool/anacron/cron.weekly First check the default configuration file: shell > cat /etc/anacontab # /etc/anacrontab: configuration file for anacron # See anacron(8) and anacrontab(5) for details. SHELL=/bin/sh PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # Default 45 minutes delay for each specified job anacron random increase 0-45 minutes. RANDOM_DELAY=45 # Specify the scope of work time, represented here 3:00 ~ 22:00 START_HOURS_RANGE=3-22 # period in days delay in minutes job-identifier command # Boot every day to check whether the files in the directory /etc/cron.daily be executed in 5 minutes, if not executed today, then to the next 1 5 cron.daily nice run-parts /etc/cron.daily # Every 7 days within 25 minutes if the file check /etc/cron.weekly directory is executed after boot, if not executed within a week, it will be executed next 7 25 cron.weekly nice run-parts /etc/cron.weekly # Whether the files in the directory /etc/cron.monthly 45 minutes checking is performed after every start for a month @monthly 45 cron.monthly nice run-parts /etc/cron.monthly /etc/cron.hourly/ -Through journalctl -u crond.service , you can know that the files put inside are actually called by crond.server, which means that the command will be executed after the first minute of every hour. As follows: shell > cat /etc/cron.d/0hourly # Run the hourly jobs SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root 01 * * * * root run-parts /etc/cron.hourly shell > journalctl -u crond.service - Logs begin at Wed 2021-10-20 19:27:39 CST, end at Wed 2021-10-20 23:32:42 CST. - October 20 19:27:42 li systemd[1]: Started Command Scheduler. October 20 19:27:42 li crond[733]: (CRON) STARTUP (1.5.2) October 20 19:27:42 li crond[733]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 76% if used.) October 20 19:27:42 li crond[733]: (CRON) INFO (running with inotify support) October 20 20:01:01 li CROND[1897]: (root) CMD (run-parts /etc/cron.hourly) October 20 21:01:01 li CROND[1922]: (root) CMD (run-parts /etc/cron.hourly) October 20 22:01:01 li CROND[1947]: (root) CMD (run-parts /etc/cron.hourly) October 20 23:01:01 li CROND[2037]: (root) CMD (run-parts /etc/cron.hourly) For more configuration file information, please Browse the manual page","title":"anacron configuration file"},{"location":"guides/automation/anacron/#user-use","text":"In order to make certain files run within these automatically defined times, all you need to do is to copy the script file to the relevant directory and make sure that it has x execution permission (chmod +x) . Therefore, you only need to let the system automatically run the script at one of these scheduled times, which makes the automation task very easy. Let's use cron.daily to illustrate the execution process of /etc/anacrontab: Anacron reads the /var/spool/anacron/cron.daily file, and the content of the file shows the time of the last execution. Compared with the current time, if the difference between the two times exceeds 1 day, the cron.daily job will be executed. This work can only be performed from 03:00-22:00. Check whether a file is executed after 5 minutes after booting. When the first one is executed, it will be randomly delayed for 0\uff5e45 minutes to execute the next one. Use the nice parameter to specify the default priority, and use the run-parts parameter to execute all executable files in the /etc/cron.daily/ directory.","title":"User use"},{"location":"guides/automation/anacron/#related-commands","text":"Use the command anacron , commonly used options are: Options Description -f Execute all jobs, ignoring timestamps -u Update the timestamp to the current time without performing any action -T Test the validity of the configuration file /etc/anacrontab For more help information, please Browse the manual page","title":"Related commands"},{"location":"guides/automation/cron_jobs_howto/","tags":["job automation","automation","cron"],"text":"Automating Processes with cron and crontab Prerequisites A machine running Rocky Linux Some comfort with modifying configuration files from the command-line using your favorite editor ( vi is used here) Assumptions Basic knowledge of bash, python, or other scripting/programming tools, and the desire to have a script run automatically That you are either running as the root user or have switched to root with sudo -s (You can run certain scripts in your own directories as your own user. In this case, switching to root is not necessary.) We assume that you're pretty cool. Introduction Linux provides the cron system, a time-based job scheduler, for automating processes. It's simple and yet quite powerful. Want a script or program to run every day at 5 PM? This is where you set that up. The crontab is essentially a list where users add their own automated tasks and jobs, and it has a number of options that can simplify things even further. This document will explore some of these. It's a good refresher for those with some experience, and new users can add the cron system to their repertoire. anacron is discussed briefly here in reference to the cron \"dot\" directories. anacron is run by cron , and is advantageous for machines that are not up all the time, such as workstations and laptops. The reason for this is that while cron runs jobs on a schedule, if the machine is off when the job is scheduled, the job does not run. With anacron the job is picked up and run when the machine is on again, even if the scheduled run was in the past. anacron though, uses a more randomized approach to running tasks where the timing is not exact. This makes sense for workstations and laptops, but not so much for servers. This can be a problem for things like server backups, for instance, that need to run at a specific time. That's where cron continues to provide the best solution for server administrators. All that being said, server administrators and workstation or laptop users can gain something from both approaches. You can easily mix and match based on your needs. For more information on anacron see anacron - Automating commands . Starting Easy - The cron Dot Directories Built into every Linux system for many versions now, the cron \"dot\" directories help to automate processes quickly. These show up as directories that the cron system calls based on their naming conventions. They are called differently, however, based on which process is assigned to call them, anacron or cron . The default behavior is to use anacron , but this can be changed by a server, workstation or laptop administrator. For Servers As stated in the introduction, cron normally runs anacron these days to execute scripts in these \"dot\" directories. You may , though, want to use these \"dot\" directories on servers as well, and if that is the case, then there are two steps that you can take to make sure that these \"dot\" directories are run on a strict schedule. To do so, we need to install a package and remove another one: dnf install cronie-noanacron and dnf remove cronie-anacron As you might expect, this removes anacron from the server and reverts to running tasks within the \"dot\" directories on a strict schedule. This is defined by this file: /etc/cron.d/dailyjobs , which has the following contents: # Run the daily, weekly, and monthly jobs if cronie-anacron is not installed SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # run-parts 02 4 * * * root [ ! -f /etc/cron.hourly/0anacron ] && run-parts /etc/cron.daily 22 4 * * 0 root [ ! -f /etc/cron.hourly/0anacron ] && run-parts /etc/cron.weekly 42 4 1 * * root [ ! -f /etc/cron.hourly/0anacron ] && run-parts /etc/cron.monthly This translates to the following: run scripts in cron.daily at 04:02:00 every day. run scripts in cron.weekly at 04:22:00 on Sunday every week. run scripts in cron.monthly at 04:42:00 on the first day of every month. For Workstations If you want to run scripts on a workstation or laptop in the cron \"dot\" directories, then there is nothing special that you need to do. Simply copy your script file into the directory in question, and make sure it is executable. Here are the directories: /etc/cron.hourly - Scripts placed here will run one minute past the hour every hour. (this is run by cron regardless of whether anacron is installed or not) /etc/cron.daily - Scripts placed here will run every day. anacron adjusts the timing of these. (see tip) /etc/cron.weekly - Scripts placed here will run every 7 days, based on the calendar day of the last run time. (see tip) /etc/cron.monthly - Scripts placed here will run monthly based on the calendar day of the last run time. (see tip) !!! tip These are likely to be run at similar (but not exactly the same) times every day, week, and month. For more exact running times, see the @options below. So provided you're alright with just letting the system auto-run your scripts, and allowing them to run sometime during the specified period, then it makes it very easy to automate tasks. !!! note There is no rule that says a server administrator cannot use the randomized run times which `anacron` uses to run scripts in the \"dot\" directories. The use case for this would be for a script that is not time sensitive. Create Your Own cron Of course, if the automated, randomized times don't work well in For Workstations above , and the scheduled times in the For Servers above , then you can create your own. In this example, we are assuming you are doing this as root. see Assumptions To do this, type the following: crontab -e This will pull up root user's crontab as it exists at this moment in your chosen editor, and may look something like this. Go ahead and read through this commented version, as it contains descriptions of each field that we will be using next: # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any'). # # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # cron # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command Notice that this particular crontab file has some of its own documentation built-in. That isn't always the case. When modifying a crontab on a container or minimalist operating system, the crontab will be an empty file unless an entry has already been placed in it. Let's assume that we have a backup script that we want to run at 10 PM at night. The crontab uses a 24 hour clock, so this would be 22:00. Let's assume that the backup script is called \"backup\" and that it is currently in the /usr/local/sbin directory. !!! note Remember that this script needs to also be executable (`chmod +x`) in order for the `cron` to run it. To add the job, we would: crontab -e crontab stands for \"cron table\" and the format of the file is, in fact, a loose table layout. Now that we are in the crontab , go to the bottom of the file and add your new entry. If you are using vi as your default system editor, then this is done with the following keys: Shift : $ Now that you are at the bottom of the file, insert a line and type a brief comment to describe what is going on with your entry. This is done by adding a \"#\" to the beginning of the line: # Backing up the system every night at 10PM Now hit enter. You should still be in the insert mode, so the next step is to add your entry. As shown in our empty commented crontab (above) this is m for minutes, h for hours, dom for day of month, mon for month, and dow for day of week. To run our backup script every day at 10:00, the entry would look like this: 00 22 * * * /usr/local/sbin/backup This says run the script at 10 PM, every day of the month, every month, and every day of the week. Obviously, this is a pretty simple example and things can get quite complicated when you need specifics. The @options for crontab Another way to run jobs at a strictly scheduled time (i.e., day, week, month, year, etc.) is to use the @options, which offer the ability to use more natural timing. The @options consist of: @hourly runs the script every hour of every day at 0 minutes past the hour. (this is exactly the result of placing your script in /etc/cron.hourly too) @daily runs the script every day at midnight. @weekly runs the script every week at midnight on Sunday. @monthly runs the script every month at midnight on the first day of the month. @yearly runs the script every year at midnight on the first day of January. @reboot runs the script on system startup only. !!! note Using these `crontab` entries bypasses the `anacron` system and reverts to the `crond.service` whether `anacron` is installed or not. For our backup script example, if we used use the @daily option to run the backup script at midnight, the entry would look like this: @daily /usr/local/sbin/backup More Complex Options So far, everything we have talked about has had pretty simple options, but what about the more complex task timings? Let's say that you want to run your backup script every 10 minutes during the day (probably not a very practical thing to do, but hey, this is an example!). To do this you would write: */10 * * * * /usr/local/sbin/backup What if you wanted to run the backup every 10 minutes, but only on Monday, Wednesday and Friday?: */10 * * * 1,3,5 /usr/local/sbin/backup What about every 10 minutes every day except Saturday and Sunday?: */10 * * * 1-5 /usr/local/sbin/backup In the table, the commas let you specify individual entries within a field, while the dash lets you specify a range of values within a field. This can happen in any of the fields, and on multiple fields at the same time. As you can see, things can get pretty complicated. When determining when to run a script, you need to take time and plan it out, particularly if the criteria are complex. Conclusions The cron/crontab system is a very powerful tool for the Rocky Linux systems administrator or desktop user. It can allow you to automate tasks and scripts so that you don't have to remember to run them manually. There are more examples provided here: For machines that are not on 24 hours a day, explore anacron - Automating commands . For a concise description of cron processes, check out cronie - Timed Tasks While the basics are pretty easy, you can get a lot more complex. For more information on crontab head up to the crontab manual page . On most systems, you can also enter man crontab for additional command details. You can also simply do a web search for \"crontab\" which will give you a wealth of results to help you fine-tune your crontab skills.","title":"cron - Automating Commands"},{"location":"guides/automation/cron_jobs_howto/#automating-processes-with-cron-and-crontab","text":"","title":"Automating Processes with cron and crontab"},{"location":"guides/automation/cron_jobs_howto/#prerequisites","text":"A machine running Rocky Linux Some comfort with modifying configuration files from the command-line using your favorite editor ( vi is used here)","title":"Prerequisites"},{"location":"guides/automation/cron_jobs_howto/#assumptions","text":"Basic knowledge of bash, python, or other scripting/programming tools, and the desire to have a script run automatically That you are either running as the root user or have switched to root with sudo -s (You can run certain scripts in your own directories as your own user. In this case, switching to root is not necessary.) We assume that you're pretty cool.","title":" Assumptions"},{"location":"guides/automation/cron_jobs_howto/#introduction","text":"Linux provides the cron system, a time-based job scheduler, for automating processes. It's simple and yet quite powerful. Want a script or program to run every day at 5 PM? This is where you set that up. The crontab is essentially a list where users add their own automated tasks and jobs, and it has a number of options that can simplify things even further. This document will explore some of these. It's a good refresher for those with some experience, and new users can add the cron system to their repertoire. anacron is discussed briefly here in reference to the cron \"dot\" directories. anacron is run by cron , and is advantageous for machines that are not up all the time, such as workstations and laptops. The reason for this is that while cron runs jobs on a schedule, if the machine is off when the job is scheduled, the job does not run. With anacron the job is picked up and run when the machine is on again, even if the scheduled run was in the past. anacron though, uses a more randomized approach to running tasks where the timing is not exact. This makes sense for workstations and laptops, but not so much for servers. This can be a problem for things like server backups, for instance, that need to run at a specific time. That's where cron continues to provide the best solution for server administrators. All that being said, server administrators and workstation or laptop users can gain something from both approaches. You can easily mix and match based on your needs. For more information on anacron see anacron - Automating commands .","title":"Introduction"},{"location":"guides/automation/cron_jobs_howto/#starting-easy-the-cron-dot-directories","text":"Built into every Linux system for many versions now, the cron \"dot\" directories help to automate processes quickly. These show up as directories that the cron system calls based on their naming conventions. They are called differently, however, based on which process is assigned to call them, anacron or cron . The default behavior is to use anacron , but this can be changed by a server, workstation or laptop administrator.","title":"Starting Easy - The cron Dot Directories"},{"location":"guides/automation/cron_jobs_howto/#for-servers","text":"As stated in the introduction, cron normally runs anacron these days to execute scripts in these \"dot\" directories. You may , though, want to use these \"dot\" directories on servers as well, and if that is the case, then there are two steps that you can take to make sure that these \"dot\" directories are run on a strict schedule. To do so, we need to install a package and remove another one: dnf install cronie-noanacron and dnf remove cronie-anacron As you might expect, this removes anacron from the server and reverts to running tasks within the \"dot\" directories on a strict schedule. This is defined by this file: /etc/cron.d/dailyjobs , which has the following contents: # Run the daily, weekly, and monthly jobs if cronie-anacron is not installed SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # run-parts 02 4 * * * root [ ! -f /etc/cron.hourly/0anacron ] && run-parts /etc/cron.daily 22 4 * * 0 root [ ! -f /etc/cron.hourly/0anacron ] && run-parts /etc/cron.weekly 42 4 1 * * root [ ! -f /etc/cron.hourly/0anacron ] && run-parts /etc/cron.monthly This translates to the following: run scripts in cron.daily at 04:02:00 every day. run scripts in cron.weekly at 04:22:00 on Sunday every week. run scripts in cron.monthly at 04:42:00 on the first day of every month.","title":"For Servers"},{"location":"guides/automation/cron_jobs_howto/#for-workstations","text":"If you want to run scripts on a workstation or laptop in the cron \"dot\" directories, then there is nothing special that you need to do. Simply copy your script file into the directory in question, and make sure it is executable. Here are the directories: /etc/cron.hourly - Scripts placed here will run one minute past the hour every hour. (this is run by cron regardless of whether anacron is installed or not) /etc/cron.daily - Scripts placed here will run every day. anacron adjusts the timing of these. (see tip) /etc/cron.weekly - Scripts placed here will run every 7 days, based on the calendar day of the last run time. (see tip) /etc/cron.monthly - Scripts placed here will run monthly based on the calendar day of the last run time. (see tip) !!! tip These are likely to be run at similar (but not exactly the same) times every day, week, and month. For more exact running times, see the @options below. So provided you're alright with just letting the system auto-run your scripts, and allowing them to run sometime during the specified period, then it makes it very easy to automate tasks. !!! note There is no rule that says a server administrator cannot use the randomized run times which `anacron` uses to run scripts in the \"dot\" directories. The use case for this would be for a script that is not time sensitive.","title":"For Workstations"},{"location":"guides/automation/cron_jobs_howto/#create-your-own-cron","text":"Of course, if the automated, randomized times don't work well in For Workstations above , and the scheduled times in the For Servers above , then you can create your own. In this example, we are assuming you are doing this as root. see Assumptions To do this, type the following: crontab -e This will pull up root user's crontab as it exists at this moment in your chosen editor, and may look something like this. Go ahead and read through this commented version, as it contains descriptions of each field that we will be using next: # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any'). # # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # cron # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command Notice that this particular crontab file has some of its own documentation built-in. That isn't always the case. When modifying a crontab on a container or minimalist operating system, the crontab will be an empty file unless an entry has already been placed in it. Let's assume that we have a backup script that we want to run at 10 PM at night. The crontab uses a 24 hour clock, so this would be 22:00. Let's assume that the backup script is called \"backup\" and that it is currently in the /usr/local/sbin directory. !!! note Remember that this script needs to also be executable (`chmod +x`) in order for the `cron` to run it. To add the job, we would: crontab -e crontab stands for \"cron table\" and the format of the file is, in fact, a loose table layout. Now that we are in the crontab , go to the bottom of the file and add your new entry. If you are using vi as your default system editor, then this is done with the following keys: Shift : $ Now that you are at the bottom of the file, insert a line and type a brief comment to describe what is going on with your entry. This is done by adding a \"#\" to the beginning of the line: # Backing up the system every night at 10PM Now hit enter. You should still be in the insert mode, so the next step is to add your entry. As shown in our empty commented crontab (above) this is m for minutes, h for hours, dom for day of month, mon for month, and dow for day of week. To run our backup script every day at 10:00, the entry would look like this: 00 22 * * * /usr/local/sbin/backup This says run the script at 10 PM, every day of the month, every month, and every day of the week. Obviously, this is a pretty simple example and things can get quite complicated when you need specifics.","title":"Create Your Own cron"},{"location":"guides/automation/cron_jobs_howto/#the-options-for-crontab","text":"Another way to run jobs at a strictly scheduled time (i.e., day, week, month, year, etc.) is to use the @options, which offer the ability to use more natural timing. The @options consist of: @hourly runs the script every hour of every day at 0 minutes past the hour. (this is exactly the result of placing your script in /etc/cron.hourly too) @daily runs the script every day at midnight. @weekly runs the script every week at midnight on Sunday. @monthly runs the script every month at midnight on the first day of the month. @yearly runs the script every year at midnight on the first day of January. @reboot runs the script on system startup only. !!! note Using these `crontab` entries bypasses the `anacron` system and reverts to the `crond.service` whether `anacron` is installed or not. For our backup script example, if we used use the @daily option to run the backup script at midnight, the entry would look like this: @daily /usr/local/sbin/backup","title":"The @options for crontab"},{"location":"guides/automation/cron_jobs_howto/#more-complex-options","text":"So far, everything we have talked about has had pretty simple options, but what about the more complex task timings? Let's say that you want to run your backup script every 10 minutes during the day (probably not a very practical thing to do, but hey, this is an example!). To do this you would write: */10 * * * * /usr/local/sbin/backup What if you wanted to run the backup every 10 minutes, but only on Monday, Wednesday and Friday?: */10 * * * 1,3,5 /usr/local/sbin/backup What about every 10 minutes every day except Saturday and Sunday?: */10 * * * 1-5 /usr/local/sbin/backup In the table, the commas let you specify individual entries within a field, while the dash lets you specify a range of values within a field. This can happen in any of the fields, and on multiple fields at the same time. As you can see, things can get pretty complicated. When determining when to run a script, you need to take time and plan it out, particularly if the criteria are complex.","title":"More Complex Options"},{"location":"guides/automation/cron_jobs_howto/#conclusions","text":"The cron/crontab system is a very powerful tool for the Rocky Linux systems administrator or desktop user. It can allow you to automate tasks and scripts so that you don't have to remember to run them manually. There are more examples provided here: For machines that are not on 24 hours a day, explore anacron - Automating commands . For a concise description of cron processes, check out cronie - Timed Tasks While the basics are pretty easy, you can get a lot more complex. For more information on crontab head up to the crontab manual page . On most systems, you can also enter man crontab for additional command details. You can also simply do a web search for \"crontab\" which will give you a wealth of results to help you fine-tune your crontab skills.","title":"Conclusions"},{"location":"guides/automation/cronie/","text":"Prerequisite A machine running Rocky Linux. Know how to use your favorite editor to modify the configuration file in the command line environment (this article will use vi ). You have understood the basic knowledge of bash, python or other scripting/programming tools, and expect to run the script automatically. You have connected to your machine via ssh (it can be root user or ordinary user with UID greater than 1000) We think you are a very cool person. cron introduction GNU/Linux provides the cron system, which is a time-based cron jobs program for automated processes. It is simple, but quite powerful. Want a script or program to run at 5 pm every day? cron can do it. There are different branches (or variants) of cron , which have the same functions. In this document, cronie is used, and the version is 1.5.2. You can click here to find the latest version and update log. cronie's description cronie -package name, Rocky Linux includes cronie by default; crontab -command to maintain crontab (task schedule) for each user; crond.service -cronie's daemon, you can manage the daemon by systemctl start | restart | stop | status ; /etc/crontab -Assign cron jobs to different users, usually we are more accustomed to using crontab -e . For example, if you are currently logged in as the root user, type crontab -e and you will see specific cron jobs in the file /var/spool/cron/root after saving. /var/log/cron * -Cronie's log, by default, does log rotation and ends with a date suffix. * Here means wildcard anacron -part of cronie . For more information about anacron , see anacron-automation commands . crontab command crontab is a command obtained after installation of the cronie package. Compared with anacron , it is more suitable for servers that work 7 * 24 hours a day. Common options of crontab are: -e # edit crontab scheduled tasks the -l # View crontab task -r # delete all the current user's crontab tasks Use of cronie To allow different users to execute different commands (or scripts) at different times, they can be written into this file. However, usually we are more accustomed to using crontab -e . shell > cat /etc/crontab SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0-59) # | .------------- hour (0-23) # | | .---------- day of month (1-31) # | | | .------- month (1-12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0-6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed Parameter Meaning Value Range The 1st* The first minute of the hour 0-59 The 2nd* Hour of the day 0-23 The 3rd* Day of the month 1-31 The 4th* The month of the year 1-12 The 5th* Day of the week 0-7 (0 and 7 both indicate Sunday) In this example, assuming you are performing this operation as the root user, type the following: crontab -e , this will bring up the timed tasks of the root user, if you use vi as the default system editor, press i key to enter the insert mode, enter the following content, # means this is a line of comment. Press Esc to exit insert mode, enter: wq (displayed at the bottom) to save and exit vi , which means to run the script once every night at 22:00. Obviously, this is a very simple example, and the situation can become very complicated when you need to elaborate. # Nightly 10:00 backup system 00 22 * * * /usr/local/sbin/backup !!! tip \"Attention\" The script needs to have execute permission (`chmod +x`) before cronie can run it. Complex options So far, the content discussed are very simple options, but how to complete more complex timed tasks? # Suppose you want to run every 10 minutes backup script (may be impractical, however, it is only an example!) Throughout the day. To this end, the following will be written: * /10 * * * * /usr/local/sbin/backup #What if you only want to run a backup every 10 minutes on Monday, Wednesday, and Friday? : * /10 * * * 1,3,5 /usr/local/sbin/backup # In addition to Saturdays and Sundays, once every 10 minutes, every day, how to back up? * /10 * * * 1-5 /usr/local/sbin/backup Special Symbols Meaning * represents any time. For example, the first * means any minute, and the second * means any hour , stands for discontinuous time, such as \"0 8,12,16 * * * \", which means that the command will be executed once every day at 8:00, 12:00, and 16:00 - represents a continuous time range, such as \"0 5 * * 1-6 \", which means that a command will be executed at five o'clock in the morning every day from Monday to Saturday */n Represents how often the interval is executed, such as \" /10 * * *\" means that it is executed every 10 minutes !!! tip \"Attention\" The smallest time unit that cronie can recognize is 1 minute; when using, for example, `30 4 1,15 * 5 command` , it will cause the command to run on the 1st and 15th of each month and 4:30 in the morning of every Friday ; The output information of some scripts or commands will prevent the execution of timed tasks, and output redirection is required, such as this- `*/10 * * * * /usr/local/sbin/backup &> /dev/null` Q & A /etc/crontab and crontab -e , is there any difference between the two methods? crontab -e does not need to specify a user (the currently logged-in user is used by default), while /etc/crontab needs to specify a user. What should I do if the specified command or script is not executed correctly? Check the /var/log/cron* file, use journalctl -u crond.service to check the information about the daemon process, whether the script has x permission, etc., for troubleshooting. In addition to cronie, what cron variants are there? dcron , the latest version is 4.5 (2011-50-01). fcron , the latest version is 3.3.0 (dev, 2016-08-14). bcron , the latest version is 0.11 (2015-08-12). cronsun , the latest version 0.3.5 (2018-11-20). Summary For Rocky Linux desktop users or system administrators, cronie is a very powerful tool. It allows you to automate tasks and scripts so you don't have to remember to run them manually. Although the basic knowledge is simple, the actual task may be complex. For more information about crontab , please visit crontab man page . You can also simply search for \"crontab\" on the Internet, which will provide you with a large number of search results and help you fine-tune the crontab expression.","title":"cronie - Timed Tasks"},{"location":"guides/automation/cronie/#prerequisite","text":"A machine running Rocky Linux. Know how to use your favorite editor to modify the configuration file in the command line environment (this article will use vi ). You have understood the basic knowledge of bash, python or other scripting/programming tools, and expect to run the script automatically. You have connected to your machine via ssh (it can be root user or ordinary user with UID greater than 1000) We think you are a very cool person.","title":"Prerequisite"},{"location":"guides/automation/cronie/#cron-introduction","text":"GNU/Linux provides the cron system, which is a time-based cron jobs program for automated processes. It is simple, but quite powerful. Want a script or program to run at 5 pm every day? cron can do it. There are different branches (or variants) of cron , which have the same functions. In this document, cronie is used, and the version is 1.5.2. You can click here to find the latest version and update log.","title":"cron introduction"},{"location":"guides/automation/cronie/#cronies-description","text":"cronie -package name, Rocky Linux includes cronie by default; crontab -command to maintain crontab (task schedule) for each user; crond.service -cronie's daemon, you can manage the daemon by systemctl start | restart | stop | status ; /etc/crontab -Assign cron jobs to different users, usually we are more accustomed to using crontab -e . For example, if you are currently logged in as the root user, type crontab -e and you will see specific cron jobs in the file /var/spool/cron/root after saving. /var/log/cron * -Cronie's log, by default, does log rotation and ends with a date suffix. * Here means wildcard anacron -part of cronie . For more information about anacron , see anacron-automation commands .","title":"cronie's description"},{"location":"guides/automation/cronie/#crontab-command","text":"crontab is a command obtained after installation of the cronie package. Compared with anacron , it is more suitable for servers that work 7 * 24 hours a day. Common options of crontab are: -e # edit crontab scheduled tasks the -l # View crontab task -r # delete all the current user's crontab tasks","title":"crontab command"},{"location":"guides/automation/cronie/#use-of-cronie","text":"To allow different users to execute different commands (or scripts) at different times, they can be written into this file. However, usually we are more accustomed to using crontab -e . shell > cat /etc/crontab SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0-59) # | .------------- hour (0-23) # | | .---------- day of month (1-31) # | | | .------- month (1-12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0-6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed Parameter Meaning Value Range The 1st* The first minute of the hour 0-59 The 2nd* Hour of the day 0-23 The 3rd* Day of the month 1-31 The 4th* The month of the year 1-12 The 5th* Day of the week 0-7 (0 and 7 both indicate Sunday) In this example, assuming you are performing this operation as the root user, type the following: crontab -e , this will bring up the timed tasks of the root user, if you use vi as the default system editor, press i key to enter the insert mode, enter the following content, # means this is a line of comment. Press Esc to exit insert mode, enter: wq (displayed at the bottom) to save and exit vi , which means to run the script once every night at 22:00. Obviously, this is a very simple example, and the situation can become very complicated when you need to elaborate. # Nightly 10:00 backup system 00 22 * * * /usr/local/sbin/backup !!! tip \"Attention\" The script needs to have execute permission (`chmod +x`) before cronie can run it.","title":"Use of cronie"},{"location":"guides/automation/cronie/#complex-options","text":"So far, the content discussed are very simple options, but how to complete more complex timed tasks? # Suppose you want to run every 10 minutes backup script (may be impractical, however, it is only an example!) Throughout the day. To this end, the following will be written: * /10 * * * * /usr/local/sbin/backup #What if you only want to run a backup every 10 minutes on Monday, Wednesday, and Friday? : * /10 * * * 1,3,5 /usr/local/sbin/backup # In addition to Saturdays and Sundays, once every 10 minutes, every day, how to back up? * /10 * * * 1-5 /usr/local/sbin/backup Special Symbols Meaning * represents any time. For example, the first * means any minute, and the second * means any hour , stands for discontinuous time, such as \"0 8,12,16 * * * \", which means that the command will be executed once every day at 8:00, 12:00, and 16:00 - represents a continuous time range, such as \"0 5 * * 1-6 \", which means that a command will be executed at five o'clock in the morning every day from Monday to Saturday */n Represents how often the interval is executed, such as \" /10 * * *\" means that it is executed every 10 minutes !!! tip \"Attention\" The smallest time unit that cronie can recognize is 1 minute; when using, for example, `30 4 1,15 * 5 command` , it will cause the command to run on the 1st and 15th of each month and 4:30 in the morning of every Friday ; The output information of some scripts or commands will prevent the execution of timed tasks, and output redirection is required, such as this- `*/10 * * * * /usr/local/sbin/backup &> /dev/null`","title":"Complex options"},{"location":"guides/automation/cronie/#q-a","text":"/etc/crontab and crontab -e , is there any difference between the two methods? crontab -e does not need to specify a user (the currently logged-in user is used by default), while /etc/crontab needs to specify a user. What should I do if the specified command or script is not executed correctly? Check the /var/log/cron* file, use journalctl -u crond.service to check the information about the daemon process, whether the script has x permission, etc., for troubleshooting. In addition to cronie, what cron variants are there? dcron , the latest version is 4.5 (2011-50-01). fcron , the latest version is 3.3.0 (dev, 2016-08-14). bcron , the latest version is 0.11 (2015-08-12). cronsun , the latest version 0.3.5 (2018-11-20).","title":"Q &amp; A"},{"location":"guides/automation/cronie/#summary","text":"For Rocky Linux desktop users or system administrators, cronie is a very powerful tool. It allows you to automate tasks and scripts so you don't have to remember to run them manually. Although the basic knowledge is simple, the actual task may be complex. For more information about crontab , please visit crontab man page . You can also simply search for \"crontab\" on the Internet, which will provide you with a large number of search results and help you fine-tune the crontab expression.","title":"Summary"},{"location":"guides/automation/olivetin/","tags":["automation","web","bash"],"text":"How to Install & Use OliveTin on Rocky Linux Introduction Have you ever gotten tired of typing in the same CLI commands over and over again? Have you ever wanted everyone else in your house to be able to restart the Plex server without your intervention? Do you want to just type in a name in a web panel, push a button, and watch a customized Docker/LXD container magically appear? Then you might want to check out OliveTin. OliveTin is literally just an app that lets you generate a web page from a config file, and that web page has buttons. Push the buttons, and OliveTin will run preset bash commands that you set up yourself. Sure, you could technically create something like this yourself, from scratch, with enough programming experience... but this is way easier. It looks a little something like this when set up (image courtesy of the OliveTin repository ): !!! Warning \"NEVER run this app on a public server\" This app is, by design and the creator's own admission, meant to be used on local networks, *maybe* on dev setups. However, it has no user authentication system at present, and (until the developer fixes this) *runs as root by default*. So yeah, use this all you want on a secured and firewalled network. *Don't* put it on anything meant to be used by the public. For now. Prerequisites and assumptions To follow this guide you will need: A machine running Rocky Linux A minimal amount of comfort/experience with the command line. Root access, or the ability to use sudo . To learn the very basics of YAML. It's not hard; you'll get the hang of it down below. Installing OliveTin So this is the crazy easy part: OliveTin comes with pre-built RPMs. Just download the latest release here for your architecture, and install it. If you're following this guide on a workstation with a graphical desktop, just download the file and double click on it in your file manager of choice. If you're installing this app on a server, then you can download it on your work machine and upload it via SSH/SCP/SFTP, or do the thing some people say not to do, and download it with wget . e.g. wget https://github.com/OliveTin/OliveTin/releases/download/2022-04-07/OliveTin_2022-04-07_linux_amd64.rpm Then install the app with (again, for example): sudo rpm -i OliveTin_2022-04-07_linux_amd64.rpm Now OliveTin can run as a normal systemd service, but don't enable it just yet. You need to set up your configuration file first. !!! Note After some testing, I have determined that these same install instructions will work just fine in a Rocky Linux LXD container. For anyone who likes Docker, pre-built images are available. Configuring OliveTin Actions OliveTin can do anything bash can do, and more. You can use it to execute apps with CLI options, run bash scripts, restart services, etc. To get started, open up the configuration file with the text editor of your choice with root/sudo: sudo nano /etc/OliveTin/config.yaml The most basic kind of action is a simple button; you click it, and the command is run on the host machine. You can define it in the YAML file like so: actions: - title: Restart Nginx shell: systemctl restart nginx You can also add custom icons to every action like with unicode emoji: actions: - title: Restart Nginx icon: \"&#1F504\" shell: systemctl restart nginx I'm not going to go into every detail of the customization options, but you can also use text inputs and dropdown menus to add variables and options to the commands you want to run. If you do, OliveTin will prompt you for input before the command is run. Doing this, you can run any program, control remote machines via SSH, trigger webhooks, and more. Check out the official documentation for more ideas. But here's an example of my own: I have a personal script that I use to generate LXD containers with web servers pre-installed on them. With OliveTin, I was able to quickly make a GUI for said script like this: actions: - title: Build Container shell: sh /home/ezequiel/server-scripts/rocky-host/buildcontainer -c {{ containerName }} -d {{ domainName }} {{ softwarePackage }} timeout: 60 arguments: - name: containerName title: Container Name type: ascii_identifier - name: domainName title: Domain type: ascii_identifier - name: softwarePackage title: Default Software choices: - title: None value: - title: Nginx value: -s nginx - title: Nginx & PHP value: -s nginx-php - title: mariadb value: -s mariadb On the front end, that looks like this (and yes, OliveTin has a dark mode, and I really need to change that icon): Enabling OliveTin Once you have your config file built the way you want it, just enable and start OliveTin with: sudo systemctl enable --now OliveTin Every time you edit the configuration file, you'll need to restart the service in the usual way: sudo systemctl restart OliveTin Conclusion OliveTin is a pretty great way to run everything from simple bash commands to some fairly complex operations via scripts. Keep in mind, though, that everything runs as root by default, unless you use su/sudo in your shell commands to change the user for that particular command. As such, you should be careful how you set this whole thing up, especially if you plan to give access to (for example) your family, to control home servers and appliances, etc. And again, don't put this on a public server unless you're ready to try and secure the page yourself. Otherwise, have fun with it. It's a neat little tool.","title":"OliveTin"},{"location":"guides/automation/olivetin/#how-to-install-use-olivetin-on-rocky-linux","text":"","title":"How to Install &amp; Use OliveTin on Rocky Linux"},{"location":"guides/automation/olivetin/#introduction","text":"Have you ever gotten tired of typing in the same CLI commands over and over again? Have you ever wanted everyone else in your house to be able to restart the Plex server without your intervention? Do you want to just type in a name in a web panel, push a button, and watch a customized Docker/LXD container magically appear? Then you might want to check out OliveTin. OliveTin is literally just an app that lets you generate a web page from a config file, and that web page has buttons. Push the buttons, and OliveTin will run preset bash commands that you set up yourself. Sure, you could technically create something like this yourself, from scratch, with enough programming experience... but this is way easier. It looks a little something like this when set up (image courtesy of the OliveTin repository ): !!! Warning \"NEVER run this app on a public server\" This app is, by design and the creator's own admission, meant to be used on local networks, *maybe* on dev setups. However, it has no user authentication system at present, and (until the developer fixes this) *runs as root by default*. So yeah, use this all you want on a secured and firewalled network. *Don't* put it on anything meant to be used by the public. For now.","title":"Introduction"},{"location":"guides/automation/olivetin/#prerequisites-and-assumptions","text":"To follow this guide you will need: A machine running Rocky Linux A minimal amount of comfort/experience with the command line. Root access, or the ability to use sudo . To learn the very basics of YAML. It's not hard; you'll get the hang of it down below.","title":"Prerequisites and assumptions"},{"location":"guides/automation/olivetin/#installing-olivetin","text":"So this is the crazy easy part: OliveTin comes with pre-built RPMs. Just download the latest release here for your architecture, and install it. If you're following this guide on a workstation with a graphical desktop, just download the file and double click on it in your file manager of choice. If you're installing this app on a server, then you can download it on your work machine and upload it via SSH/SCP/SFTP, or do the thing some people say not to do, and download it with wget . e.g. wget https://github.com/OliveTin/OliveTin/releases/download/2022-04-07/OliveTin_2022-04-07_linux_amd64.rpm Then install the app with (again, for example): sudo rpm -i OliveTin_2022-04-07_linux_amd64.rpm Now OliveTin can run as a normal systemd service, but don't enable it just yet. You need to set up your configuration file first. !!! Note After some testing, I have determined that these same install instructions will work just fine in a Rocky Linux LXD container. For anyone who likes Docker, pre-built images are available.","title":"Installing OliveTin"},{"location":"guides/automation/olivetin/#configuring-olivetin-actions","text":"OliveTin can do anything bash can do, and more. You can use it to execute apps with CLI options, run bash scripts, restart services, etc. To get started, open up the configuration file with the text editor of your choice with root/sudo: sudo nano /etc/OliveTin/config.yaml The most basic kind of action is a simple button; you click it, and the command is run on the host machine. You can define it in the YAML file like so: actions: - title: Restart Nginx shell: systemctl restart nginx You can also add custom icons to every action like with unicode emoji: actions: - title: Restart Nginx icon: \"&#1F504\" shell: systemctl restart nginx I'm not going to go into every detail of the customization options, but you can also use text inputs and dropdown menus to add variables and options to the commands you want to run. If you do, OliveTin will prompt you for input before the command is run. Doing this, you can run any program, control remote machines via SSH, trigger webhooks, and more. Check out the official documentation for more ideas. But here's an example of my own: I have a personal script that I use to generate LXD containers with web servers pre-installed on them. With OliveTin, I was able to quickly make a GUI for said script like this: actions: - title: Build Container shell: sh /home/ezequiel/server-scripts/rocky-host/buildcontainer -c {{ containerName }} -d {{ domainName }} {{ softwarePackage }} timeout: 60 arguments: - name: containerName title: Container Name type: ascii_identifier - name: domainName title: Domain type: ascii_identifier - name: softwarePackage title: Default Software choices: - title: None value: - title: Nginx value: -s nginx - title: Nginx & PHP value: -s nginx-php - title: mariadb value: -s mariadb On the front end, that looks like this (and yes, OliveTin has a dark mode, and I really need to change that icon):","title":"Configuring OliveTin Actions"},{"location":"guides/automation/olivetin/#enabling-olivetin","text":"Once you have your config file built the way you want it, just enable and start OliveTin with: sudo systemctl enable --now OliveTin Every time you edit the configuration file, you'll need to restart the service in the usual way: sudo systemctl restart OliveTin","title":"Enabling OliveTin"},{"location":"guides/automation/olivetin/#conclusion","text":"OliveTin is a pretty great way to run everything from simple bash commands to some fairly complex operations via scripts. Keep in mind, though, that everything runs as root by default, unless you use su/sudo in your shell commands to change the user for that particular command. As such, you should be careful how you set this whole thing up, especially if you plan to give access to (for example) your family, to control home servers and appliances, etc. And again, don't put this on a public server unless you're ready to try and secure the page yourself. Otherwise, have fun with it. It's a neat little tool.","title":"Conclusion"},{"location":"guides/automation/templates-automation-packer-vsphere/","text":"Automatic template creation with Packer and deployment with Ansible in a VMware vSphere environment Knowledge : :star: :star: :star: Complexity : :star: :star: :star: Reading time : 30 minutes Prerequisites, Assumptions, and General Notes A vSphere environment available, and a user with granted access An internal web server to store files Web access to the Rocky Linux repositories An Ansible environment available It is assumed that you have some knowledge on each product mentioned. If not, dig into that documentation before you begin. Vagrant is not in use here. It was pointed out that with Vagrant, an SSH key that was not self-signed would be provided. If you want to dig into that you can do so, but it is not covered in this document. Introduction This document covers the vSphere virtual machine template creation with Packer and how to deploy the artifact as new virtual machines with Ansible. Possible adjustments Of course, you can adapt this how-to for other hypervisors. You can also choose not to convert the virtual machine into a template, in this case you will use Packer to deploy each new VM, which is still quite feasible (an installation starting from 0 takes less than 10 minutes without human interaction). Packer Packer is a Hashicorp tool to automate the creation of a virtual machine. You can have a look at these resources for additional information: The Packer website Packer documentation The builder vsphere-iso 's documentation You can start by downloading the binaries for you own platform with Packer downloads . You will also need an iso copy of Rocky Linux. Although I'm using the minimal ISO image here, you could choose to use the DVD image (much bigger and perhaps too big) or the boot image (much smaller and perhaps too small). This choice is up to you. It impacts in particular the bandwidth you will need for the installation, and thus the provisioning time. We will discuss next the impact of the default choice and how to remedy it. It is assumed that you are on Linux to perform the following tasks. As we will connect to a VMware vCenter Server to send our commands via Packer, we need to store our credentials outside the configuration files that we will create next. Let's create a hidden file with our credentials in our home directory. This is a json file: $ vim .vsphere-secrets.json { \"vcenter_username\": \"rockstar\", \"vcenter_password\": \"mysecurepassword\" } Those credentials needs some grant access to your vSphere environment. Let's create a json file (in the future, the format of this file will change to the HCL): { \"variables\": { \"version\": \"0.0.X\", \"HTTP_IP\": \"fileserver.rockylinux.lan\", \"HTTP_PATH\": \"/packer/rockylinux/8/ks.cfg\" }, \"sensitive-variables\": [\"vcenter_password\"], \"provisioners\": [ { \"type\": \"shell\", \"expect_disconnect\": true, \"execute_command\": \"bash '{{.Path}}'\", \"script\": \"{{template_dir}}/scripts/requirements.sh\" } ], \"builders\": [ { \"type\": \"vsphere-iso\", \"CPUs\": 2, \"CPU_hot_plug\": true, \"RAM\": 2048, \"RAM_hot_plug\": true, \"disk_controller_type\": \"pvscsi\", \"guest_os_type\": \"centos8_64Guest\", \"iso_paths\": [ \"[datasyno-contentlibrary-mylib] contentlib-a86ad29a-a43b-4717-97e6-593b8358801b/3a381c78-b9df-45a6-82e1-3c07c8187dbe/Rocky-8.4-x86_64-minimal_72cc0cc6-9d0f-4c68-9bcd-06385a506a5d.iso\" ], \"network_adapters\": [ { \"network_card\": \"vmxnet3\", \"network\": \"net_infra\" } ], \"storage\": [ { \"disk_size\": 40000, \"disk_thin_provisioned\": true } ], \"boot_command\": [ \"<up><tab> text ip=192.168.1.11::192.168.1.254:255.255.255.0:template:ens192:none nameserver=192.168.1.254 inst.ks=http://{{ user `HTTP_IP` }}/{{ user `HTTP_PATH` }}<enter><wait><enter>\" ], \"ssh_password\": \"mysecurepassword\", \"ssh_username\": \"root\", \"shutdown_command\": \"/sbin/halt -h -p\", \"insecure_connection\": \"true\", \"username\": \"{{ user `vcenter_username` }}\", \"password\": \"{{ user `vcenter_password` }}\", \"vcenter_server\": \"vsphere.rockylinux.lan\", \"datacenter\": \"DC_NAME\", \"datastore\": \"DS_NAME\", \"vm_name\": \"template-rockylinux8-{{ user `version` }}\", \"folder\": \"Templates/RockyLinux\", \"cluster\": \"CLUSTER_NAME\", \"host\": \"esx1.rockylinux.lan\", \"notes\": \"Template RockyLinux version {{ user `version` }}\", \"convert_to_template\": true, \"create_snapshot\": false } ] } Next, we will describe each section of this file. Variables section In a first step, we declare variables, mainly for the sake of readability: \"variables\": { \"version\": \"0.0.X\", \"HTTP_IP\": \"fileserver.rockylinux.lan\", \"HTTP_PATH\": \"/packer/rockylinux/8/ks.cfg\" }, We will use the variable version later in the template name we will create. You can easily increment this value to suit your needs. We will also need our booting virtual machine to access a ks.cfg (Kickstart) file. A Kickstart file contains the answers to the questions asked during the installation process. This file passes all its contents to Anaconda (the installation process), which allows you to fully automate the creation of the template. The author likes to store his ks.cfg file in an internal web server accessible from his template, but other possibilities exists that you may chose to use instead. For example, the ks.cfg file is accessible from the VM at this url in our lab: http://fileserver.rockylinux.lan/packer/rockylinux/8/ks.cfg. You would need to set up something similar to use this method. Since we want to keep our password private, It is declared as a sensitive variable. Example: \"sensitive-variables\": [\"vcenter_password\"], Provisioners section Next part is interesting, and will be covered later by providing you the script for requirements.sh : \"provisioners\": [ { \"type\": \"shell\", \"expect_disconnect\": true, \"execute_command\": \"bash '{{.Path}}'\", \"script\": \"{{template_dir}}/scripts/requirements.sh\" } ], After the installation is finished, the VM will reboot. As soon as Packer detects an IP address (thanks to the VMware Tools), it will copy the requirements.sh and execute it. It's a nice feature to clean the VM after the installation process (remove SSH keys, clean the history, etc.) and install some extra package. The builders section You can declare one or more builders to target something other than your vSphere environment (perhaps a Vagrant template). But here we are using the vsphere-iso builder: \"builders\": [ { \"type\": \"vsphere-iso\", This builder lets us configure the hardware we need: \"CPUs\": 2, \"CPU_hot_plug\": true, \"RAM\": 2048, \"RAM_hot_plug\": true, \"disk_controller_type\": \"pvscsi\", \"guest_os_type\": \"centos8_64Guest\", \"network_adapters\": [ { \"network_card\": \"vmxnet3\", \"network\": \"net_infra\" } ], \"storage\": [ { \"disk_size\": 40000, \"disk_thin_provisioned\": true } ], !!! Note You will never forget again to include CPU_hot_plug as it is automatic now! You can do more cool thing with the disk, cpu, etc. You should refer to the documentation if you are interested in making other adjustments. To start the installation, you need an ISO image of Rocky Linux. Here is an example of how to use an image located in a vSphere content library. You can of course store the ISO elsewhere, but in the case of a vSphere content library, you have to get the full path to the ISO file on the server hosting the Content Library (in this case it is a Synology, so directly on the DSM explorer). \"iso_paths\": [ \"[datasyno-contentlibrary-mylib] contentlib-a86ad29a-a43b-4717-97e6-593b8358801b/3a381c78-b9df-45a6-82e1-3c07c8187dbe/Rocky-8.4-x86_64-minimal_72cc0cc6-9d0f-4c68-9bcd-06385a506a5d.iso\" ], Then you have to provide the complete command to be entered during the installation process: configuration of the IP and transmission of the path to the Kickstart response file. !!! Note This example takes the most complex case: using a static IP. If you have a DHCP server available, the process will be much easier. This is the most amusing part of the procedure: I'm sure you'll go and admire the VMware console during the generation, just to see the automatic entry of the commands during the boot. \"boot_command\": [ \"<up><tab> text ip=192.168.1.11::192.168.1.254:255.255.255.0:template:ens192:none nameserver=192.168.1.254 inst.ks=http://{{ user `HTTP_IP` }}/{{ user `HTTP_PATH` }}<enter><wait><enter>\" ], After the first reboot, Packer will connect to your server by SSH. You can use the root user, or another user with sudo rights, but in any case, this user must correspond to the user that is defined in your ks.cfg file. \"ssh_password\": \"mysecurepassword\", \"ssh_username\": \"root\", At the end of the process, the VM must be stopped. It's a little bit more complicated with a non root user, but it's is well documented: \"shutdown_command\": \"/sbin/halt -h -p\", Next, we deal with the vSphere configuration. The only notable things here are the use of the variables defined at the beginning of the document in our home directory, as well as the insecure_connection option, because our vSphere uses a self-signed certificate (See note in Assumptions at the top of this document): \"insecure_connection\": \"true\", \"username\": \"{{ user `vcenter_username` }}\", \"password\": \"{{ user `vcenter_password` }}\", \"vcenter_server\": \"vsphere.rockylinux.lan\", \"datacenter\": \"DC_NAME\", \"datastore\": \"DS_NAME\", \"vm_name\": \"template-rockylinux8-{{ user `version` }}\", \"folder\": \"Templates/RockyLinux\", \"cluster\": \"CLUSTER_NAME\", \"host\": \"esx1.rockylinux.lan\", \"notes\": \"Template RockyLinux version {{ user `version` }}\" And finally, we will ask vSphere to convert our stopped VM to a template. At this stage, you could also elect to just use the VM as is (not converting it to a template). In this case, you can decide to take a snapshot instead: \"convert_to_template\": true, \"create_snapshot\": false, The ks.cfg file As noted above, we need to provide a Kicstart response file that will be used by Anaconda. Here's an example of that file: # Use CDROM installation media repo --name=\"AppStream\" --baseurl=\"http://download.rockylinux.org/pub/rocky/8.4/AppStream/x86_64/os/\" cdrom # Use text install text # Don't run the Setup Agent on first boot firstboot --disabled eula --agreed ignoredisk --only-use=sda # Keyboard layouts keyboard --vckeymap=us --xlayouts='us' # System language lang en_US.UTF-8 # Network information network --bootproto=static --device=ens192 --gateway=192.168.1.254 --ip=192.168.1.11 --nameserver=192.168.1.254,4.4.4.4 --netmask=255.255.255.0 --onboot=on --ipv6=auto --activate # Root password rootpw mysecurepassword # System services selinux --permissive firewall --enabled services --enabled=\"NetworkManager,sshd,chronyd\" # System timezone timezone Europe/Paris --isUtc # System booloader configuration bootloader --location=mbr --boot-drive=sda # Partition clearing information clearpart --all --initlabel --drives=sda # Disk partitionning information part /boot --fstype=\"xfs\" --ondisk=sda --size=512 part pv.01 --fstype=\"lvmpv\" --ondisk=sda --grow volgroup vg_root --pesize=4096 pv.01 logvol /home --fstype=\"xfs\" --size=5120 --name=lv_home --vgname=vg_root logvol /var --fstype=\"xfs\" --size=10240 --name=lv_var --vgname=vg_root logvol / --fstype=\"xfs\" --size=10240 --name=lv_root --vgname=vg_root logvol swap --fstype=\"swap\" --size=4092 --name=lv_swap --vgname=vg_root skipx reboot %packages --ignoremissing --excludedocs openssh-clients curl dnf-utils drpm net-tools open-vm-tools perl perl-File-Temp sudo vim wget python3 # unnecessary firmware -aic94xx-firmware -atmel-firmware -b43-openfwwf -bfa-firmware -ipw2100-firmware -ipw2200-firmware -ivtv-firmware -iwl*-firmware -libertas-usb8388-firmware -ql*-firmware -rt61pci-firmware -rt73usb-firmware -xorg-x11-drv-ati-firmware -zd1211-firmware -cockpit -quota -alsa-* -fprintd-pam -intltool -microcode_ctl %end %addon com_redhat_kdump --disable %end %post # Manage Ansible access groupadd -g 1001 ansible useradd -m -g 1001 -u 1001 ansible mkdir /home/ansible/.ssh echo -e \"<---- PAST YOUR PUBKEY HERE ---->\" > /home/ansible/.ssh/authorized_keys chown -R ansible:ansible /home/ansible/.ssh chmod 700 /home/ansible/.ssh chmod 600 /home/ansible/.ssh/authorized_keys echo \"ansible ALL=(ALL:ALL) NOPASSWD:ALL\" > /etc/sudoers.d/ansible chmod 440 /etc/sudoers.d/ansible systemctl enable vmtoolsd systemctl start vmtoolsd %end As we have chosen to use the minimal iso, instead of the Boot or DVD, not all required installation packages will be available. As Packer relies on VMware Tools to detect the end of the installation, and the open-vm-tools package is only available in the AppStream repos, we have to specify to the installation process that we want to use as source both the cdrom and this remote repo: !!! Note If you don't have access to the external repos, you can use either a mirror of the repo, a squid proxy, or the dvd. # Use CDROM installation media repo --name=\"AppStream\" --baseurl=\"http://download.rockylinux.org/pub/rocky/8.4/AppStream/x86_64/os/\" cdrom Let's jump to the network configuration, as once again, in this example we aren't using a DHCP server: # Network information network --bootproto=static --device=ens192 --gateway=192.168.1.254 --ip=192.168.1.11 --nameserver=192.168.1.254,4.4.4.4 --netmask=255.255.255.0 --onboot=on --ipv6=auto --activate Remember we specified the user to connect via SSH with to Packer at the end of the installation. This user and password must match: # Root password rootpw mysecurepassword !!! Warning You can use an insecure password here, as long as you make sure that this password will be changed immediately after the deployment of your VM, for example with Ansible. Here is the selected partition scheme. Much more complex things can be done. You can define a partition scheme that suits your needs, adapting it to the disk space defined in Packer, and which respects the security rules defined for your environment (dedicated partition for /tmp , etc.): # System booloader configuration bootloader --location=mbr --boot-drive=sda # Partition clearing information clearpart --all --initlabel --drives=sda # Disk partitionning information part /boot --fstype=\"xfs\" --ondisk=sda --size=512 part pv.01 --fstype=\"lvmpv\" --ondisk=sda --grow volgroup vg_root --pesize=4096 pv.01 logvol /home --fstype=\"xfs\" --size=5120 --name=lv_home --vgname=vg_root logvol /var --fstype=\"xfs\" --size=10240 --name=lv_var --vgname=vg_root logvol / --fstype=\"xfs\" --size=10240 --name=lv_root --vgname=vg_root logvol swap --fstype=\"swap\" --size=4092 --name=lv_swap --vgname=vg_root The next section concerns the packages that will be installed. A \"best practice\" is to limit the quantity of installed packages to only those you need, which limits the attack surface, especially in a server environment. !!! Note The author likes to limit the actions to be done in the installation process and to defer installing what is needed in the post installation script of Packer. So, in this case, we install only the minimum required packages. The openssh-clients package seems to be required for Packer to copy its scripts into the VM. The open-vm-tools is also needed by Packer to detect the end of the installation, this explains the addition of the AppStream repository. perl and perl-File-Temp will also be required by VMware Tools during the deployment part. This is a shame because it requires a lot of other dependent packages. python3 (3.6) will also be required in the future for Ansible to work (if you won't use Ansible or python, remove them!). %packages --ignoremissing --excludedocs openssh-clients open-vm-tools python3 perl perl-File-Temp curl dnf-utils drpm net-tools sudo vim wget You can not only add packages but also remove them. Since we control the environment in which our hardware will work, we can remove any of the firmware that will be useless to us: # unnecessary firmware -aic94xx-firmware -atmel-firmware ... The next part adds some users. It's interesting in our case to create an ansible user, without password but with a pubkey. This allows all of our new VMs to be accessible from our Ansible server to run the post-install actions: # Manage Ansible access groupadd -g 1001 ansible useradd -m -g 1001 -u 1001 ansible mkdir /home/ansible/.ssh echo -e \"<---- PAST YOUR PUBKEY HERE ---->\" > /home/ansible/.ssh/authorized_keys chown -R ansible:ansible /home/ansible/.ssh chmod 700 /home/ansible/.ssh chmod 600 /home/ansible/.ssh/authorized_keys echo \"ansible ALL=(ALL:ALL) NOPASSWD:ALL\" > /etc/sudoers.d/ansible chmod 440 /etc/sudoers.d/ansible Now we need to enable and start vmtoolsd (the process that manages open-vm-tools). vSphere will detect the IP address after the reboot of the VM. systemctl enable vmtoolsd systemctl start vmtoolsd The installation process is finished and the VM will reboot. The provisioners Remember, we declared in Packer a provisioner, which in our case corresponds to a .sh script, to be stored in a subdirectory next to our json file. There are different types of provisioners, we could also have used Ansible. You are free to explore these possibilities. This file can be completely changed, but this provides an example of what can be done with a script, in this case requirements.sh : #!/bin/sh -eux echo \"Updating the system...\" dnf -y update echo \"Installing cloud-init...\" dnf -y install cloud-init # see https://bugs.launchpad.net/cloud-init/+bug/1712680 # and https://kb.vmware.com/s/article/71264 # Virtual Machine customized with cloud-init is set to DHCP after reboot echo \"manual_cache_clean: True \" > /etc/cloud/cloud.cfg.d/99-manual.cfg echo \"Disable NetworkManager-wait-online.service\" systemctl disable NetworkManager-wait-online.service # cleanup current SSH keys so templated VMs get fresh key rm -f /etc/ssh/ssh_host_* # Avoid ~200 meg firmware package we don't need # this cannot be done in the KS file so we do it here echo \"Removing extra firmware packages\" dnf -y remove linux-firmware dnf -y autoremove echo \"Remove previous kernels that preserved for rollbacks\" dnf -y remove -y $(dnf repoquery --installonly --latest-limit=-1 -q) dnf -y clean all --enablerepo=\\*; echo \"truncate any logs that have built up during the install\" find /var/log -type f -exec truncate --size=0 {} \\; echo \"remove the install log\" rm -f /root/anaconda-ks.cfg /root/original-ks.cfg echo \"remove the contents of /tmp and /var/tmp\" rm -rf /tmp/* /var/tmp/* echo \"Force a new random seed to be generated\" rm -f /var/lib/systemd/random-seed echo \"Wipe netplan machine-id (DUID) so machines get unique ID generated on boot\" truncate -s 0 /etc/machine-id echo \"Clear the history so our install commands aren't there\" rm -f /root/.wget-hsts export HISTSIZE=0 Some explanations are necessary: echo \"Installing cloud-init...\" dnf -y install cloud-init # see https://bugs.launchpad.net/cloud-init/+bug/1712680 # and https://kb.vmware.com/s/article/71264 # Virtual Machine customized with cloud-init is set to DHCP after reboot echo \"manual_cache_clean: True\" > /etc/cloud/cloud.cfg.d/99-manual.cfg Since vSphere now uses cloud-init via the VMware Tools to configure the network of a centos8 guest machine, it must be installed. However, if you do nothing, the configuration will be applied on the first reboot and everything will be fine. But on the next reboot, cloud-init will not receive any new information from vSphere. In these cases, without information about what to do, cloud-init will reconfigure the VM's network interface to use DHCP, and you will loose your static configuration. As this is not the behavior we want, we need to specify to cloud-init not to delete its cache automatically, and therefore to reuse the configuration information it received during its first reboot and each reboot after that. For this, we create a file /etc/cloud/cloud.cfg.d/99-manual.cfg with the manual_cache_clean: True directive. !!! Note This implies that if you need to re-apply a network configuration via vSphere guest customizations (which, in normal use, should be quite rare), you will have to delete the cloud-init cache yourself. The rest of the script is commented and does not require more details You can check the Bento project to get more ideas of what can be done in this part of the automation process. Template creation Now it's time to launch Packer and check that the creation process, which is completely automatic, works well. Simply enter this at the command line: ./packer build -var-file=~/.vsphere-secrets.json rockylinux8/template.json You can quickly go to vSphere and admire the work. You will see the machine being created, started, and if you launch a console, you will see the automatic entry of commands and the installation process. At the end of the creation, you will find your template ready to use in vSphere. Deployment part This documentation would not be complete without the automatic deployment part of the template. For this, we will use a simple Ansible playbook, which uses the vmware_guest module. This playbook that we provide you, must be adapted to your needs and your way of doing things. --- - name: Deploy VM from template hosts: localhost gather_facts: no vars_files: - ./vars/credentials.yml tasks: - name: Clone the template vmware_guest: hostname: \"{{ vmware_vcenter_hostname }}\" username: \"{{ vmware_username }}\" password: \"{{ vmware_password }}\" validate_certs: False name: \"{{ vm_name }}\" template: \"{{ template_name }}\" datacenter: \"{{ datacenter_name }}\" folder: \"{{ storage_folder }}\" state: \"{{ state }}\" cluster: \"{{ cluster_name | default(omit,true) }}\" esxi_hostname: \"{{ esxi_hostname | default(omit,true) }}\" wait_for_ip_address: no annotation: \"{{ comments | default('Deployed by Ansible') }}\" datastore: \"{{ datastore_name | default(omit,true) }}\" networks: - name: \"{{ network_name }}\" ip: \"{{ network_ip }}\" netmask: \"{{ network_mask }}\" gateway: \"{{ network_gateway }}\" device_type: \"vmxnet3\" type: static hardware: memory_mb: \"{{ memory_mb|int * 1024 }}\" num_cpu: \"{{ num_cpu }}\" hotadd_cpu: True hotadd_memory: True customization: domain: \"{{ domain }}\" dns_servers: \"{{ dns_servers.split(',') }}\" guest_id: \"{{ guest_id }}\" register: deploy_vm You can store sensitive data in the ./vars/credentials.yml , which you will obviously have encrypted beforehand with ansible-vault (especially if you use git for your work). As everything uses a variable, you can easily make it suit your needs. If you don't use something like Rundeck or Awx, you can launch the deployment with a command line similar to this one: ansible-playbook -i ./inventory/hosts -e '{\"comments\":\"my comments\",\"cluster_name\":\"CS_NAME\",\"esxi_hostname\":\"ESX_NAME\",\"state\":\"started\",\"storage_folder\":\"PROD\",\"datacenter_name\":\"DC_NAME}\",\"datastore_name\":\"DS_NAME\",\"template_name\":\"template-rockylinux8-0.0.1\",\"vm_name\":\"test_vm\",\"network_name\":\"net_prod\",\"network_ip\":\"192.168.1.20\",\"network_gateway\":\"192.168.1.254\",\"network_mask\":\"255.255.255.0\",\"memory_mb\":\"4\",\"num_cpu\":\"2\",\"domain\":\"rockylinux.lan\",\"dns_servers\":\"192.168.1.254\",\"guest_id\":\"centos8_64Guest\"}' ./vmware/create_vm.yml --vault-password-file /etc/ansible/vault_pass.py It is at this point that you can launch the final configuration of your virtual machine using Ansible. Don't forget to change the root password, secure SSH, register the new VM in your monitoring tool and in your IT inventory, etc. In summary As we have seen, there are now fully automated DevOps solutions to create and deploy VMs. At the same time, this represents an undeniable saving of time, especially in cloud or data center environments. It also facilitates a standard compliance across all of the computers in the company (servers and workstations), and an easy maintenance / evolution of templates. Other References For a detailed project that also covers the deployment of Rocky Linux and other operating systems using the latest in vSphere, Packer, and the Packer Plugin for vSphere, please visit this project .","title":"Automatic Template Creation - Packer - Ansible - VMware vSphere"},{"location":"guides/automation/templates-automation-packer-vsphere/#automatic-template-creation-with-packer-and-deployment-with-ansible-in-a-vmware-vsphere-environment","text":"Knowledge : :star: :star: :star: Complexity : :star: :star: :star: Reading time : 30 minutes","title":"Automatic template creation with Packer and deployment with Ansible in a VMware vSphere environment"},{"location":"guides/automation/templates-automation-packer-vsphere/#prerequisites-assumptions-and-general-notes","text":"A vSphere environment available, and a user with granted access An internal web server to store files Web access to the Rocky Linux repositories An Ansible environment available It is assumed that you have some knowledge on each product mentioned. If not, dig into that documentation before you begin. Vagrant is not in use here. It was pointed out that with Vagrant, an SSH key that was not self-signed would be provided. If you want to dig into that you can do so, but it is not covered in this document.","title":"Prerequisites, Assumptions, and General Notes"},{"location":"guides/automation/templates-automation-packer-vsphere/#introduction","text":"This document covers the vSphere virtual machine template creation with Packer and how to deploy the artifact as new virtual machines with Ansible.","title":"Introduction"},{"location":"guides/automation/templates-automation-packer-vsphere/#possible-adjustments","text":"Of course, you can adapt this how-to for other hypervisors. You can also choose not to convert the virtual machine into a template, in this case you will use Packer to deploy each new VM, which is still quite feasible (an installation starting from 0 takes less than 10 minutes without human interaction).","title":"Possible adjustments"},{"location":"guides/automation/templates-automation-packer-vsphere/#packer","text":"Packer is a Hashicorp tool to automate the creation of a virtual machine. You can have a look at these resources for additional information: The Packer website Packer documentation The builder vsphere-iso 's documentation You can start by downloading the binaries for you own platform with Packer downloads . You will also need an iso copy of Rocky Linux. Although I'm using the minimal ISO image here, you could choose to use the DVD image (much bigger and perhaps too big) or the boot image (much smaller and perhaps too small). This choice is up to you. It impacts in particular the bandwidth you will need for the installation, and thus the provisioning time. We will discuss next the impact of the default choice and how to remedy it. It is assumed that you are on Linux to perform the following tasks. As we will connect to a VMware vCenter Server to send our commands via Packer, we need to store our credentials outside the configuration files that we will create next. Let's create a hidden file with our credentials in our home directory. This is a json file: $ vim .vsphere-secrets.json { \"vcenter_username\": \"rockstar\", \"vcenter_password\": \"mysecurepassword\" } Those credentials needs some grant access to your vSphere environment. Let's create a json file (in the future, the format of this file will change to the HCL): { \"variables\": { \"version\": \"0.0.X\", \"HTTP_IP\": \"fileserver.rockylinux.lan\", \"HTTP_PATH\": \"/packer/rockylinux/8/ks.cfg\" }, \"sensitive-variables\": [\"vcenter_password\"], \"provisioners\": [ { \"type\": \"shell\", \"expect_disconnect\": true, \"execute_command\": \"bash '{{.Path}}'\", \"script\": \"{{template_dir}}/scripts/requirements.sh\" } ], \"builders\": [ { \"type\": \"vsphere-iso\", \"CPUs\": 2, \"CPU_hot_plug\": true, \"RAM\": 2048, \"RAM_hot_plug\": true, \"disk_controller_type\": \"pvscsi\", \"guest_os_type\": \"centos8_64Guest\", \"iso_paths\": [ \"[datasyno-contentlibrary-mylib] contentlib-a86ad29a-a43b-4717-97e6-593b8358801b/3a381c78-b9df-45a6-82e1-3c07c8187dbe/Rocky-8.4-x86_64-minimal_72cc0cc6-9d0f-4c68-9bcd-06385a506a5d.iso\" ], \"network_adapters\": [ { \"network_card\": \"vmxnet3\", \"network\": \"net_infra\" } ], \"storage\": [ { \"disk_size\": 40000, \"disk_thin_provisioned\": true } ], \"boot_command\": [ \"<up><tab> text ip=192.168.1.11::192.168.1.254:255.255.255.0:template:ens192:none nameserver=192.168.1.254 inst.ks=http://{{ user `HTTP_IP` }}/{{ user `HTTP_PATH` }}<enter><wait><enter>\" ], \"ssh_password\": \"mysecurepassword\", \"ssh_username\": \"root\", \"shutdown_command\": \"/sbin/halt -h -p\", \"insecure_connection\": \"true\", \"username\": \"{{ user `vcenter_username` }}\", \"password\": \"{{ user `vcenter_password` }}\", \"vcenter_server\": \"vsphere.rockylinux.lan\", \"datacenter\": \"DC_NAME\", \"datastore\": \"DS_NAME\", \"vm_name\": \"template-rockylinux8-{{ user `version` }}\", \"folder\": \"Templates/RockyLinux\", \"cluster\": \"CLUSTER_NAME\", \"host\": \"esx1.rockylinux.lan\", \"notes\": \"Template RockyLinux version {{ user `version` }}\", \"convert_to_template\": true, \"create_snapshot\": false } ] } Next, we will describe each section of this file.","title":"Packer"},{"location":"guides/automation/templates-automation-packer-vsphere/#variables-section","text":"In a first step, we declare variables, mainly for the sake of readability: \"variables\": { \"version\": \"0.0.X\", \"HTTP_IP\": \"fileserver.rockylinux.lan\", \"HTTP_PATH\": \"/packer/rockylinux/8/ks.cfg\" }, We will use the variable version later in the template name we will create. You can easily increment this value to suit your needs. We will also need our booting virtual machine to access a ks.cfg (Kickstart) file. A Kickstart file contains the answers to the questions asked during the installation process. This file passes all its contents to Anaconda (the installation process), which allows you to fully automate the creation of the template. The author likes to store his ks.cfg file in an internal web server accessible from his template, but other possibilities exists that you may chose to use instead. For example, the ks.cfg file is accessible from the VM at this url in our lab: http://fileserver.rockylinux.lan/packer/rockylinux/8/ks.cfg. You would need to set up something similar to use this method. Since we want to keep our password private, It is declared as a sensitive variable. Example: \"sensitive-variables\": [\"vcenter_password\"],","title":"Variables section"},{"location":"guides/automation/templates-automation-packer-vsphere/#provisioners-section","text":"Next part is interesting, and will be covered later by providing you the script for requirements.sh : \"provisioners\": [ { \"type\": \"shell\", \"expect_disconnect\": true, \"execute_command\": \"bash '{{.Path}}'\", \"script\": \"{{template_dir}}/scripts/requirements.sh\" } ], After the installation is finished, the VM will reboot. As soon as Packer detects an IP address (thanks to the VMware Tools), it will copy the requirements.sh and execute it. It's a nice feature to clean the VM after the installation process (remove SSH keys, clean the history, etc.) and install some extra package.","title":"Provisioners section"},{"location":"guides/automation/templates-automation-packer-vsphere/#the-builders-section","text":"You can declare one or more builders to target something other than your vSphere environment (perhaps a Vagrant template). But here we are using the vsphere-iso builder: \"builders\": [ { \"type\": \"vsphere-iso\", This builder lets us configure the hardware we need: \"CPUs\": 2, \"CPU_hot_plug\": true, \"RAM\": 2048, \"RAM_hot_plug\": true, \"disk_controller_type\": \"pvscsi\", \"guest_os_type\": \"centos8_64Guest\", \"network_adapters\": [ { \"network_card\": \"vmxnet3\", \"network\": \"net_infra\" } ], \"storage\": [ { \"disk_size\": 40000, \"disk_thin_provisioned\": true } ], !!! Note You will never forget again to include CPU_hot_plug as it is automatic now! You can do more cool thing with the disk, cpu, etc. You should refer to the documentation if you are interested in making other adjustments. To start the installation, you need an ISO image of Rocky Linux. Here is an example of how to use an image located in a vSphere content library. You can of course store the ISO elsewhere, but in the case of a vSphere content library, you have to get the full path to the ISO file on the server hosting the Content Library (in this case it is a Synology, so directly on the DSM explorer). \"iso_paths\": [ \"[datasyno-contentlibrary-mylib] contentlib-a86ad29a-a43b-4717-97e6-593b8358801b/3a381c78-b9df-45a6-82e1-3c07c8187dbe/Rocky-8.4-x86_64-minimal_72cc0cc6-9d0f-4c68-9bcd-06385a506a5d.iso\" ], Then you have to provide the complete command to be entered during the installation process: configuration of the IP and transmission of the path to the Kickstart response file. !!! Note This example takes the most complex case: using a static IP. If you have a DHCP server available, the process will be much easier. This is the most amusing part of the procedure: I'm sure you'll go and admire the VMware console during the generation, just to see the automatic entry of the commands during the boot. \"boot_command\": [ \"<up><tab> text ip=192.168.1.11::192.168.1.254:255.255.255.0:template:ens192:none nameserver=192.168.1.254 inst.ks=http://{{ user `HTTP_IP` }}/{{ user `HTTP_PATH` }}<enter><wait><enter>\" ], After the first reboot, Packer will connect to your server by SSH. You can use the root user, or another user with sudo rights, but in any case, this user must correspond to the user that is defined in your ks.cfg file. \"ssh_password\": \"mysecurepassword\", \"ssh_username\": \"root\", At the end of the process, the VM must be stopped. It's a little bit more complicated with a non root user, but it's is well documented: \"shutdown_command\": \"/sbin/halt -h -p\", Next, we deal with the vSphere configuration. The only notable things here are the use of the variables defined at the beginning of the document in our home directory, as well as the insecure_connection option, because our vSphere uses a self-signed certificate (See note in Assumptions at the top of this document): \"insecure_connection\": \"true\", \"username\": \"{{ user `vcenter_username` }}\", \"password\": \"{{ user `vcenter_password` }}\", \"vcenter_server\": \"vsphere.rockylinux.lan\", \"datacenter\": \"DC_NAME\", \"datastore\": \"DS_NAME\", \"vm_name\": \"template-rockylinux8-{{ user `version` }}\", \"folder\": \"Templates/RockyLinux\", \"cluster\": \"CLUSTER_NAME\", \"host\": \"esx1.rockylinux.lan\", \"notes\": \"Template RockyLinux version {{ user `version` }}\" And finally, we will ask vSphere to convert our stopped VM to a template. At this stage, you could also elect to just use the VM as is (not converting it to a template). In this case, you can decide to take a snapshot instead: \"convert_to_template\": true, \"create_snapshot\": false,","title":"The builders section"},{"location":"guides/automation/templates-automation-packer-vsphere/#the-kscfg-file","text":"As noted above, we need to provide a Kicstart response file that will be used by Anaconda. Here's an example of that file: # Use CDROM installation media repo --name=\"AppStream\" --baseurl=\"http://download.rockylinux.org/pub/rocky/8.4/AppStream/x86_64/os/\" cdrom # Use text install text # Don't run the Setup Agent on first boot firstboot --disabled eula --agreed ignoredisk --only-use=sda # Keyboard layouts keyboard --vckeymap=us --xlayouts='us' # System language lang en_US.UTF-8 # Network information network --bootproto=static --device=ens192 --gateway=192.168.1.254 --ip=192.168.1.11 --nameserver=192.168.1.254,4.4.4.4 --netmask=255.255.255.0 --onboot=on --ipv6=auto --activate # Root password rootpw mysecurepassword # System services selinux --permissive firewall --enabled services --enabled=\"NetworkManager,sshd,chronyd\" # System timezone timezone Europe/Paris --isUtc # System booloader configuration bootloader --location=mbr --boot-drive=sda # Partition clearing information clearpart --all --initlabel --drives=sda # Disk partitionning information part /boot --fstype=\"xfs\" --ondisk=sda --size=512 part pv.01 --fstype=\"lvmpv\" --ondisk=sda --grow volgroup vg_root --pesize=4096 pv.01 logvol /home --fstype=\"xfs\" --size=5120 --name=lv_home --vgname=vg_root logvol /var --fstype=\"xfs\" --size=10240 --name=lv_var --vgname=vg_root logvol / --fstype=\"xfs\" --size=10240 --name=lv_root --vgname=vg_root logvol swap --fstype=\"swap\" --size=4092 --name=lv_swap --vgname=vg_root skipx reboot %packages --ignoremissing --excludedocs openssh-clients curl dnf-utils drpm net-tools open-vm-tools perl perl-File-Temp sudo vim wget python3 # unnecessary firmware -aic94xx-firmware -atmel-firmware -b43-openfwwf -bfa-firmware -ipw2100-firmware -ipw2200-firmware -ivtv-firmware -iwl*-firmware -libertas-usb8388-firmware -ql*-firmware -rt61pci-firmware -rt73usb-firmware -xorg-x11-drv-ati-firmware -zd1211-firmware -cockpit -quota -alsa-* -fprintd-pam -intltool -microcode_ctl %end %addon com_redhat_kdump --disable %end %post # Manage Ansible access groupadd -g 1001 ansible useradd -m -g 1001 -u 1001 ansible mkdir /home/ansible/.ssh echo -e \"<---- PAST YOUR PUBKEY HERE ---->\" > /home/ansible/.ssh/authorized_keys chown -R ansible:ansible /home/ansible/.ssh chmod 700 /home/ansible/.ssh chmod 600 /home/ansible/.ssh/authorized_keys echo \"ansible ALL=(ALL:ALL) NOPASSWD:ALL\" > /etc/sudoers.d/ansible chmod 440 /etc/sudoers.d/ansible systemctl enable vmtoolsd systemctl start vmtoolsd %end As we have chosen to use the minimal iso, instead of the Boot or DVD, not all required installation packages will be available. As Packer relies on VMware Tools to detect the end of the installation, and the open-vm-tools package is only available in the AppStream repos, we have to specify to the installation process that we want to use as source both the cdrom and this remote repo: !!! Note If you don't have access to the external repos, you can use either a mirror of the repo, a squid proxy, or the dvd. # Use CDROM installation media repo --name=\"AppStream\" --baseurl=\"http://download.rockylinux.org/pub/rocky/8.4/AppStream/x86_64/os/\" cdrom Let's jump to the network configuration, as once again, in this example we aren't using a DHCP server: # Network information network --bootproto=static --device=ens192 --gateway=192.168.1.254 --ip=192.168.1.11 --nameserver=192.168.1.254,4.4.4.4 --netmask=255.255.255.0 --onboot=on --ipv6=auto --activate Remember we specified the user to connect via SSH with to Packer at the end of the installation. This user and password must match: # Root password rootpw mysecurepassword !!! Warning You can use an insecure password here, as long as you make sure that this password will be changed immediately after the deployment of your VM, for example with Ansible. Here is the selected partition scheme. Much more complex things can be done. You can define a partition scheme that suits your needs, adapting it to the disk space defined in Packer, and which respects the security rules defined for your environment (dedicated partition for /tmp , etc.): # System booloader configuration bootloader --location=mbr --boot-drive=sda # Partition clearing information clearpart --all --initlabel --drives=sda # Disk partitionning information part /boot --fstype=\"xfs\" --ondisk=sda --size=512 part pv.01 --fstype=\"lvmpv\" --ondisk=sda --grow volgroup vg_root --pesize=4096 pv.01 logvol /home --fstype=\"xfs\" --size=5120 --name=lv_home --vgname=vg_root logvol /var --fstype=\"xfs\" --size=10240 --name=lv_var --vgname=vg_root logvol / --fstype=\"xfs\" --size=10240 --name=lv_root --vgname=vg_root logvol swap --fstype=\"swap\" --size=4092 --name=lv_swap --vgname=vg_root The next section concerns the packages that will be installed. A \"best practice\" is to limit the quantity of installed packages to only those you need, which limits the attack surface, especially in a server environment. !!! Note The author likes to limit the actions to be done in the installation process and to defer installing what is needed in the post installation script of Packer. So, in this case, we install only the minimum required packages. The openssh-clients package seems to be required for Packer to copy its scripts into the VM. The open-vm-tools is also needed by Packer to detect the end of the installation, this explains the addition of the AppStream repository. perl and perl-File-Temp will also be required by VMware Tools during the deployment part. This is a shame because it requires a lot of other dependent packages. python3 (3.6) will also be required in the future for Ansible to work (if you won't use Ansible or python, remove them!). %packages --ignoremissing --excludedocs openssh-clients open-vm-tools python3 perl perl-File-Temp curl dnf-utils drpm net-tools sudo vim wget You can not only add packages but also remove them. Since we control the environment in which our hardware will work, we can remove any of the firmware that will be useless to us: # unnecessary firmware -aic94xx-firmware -atmel-firmware ... The next part adds some users. It's interesting in our case to create an ansible user, without password but with a pubkey. This allows all of our new VMs to be accessible from our Ansible server to run the post-install actions: # Manage Ansible access groupadd -g 1001 ansible useradd -m -g 1001 -u 1001 ansible mkdir /home/ansible/.ssh echo -e \"<---- PAST YOUR PUBKEY HERE ---->\" > /home/ansible/.ssh/authorized_keys chown -R ansible:ansible /home/ansible/.ssh chmod 700 /home/ansible/.ssh chmod 600 /home/ansible/.ssh/authorized_keys echo \"ansible ALL=(ALL:ALL) NOPASSWD:ALL\" > /etc/sudoers.d/ansible chmod 440 /etc/sudoers.d/ansible Now we need to enable and start vmtoolsd (the process that manages open-vm-tools). vSphere will detect the IP address after the reboot of the VM. systemctl enable vmtoolsd systemctl start vmtoolsd The installation process is finished and the VM will reboot.","title":"The ks.cfg file"},{"location":"guides/automation/templates-automation-packer-vsphere/#the-provisioners","text":"Remember, we declared in Packer a provisioner, which in our case corresponds to a .sh script, to be stored in a subdirectory next to our json file. There are different types of provisioners, we could also have used Ansible. You are free to explore these possibilities. This file can be completely changed, but this provides an example of what can be done with a script, in this case requirements.sh : #!/bin/sh -eux echo \"Updating the system...\" dnf -y update echo \"Installing cloud-init...\" dnf -y install cloud-init # see https://bugs.launchpad.net/cloud-init/+bug/1712680 # and https://kb.vmware.com/s/article/71264 # Virtual Machine customized with cloud-init is set to DHCP after reboot echo \"manual_cache_clean: True \" > /etc/cloud/cloud.cfg.d/99-manual.cfg echo \"Disable NetworkManager-wait-online.service\" systemctl disable NetworkManager-wait-online.service # cleanup current SSH keys so templated VMs get fresh key rm -f /etc/ssh/ssh_host_* # Avoid ~200 meg firmware package we don't need # this cannot be done in the KS file so we do it here echo \"Removing extra firmware packages\" dnf -y remove linux-firmware dnf -y autoremove echo \"Remove previous kernels that preserved for rollbacks\" dnf -y remove -y $(dnf repoquery --installonly --latest-limit=-1 -q) dnf -y clean all --enablerepo=\\*; echo \"truncate any logs that have built up during the install\" find /var/log -type f -exec truncate --size=0 {} \\; echo \"remove the install log\" rm -f /root/anaconda-ks.cfg /root/original-ks.cfg echo \"remove the contents of /tmp and /var/tmp\" rm -rf /tmp/* /var/tmp/* echo \"Force a new random seed to be generated\" rm -f /var/lib/systemd/random-seed echo \"Wipe netplan machine-id (DUID) so machines get unique ID generated on boot\" truncate -s 0 /etc/machine-id echo \"Clear the history so our install commands aren't there\" rm -f /root/.wget-hsts export HISTSIZE=0 Some explanations are necessary: echo \"Installing cloud-init...\" dnf -y install cloud-init # see https://bugs.launchpad.net/cloud-init/+bug/1712680 # and https://kb.vmware.com/s/article/71264 # Virtual Machine customized with cloud-init is set to DHCP after reboot echo \"manual_cache_clean: True\" > /etc/cloud/cloud.cfg.d/99-manual.cfg Since vSphere now uses cloud-init via the VMware Tools to configure the network of a centos8 guest machine, it must be installed. However, if you do nothing, the configuration will be applied on the first reboot and everything will be fine. But on the next reboot, cloud-init will not receive any new information from vSphere. In these cases, without information about what to do, cloud-init will reconfigure the VM's network interface to use DHCP, and you will loose your static configuration. As this is not the behavior we want, we need to specify to cloud-init not to delete its cache automatically, and therefore to reuse the configuration information it received during its first reboot and each reboot after that. For this, we create a file /etc/cloud/cloud.cfg.d/99-manual.cfg with the manual_cache_clean: True directive. !!! Note This implies that if you need to re-apply a network configuration via vSphere guest customizations (which, in normal use, should be quite rare), you will have to delete the cloud-init cache yourself. The rest of the script is commented and does not require more details You can check the Bento project to get more ideas of what can be done in this part of the automation process.","title":"The provisioners"},{"location":"guides/automation/templates-automation-packer-vsphere/#template-creation","text":"Now it's time to launch Packer and check that the creation process, which is completely automatic, works well. Simply enter this at the command line: ./packer build -var-file=~/.vsphere-secrets.json rockylinux8/template.json You can quickly go to vSphere and admire the work. You will see the machine being created, started, and if you launch a console, you will see the automatic entry of commands and the installation process. At the end of the creation, you will find your template ready to use in vSphere.","title":"Template creation"},{"location":"guides/automation/templates-automation-packer-vsphere/#deployment-part","text":"This documentation would not be complete without the automatic deployment part of the template. For this, we will use a simple Ansible playbook, which uses the vmware_guest module. This playbook that we provide you, must be adapted to your needs and your way of doing things. --- - name: Deploy VM from template hosts: localhost gather_facts: no vars_files: - ./vars/credentials.yml tasks: - name: Clone the template vmware_guest: hostname: \"{{ vmware_vcenter_hostname }}\" username: \"{{ vmware_username }}\" password: \"{{ vmware_password }}\" validate_certs: False name: \"{{ vm_name }}\" template: \"{{ template_name }}\" datacenter: \"{{ datacenter_name }}\" folder: \"{{ storage_folder }}\" state: \"{{ state }}\" cluster: \"{{ cluster_name | default(omit,true) }}\" esxi_hostname: \"{{ esxi_hostname | default(omit,true) }}\" wait_for_ip_address: no annotation: \"{{ comments | default('Deployed by Ansible') }}\" datastore: \"{{ datastore_name | default(omit,true) }}\" networks: - name: \"{{ network_name }}\" ip: \"{{ network_ip }}\" netmask: \"{{ network_mask }}\" gateway: \"{{ network_gateway }}\" device_type: \"vmxnet3\" type: static hardware: memory_mb: \"{{ memory_mb|int * 1024 }}\" num_cpu: \"{{ num_cpu }}\" hotadd_cpu: True hotadd_memory: True customization: domain: \"{{ domain }}\" dns_servers: \"{{ dns_servers.split(',') }}\" guest_id: \"{{ guest_id }}\" register: deploy_vm You can store sensitive data in the ./vars/credentials.yml , which you will obviously have encrypted beforehand with ansible-vault (especially if you use git for your work). As everything uses a variable, you can easily make it suit your needs. If you don't use something like Rundeck or Awx, you can launch the deployment with a command line similar to this one: ansible-playbook -i ./inventory/hosts -e '{\"comments\":\"my comments\",\"cluster_name\":\"CS_NAME\",\"esxi_hostname\":\"ESX_NAME\",\"state\":\"started\",\"storage_folder\":\"PROD\",\"datacenter_name\":\"DC_NAME}\",\"datastore_name\":\"DS_NAME\",\"template_name\":\"template-rockylinux8-0.0.1\",\"vm_name\":\"test_vm\",\"network_name\":\"net_prod\",\"network_ip\":\"192.168.1.20\",\"network_gateway\":\"192.168.1.254\",\"network_mask\":\"255.255.255.0\",\"memory_mb\":\"4\",\"num_cpu\":\"2\",\"domain\":\"rockylinux.lan\",\"dns_servers\":\"192.168.1.254\",\"guest_id\":\"centos8_64Guest\"}' ./vmware/create_vm.yml --vault-password-file /etc/ansible/vault_pass.py It is at this point that you can launch the final configuration of your virtual machine using Ansible. Don't forget to change the root password, secure SSH, register the new VM in your monitoring tool and in your IT inventory, etc.","title":"Deployment part"},{"location":"guides/automation/templates-automation-packer-vsphere/#in-summary","text":"As we have seen, there are now fully automated DevOps solutions to create and deploy VMs. At the same time, this represents an undeniable saving of time, especially in cloud or data center environments. It also facilitates a standard compliance across all of the computers in the company (servers and workstations), and an easy maintenance / evolution of templates.","title":"In summary"},{"location":"guides/automation/templates-automation-packer-vsphere/#other-references","text":"For a detailed project that also covers the deployment of Rocky Linux and other operating systems using the latest in vSphere, Packer, and the Packer Plugin for vSphere, please visit this project .","title":"Other References"},{"location":"guides/backup/mirroring_lsyncd/","tags":["lsyncd","synchronization","mirroring"],"text":"Mirroring Solution - lsyncd Prerequisites This is everything you'll need to understand and follow along with this guide: A machine running Rocky Linux A comfort level with modifying configuration files from the command-line Knowledge of how to use a command line editor (we use vi here, but you could use your favorite editor) You will need root access, and ideally be signed in as the root user in your terminal Public and Private SSH key pairs The EPEL repositories from Fedora You will need to be familiar with inotify , an event monitor interface Optional: familiarity with tail Introduction If you're looking for a way to synchronize files and folders between computers automatically, lsyncd is a pretty great option. The only downside for beginners? You have to configure everything via the command line, and text files. Even so, it's a program worth learning for any sysadmin. The best description of lsyncd , comes from its own man page. Slightly paraphrased, lsyncd is a light-weight live mirror solution that is comparatively easy to install. It doesn't require new filesystems or blockdevices, and does not hamper local filesystem performance. In short, it mirrors files. lsyncd watches a local directory trees event monitor interface (inotify). It aggregates and combines events for a few seconds, and then spawns one (or more) process(es) to synchronize the changes. By default this is rsync . For the purposes of this guide, we will call the system with the original files the \"master\", and the one that we are synchronizing to will be the \"target\". It is actually possible to completely mirror a server using lsyncd by very carefully specifying directories and files that you want to synchronize. It's pretty sweet! For remote syncing, you will also want to set up Rocky Linux SSH Public Private Key Pairs . The examples here use SSH (port 22). Installing lsyncd There are actually two ways to install lsyncd . We will include them both here. The RPM tends to lag behind the source packages by a little, but only by a little. The version installed by the RPM method at the time of this writing is 2.2.2-9, whereas the source code version is now at 2.2.3. That said, we want to give you both options and let you choose. Installing lsyncd - RPM Method Installing the RPM version is relatively easy. The only thing you will need to install first is the EPEL software repository from Fedora. This can be done with a single command: dnf install -y epel-release Then, we just need to install lsyncd and any missing dependencies will be installed along with it: dnf install lsyncd Set up the service to start on boot, but don't start it just yet: systemctl enable lsyncd That's it! Installing lsyncd - Source Method Installing from source is not as bad is it sounds. Just follow this guide and you will be up and running in no time! Install Dependencies We will need some dependencies: a few that are required by lsyncd itself, and a few that are required to build packages from source. Use this command on your Rocky Linux machine to make sure you have the dependencies you need. If you are going to be building from source, it's a good idea to have all of the development tools installed: dnf groupinstall 'Development Tools' !!! important \"For Rocky Linux 9.0\" `lsyncd` has been fully tested in Rocky Linux 9.0, and will work as expected. In order to get all of the needed dependencies installed, however, you will need to enable an additional repository: ``` dnf config-manager --enable crb ``` Doing this in 9 before then next steps, will allow you to finish the build without backtracking. And here are the dependencies we need for lsyncd itself, and its build process: dnf install lua lua-libs lua-devel cmake unzip wget rsync Download lsyncd And Build It Next we need the source code: wget https://github.com/axkibe/lsyncd/archive/master.zip Now unzip the master.zip file: unzip master.zip This will create a directory called \"lsyncd-master\". We need to change to this directory and create a directory called build: cd lsyncd-master And then: mkdir build Now change directories again so that you are in the build directory: cd build Now execute these commands: cmake .. make make install When done, you should have the lsyncd binary installed and ready for use in /usr/local/bin lsyncd Systemd Service With the RPM install method, the systemd service will be installed for you, but if you choose to install from source, you will need to create the systemd service. While you can start the binary without the systemd service, we want to make sure that it does start on boot. If not, a server reboot would stop your synchronization effort and if you forgot to start it again, which is highly likely, that could be very embarrassing for any systems administrator! Creating the systemd service is not terribly difficult, though, and will save you a lot of time in the long run. Create The lsyncd Service File This file can be created anywhere, even in the root directory of your server. Once it is created, we can easily move it the right location. vi /root/lsyncd.service The contents of this file should be: [Unit] Description=Live Syncing (Mirror) Daemon After=network.target [Service] Restart=always Type=simple Nice=19 ExecStart=/usr/local/bin/lsyncd -nodaemon -pidfile /run/lsyncd.pid /etc/lsyncd.conf ExecReload=/bin/kill -HUP $MAINPID PIDFile=/run/lsyncd.pid [Install] WantedBy=multi-user.target Now let's install the file you just made to the correct location: install -Dm0644 /root/lsyncd.service /usr/lib/systemd/system/lsyncd.service Finally, reload the systemctl daemon so that systemd will \"see\" the new service file: systemctl daemon-reload lsyncd Configuration Whichever method you choose for installing lsyncd , you will need a configuration file: /etc/lsyncd.conf . The next section will tell you how to build a simple configuration file, and test it. Sample Configuration For Testing Here's an example of a simple configuration file that synchronizes /home to another machine. Our target machine is going to be a local IP address: 192.168.1.40 settings { logfile = \"/var/log/lsyncd.log\", statusFile = \"/var/log/lsyncd-status.log\", statusInterval = 20, maxProcesses = 1 } sync { default.rsyncssh, source=\"/home\", host=\"root@192.168.1.40\", excludeFrom=\"/etc/lsyncd.exclude\", targetdir=\"/home\", rsync = { archive = true, compress = false, whole_file = false }, ssh = { port = 22 } } Breaking down this file a bit: The \"logfile\" and \"statusFile\" will be automatically created when the service starts. The \"statusInterval\" is the number of seconds to wait before writing to the statusFile. \"maxProcesses\" is the number of processes lsyncd is allowed to spawn. Honestly, unless you are running this on a super busy machine, 1 process is enough. In the sync section \"default.rsyncssh\" says to use rsync over ssh The \"source=\" is the directory path we are syncing from. The \"host=\" is our target machine that we are syncing to. The \"excludeFrom=\" tells lsyncd where the eclusions file is. It must exist, but can be empty. The \"targetdir=\" is the target directory we are sending files to. In most cases this will be equal to the source, but not always. Then we have the \"rsync =\" section, and these are the options that we are running rsync with. Finally we have the \"ssh =\" section, and this specifies the SSH port that is listening on the target machine. If you are adding more than one directory to sync, then you need to repeat the entire \"sync\" section including all the opening and closing brackets for each directory. The lsyncd.exclude File As noted earlier, the \"excludeFrom\" file must exist, so let's create that now: touch /etc/lsyncd.exclude If we were syncing the /etc folder on our machine, there would be a number of files and/or directories that we should leave out. Each excluded file or directory is simply listed in the file, one per line, like this: /etc/hostname /etc/hosts /etc/networks /etc/fstab Test And Turn Up Now that everything else is set up, we can test it all. For starters, lets make sure our systemd lsyncd.service will start: systemctl start lsyncd If no errors appear after executing this command, check the status of the service, just to make sure: systemctl status lsyncd If it shows the service running, use tail to see the ends of the two log files, and make sure everything show up OK: tail /var/log/lsyncd.log And then: tail /var/log/lsyncd-status.log Assuming that this all looks correct, navigate to the /home/[user] directory, where [user] is a user on the machine and create a new file there with touch . touch /home/[user]/testfile Now go to the target machine and see if the file shows up. If so, everything is working as it should. Set the lsyncd.service to start on boot with: systemctl enable lsyncd And you should be ready to go. Remember To Be Careful Anytime you are synchronizing a set of files or directories to another machine, think carefully about the effect it will have on the target machine. If you go back to The lsyncd.exclude File in our example above, can you imagine what might happen if /etc/fstab is synchronized? For newbies, fstab is the file that is used to configure storage drives on any Linux machine. The disks and labels are almost certainly different. The next time the target machine was rebooted it would likely fail to boot entirely. Conclusions And References lsyncd is a powerful tool for directory synchronization between machines. As you've seen, it's not hard to install, and it's easy to maintain going forward. Can't ask for more than that. You can find out more about lsyncd by going to The Official Site","title":"Mirroring Solution - lsyncd"},{"location":"guides/backup/mirroring_lsyncd/#mirroring-solution-lsyncd","text":"","title":"Mirroring Solution - lsyncd"},{"location":"guides/backup/mirroring_lsyncd/#prerequisites","text":"This is everything you'll need to understand and follow along with this guide: A machine running Rocky Linux A comfort level with modifying configuration files from the command-line Knowledge of how to use a command line editor (we use vi here, but you could use your favorite editor) You will need root access, and ideally be signed in as the root user in your terminal Public and Private SSH key pairs The EPEL repositories from Fedora You will need to be familiar with inotify , an event monitor interface Optional: familiarity with tail","title":"Prerequisites"},{"location":"guides/backup/mirroring_lsyncd/#introduction","text":"If you're looking for a way to synchronize files and folders between computers automatically, lsyncd is a pretty great option. The only downside for beginners? You have to configure everything via the command line, and text files. Even so, it's a program worth learning for any sysadmin. The best description of lsyncd , comes from its own man page. Slightly paraphrased, lsyncd is a light-weight live mirror solution that is comparatively easy to install. It doesn't require new filesystems or blockdevices, and does not hamper local filesystem performance. In short, it mirrors files. lsyncd watches a local directory trees event monitor interface (inotify). It aggregates and combines events for a few seconds, and then spawns one (or more) process(es) to synchronize the changes. By default this is rsync . For the purposes of this guide, we will call the system with the original files the \"master\", and the one that we are synchronizing to will be the \"target\". It is actually possible to completely mirror a server using lsyncd by very carefully specifying directories and files that you want to synchronize. It's pretty sweet! For remote syncing, you will also want to set up Rocky Linux SSH Public Private Key Pairs . The examples here use SSH (port 22).","title":"Introduction"},{"location":"guides/backup/mirroring_lsyncd/#installing-lsyncd","text":"There are actually two ways to install lsyncd . We will include them both here. The RPM tends to lag behind the source packages by a little, but only by a little. The version installed by the RPM method at the time of this writing is 2.2.2-9, whereas the source code version is now at 2.2.3. That said, we want to give you both options and let you choose.","title":"Installing lsyncd"},{"location":"guides/backup/mirroring_lsyncd/#installing-lsyncd-rpm-method","text":"Installing the RPM version is relatively easy. The only thing you will need to install first is the EPEL software repository from Fedora. This can be done with a single command: dnf install -y epel-release Then, we just need to install lsyncd and any missing dependencies will be installed along with it: dnf install lsyncd Set up the service to start on boot, but don't start it just yet: systemctl enable lsyncd That's it!","title":"Installing lsyncd - RPM Method"},{"location":"guides/backup/mirroring_lsyncd/#installing-lsyncd-source-method","text":"Installing from source is not as bad is it sounds. Just follow this guide and you will be up and running in no time!","title":"Installing lsyncd - Source Method"},{"location":"guides/backup/mirroring_lsyncd/#install-dependencies","text":"We will need some dependencies: a few that are required by lsyncd itself, and a few that are required to build packages from source. Use this command on your Rocky Linux machine to make sure you have the dependencies you need. If you are going to be building from source, it's a good idea to have all of the development tools installed: dnf groupinstall 'Development Tools' !!! important \"For Rocky Linux 9.0\" `lsyncd` has been fully tested in Rocky Linux 9.0, and will work as expected. In order to get all of the needed dependencies installed, however, you will need to enable an additional repository: ``` dnf config-manager --enable crb ``` Doing this in 9 before then next steps, will allow you to finish the build without backtracking. And here are the dependencies we need for lsyncd itself, and its build process: dnf install lua lua-libs lua-devel cmake unzip wget rsync","title":"Install Dependencies"},{"location":"guides/backup/mirroring_lsyncd/#download-lsyncd-and-build-it","text":"Next we need the source code: wget https://github.com/axkibe/lsyncd/archive/master.zip Now unzip the master.zip file: unzip master.zip This will create a directory called \"lsyncd-master\". We need to change to this directory and create a directory called build: cd lsyncd-master And then: mkdir build Now change directories again so that you are in the build directory: cd build Now execute these commands: cmake .. make make install When done, you should have the lsyncd binary installed and ready for use in /usr/local/bin","title":"Download lsyncd And Build It"},{"location":"guides/backup/mirroring_lsyncd/#lsyncd-systemd-service","text":"With the RPM install method, the systemd service will be installed for you, but if you choose to install from source, you will need to create the systemd service. While you can start the binary without the systemd service, we want to make sure that it does start on boot. If not, a server reboot would stop your synchronization effort and if you forgot to start it again, which is highly likely, that could be very embarrassing for any systems administrator! Creating the systemd service is not terribly difficult, though, and will save you a lot of time in the long run.","title":"lsyncd Systemd Service"},{"location":"guides/backup/mirroring_lsyncd/#create-the-lsyncd-service-file","text":"This file can be created anywhere, even in the root directory of your server. Once it is created, we can easily move it the right location. vi /root/lsyncd.service The contents of this file should be: [Unit] Description=Live Syncing (Mirror) Daemon After=network.target [Service] Restart=always Type=simple Nice=19 ExecStart=/usr/local/bin/lsyncd -nodaemon -pidfile /run/lsyncd.pid /etc/lsyncd.conf ExecReload=/bin/kill -HUP $MAINPID PIDFile=/run/lsyncd.pid [Install] WantedBy=multi-user.target Now let's install the file you just made to the correct location: install -Dm0644 /root/lsyncd.service /usr/lib/systemd/system/lsyncd.service Finally, reload the systemctl daemon so that systemd will \"see\" the new service file: systemctl daemon-reload","title":"Create The lsyncd Service File"},{"location":"guides/backup/mirroring_lsyncd/#lsyncd-configuration","text":"Whichever method you choose for installing lsyncd , you will need a configuration file: /etc/lsyncd.conf . The next section will tell you how to build a simple configuration file, and test it.","title":"lsyncd Configuration"},{"location":"guides/backup/mirroring_lsyncd/#sample-configuration-for-testing","text":"Here's an example of a simple configuration file that synchronizes /home to another machine. Our target machine is going to be a local IP address: 192.168.1.40 settings { logfile = \"/var/log/lsyncd.log\", statusFile = \"/var/log/lsyncd-status.log\", statusInterval = 20, maxProcesses = 1 } sync { default.rsyncssh, source=\"/home\", host=\"root@192.168.1.40\", excludeFrom=\"/etc/lsyncd.exclude\", targetdir=\"/home\", rsync = { archive = true, compress = false, whole_file = false }, ssh = { port = 22 } } Breaking down this file a bit: The \"logfile\" and \"statusFile\" will be automatically created when the service starts. The \"statusInterval\" is the number of seconds to wait before writing to the statusFile. \"maxProcesses\" is the number of processes lsyncd is allowed to spawn. Honestly, unless you are running this on a super busy machine, 1 process is enough. In the sync section \"default.rsyncssh\" says to use rsync over ssh The \"source=\" is the directory path we are syncing from. The \"host=\" is our target machine that we are syncing to. The \"excludeFrom=\" tells lsyncd where the eclusions file is. It must exist, but can be empty. The \"targetdir=\" is the target directory we are sending files to. In most cases this will be equal to the source, but not always. Then we have the \"rsync =\" section, and these are the options that we are running rsync with. Finally we have the \"ssh =\" section, and this specifies the SSH port that is listening on the target machine. If you are adding more than one directory to sync, then you need to repeat the entire \"sync\" section including all the opening and closing brackets for each directory.","title":"Sample Configuration For Testing"},{"location":"guides/backup/mirroring_lsyncd/#the-lsyncdexclude-file","text":"As noted earlier, the \"excludeFrom\" file must exist, so let's create that now: touch /etc/lsyncd.exclude If we were syncing the /etc folder on our machine, there would be a number of files and/or directories that we should leave out. Each excluded file or directory is simply listed in the file, one per line, like this: /etc/hostname /etc/hosts /etc/networks /etc/fstab","title":"The lsyncd.exclude File"},{"location":"guides/backup/mirroring_lsyncd/#test-and-turn-up","text":"Now that everything else is set up, we can test it all. For starters, lets make sure our systemd lsyncd.service will start: systemctl start lsyncd If no errors appear after executing this command, check the status of the service, just to make sure: systemctl status lsyncd If it shows the service running, use tail to see the ends of the two log files, and make sure everything show up OK: tail /var/log/lsyncd.log And then: tail /var/log/lsyncd-status.log Assuming that this all looks correct, navigate to the /home/[user] directory, where [user] is a user on the machine and create a new file there with touch . touch /home/[user]/testfile Now go to the target machine and see if the file shows up. If so, everything is working as it should. Set the lsyncd.service to start on boot with: systemctl enable lsyncd And you should be ready to go.","title":"Test And Turn Up"},{"location":"guides/backup/mirroring_lsyncd/#remember-to-be-careful","text":"Anytime you are synchronizing a set of files or directories to another machine, think carefully about the effect it will have on the target machine. If you go back to The lsyncd.exclude File in our example above, can you imagine what might happen if /etc/fstab is synchronized? For newbies, fstab is the file that is used to configure storage drives on any Linux machine. The disks and labels are almost certainly different. The next time the target machine was rebooted it would likely fail to boot entirely.","title":"Remember To Be Careful"},{"location":"guides/backup/mirroring_lsyncd/#conclusions-and-references","text":"lsyncd is a powerful tool for directory synchronization between machines. As you've seen, it's not hard to install, and it's easy to maintain going forward. Can't ask for more than that. You can find out more about lsyncd by going to The Official Site","title":"Conclusions And References"},{"location":"guides/backup/rsnapshot_backup/","tags":["backup","rsnapshot"],"text":"Backup Solution - Rsnapshot Prerequisites Know how to install additional repositories and snapshots from the command-line Know about mounting filesystems external of your machine (external hard drive, remote filesystem, etc.) Know how to use an editor ( vi is used here, but you can use your favorite editor) Know a little BASH scripting Know how to modify the crontab for the root user Knowledge of SSH public and private keys (only if you plan to run remote backups from another server) Introduction rsnapshot is a very powerful backup utility that can be installed on any Linux-based machine. It can either back up a machine locally, or you can back up multiple machines, say servers for instance, from a single machine. rsnapshot uses rsync and is written entirely in perl with no library dependencies, so there are no weird requirements to installing it. In the case of Rocky Linux, you should be able to install rsnapshot simply by installing the EPEL software repository. This documentation covers the installation of rsnapshot on Rocky Linux only. Installing Rsnapshot All commands shown here are from the command-line on your server or workstation unless otherwise noted. Installing The EPEL repository We need the EPEL software repository from Fedora to install rsnapshot . To install the repository, just use this command: sudo dnf install epel-release The repository should now be active. Install the Rsnapshot Package Next, install rsnapshot itself: sudo dnf install rsnapshot If there are any missing dependencies, those will show up and you simply need to answer the prompt to continue. For example: dnf install rsnapshot Last metadata expiration check: 0:00:16 ago on Mon Feb 22 00:12:45 2021. Dependencies resolved. ======================================================================================================================================== Package Architecture Version Repository Size ======================================================================================================================================== Installing: rsnapshot noarch 1.4.3-1.el8 epel 121 k Installing dependencies: perl-Lchown x86_64 1.01-14.el8 epel 18 k rsync x86_64 3.1.3-9.el8 baseos 404 k Transaction Summary ======================================================================================================================================== Install 3 Packages Total download size: 543 k Installed size: 1.2 M Is this ok [y/N]: y Mounting A Drive or Filesystem For Backup In this step, we show how to mount a hard drive, such as an external USB hard drive, that will be used to back up your system. This particular step is only necessary if you are backing up a single machine or server, as seen in our first example below. Plug in the USB drive. Type dmesg | grep sd which should show you the drive you want to use. In this case, it'll be called sda1 . Example: EXT4-fs (sda1): mounting ext2 file system using the ext4 subsystem . Unfortunately (or fortunately depending on your opinion) most modern Linux desktop operating systems automount the drive if they can. This means that, depending on various factors, rsnapshot might lose track of the hard drive. We want the drive to \"mount\" or make its files available in the same place every time. To do that, take the drive information revealed in the dmesg command above and type mount | grep sda1 , which should show something like this: /dev/sda1 on /media/username/8ea89e5e-9291-45c1-961d-99c346a2628a Type sudo umount /dev/sda1 to unmount your external hard drive. Next, create a new mount point for the backup: sudo mkdir /mnt/backup Now mount the drive to your backup folder location: sudo mount /dev/sda1 /mnt/backup Now type mount | grep sda1 again, and you should see something like this: /dev/sda1 on /mnt/backup type ext2 (rw,relatime) Next create a directory that must exist for the backup to continue on the mounted drive. We are using a folder called \"storage\" for this example: sudo mkdir /mnt/backup/storage Note that for a single machine, you will have to either repeat the umount and mount steps each time the drive is plugged in again, or each time the system reboots, or automate these commands with a script. We recommend automation. Automation is the sysadmin way. Configuring rsnapshot This is the most important step. It's easy to make a mistake when making changes to the configuration file. The rsnapshot configuration requires tabs for any separation between elements, and a warning to that effect is at the very top of the configuration file. A space character will cause the entire configuration\u2014and your backup\u2014to fail. For instance, near the top of the configuration file is a section for the # SNAPSHOT ROOT DIRECTORY # . If you were adding this in from scratch, you would type snapshot_root then TAB and then type /whatever_the_path_to_the_snapshot_root_will_be/ The best thing is that the default configuration that comes with rsnapshot only needs minor changes to make it work for a backup of a local machine. It's always a good idea, though, to make a backup copy of the configuration file before you start editing: cp /etc/rsnapshot.conf /etc/rsnapshot.conf.bak Basic Machine or Single Server Backup In this case, rsnapshot is going to be run locally to back up a particular machine. In this example, we'll break down the configuration file, and show you exactly what you need to change. You will need to use vi (or edit with your favorite editor) to open the /etc/rsnapshot.conf file. The first thing to change is the snapshot_root setting which by default has this value: snapshot_root /.snapshots/ We need to change this to our mount point that we created above plus the addition of \"storage\". snapshot_root /mnt/backup/storage/ We also want to tell the backup NOT to run if the drive is not mounted. To do this, remove the \"#\" sign (also called a remark, pound sign, number sign, hash symbol, etc.) next to no_create_root so that it looks like this: no_create_root 1 Next go down to the section titled # EXTERNAL PROGRAM DEPENDENCIES # and remove the comment (again, the \"#\" sign) from this line: #cmd_cp /usr/bin/cp So that it now reads: cmd_cp /usr/bin/cp While we do not need cmd_ssh for this particular configuration, we will need it for our other option below and it doesn't hurt to have it enabled. So find the line that says: #cmd_ssh /usr/bin/ssh And remove the \"#\" sign so that it looks like this: cmd_ssh /usr/bin/ssh Next we need to skip down to the section titled # BACKUP LEVELS / INTERVALS # This has been changed from earlier versions of rsnapshot from hourly, daily, monthly, yearly to alpha, beta, gamma, delta . Which is a bit confusing. What you need to do is add a remark to any interval that you won't be using. In the configuration, delta is already remarked out. For this example, we aren't going to be running any other increments other than a nightly backup, so just add a remark to alpha and gamma so that the configuration looks like this when you are done: #retain alpha 6 retain beta 7 #retain gamma 4 #retain delta 3 Now skip down to the logfile line, which by default should read: #logfile /var/log/rsnapshot And remove the remark so that it is enabled: logfile /var/log/rsnapshot Finally, skip down to the ### BACKUP POINTS / SCRIPTS ### section and add any directories that you want to add in the # LOCALHOST section, remember to use TAB rather than SPACE between elements! For now write your changes ( SHIFT :wq! for vi ) and exit the configuration file. Checking The Configuration We want to make sure that we didn't add spaces or any other glaring errors to our configuration file while we were editing it. To do this, we run rsnapshot against our configuration with the configtest option: rsnapshot configtest will show Syntax OK if there are no errors in the configuration. You should get into the habit of running configtest against a particular configuration. The reason for that will be more evident when we get into the Multiple Machine or Multiple Server Backups section. To run configtest against a particular configuration file, run it with the -c option to specify the configuration: rsnapshot -c /etc/rsnapshot.conf configtest Running The Backup The First Time Everything has checked out, so it's time to go ahead and run the backup for the first time. You can run this in test mode first if you like, so that you can see what the backup script is going to do. Again, to do this you don't necessarily have to specify the configuration in this case, but you should get into the habit of doing so: rsnapshot -c /etc/rsnapshot.conf -t beta Which should return something like this, showing you what will happen when the backup is actually run: echo 1441 > /var/run/rsnapshot.pid mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded \\ /home/ /mnt/backup/storage/beta.0/localhost/ mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded /etc/ \\ /mnt/backup/storage/beta.0/localhost/ mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded \\ /usr/local/ /mnt/backup/storage/beta.0/localhost/ touch /mnt/backup/storage/beta.0/ Once you are satisfied with the test, go ahead and run it manually the first time without the test: rsnapshot -c /etc/rsnapshot.conf beta When the backup finishes, navigate to /mnt/backup and take a look at the directory structure that was created there. There will be a storage/beta.0/localhost directory, followed by the directories that you specified to backup. Further Explanation Each time the backup is run, it will create a new beta increment, 0-6, or 7 days worth of backups. The newest backup will always be beta.0 whereas yesterday's backup will always be beta.1. The size of each of these backups will appear to take up the same amount (or more) of disk space, but this is because of rsnapshot's use of hard links. To restore files from yesterday's backup, you would simply copy them back from beta.1's directory structure. Each backup is only an incremental backup from the previous run, BUT, because of the use of hard links, each backup directory, contains either the file or the hard-link to the file in whichever directory it was actually backed up in. So to restore files, you don't have to pick and choose which directory or increment to restore them from, just what time stamp the backup should have that you are restoring. It's a great system and uses far less disk space than many other backup solutions. Setting The Backup To Run Automatically Once everything has been tested and we know that things will work without issue, the next step is to set up the crontab for the root user, so that all of this can be done automatically every day: sudo crontab -e If you haven't run this before, choose vim.basic as your editor or your own editor preference when the Select an editor line comes up. We are going to set our backup to automatically run at 11 PM, so we will add this to the crontab: ## Running the backup at 11 PM 00 23 * * * /usr/bin/rsnapshot -c /etc/rsnapshot.conf beta` Multiple Machine or Multiple Server Backups Doing backups of multiple machines from a machine with a RAID array or large storage capacity, either on premises or from across the Internet works very well. If running these backups from across the Internet, you need to make sure that both locations have adequate bandwidth for the backups to occur. You can use rsnapshot to synchronize an on-site server with an off-site backup array or backup server to improve data redundancy. Assumptions We are assuming that you are running rsnapshot from a machine remotely, on-premise. This exact configuration can be duplicated, as indicated above, remotely off-premise as well. In this case, you will want to install rsnapshot on the machine that is doing all of the backups. We are also assuming: That the servers you will be backing up to, have a firewall rule that allows the remote machine to SSH into it That each server that you will be backing up has a recent version of rsync installed. For Rocky Linux servers, run dnf install rsync to update your system's version of rsync . That you've either connected to the machine as the root user, or that you have run sudo -s to switch to the root user. SSH Public / Private Keys For the server that will be running the backups, we need to generate an SSH key-pair for use during the backups. For our example, we will be creating RSA keys. If you already have a set of keys generated, you can skip this step. You can find out by doing an ls -al .ssh and looking for an id_rsa and id_rsa.pub key pair. If none exists, use the following link to set up keys for your machine and the server(s) that you want to access: SSH Public Private Key Pairs Rsnapshot Configuration The configuration file needs to be just like the one we created for the Basic Machine or Single Server Backup above, except that we want to change some of the options. The snapshot root can be reverted back to the default like so: snapshot_root /.snapshots/ And this line: no_create_root 1 ... can be commented out again: #no_create_root 1 The other difference here is that each machine will have its very own configuration. Once you get used to this, you'll simply copy one of your existing configuration files over to a new name and then modify it to fit any additional machines that you want to backup. For now, we want to modify the configuration file just like we did above, and then save it. Then copy that file as a template for our first server: cp /etc/rsnapshot.conf /etc/rsnapshot_web.conf We want to modify the new configuration file and create the log and lockfile with the machine's name: logfile /var/log/rsnapshot_web.log lockfile /var/run/rsnapshot_web.pid Next, we want to modify rsnapshot_web.conf so that it includes the directories we want to back up. The only thing that is different here is the target. Here's an example of the web.ourdomain.com configuration: ### BACKUP POINTS / SCRIPTS ### backup root@web.ourourdomain.com:/etc/ web.ourourdomain.com/ backup root@web.ourourdomain.com:/var/www/ web.ourourdomain.com/ backup root@web.ourdomain.com:/usr/local/ web.ourdomain.com/ backup root@web.ourdomain.com:/home/ web.ourdomain.com/ backup root@web.ourdomain.com:/root/ web.ourdomain.com/ Checking The Configuration and Running The Initial Backup Just like before, we can now check the configuration to make sure it is syntactically correct: rsnapshot -c /etc/rsnapshot_web.conf configtest And just like before, we are looking for the Syntax OK message. If all is well, we can execute the backup manually: /usr/bin/rsnapshot -c /etc/rsnapshot_web.conf beta Assuming that everything works alright, we can then create the configuration files for the mail server (rsnapshot_mail.conf) and portal server (rsnapshot_portal.conf), test them, and do a trial backup. Automating The Backup Automating backups for the multiple machine/server version is slightly different. We want to create a bash script to call the backups in order. When one finishes the next will start. This script will look something like this and be stored in /usr/local/sbin: vi /usr/local/sbin/backup_all With the content: #!/bin/bash # script to run rsnapshot backups in succession /usr/bin/rsnapshot -c /etc/rsnapshot_web.conf beta /usr/bin/rsnapshot -c /etc/rsnapshot_mail.conf beta /usr/bin/rsnapshot -c /etc/rsnapshot_portal.conf beta Then we make the script executable: chmod +x /usr/local/sbin/backup_all Then create the crontab for root to run the backup script: crontab -e And add this line: ## Running the backup at 11 PM 00 23 * * * /usr/local/sbin/backup_all Reporting The Backup Status To make sure that everything is backing up according to plan, you might want to send the backup log files to your email. If your are running multiple machine backups using rsnapshot , each log file will have its own name, which you can then send to your email for review by Using the postfix For Server Process Reporting procedure. Restoring a Backup Restoring a backup, either a few files or a complete restore, involves copying the files you want from the directory with the date that you want to restore from back to your machine. Simple! Conclusions and Other Resources Getting the setup right with rsnapshot is a little daunting at first, but can save you loads of time backing up your machines or servers. rsnapshot is very powerful, very fast, and very economical on disk space usage. You can find more information on Rsnapshot, by visiting rsnapshot.org","title":"Backup Solution - Rsnapshot"},{"location":"guides/backup/rsnapshot_backup/#backup-solution-rsnapshot","text":"","title":"Backup Solution - Rsnapshot"},{"location":"guides/backup/rsnapshot_backup/#prerequisites","text":"Know how to install additional repositories and snapshots from the command-line Know about mounting filesystems external of your machine (external hard drive, remote filesystem, etc.) Know how to use an editor ( vi is used here, but you can use your favorite editor) Know a little BASH scripting Know how to modify the crontab for the root user Knowledge of SSH public and private keys (only if you plan to run remote backups from another server)","title":"Prerequisites"},{"location":"guides/backup/rsnapshot_backup/#introduction","text":"rsnapshot is a very powerful backup utility that can be installed on any Linux-based machine. It can either back up a machine locally, or you can back up multiple machines, say servers for instance, from a single machine. rsnapshot uses rsync and is written entirely in perl with no library dependencies, so there are no weird requirements to installing it. In the case of Rocky Linux, you should be able to install rsnapshot simply by installing the EPEL software repository. This documentation covers the installation of rsnapshot on Rocky Linux only.","title":"Introduction"},{"location":"guides/backup/rsnapshot_backup/#installing-rsnapshot","text":"All commands shown here are from the command-line on your server or workstation unless otherwise noted.","title":"Installing Rsnapshot"},{"location":"guides/backup/rsnapshot_backup/#installing-the-epel-repository","text":"We need the EPEL software repository from Fedora to install rsnapshot . To install the repository, just use this command: sudo dnf install epel-release The repository should now be active.","title":"Installing The EPEL repository"},{"location":"guides/backup/rsnapshot_backup/#install-the-rsnapshot-package","text":"Next, install rsnapshot itself: sudo dnf install rsnapshot If there are any missing dependencies, those will show up and you simply need to answer the prompt to continue. For example: dnf install rsnapshot Last metadata expiration check: 0:00:16 ago on Mon Feb 22 00:12:45 2021. Dependencies resolved. ======================================================================================================================================== Package Architecture Version Repository Size ======================================================================================================================================== Installing: rsnapshot noarch 1.4.3-1.el8 epel 121 k Installing dependencies: perl-Lchown x86_64 1.01-14.el8 epel 18 k rsync x86_64 3.1.3-9.el8 baseos 404 k Transaction Summary ======================================================================================================================================== Install 3 Packages Total download size: 543 k Installed size: 1.2 M Is this ok [y/N]: y","title":"Install the Rsnapshot Package"},{"location":"guides/backup/rsnapshot_backup/#mounting-a-drive-or-filesystem-for-backup","text":"In this step, we show how to mount a hard drive, such as an external USB hard drive, that will be used to back up your system. This particular step is only necessary if you are backing up a single machine or server, as seen in our first example below. Plug in the USB drive. Type dmesg | grep sd which should show you the drive you want to use. In this case, it'll be called sda1 . Example: EXT4-fs (sda1): mounting ext2 file system using the ext4 subsystem . Unfortunately (or fortunately depending on your opinion) most modern Linux desktop operating systems automount the drive if they can. This means that, depending on various factors, rsnapshot might lose track of the hard drive. We want the drive to \"mount\" or make its files available in the same place every time. To do that, take the drive information revealed in the dmesg command above and type mount | grep sda1 , which should show something like this: /dev/sda1 on /media/username/8ea89e5e-9291-45c1-961d-99c346a2628a Type sudo umount /dev/sda1 to unmount your external hard drive. Next, create a new mount point for the backup: sudo mkdir /mnt/backup Now mount the drive to your backup folder location: sudo mount /dev/sda1 /mnt/backup Now type mount | grep sda1 again, and you should see something like this: /dev/sda1 on /mnt/backup type ext2 (rw,relatime) Next create a directory that must exist for the backup to continue on the mounted drive. We are using a folder called \"storage\" for this example: sudo mkdir /mnt/backup/storage Note that for a single machine, you will have to either repeat the umount and mount steps each time the drive is plugged in again, or each time the system reboots, or automate these commands with a script. We recommend automation. Automation is the sysadmin way.","title":"Mounting A Drive or Filesystem For Backup"},{"location":"guides/backup/rsnapshot_backup/#configuring-rsnapshot","text":"This is the most important step. It's easy to make a mistake when making changes to the configuration file. The rsnapshot configuration requires tabs for any separation between elements, and a warning to that effect is at the very top of the configuration file. A space character will cause the entire configuration\u2014and your backup\u2014to fail. For instance, near the top of the configuration file is a section for the # SNAPSHOT ROOT DIRECTORY # . If you were adding this in from scratch, you would type snapshot_root then TAB and then type /whatever_the_path_to_the_snapshot_root_will_be/ The best thing is that the default configuration that comes with rsnapshot only needs minor changes to make it work for a backup of a local machine. It's always a good idea, though, to make a backup copy of the configuration file before you start editing: cp /etc/rsnapshot.conf /etc/rsnapshot.conf.bak","title":"Configuring rsnapshot"},{"location":"guides/backup/rsnapshot_backup/#basic-machine-or-single-server-backup","text":"In this case, rsnapshot is going to be run locally to back up a particular machine. In this example, we'll break down the configuration file, and show you exactly what you need to change. You will need to use vi (or edit with your favorite editor) to open the /etc/rsnapshot.conf file. The first thing to change is the snapshot_root setting which by default has this value: snapshot_root /.snapshots/ We need to change this to our mount point that we created above plus the addition of \"storage\". snapshot_root /mnt/backup/storage/ We also want to tell the backup NOT to run if the drive is not mounted. To do this, remove the \"#\" sign (also called a remark, pound sign, number sign, hash symbol, etc.) next to no_create_root so that it looks like this: no_create_root 1 Next go down to the section titled # EXTERNAL PROGRAM DEPENDENCIES # and remove the comment (again, the \"#\" sign) from this line: #cmd_cp /usr/bin/cp So that it now reads: cmd_cp /usr/bin/cp While we do not need cmd_ssh for this particular configuration, we will need it for our other option below and it doesn't hurt to have it enabled. So find the line that says: #cmd_ssh /usr/bin/ssh And remove the \"#\" sign so that it looks like this: cmd_ssh /usr/bin/ssh Next we need to skip down to the section titled # BACKUP LEVELS / INTERVALS # This has been changed from earlier versions of rsnapshot from hourly, daily, monthly, yearly to alpha, beta, gamma, delta . Which is a bit confusing. What you need to do is add a remark to any interval that you won't be using. In the configuration, delta is already remarked out. For this example, we aren't going to be running any other increments other than a nightly backup, so just add a remark to alpha and gamma so that the configuration looks like this when you are done: #retain alpha 6 retain beta 7 #retain gamma 4 #retain delta 3 Now skip down to the logfile line, which by default should read: #logfile /var/log/rsnapshot And remove the remark so that it is enabled: logfile /var/log/rsnapshot Finally, skip down to the ### BACKUP POINTS / SCRIPTS ### section and add any directories that you want to add in the # LOCALHOST section, remember to use TAB rather than SPACE between elements! For now write your changes ( SHIFT :wq! for vi ) and exit the configuration file.","title":"Basic Machine or Single Server Backup"},{"location":"guides/backup/rsnapshot_backup/#checking-the-configuration","text":"We want to make sure that we didn't add spaces or any other glaring errors to our configuration file while we were editing it. To do this, we run rsnapshot against our configuration with the configtest option: rsnapshot configtest will show Syntax OK if there are no errors in the configuration. You should get into the habit of running configtest against a particular configuration. The reason for that will be more evident when we get into the Multiple Machine or Multiple Server Backups section. To run configtest against a particular configuration file, run it with the -c option to specify the configuration: rsnapshot -c /etc/rsnapshot.conf configtest","title":"Checking The Configuration"},{"location":"guides/backup/rsnapshot_backup/#running-the-backup-the-first-time","text":"Everything has checked out, so it's time to go ahead and run the backup for the first time. You can run this in test mode first if you like, so that you can see what the backup script is going to do. Again, to do this you don't necessarily have to specify the configuration in this case, but you should get into the habit of doing so: rsnapshot -c /etc/rsnapshot.conf -t beta Which should return something like this, showing you what will happen when the backup is actually run: echo 1441 > /var/run/rsnapshot.pid mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded \\ /home/ /mnt/backup/storage/beta.0/localhost/ mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded /etc/ \\ /mnt/backup/storage/beta.0/localhost/ mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded \\ /usr/local/ /mnt/backup/storage/beta.0/localhost/ touch /mnt/backup/storage/beta.0/ Once you are satisfied with the test, go ahead and run it manually the first time without the test: rsnapshot -c /etc/rsnapshot.conf beta When the backup finishes, navigate to /mnt/backup and take a look at the directory structure that was created there. There will be a storage/beta.0/localhost directory, followed by the directories that you specified to backup.","title":"Running The Backup The First Time"},{"location":"guides/backup/rsnapshot_backup/#further-explanation","text":"Each time the backup is run, it will create a new beta increment, 0-6, or 7 days worth of backups. The newest backup will always be beta.0 whereas yesterday's backup will always be beta.1. The size of each of these backups will appear to take up the same amount (or more) of disk space, but this is because of rsnapshot's use of hard links. To restore files from yesterday's backup, you would simply copy them back from beta.1's directory structure. Each backup is only an incremental backup from the previous run, BUT, because of the use of hard links, each backup directory, contains either the file or the hard-link to the file in whichever directory it was actually backed up in. So to restore files, you don't have to pick and choose which directory or increment to restore them from, just what time stamp the backup should have that you are restoring. It's a great system and uses far less disk space than many other backup solutions.","title":"Further Explanation"},{"location":"guides/backup/rsnapshot_backup/#setting-the-backup-to-run-automatically","text":"Once everything has been tested and we know that things will work without issue, the next step is to set up the crontab for the root user, so that all of this can be done automatically every day: sudo crontab -e If you haven't run this before, choose vim.basic as your editor or your own editor preference when the Select an editor line comes up. We are going to set our backup to automatically run at 11 PM, so we will add this to the crontab: ## Running the backup at 11 PM 00 23 * * * /usr/bin/rsnapshot -c /etc/rsnapshot.conf beta`","title":"Setting The Backup To Run Automatically"},{"location":"guides/backup/rsnapshot_backup/#multiple-machine-or-multiple-server-backups","text":"Doing backups of multiple machines from a machine with a RAID array or large storage capacity, either on premises or from across the Internet works very well. If running these backups from across the Internet, you need to make sure that both locations have adequate bandwidth for the backups to occur. You can use rsnapshot to synchronize an on-site server with an off-site backup array or backup server to improve data redundancy.","title":"Multiple Machine or Multiple Server Backups"},{"location":"guides/backup/rsnapshot_backup/#assumptions","text":"We are assuming that you are running rsnapshot from a machine remotely, on-premise. This exact configuration can be duplicated, as indicated above, remotely off-premise as well. In this case, you will want to install rsnapshot on the machine that is doing all of the backups. We are also assuming: That the servers you will be backing up to, have a firewall rule that allows the remote machine to SSH into it That each server that you will be backing up has a recent version of rsync installed. For Rocky Linux servers, run dnf install rsync to update your system's version of rsync . That you've either connected to the machine as the root user, or that you have run sudo -s to switch to the root user.","title":"Assumptions"},{"location":"guides/backup/rsnapshot_backup/#ssh-public-private-keys","text":"For the server that will be running the backups, we need to generate an SSH key-pair for use during the backups. For our example, we will be creating RSA keys. If you already have a set of keys generated, you can skip this step. You can find out by doing an ls -al .ssh and looking for an id_rsa and id_rsa.pub key pair. If none exists, use the following link to set up keys for your machine and the server(s) that you want to access: SSH Public Private Key Pairs","title":"SSH Public / Private Keys"},{"location":"guides/backup/rsnapshot_backup/#rsnapshot-configuration","text":"The configuration file needs to be just like the one we created for the Basic Machine or Single Server Backup above, except that we want to change some of the options. The snapshot root can be reverted back to the default like so: snapshot_root /.snapshots/ And this line: no_create_root 1 ... can be commented out again: #no_create_root 1 The other difference here is that each machine will have its very own configuration. Once you get used to this, you'll simply copy one of your existing configuration files over to a new name and then modify it to fit any additional machines that you want to backup. For now, we want to modify the configuration file just like we did above, and then save it. Then copy that file as a template for our first server: cp /etc/rsnapshot.conf /etc/rsnapshot_web.conf We want to modify the new configuration file and create the log and lockfile with the machine's name: logfile /var/log/rsnapshot_web.log lockfile /var/run/rsnapshot_web.pid Next, we want to modify rsnapshot_web.conf so that it includes the directories we want to back up. The only thing that is different here is the target. Here's an example of the web.ourdomain.com configuration: ### BACKUP POINTS / SCRIPTS ### backup root@web.ourourdomain.com:/etc/ web.ourourdomain.com/ backup root@web.ourourdomain.com:/var/www/ web.ourourdomain.com/ backup root@web.ourdomain.com:/usr/local/ web.ourdomain.com/ backup root@web.ourdomain.com:/home/ web.ourdomain.com/ backup root@web.ourdomain.com:/root/ web.ourdomain.com/","title":"Rsnapshot Configuration"},{"location":"guides/backup/rsnapshot_backup/#checking-the-configuration-and-running-the-initial-backup","text":"Just like before, we can now check the configuration to make sure it is syntactically correct: rsnapshot -c /etc/rsnapshot_web.conf configtest And just like before, we are looking for the Syntax OK message. If all is well, we can execute the backup manually: /usr/bin/rsnapshot -c /etc/rsnapshot_web.conf beta Assuming that everything works alright, we can then create the configuration files for the mail server (rsnapshot_mail.conf) and portal server (rsnapshot_portal.conf), test them, and do a trial backup.","title":"Checking The Configuration and Running The Initial Backup"},{"location":"guides/backup/rsnapshot_backup/#automating-the-backup","text":"Automating backups for the multiple machine/server version is slightly different. We want to create a bash script to call the backups in order. When one finishes the next will start. This script will look something like this and be stored in /usr/local/sbin: vi /usr/local/sbin/backup_all With the content: #!/bin/bash # script to run rsnapshot backups in succession /usr/bin/rsnapshot -c /etc/rsnapshot_web.conf beta /usr/bin/rsnapshot -c /etc/rsnapshot_mail.conf beta /usr/bin/rsnapshot -c /etc/rsnapshot_portal.conf beta Then we make the script executable: chmod +x /usr/local/sbin/backup_all Then create the crontab for root to run the backup script: crontab -e And add this line: ## Running the backup at 11 PM 00 23 * * * /usr/local/sbin/backup_all","title":"Automating The Backup"},{"location":"guides/backup/rsnapshot_backup/#reporting-the-backup-status","text":"To make sure that everything is backing up according to plan, you might want to send the backup log files to your email. If your are running multiple machine backups using rsnapshot , each log file will have its own name, which you can then send to your email for review by Using the postfix For Server Process Reporting procedure.","title":"Reporting The Backup Status"},{"location":"guides/backup/rsnapshot_backup/#restoring-a-backup","text":"Restoring a backup, either a few files or a complete restore, involves copying the files you want from the directory with the date that you want to restore from back to your machine. Simple!","title":"Restoring a Backup"},{"location":"guides/backup/rsnapshot_backup/#conclusions-and-other-resources","text":"Getting the setup right with rsnapshot is a little daunting at first, but can save you loads of time backing up your machines or servers. rsnapshot is very powerful, very fast, and very economical on disk space usage. You can find more information on Rsnapshot, by visiting rsnapshot.org","title":"Conclusions and Other Resources"},{"location":"guides/backup/rsync_ssh/","tags":["synchronization","rsync"],"text":"Using rsync To Keep Two Machines Synchronized Prerequisites This is everything you'll need to understand and follow along with this guide. A machine running Rocky Linux. To be comfortable with modifying configuration files from the command-line. Knowledge of how to use a command line editor (we use vi here, but you could use your favorite editor). You will need root access, and ideally be signed in as the root user in your terminal. Public and Private SSH key pairs. Able to create a simple bash script, using vi or your favorite editor, and test it. Able to use crontab to automate the running of the script. Introduction Using rsync over SSH is neither as powerful as lsyncd (which allows you to watch a directory or file for changes and keep it synchronized in real time), or as flexible as rsnapshot (which offers the ability to easily backup multiple targets from a single machine). However, it does provide the ability to keep two computers up to date on a schedule that you define. If you need to keep a set of directories on the target computer up to date, and you don't care about real-time synchronization as a feature, then rsync over SSH is probably the best solution. For all of the below, we will be doing things as the root user, so either login as root or use the sudo -s command to switch to the root user in your terminal. Installing rsync Although rsync may already be installed, it is best to update rsync to the latest version on the source and target computers. To ensure that rsync is installed and up to date, do the following on both computers: dnf install rsync If the package is not installed, dnf will ask you to confirm the installation, if it is already installed, dnf will look for an update and prompt to install it. Preparing The Environment This particular example will use rsync on the target machine to pull from the source instead of pushing from the source to the target, so you need to set up an SSH key pair for this . Once the SSH key pair has been created and password-free access from the target computer to the source computer has been confirmed, you can start. rsync Parameters And Setting Up A Script Before we get terribly carried away with setting up a script, we first need to decide what parameters we want to use with rsync . There are many possibilities, so take a look at the manual for rsync . The most common way to use rsync is to use the -a option, because -a , or archive, combines a number of options into one and these are very common options. What does -a include? -r, recurse the directories -l, maintain symbolic links as symbolic links -p, preserve permissions -t, preserve modification times -g, preserve group- -o, preserve owner -D, preserve device files The only other options that we need to specify in this example is: -e, specify the remote shell to use --delete, which says if the target directory has a file in it that doesn't exist on the source, get rid of it Next, we need to set up a script by creating a file for it. (Again, use your favorite editor if you are not familiar with vi.) To create the file, just use this command: vi /usr/local/sbin/rsync_dirs And then make it executable: chmod +x /usr/local/sbin/rsync_dirs Testing Now, scripting makes it super simple and safe so that you can test it fearlessly. Please note that the URL used below is \"Soure.domain.com\". Replace it with the domain or IP address of your own source computer, both will work. Also remember that in this example, the script is created on the \"target\" computer, because the file is pulled from the source computer: #!/bin/bash /usr/bin/rsync -ae ssh --delete root@source.domain.com:/home/your_user /home !!! attention In this case, we assume that your home directory does not exist on the target machine. **If it exists, you may want to back it up before executing the script!** Now run the script: /usr/local/sbin/rsync_dirs If all is well, you should get a completely synchronized copy of your home directory on the target machine. Check to be sure this is the case. Assuming all of that worked out as we hoped, go ahead and create a new file on the source machine in your home directory: touch /home/your_user/testfile.txt Run the script again: /usr/local/sbin/rsync_dirs Then verify that the target computer receives the new file. If so, the next step is to check the deletion process. Delete the file we just created on the source computer: rm -f /home/your_user/testfile.txt Run the script again: /usr/local/sbin/rsync_dirs Verify that the file no longer exists on the target computer. Finally, let's create a file on the target machine that doesn't exist on the source. So on the target: touch /home/your_user/a_different_file.txt Run the script a final time: /usr/local/sbin/rsync_dirs The file we just created on the target should now be gone, because it does not exist on the source. Assuming all of this worked as expected, go ahead and modify the script to synchronize all the directories that you want. Automating Everything We may not want to manually run this script every time we want to synchronize, so the next step is to do this automatically. Suppose you want to run this script at 11 PM every night. To automate this, use crontab: crontab -e This will pull up the cron, which may look something like this: # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any'). # # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command The cron is set up on a 24 hour clock, so what we will need for our entry at the bottom of this file is: 00 23 * * * /usr/local/sbin/rsync_dirs What this says is to run this command at 00 minutes, 23 hundred hours, every day, every month, and every day of the week. Save your cron entry with: Shift : wq! ... or with the commands that your favorite editor uses for saving a file. Conclusions Although rsync is not as flexible or powerful as other tools, it provides simple file synchronization, which is always useful.","title":"Synchronization With rsync"},{"location":"guides/backup/rsync_ssh/#using-rsync-to-keep-two-machines-synchronized","text":"","title":"Using rsync To Keep Two Machines Synchronized"},{"location":"guides/backup/rsync_ssh/#prerequisites","text":"This is everything you'll need to understand and follow along with this guide. A machine running Rocky Linux. To be comfortable with modifying configuration files from the command-line. Knowledge of how to use a command line editor (we use vi here, but you could use your favorite editor). You will need root access, and ideally be signed in as the root user in your terminal. Public and Private SSH key pairs. Able to create a simple bash script, using vi or your favorite editor, and test it. Able to use crontab to automate the running of the script.","title":"Prerequisites"},{"location":"guides/backup/rsync_ssh/#introduction","text":"Using rsync over SSH is neither as powerful as lsyncd (which allows you to watch a directory or file for changes and keep it synchronized in real time), or as flexible as rsnapshot (which offers the ability to easily backup multiple targets from a single machine). However, it does provide the ability to keep two computers up to date on a schedule that you define. If you need to keep a set of directories on the target computer up to date, and you don't care about real-time synchronization as a feature, then rsync over SSH is probably the best solution. For all of the below, we will be doing things as the root user, so either login as root or use the sudo -s command to switch to the root user in your terminal.","title":"Introduction"},{"location":"guides/backup/rsync_ssh/#installing-rsync","text":"Although rsync may already be installed, it is best to update rsync to the latest version on the source and target computers. To ensure that rsync is installed and up to date, do the following on both computers: dnf install rsync If the package is not installed, dnf will ask you to confirm the installation, if it is already installed, dnf will look for an update and prompt to install it.","title":"Installing rsync"},{"location":"guides/backup/rsync_ssh/#preparing-the-environment","text":"This particular example will use rsync on the target machine to pull from the source instead of pushing from the source to the target, so you need to set up an SSH key pair for this . Once the SSH key pair has been created and password-free access from the target computer to the source computer has been confirmed, you can start.","title":"Preparing The Environment"},{"location":"guides/backup/rsync_ssh/#rsync-parameters-and-setting-up-a-script","text":"Before we get terribly carried away with setting up a script, we first need to decide what parameters we want to use with rsync . There are many possibilities, so take a look at the manual for rsync . The most common way to use rsync is to use the -a option, because -a , or archive, combines a number of options into one and these are very common options. What does -a include? -r, recurse the directories -l, maintain symbolic links as symbolic links -p, preserve permissions -t, preserve modification times -g, preserve group- -o, preserve owner -D, preserve device files The only other options that we need to specify in this example is: -e, specify the remote shell to use --delete, which says if the target directory has a file in it that doesn't exist on the source, get rid of it Next, we need to set up a script by creating a file for it. (Again, use your favorite editor if you are not familiar with vi.) To create the file, just use this command: vi /usr/local/sbin/rsync_dirs And then make it executable: chmod +x /usr/local/sbin/rsync_dirs","title":"rsync Parameters And Setting Up A Script"},{"location":"guides/backup/rsync_ssh/#testing","text":"Now, scripting makes it super simple and safe so that you can test it fearlessly. Please note that the URL used below is \"Soure.domain.com\". Replace it with the domain or IP address of your own source computer, both will work. Also remember that in this example, the script is created on the \"target\" computer, because the file is pulled from the source computer: #!/bin/bash /usr/bin/rsync -ae ssh --delete root@source.domain.com:/home/your_user /home !!! attention In this case, we assume that your home directory does not exist on the target machine. **If it exists, you may want to back it up before executing the script!** Now run the script: /usr/local/sbin/rsync_dirs If all is well, you should get a completely synchronized copy of your home directory on the target machine. Check to be sure this is the case. Assuming all of that worked out as we hoped, go ahead and create a new file on the source machine in your home directory: touch /home/your_user/testfile.txt Run the script again: /usr/local/sbin/rsync_dirs Then verify that the target computer receives the new file. If so, the next step is to check the deletion process. Delete the file we just created on the source computer: rm -f /home/your_user/testfile.txt Run the script again: /usr/local/sbin/rsync_dirs Verify that the file no longer exists on the target computer. Finally, let's create a file on the target machine that doesn't exist on the source. So on the target: touch /home/your_user/a_different_file.txt Run the script a final time: /usr/local/sbin/rsync_dirs The file we just created on the target should now be gone, because it does not exist on the source. Assuming all of this worked as expected, go ahead and modify the script to synchronize all the directories that you want.","title":"Testing"},{"location":"guides/backup/rsync_ssh/#automating-everything","text":"We may not want to manually run this script every time we want to synchronize, so the next step is to do this automatically. Suppose you want to run this script at 11 PM every night. To automate this, use crontab: crontab -e This will pull up the cron, which may look something like this: # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any'). # # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command The cron is set up on a 24 hour clock, so what we will need for our entry at the bottom of this file is: 00 23 * * * /usr/local/sbin/rsync_dirs What this says is to run this command at 00 minutes, 23 hundred hours, every day, every month, and every day of the week. Save your cron entry with: Shift : wq! ... or with the commands that your favorite editor uses for saving a file.","title":"Automating Everything"},{"location":"guides/backup/rsync_ssh/#conclusions","text":"Although rsync is not as flexible or powerful as other tools, it provides simple file synchronization, which is always useful.","title":"Conclusions"},{"location":"guides/cms/cloud_server_using_nextcloud/","tags":["cloud","nextcloud"],"text":"Cloud Server Using Nextcloud Prerequisites And Assumptions Server running Rocky Linux (you can install Nextcloud on any Linux distribution, but this procedure will assume you're using Rocky). A high degree of comfort operating from the command line for installation and for configuration. Knowledge of a command-line editor. For this example, we are using vi , but you can use your favorite editor if you have one. While Nextcloud can be installed via a snap application, we will be documenting two installation methods, the module and the .zip file. We will be applying concepts from the Apache \"sites enabled\" document (linked to down below) for directory setup in the .zip file method. We will also be using the mariadb-server hardening procedure (also linked to later) for database setup. Throughout this document we will assume that you are root, or that you can be by using sudo . We are using an example domain of \"yourdomain.com\" in the .zip file method. Introduction If you are in charge of a server environment for a large (or even a small) company, you may be tempted by cloud applications. Doing things in the cloud can free up your own resources for other things, but there is a downside to this, and that is the loss of control of your company's data. If the cloud application is compromised, so too may be your company's data. Taking the cloud back into your own environment is a way to reclaim security of your data at the expense of your time and energy. Sometimes, that is a cost worth paying. Nextcloud offers an open source cloud with security and flexibility in mind. Note that building a Nextcloud server is a good exercise, even if you opt to take your cloud off-site in the end. The following procedure deals with setting up Nextcloud on Rocky Linux. Common Procedures Needed In For Both Installations There are several steps here that are the same regardless of which install method you are using. These are installing the EPEL and Remi repositories, configuring PHP, and setting up mariadb. I will link back to these procedures within the .zip file installation method (second method). Just be aware of this. Nextcloud - Module Method Why use the Nextcloud module? After enabling the module we can then install Nextcloud, which will download nearly all of the dependencies for you. You will still have to install your database of choice (mariadb, postgresql, or sqlite) but your web platform will be handled by the Nextcloud packages, as well as any back-end scripts. The downside to this particular method is that you lose control over where you want Nextcloud to install. When operating a bunch of servers or containers with web applications on them, a Systems Administrator would prefer to look for things in the same spot, not try to keep up with where package 'A' installed itself as opposed to package 'B'. Installing And Configuring Repositories and Modules For this installation, we will require two repositories. We need to install the EPEL (Extra Packages for Enterprise Linux), and the Remi Repository for PHP 8.0 (a minimum of version 7.3 or 7.4 is required and the Rocky Linux version of 7.4 (not enabled by default) does not contain all of the packages that Nextcloud needs. We are going to use PHP 8.0 from the Remi repository instead. To install the EPEL run: dnf install epel-release To install the Remi repository run: dnf install https://rpms.remirepo.net/enterprise/remi-release-8.rpm Then run dnf update again. Run the following to see a list of php modules that can be enabled: dnf module list php Rocky Linux 8 - AppStream Name Stream Profiles Summary php 7.2 [d] common [d], devel, minimal PHP scripting language php 7.3 common [d], devel, minimal PHP scripting language php 7.4 common [d], devel, minimal PHP scripting language php 7.4 common [d], devel, minimal PHP scripting language Remi's Modular repository for Enterprise Linux 8 - x86_64 Name Stream Profiles Summary php remi-7.2 common [d], devel, minimal PHP scripting language php remi-7.3 common [d], devel, minimal PHP scripting language php remi-7.4 common [d], devel, minimal PHP scripting language php remi-8.0 common [d], devel, minimal PHP scripting language php remi-8.1 common [d], devel, minimal PHP scripting language Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled We want to grab the newest PHP that Nextcloud is compatible with, which at this moment is 8.0, so we will enable that module by doing: dnf module enable php:remi-8.0 To see how this changes the output of the module list, run the module list command again and you will see the \"[e]\" next to 8.0: dnf module list php And the output again is the same except for this line: php remi-8.0 [e] common [d], devel, minimal PHP scripting language The final step is to enable the stable version of Nextcloud from the modules. This is as easy as: dnf module enable nextcloud:nextcloud-stable Installing Packages To see what enabling the Nextcloud module will offer for you to install, do the following: dnf list available | grep nextcloud which will show you output like this: nextcloud.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-client.x86_64 3.2.4-2.el8 epel nextcloud-client-devel.x86_64 3.2.4-2.el8 epel nextcloud-client-dolphin.x86_64 3.2.4-2.el8 epel nextcloud-client-libs.x86_64 3.2.4-2.el8 epel nextcloud-client-nautilus.x86_64 3.2.4-2.el8 epel nextcloud-httpd.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-mysql.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-nginx.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-postgresql.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-sqlite.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular Our example here uses Apache and mariadb, so to install what we need, we simply need to do the following: dnf install nextcloud nextcloud-httpd nextcloud-mysql mariadb-server Configuring Configuring Apache Set apache to start on boot: systemctl enable httpd Then start it: systemctl start httpd When you install Nextcloud using the module, the configuration is created for you. In fact, there are multiple configurations. You can find these by looking in conf.d directory like this: ls -al /etc/httpd/conf.d which should show you output similar to this: -rw-r--r--. 1 root root 400 Nov 15 03:13 README -rw-r--r--. 1 root root 2926 Nov 15 03:13 autoindex.conf -rw-r--r--. 1 root root 994 Jul 14 2021 nextcloud-access.conf.avail -rw-r--r--. 1 root root 278 Jul 14 2021 nextcloud-auth-any.inc -rw-r--r--. 1 root root 313 Jul 14 2021 nextcloud-auth-local.inc -rw-r--r--. 1 root root 263 Jul 14 2021 nextcloud-auth-none.inc -rw-r--r--. 1 root root 2407 Jul 14 2021 nextcloud-defaults.inc -rw-r--r--. 1 root root 1893 Jul 14 2021 nextcloud.conf -rw-r--r--. 1 root root 1668 Dec 16 06:57 php.conf -rw-r--r--. 1 root root 1252 Nov 15 03:10 userdir.conf -rw-r--r--. 1 root root 574 Nov 15 03:10 welcome.conf The primary configuration here for Nextcloud is nextcloud.conf , but you should review the rest of these files. There are instructions on how to use them at the top of each file. In our lab installation, the localhost is not available from any web interface. If you look at the top of the nextcloud-access.conf.avail you will see a warning to enable this only after the admin account and initial installation have been complete. Since this is not possible in the lab instance, we are doing this early: ln -s /etc/httpd/conf.d/nextcloud-access.conf.avail /etc/httpd/conf.d/z-nextcloud-access.conf We also need a special empty file so that we can install Nextcloud. This file resides in /etc/nextcloud and is called CAN_INSTALL. To create it, simply do the following: touch /etc/nextcloud/CAN_INSTALL Configuring PHP We need to set the timezone for PHP. To do this, open up php.ini with your text editor of choice: vi /etc/php.ini Then find the line: ;date.timezone = We need to remove the remark (;) and set our timezone. For our example timezone, we would put in either: date.timezone = \"America/Chicago\" OR date.timezone = \"US/Central\" Then save an exit the php.ini file. Note that for the sake of keeping things the same, your timezone in the php.ini file should match up to your machine's timezone setting. You can find out what this is set to by doing the following: ls -al /etc/localtime Which should show you something like this, assuming you set your timezone when you installed Rocky Linux and are living in the Central time zone: /etc/localtime -> /usr/share/zoneinfo/America/Chicago Configuring mariadb-server Set mariadb-server to start on boot: systemctl enable mariadb And then start it: systemctl restart mariadb Again, as indicated earlier, we will be using the setup procedure for hardening mariadb-server found here for the initial configuration. Configuring Nextcloud Now comes the fun! First, make sure that you have your services running. If you followed the above steps, they should already be running. We have had several steps between those initial service starts, so let's go ahead and restart them, just to be sure: systemctl restart httpd systemctl restart mariadb If everything restarts and there are no issues, then you are ready to move on. To do the initial configuration, we want to actually load the site in a web browser. In our lab instance, we've got no hostname set up, so we are going to the site by IP address like this: http://192.168.1.108/nextcloud Assuming that you've done everything correctly so far, you should be presented with a Nextcloud setup screen: There are a couple of things that we want to do differently than the defaults that show up: At the top of the web page, where it says \"Create an admin account\", set the user and password. For the sake of this document, we are entering \"admin\" and setting a strong password. Remember to save this somewhere safe (like a password manager) so that you don't lose it! Even though you have typed into this field, don't hit 'Enter' until we have done all of the setup fields! Under the \"Configure the database\" section, change from \"SQLite\" to \"MySQL/MariaDB\" by clicking on that button. Type the MariaDB root user and password that you set earlier into the \"Database user\" and \"Database password\" fields In the \"Database name\" field, type \"nextcloud\" In the \"localhost\" field, type \"localhost:3306\" (3306 is the default mariadb connect port) Once you have all this, click Finish Setup and you should be up and running. Notes for the Systems Administrator As noted earlier, if using the module install for Nextcloud, Nextcloud is going to put things where it thinks they should be, not where the Systems Administrator might go looking for them. For this reason, as part of the setup steps, I recommend that a README.txt file be created in each location where the Systems Administrator would logically look. I came from an environment where we used /etc/httpd/sites-enabled for configuration files (see the alternate install steps for more) and put our web files in /var/www/sub-domains/[site_name]/html . If I were to use the module install of Nextcloud, then, I would want to put a README.txt file in both locations. The README.txt file in /etc/httpd/sites-enabled/ might contain: Nextcloud was installed using the module. You can find the configuration in /etc/httpd/conf.d/nextcloud.conf While the README.txt file in /var/www/sub-domains/[site_name]/html might contain: Nextcloud was installed using the module. You can find the web files in /usr/share/nextcloud Nextcloud .zip Install If the module install is so easy, why consider using the .zip file install method? The reason is environment control. As noted in the Nextcloud module install procedure, Nextcloud chooses where to put the web files, where to put the configuration files, and most of the remaining setup options. Using the .zip file install method is definitely more intensive than the module install method, but it does give the Systems Administrator more control over where things will end up. Installing And Configuring Repositories (same procedure) This is done exactly the same way as the with the module install procedure . Installing Packages We need a lot of packages installed. Some of these may already be installed with your default Rocky Linux installation, but make sure by running the following command the following: dnf install httpd mariadb-server vim wget zip unzip libxml2 openssl php80-php php80-php-ctype php80-php-curl php80-php-gd php80-php-iconv php80-php-json php80-php-libxml php80-php-mbstring php80-php-openssl php80-php-posix php80-php-session php80-php-xml php80-php-zip php80-php-zlib php80-php-pdo php80-php-mysqlnd php80-php-intl php80-php-bcmath php80-php-gmp Configuring Packages And Directories Configuring apache Set apache to start on boot: systemctl enable httpd As noted earlier, we are using the \"Apache Sites Enabled\" procedure found here to configure Apache. Follow that guide to get the configuration directories setup and the httpd.conf file modified and then return to this document for the remaining steps. Create The Configuration For Nextcloud, we will need to create the following configuration file. vi /etc/httpd/sites-available/com.yourdomain.nextcloud Your configuration file should look something like this: <VirtualHost *:80> DocumentRoot /var/www/sub-domains/com.yourdomain.nextcloud/html/ ServerName nextcloud.yourdomain.com <Directory /var/www/sub-domains/com.yourdomain.nextcloud/html/> Require all granted AllowOverride All Options FollowSymLinks MultiViews <IfModule mod_dav.c> Dav off </IfModule> </Directory> </VirtualHost> Once done, save your changes (with SHIFT:wq! for vi ). Next, create a link to this file in /etc/httpd/sites-enabled: ln -s /etc/httpd/sites-available/com.yourdomain.nextcloud /etc/httpd/sites-enabled/ Creating The Directory As noted in the configuration above, the DocumentRoot needs to be created. This can be done by: mkdir -p /var/www/sub-domains/com.yourdomain.com/html This is where our Nextcloud instance will be installed. Configure PHP (same procedure) This is done exactly like the module install procedure . Configure Mariadb (same procedure) This is done exactly like the module install procedure . Installing Nextcloud This install method for Nextcloud uses the server install .zip file. Get The Nextcloud .zip File And Unzip The next few steps assume that you are remotely connected to your Nextcloud server via ssh with a remote console open: Navigate to the Nextcloud web site Let your mouse hover over \"Get Nextcloud\" which will bring up a drop down menu. Click on \"Server Packages\". Right-click on \"Download Nextcloud\" and copy the link address. (the exact syntax of this is different browser to browser) In your remote console on the Nextcloud server, type \"wget\" and then a space and paste in what you just copied. You should get something like the following: wget https://download.nextcloud.com/server/releases/nextcloud-21.0.1.zip Once you hit enter, the download of the .zip file will start and will be completed fairly quickly. Once the download is complete, unzip the Nextcloud zip file by using the following: unzip nextcloud-21.0.1.zip Copying Content And Changing Permissions After completing the unzip step, you should now have a new directory in /root called \"nextcloud.\" Change into this directory: cd nextcloud And either copy or move the content to our DocumentRoot : cp -Rf * /var/www/sub-domains/com.yourdomain.nextcloud/html/ OR mv * /var/www/sub-domains/com.yourdomain.nextcloud/html/ Now that everything is where it should be, the next step is to make sure that apache owns the directory. To do this, run: chown -Rf apache.apache /var/www/sub-domains/com.yourdomain.nextcloud/html For security reasons, we also want to move the \"data\" folder from inside to outside of the DocumentRoot . Do this with the following command: mv /var/www/sub-domains/com.yourdomain.nextcloud/html/data /var/www/sub-domains/com.yourdomain.nextcloud/ Configuring Nextcloud Now comes the fun! First, make sure that you have your services running. If you followed the above steps, they should already be running. We have had several steps between those initial service starts, so let's go ahead and restart them, just to be sure: systemctl restart httpd systemctl restart mariadb If everything restarts and there are no issues, then you are ready to move on. To do the initial configuration, we want to actually load the site in a web browser: http://nextcloud.yourdomain.com/ And you should see this screen: There are a couple of things that we want to do differently than the defaults that show up: At the top of the web page, where it says \"Create an admin account\", set the user and password. For the sake of this document, we are entering \"admin\" and setting a strong password. Remember to save this somewhere safe (like a password manager) so that you don't lose it! Even though you have typed into this field, don't hit 'Enter' until we have done all of the setup fields! Under the \"Storage & database\" section, change the \"Data folder\" location from the default document root, to where we moved the data folder earlier: /var/www/sub-domains/com.yourdomain.nextcloud/data Under the \"Configure the database\" section, change from \"SQLite\" to \"MySQL/MariaDB\" by clicking on that button. Type the MariaDB root user and password that you set earlier into the \"Database user\" and \"Database password\" fields In the \"Database name\" field, type \"nextcloud\" In the \"localhost\" field, type \"localhost:3306\" (3306 is the default mariadb connect port) Now cross your fingers and click \"Finish Setup\". The browser window will refresh for a bit and then usually not reload the site. Enter your URL in the browser window again and you should be confronted with the default first pages. Your administrative user is already (or should be) logged in at this point, and there are several informational pages designed to get you up to speed. The \"Dashboard\" is what users will see when they first login. The administrative user can now create other users, install other applications and many other tasks. The \"Nextcloud Manual.pdf\" file is the user manual, so that users can get familiar with what is available. The administrative user should read through or at least scan the high points of the admin manual On the Nextcloud web site Next Steps At this point, don't forget that this is a server that you will be storing company data on. It's important to get it locked down with a firewall, get the backups setup , secure the site with an SSL , and any other duties that are required to keep your data safe. Conclusions A decision to take the company cloud in house is one that needs to be evaluated carefully. For those that decide that keeping company data locally is preferable over an external cloud host, Nextcloud is a good alternative.","title":"Cloud Server Using Nextcloud"},{"location":"guides/cms/cloud_server_using_nextcloud/#cloud-server-using-nextcloud","text":"","title":"Cloud Server Using Nextcloud"},{"location":"guides/cms/cloud_server_using_nextcloud/#prerequisites-and-assumptions","text":"Server running Rocky Linux (you can install Nextcloud on any Linux distribution, but this procedure will assume you're using Rocky). A high degree of comfort operating from the command line for installation and for configuration. Knowledge of a command-line editor. For this example, we are using vi , but you can use your favorite editor if you have one. While Nextcloud can be installed via a snap application, we will be documenting two installation methods, the module and the .zip file. We will be applying concepts from the Apache \"sites enabled\" document (linked to down below) for directory setup in the .zip file method. We will also be using the mariadb-server hardening procedure (also linked to later) for database setup. Throughout this document we will assume that you are root, or that you can be by using sudo . We are using an example domain of \"yourdomain.com\" in the .zip file method.","title":"Prerequisites And Assumptions"},{"location":"guides/cms/cloud_server_using_nextcloud/#introduction","text":"If you are in charge of a server environment for a large (or even a small) company, you may be tempted by cloud applications. Doing things in the cloud can free up your own resources for other things, but there is a downside to this, and that is the loss of control of your company's data. If the cloud application is compromised, so too may be your company's data. Taking the cloud back into your own environment is a way to reclaim security of your data at the expense of your time and energy. Sometimes, that is a cost worth paying. Nextcloud offers an open source cloud with security and flexibility in mind. Note that building a Nextcloud server is a good exercise, even if you opt to take your cloud off-site in the end. The following procedure deals with setting up Nextcloud on Rocky Linux.","title":"Introduction"},{"location":"guides/cms/cloud_server_using_nextcloud/#common-procedures-needed-in-for-both-installations","text":"There are several steps here that are the same regardless of which install method you are using. These are installing the EPEL and Remi repositories, configuring PHP, and setting up mariadb. I will link back to these procedures within the .zip file installation method (second method). Just be aware of this.","title":"Common Procedures Needed In For Both Installations"},{"location":"guides/cms/cloud_server_using_nextcloud/#nextcloud-module-method","text":"Why use the Nextcloud module? After enabling the module we can then install Nextcloud, which will download nearly all of the dependencies for you. You will still have to install your database of choice (mariadb, postgresql, or sqlite) but your web platform will be handled by the Nextcloud packages, as well as any back-end scripts. The downside to this particular method is that you lose control over where you want Nextcloud to install. When operating a bunch of servers or containers with web applications on them, a Systems Administrator would prefer to look for things in the same spot, not try to keep up with where package 'A' installed itself as opposed to package 'B'.","title":"Nextcloud - Module Method"},{"location":"guides/cms/cloud_server_using_nextcloud/#installing-and-configuring-repositories-and-modules","text":"For this installation, we will require two repositories. We need to install the EPEL (Extra Packages for Enterprise Linux), and the Remi Repository for PHP 8.0 (a minimum of version 7.3 or 7.4 is required and the Rocky Linux version of 7.4 (not enabled by default) does not contain all of the packages that Nextcloud needs. We are going to use PHP 8.0 from the Remi repository instead. To install the EPEL run: dnf install epel-release To install the Remi repository run: dnf install https://rpms.remirepo.net/enterprise/remi-release-8.rpm Then run dnf update again. Run the following to see a list of php modules that can be enabled: dnf module list php Rocky Linux 8 - AppStream Name Stream Profiles Summary php 7.2 [d] common [d], devel, minimal PHP scripting language php 7.3 common [d], devel, minimal PHP scripting language php 7.4 common [d], devel, minimal PHP scripting language php 7.4 common [d], devel, minimal PHP scripting language Remi's Modular repository for Enterprise Linux 8 - x86_64 Name Stream Profiles Summary php remi-7.2 common [d], devel, minimal PHP scripting language php remi-7.3 common [d], devel, minimal PHP scripting language php remi-7.4 common [d], devel, minimal PHP scripting language php remi-8.0 common [d], devel, minimal PHP scripting language php remi-8.1 common [d], devel, minimal PHP scripting language Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled We want to grab the newest PHP that Nextcloud is compatible with, which at this moment is 8.0, so we will enable that module by doing: dnf module enable php:remi-8.0 To see how this changes the output of the module list, run the module list command again and you will see the \"[e]\" next to 8.0: dnf module list php And the output again is the same except for this line: php remi-8.0 [e] common [d], devel, minimal PHP scripting language The final step is to enable the stable version of Nextcloud from the modules. This is as easy as: dnf module enable nextcloud:nextcloud-stable","title":"Installing And Configuring Repositories and Modules"},{"location":"guides/cms/cloud_server_using_nextcloud/#installing-packages","text":"To see what enabling the Nextcloud module will offer for you to install, do the following: dnf list available | grep nextcloud which will show you output like this: nextcloud.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-client.x86_64 3.2.4-2.el8 epel nextcloud-client-devel.x86_64 3.2.4-2.el8 epel nextcloud-client-dolphin.x86_64 3.2.4-2.el8 epel nextcloud-client-libs.x86_64 3.2.4-2.el8 epel nextcloud-client-nautilus.x86_64 3.2.4-2.el8 epel nextcloud-httpd.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-mysql.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-nginx.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-postgresql.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular nextcloud-sqlite.noarch 22.0.0-2.module_el8+12398+2facbd17 epel-modular Our example here uses Apache and mariadb, so to install what we need, we simply need to do the following: dnf install nextcloud nextcloud-httpd nextcloud-mysql mariadb-server","title":"Installing Packages"},{"location":"guides/cms/cloud_server_using_nextcloud/#configuring","text":"","title":"Configuring"},{"location":"guides/cms/cloud_server_using_nextcloud/#configuring-apache","text":"Set apache to start on boot: systemctl enable httpd Then start it: systemctl start httpd When you install Nextcloud using the module, the configuration is created for you. In fact, there are multiple configurations. You can find these by looking in conf.d directory like this: ls -al /etc/httpd/conf.d which should show you output similar to this: -rw-r--r--. 1 root root 400 Nov 15 03:13 README -rw-r--r--. 1 root root 2926 Nov 15 03:13 autoindex.conf -rw-r--r--. 1 root root 994 Jul 14 2021 nextcloud-access.conf.avail -rw-r--r--. 1 root root 278 Jul 14 2021 nextcloud-auth-any.inc -rw-r--r--. 1 root root 313 Jul 14 2021 nextcloud-auth-local.inc -rw-r--r--. 1 root root 263 Jul 14 2021 nextcloud-auth-none.inc -rw-r--r--. 1 root root 2407 Jul 14 2021 nextcloud-defaults.inc -rw-r--r--. 1 root root 1893 Jul 14 2021 nextcloud.conf -rw-r--r--. 1 root root 1668 Dec 16 06:57 php.conf -rw-r--r--. 1 root root 1252 Nov 15 03:10 userdir.conf -rw-r--r--. 1 root root 574 Nov 15 03:10 welcome.conf The primary configuration here for Nextcloud is nextcloud.conf , but you should review the rest of these files. There are instructions on how to use them at the top of each file. In our lab installation, the localhost is not available from any web interface. If you look at the top of the nextcloud-access.conf.avail you will see a warning to enable this only after the admin account and initial installation have been complete. Since this is not possible in the lab instance, we are doing this early: ln -s /etc/httpd/conf.d/nextcloud-access.conf.avail /etc/httpd/conf.d/z-nextcloud-access.conf We also need a special empty file so that we can install Nextcloud. This file resides in /etc/nextcloud and is called CAN_INSTALL. To create it, simply do the following: touch /etc/nextcloud/CAN_INSTALL","title":"Configuring Apache"},{"location":"guides/cms/cloud_server_using_nextcloud/#configuring-php","text":"We need to set the timezone for PHP. To do this, open up php.ini with your text editor of choice: vi /etc/php.ini Then find the line: ;date.timezone = We need to remove the remark (;) and set our timezone. For our example timezone, we would put in either: date.timezone = \"America/Chicago\" OR date.timezone = \"US/Central\" Then save an exit the php.ini file. Note that for the sake of keeping things the same, your timezone in the php.ini file should match up to your machine's timezone setting. You can find out what this is set to by doing the following: ls -al /etc/localtime Which should show you something like this, assuming you set your timezone when you installed Rocky Linux and are living in the Central time zone: /etc/localtime -> /usr/share/zoneinfo/America/Chicago","title":"Configuring PHP"},{"location":"guides/cms/cloud_server_using_nextcloud/#configuring-mariadb-server","text":"Set mariadb-server to start on boot: systemctl enable mariadb And then start it: systemctl restart mariadb Again, as indicated earlier, we will be using the setup procedure for hardening mariadb-server found here for the initial configuration.","title":"Configuring mariadb-server"},{"location":"guides/cms/cloud_server_using_nextcloud/#configuring-nextcloud","text":"Now comes the fun! First, make sure that you have your services running. If you followed the above steps, they should already be running. We have had several steps between those initial service starts, so let's go ahead and restart them, just to be sure: systemctl restart httpd systemctl restart mariadb If everything restarts and there are no issues, then you are ready to move on. To do the initial configuration, we want to actually load the site in a web browser. In our lab instance, we've got no hostname set up, so we are going to the site by IP address like this: http://192.168.1.108/nextcloud Assuming that you've done everything correctly so far, you should be presented with a Nextcloud setup screen: There are a couple of things that we want to do differently than the defaults that show up: At the top of the web page, where it says \"Create an admin account\", set the user and password. For the sake of this document, we are entering \"admin\" and setting a strong password. Remember to save this somewhere safe (like a password manager) so that you don't lose it! Even though you have typed into this field, don't hit 'Enter' until we have done all of the setup fields! Under the \"Configure the database\" section, change from \"SQLite\" to \"MySQL/MariaDB\" by clicking on that button. Type the MariaDB root user and password that you set earlier into the \"Database user\" and \"Database password\" fields In the \"Database name\" field, type \"nextcloud\" In the \"localhost\" field, type \"localhost:3306\" (3306 is the default mariadb connect port) Once you have all this, click Finish Setup and you should be up and running.","title":"Configuring Nextcloud"},{"location":"guides/cms/cloud_server_using_nextcloud/#notes-for-the-systems-administrator","text":"As noted earlier, if using the module install for Nextcloud, Nextcloud is going to put things where it thinks they should be, not where the Systems Administrator might go looking for them. For this reason, as part of the setup steps, I recommend that a README.txt file be created in each location where the Systems Administrator would logically look. I came from an environment where we used /etc/httpd/sites-enabled for configuration files (see the alternate install steps for more) and put our web files in /var/www/sub-domains/[site_name]/html . If I were to use the module install of Nextcloud, then, I would want to put a README.txt file in both locations. The README.txt file in /etc/httpd/sites-enabled/ might contain: Nextcloud was installed using the module. You can find the configuration in /etc/httpd/conf.d/nextcloud.conf While the README.txt file in /var/www/sub-domains/[site_name]/html might contain: Nextcloud was installed using the module. You can find the web files in /usr/share/nextcloud","title":"Notes for the Systems Administrator"},{"location":"guides/cms/cloud_server_using_nextcloud/#nextcloud-zip-install","text":"If the module install is so easy, why consider using the .zip file install method? The reason is environment control. As noted in the Nextcloud module install procedure, Nextcloud chooses where to put the web files, where to put the configuration files, and most of the remaining setup options. Using the .zip file install method is definitely more intensive than the module install method, but it does give the Systems Administrator more control over where things will end up.","title":"Nextcloud .zip Install"},{"location":"guides/cms/cloud_server_using_nextcloud/#installing-and-configuring-repositories-same-procedure","text":"This is done exactly the same way as the with the module install procedure .","title":"Installing And Configuring Repositories (same procedure)"},{"location":"guides/cms/cloud_server_using_nextcloud/#installing-packages_1","text":"We need a lot of packages installed. Some of these may already be installed with your default Rocky Linux installation, but make sure by running the following command the following: dnf install httpd mariadb-server vim wget zip unzip libxml2 openssl php80-php php80-php-ctype php80-php-curl php80-php-gd php80-php-iconv php80-php-json php80-php-libxml php80-php-mbstring php80-php-openssl php80-php-posix php80-php-session php80-php-xml php80-php-zip php80-php-zlib php80-php-pdo php80-php-mysqlnd php80-php-intl php80-php-bcmath php80-php-gmp","title":"Installing Packages"},{"location":"guides/cms/cloud_server_using_nextcloud/#configuring-packages-and-directories","text":"","title":"Configuring Packages And Directories"},{"location":"guides/cms/cloud_server_using_nextcloud/#configuring-apache_1","text":"Set apache to start on boot: systemctl enable httpd As noted earlier, we are using the \"Apache Sites Enabled\" procedure found here to configure Apache. Follow that guide to get the configuration directories setup and the httpd.conf file modified and then return to this document for the remaining steps.","title":"Configuring apache"},{"location":"guides/cms/cloud_server_using_nextcloud/#create-the-configuration","text":"For Nextcloud, we will need to create the following configuration file. vi /etc/httpd/sites-available/com.yourdomain.nextcloud Your configuration file should look something like this: <VirtualHost *:80> DocumentRoot /var/www/sub-domains/com.yourdomain.nextcloud/html/ ServerName nextcloud.yourdomain.com <Directory /var/www/sub-domains/com.yourdomain.nextcloud/html/> Require all granted AllowOverride All Options FollowSymLinks MultiViews <IfModule mod_dav.c> Dav off </IfModule> </Directory> </VirtualHost> Once done, save your changes (with SHIFT:wq! for vi ). Next, create a link to this file in /etc/httpd/sites-enabled: ln -s /etc/httpd/sites-available/com.yourdomain.nextcloud /etc/httpd/sites-enabled/","title":"Create The Configuration"},{"location":"guides/cms/cloud_server_using_nextcloud/#creating-the-directory","text":"As noted in the configuration above, the DocumentRoot needs to be created. This can be done by: mkdir -p /var/www/sub-domains/com.yourdomain.com/html This is where our Nextcloud instance will be installed.","title":"Creating The Directory"},{"location":"guides/cms/cloud_server_using_nextcloud/#configure-php-same-procedure","text":"This is done exactly like the module install procedure .","title":"Configure PHP (same procedure)"},{"location":"guides/cms/cloud_server_using_nextcloud/#configure-mariadb-same-procedure","text":"This is done exactly like the module install procedure .","title":"Configure Mariadb (same procedure)"},{"location":"guides/cms/cloud_server_using_nextcloud/#installing-nextcloud","text":"This install method for Nextcloud uses the server install .zip file.","title":"Installing Nextcloud"},{"location":"guides/cms/cloud_server_using_nextcloud/#get-the-nextcloud-zip-file-and-unzip","text":"The next few steps assume that you are remotely connected to your Nextcloud server via ssh with a remote console open: Navigate to the Nextcloud web site Let your mouse hover over \"Get Nextcloud\" which will bring up a drop down menu. Click on \"Server Packages\". Right-click on \"Download Nextcloud\" and copy the link address. (the exact syntax of this is different browser to browser) In your remote console on the Nextcloud server, type \"wget\" and then a space and paste in what you just copied. You should get something like the following: wget https://download.nextcloud.com/server/releases/nextcloud-21.0.1.zip Once you hit enter, the download of the .zip file will start and will be completed fairly quickly. Once the download is complete, unzip the Nextcloud zip file by using the following: unzip nextcloud-21.0.1.zip","title":"Get The Nextcloud .zip File And Unzip"},{"location":"guides/cms/cloud_server_using_nextcloud/#copying-content-and-changing-permissions","text":"After completing the unzip step, you should now have a new directory in /root called \"nextcloud.\" Change into this directory: cd nextcloud And either copy or move the content to our DocumentRoot : cp -Rf * /var/www/sub-domains/com.yourdomain.nextcloud/html/ OR mv * /var/www/sub-domains/com.yourdomain.nextcloud/html/ Now that everything is where it should be, the next step is to make sure that apache owns the directory. To do this, run: chown -Rf apache.apache /var/www/sub-domains/com.yourdomain.nextcloud/html For security reasons, we also want to move the \"data\" folder from inside to outside of the DocumentRoot . Do this with the following command: mv /var/www/sub-domains/com.yourdomain.nextcloud/html/data /var/www/sub-domains/com.yourdomain.nextcloud/","title":"Copying Content And Changing Permissions"},{"location":"guides/cms/cloud_server_using_nextcloud/#configuring-nextcloud_1","text":"Now comes the fun! First, make sure that you have your services running. If you followed the above steps, they should already be running. We have had several steps between those initial service starts, so let's go ahead and restart them, just to be sure: systemctl restart httpd systemctl restart mariadb If everything restarts and there are no issues, then you are ready to move on. To do the initial configuration, we want to actually load the site in a web browser: http://nextcloud.yourdomain.com/ And you should see this screen: There are a couple of things that we want to do differently than the defaults that show up: At the top of the web page, where it says \"Create an admin account\", set the user and password. For the sake of this document, we are entering \"admin\" and setting a strong password. Remember to save this somewhere safe (like a password manager) so that you don't lose it! Even though you have typed into this field, don't hit 'Enter' until we have done all of the setup fields! Under the \"Storage & database\" section, change the \"Data folder\" location from the default document root, to where we moved the data folder earlier: /var/www/sub-domains/com.yourdomain.nextcloud/data Under the \"Configure the database\" section, change from \"SQLite\" to \"MySQL/MariaDB\" by clicking on that button. Type the MariaDB root user and password that you set earlier into the \"Database user\" and \"Database password\" fields In the \"Database name\" field, type \"nextcloud\" In the \"localhost\" field, type \"localhost:3306\" (3306 is the default mariadb connect port) Now cross your fingers and click \"Finish Setup\". The browser window will refresh for a bit and then usually not reload the site. Enter your URL in the browser window again and you should be confronted with the default first pages. Your administrative user is already (or should be) logged in at this point, and there are several informational pages designed to get you up to speed. The \"Dashboard\" is what users will see when they first login. The administrative user can now create other users, install other applications and many other tasks. The \"Nextcloud Manual.pdf\" file is the user manual, so that users can get familiar with what is available. The administrative user should read through or at least scan the high points of the admin manual On the Nextcloud web site","title":"Configuring Nextcloud"},{"location":"guides/cms/cloud_server_using_nextcloud/#next-steps","text":"At this point, don't forget that this is a server that you will be storing company data on. It's important to get it locked down with a firewall, get the backups setup , secure the site with an SSL , and any other duties that are required to keep your data safe.","title":"Next Steps"},{"location":"guides/cms/cloud_server_using_nextcloud/#conclusions","text":"A decision to take the company cloud in house is one that needs to be evaluated carefully. For those that decide that keeping company data locally is preferable over an external cloud host, Nextcloud is a good alternative.","title":"Conclusions"},{"location":"guides/cms/dokuwiki_server/","tags":["wiki","documentation"],"text":"DokuWiki Server Prerequisites And Assumptions A Rocky Linux instance installed on a server, container, or virtual machine. Comfort with modifying configuration files from the command line with an editor (our examples here will use vi , but you can substitute your favorite editor) Some knowledge about web applications and setup. Our example will use the Apache Sites Enabled for setup, so it is a good idea to review that routine if you plan on following along. We will be using \"wiki-doc.yourdomain.com\" as the domain name throughout this example. We will assume throughout this document that you are the root user or can get there with sudo . We are assuming a fresh install of the OS, however that is NOT a requirement. Introduction Documentation can take many forms in an organization. Having a repository that you can reference for that documentation is invaluable. A wiki (which means quick in Hawaiian), is a way to keep documentation, process notes, corporate knowledge bases, and even code examples, in a centralized location. IT professionals who maintain a wiki, even secretly, have a built-in insurance policy against forgetting an obscure routine. DokuWiki is a mature, fast, wiki that runs without a database, has built in security features, and is relatively easy to deploy. For more information on what DokuWiki can do, check out their web page . DokuWiki is just one of many wiki's available, though it's a pretty good one. One big pro is that DokuWiki is relatively lightweight and can run on a server that is already running other services, provided you have space and memory available. Installing Dependencies The minimum PHP version for DokuWiki is now 7.2, which is exactly what Rocky Linux 8 comes with. We are specifying packages here that may already be installed: dnf install tar wget httpd php php-gd php-xml php-json php-mbstring You will see a list of additional dependencies that will be installed and this prompt: Is this ok [y/N]: Go ahead and answer with \"y\" and hit 'Enter' to install. Create Directories And Modify Configuration Apache Configuration If you have read through the Apache Sites Enabled procedure, you know that we need to create a few directories. We will start with the httpd configuration directory additions: mkdir -p /etc/httpd/{sites-available,sites-enabled} We need to edit the httpd.conf file: vi /etc/httpd/conf/httpd.conf And add this to the very bottom of the file: Include /etc/httpd/sites-enabled Create the site configuration file in sites-available: vi /etc/httpd/sites-available/com.yourdomain.wiki-doc That configuration file should look something like this: <VirtualHost *> ServerName wiki-doc.yourdomain.com DocumentRoot /var/www/sub-domains/com.yourdomain.wiki-doc/html <Directory ~ \"/var/www/sub-domains/com.yourdomain.wiki-doc/html/(bin/|conf/|data/|inc/)\"> <IfModule mod_authz_core.c> AllowOverride All Require all denied </IfModule> <IfModule !mod_authz_core.c> Order allow,deny Deny from all </IfModule> </Directory> ErrorLog /var/log/httpd/wiki-doc.yourdomain.com_error.log CustomLog /var/log/httpd/wiki-doc.yourdomain_access.log combined </VirtualHost> Note that the \"AllowOverride All\" above, allows the .htaccess (directory specific security) file to work. Go ahead and link the configuration file into sites-enabled, but don't start web services as yet: ln -s /etc/httpd/sites-available/com.yourdomain.wiki-doc /etc/httpd/sites-enabled/ Apache DocumentRoot We also need to create our DocumentRoot . To do this: mkdir -p /var/www/sub-domains/com.yourdomain.wiki-doc/html Installing DokuWiki In your server, change to the root directory. cd /root Now that we have our environment ready to go, let's get the latest stable version of DokuWiki. You can find this by going to the download page and on the left-hand side of the page under \"Version\" you will see \"Stable (Recommended) (direct link).\" Right-click on the \"(direct link)\" portion of this and copy the link address. In the console of your DokuWiki server, type \"wget\" and a space and then paste in your copied link in the terminal. You should get something like this: wget https://download.dokuwiki.org/src/dokuwiki/dokuwiki-stable.tgz Before we decompress the archive, take a look at the contents using tar ztf to see the contents of the archive: tar ztv dokuwiki-stable.tgz Notice the named dated directory ahead of all the other files that looks something like this? ... (more above) dokuwiki-2020-07-29/inc/lang/fr/resetpwd.txt dokuwiki-2020-07-29/inc/lang/fr/draft.txt dokuwiki-2020-07-29/inc/lang/fr/recent.txt ... (more below) We don't want that leading named directory when we decompress the archive, so we are going to use some options with tar to exclude it. The first option is the \"--strip-components=1\" which removes that leading directory. The second option is the \"-C\" option, and that tells tar where we want the archive to be decompressed to. So decompress the archive with this command: tar xzf dokuwiki-stable.tgz --strip-components=1 -C /var/www/sub-domains/com.yourdomain.wiki-doc/html/ Once we have executed this command, all of DokuWiki should be in our DocumentRoot . We need to make a copy of the .htaccess.dist file that came with DokuWiki and keep the old one there too, in case we need to revert to the original in the future. In the process, we will be changing the name of this file to simply .htaccess which is what apache will be looking for. To do this: cp /var/www/sub-domains/com.yourdomain.wiki-doc/html/.htaccess{.dist,} Now we need to change ownership of the new directory and its files to the apache user and group: chown -Rf apache.apache /var/www/sub-domains/com.yourdomain.wiki-doc/html Setting Up DNS Or /etc/hosts Before you'll be able to access the DokuWiki interface, you'll need to set name resolution for this site. For testing purposes, you can use your /etc/hosts file. In this example, let's assume that DokuWiki will be running on a private IPv4 address of 10.56.233.179. Let's also assume that you are modifying the /etc/hosts file on a Linux workstation. To do this, run: sudo vi /etc/hosts And then modify your hosts file to look something like this (note the IP address above in the below example): 127.0.0.1 localhost 127.0.1.1 myworkstation-home 10.56.233.179 wiki-doc.yourdomain.com wiki-doc # The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters Once you have finished testing and are ready to take things live for everyone, you will need to add this host to a DNS server. You could do this by using a Private DNS Server , or a public-facing DNS server. Starting httpd Before we start httpd let's test to make sure that our configuration is OK: httpd -t You should get: Syntax OK If so, you should be ready to start httpd and then finish the setup. Let's start by enabling httpd to start on boot: systemctl enable httpd And then start it: systemctl start httpd Testing DokuWiki Now that our host name is set for testing and the web service has been started, the next step is to open up a web browser and type this in the address bar: http://wiki-doc/install.php OR http://wiki-doc.yourdomain.com/install.php Either should work if you set your hosts file as above. This will bring you to the setup screen so that you can finish the setup: In the \"Wiki Name\" field, type the name for our wiki. Example \"Technical Documentation\" In the \"Superuser\" field, type the administrative username. Example \"admin\" In the \"Real name\" field, type the real name for the administrative user. In the \"E-Mail\" field, type the email address of the administrative user. In the \"Password\" field, type the secure password for the administrative user. In the \"once again\" field, re-type that same password. In the \"Initial ACL Policy\" drop down, choose the option that works best for your environment. Choose the appropriate check box for the license you want to put your content under. Leave checked (or uncheck if you prefer) the \"Once a month, send anonymous usage data to the DokuWiki developers\" checkbox Click the \"Save\" button Your wiki is now ready for you to add content. Securing DokuWiki Besides the ACL policy that you just created, consider: Your Firewall Before you call everything done, you need to think about security. First, you should be running a firewall on the server. We will assume that you are using iptables and have Enabled iptables , but if you want to use firewalld instead, simply modify your firewalld rules accordingly. Instead of everyone having access to the wiki, we are going to assume that anyone on the 10.0.0.0/8 network is on your private Local Area Network, and that those are the only people who need access to the site. A simple iptables firewall script for this is down below. Please note that you may need other rules for other services on this server, and that this example only takes into account the web services. First, modify or create the /etc/firewall.conf file: vi /etc/firewall.conf #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP # web ports iptables -A INPUT -p tcp -m tcp -s 10.0.0.0/8 --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 10.0.0.0/8 --dport 443 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Once the script is created, make sure it is executable: chmod +x /etc/firewall.conf Then execute the script: /etc/firewall.conf This will execute the rules and save them so that they will be reloaded on the next start of iptables or on boot. SSL For the best security, you should consider using an SSL so that all web traffic is encrypted. You can purchase an SSL from an SSL provider or use Let's Encrypt Conclusion Whether you need to document processes, company policies, program code, or something else, a wiki is a great way to get that done. DokuWiki is a product that is secure, flexible, easy to use, relatively easy to install and deploy, and is a stable project that has been around for many years.","title":"DokuWiki"},{"location":"guides/cms/dokuwiki_server/#dokuwiki-server","text":"","title":"DokuWiki Server"},{"location":"guides/cms/dokuwiki_server/#prerequisites-and-assumptions","text":"A Rocky Linux instance installed on a server, container, or virtual machine. Comfort with modifying configuration files from the command line with an editor (our examples here will use vi , but you can substitute your favorite editor) Some knowledge about web applications and setup. Our example will use the Apache Sites Enabled for setup, so it is a good idea to review that routine if you plan on following along. We will be using \"wiki-doc.yourdomain.com\" as the domain name throughout this example. We will assume throughout this document that you are the root user or can get there with sudo . We are assuming a fresh install of the OS, however that is NOT a requirement.","title":"Prerequisites And Assumptions"},{"location":"guides/cms/dokuwiki_server/#introduction","text":"Documentation can take many forms in an organization. Having a repository that you can reference for that documentation is invaluable. A wiki (which means quick in Hawaiian), is a way to keep documentation, process notes, corporate knowledge bases, and even code examples, in a centralized location. IT professionals who maintain a wiki, even secretly, have a built-in insurance policy against forgetting an obscure routine. DokuWiki is a mature, fast, wiki that runs without a database, has built in security features, and is relatively easy to deploy. For more information on what DokuWiki can do, check out their web page . DokuWiki is just one of many wiki's available, though it's a pretty good one. One big pro is that DokuWiki is relatively lightweight and can run on a server that is already running other services, provided you have space and memory available.","title":"Introduction"},{"location":"guides/cms/dokuwiki_server/#installing-dependencies","text":"The minimum PHP version for DokuWiki is now 7.2, which is exactly what Rocky Linux 8 comes with. We are specifying packages here that may already be installed: dnf install tar wget httpd php php-gd php-xml php-json php-mbstring You will see a list of additional dependencies that will be installed and this prompt: Is this ok [y/N]: Go ahead and answer with \"y\" and hit 'Enter' to install.","title":"Installing Dependencies"},{"location":"guides/cms/dokuwiki_server/#create-directories-and-modify-configuration","text":"","title":"Create Directories And Modify Configuration"},{"location":"guides/cms/dokuwiki_server/#apache-configuration","text":"If you have read through the Apache Sites Enabled procedure, you know that we need to create a few directories. We will start with the httpd configuration directory additions: mkdir -p /etc/httpd/{sites-available,sites-enabled} We need to edit the httpd.conf file: vi /etc/httpd/conf/httpd.conf And add this to the very bottom of the file: Include /etc/httpd/sites-enabled Create the site configuration file in sites-available: vi /etc/httpd/sites-available/com.yourdomain.wiki-doc That configuration file should look something like this: <VirtualHost *> ServerName wiki-doc.yourdomain.com DocumentRoot /var/www/sub-domains/com.yourdomain.wiki-doc/html <Directory ~ \"/var/www/sub-domains/com.yourdomain.wiki-doc/html/(bin/|conf/|data/|inc/)\"> <IfModule mod_authz_core.c> AllowOverride All Require all denied </IfModule> <IfModule !mod_authz_core.c> Order allow,deny Deny from all </IfModule> </Directory> ErrorLog /var/log/httpd/wiki-doc.yourdomain.com_error.log CustomLog /var/log/httpd/wiki-doc.yourdomain_access.log combined </VirtualHost> Note that the \"AllowOverride All\" above, allows the .htaccess (directory specific security) file to work. Go ahead and link the configuration file into sites-enabled, but don't start web services as yet: ln -s /etc/httpd/sites-available/com.yourdomain.wiki-doc /etc/httpd/sites-enabled/","title":"Apache Configuration"},{"location":"guides/cms/dokuwiki_server/#apache-documentroot","text":"We also need to create our DocumentRoot . To do this: mkdir -p /var/www/sub-domains/com.yourdomain.wiki-doc/html","title":"Apache DocumentRoot"},{"location":"guides/cms/dokuwiki_server/#installing-dokuwiki","text":"In your server, change to the root directory. cd /root Now that we have our environment ready to go, let's get the latest stable version of DokuWiki. You can find this by going to the download page and on the left-hand side of the page under \"Version\" you will see \"Stable (Recommended) (direct link).\" Right-click on the \"(direct link)\" portion of this and copy the link address. In the console of your DokuWiki server, type \"wget\" and a space and then paste in your copied link in the terminal. You should get something like this: wget https://download.dokuwiki.org/src/dokuwiki/dokuwiki-stable.tgz Before we decompress the archive, take a look at the contents using tar ztf to see the contents of the archive: tar ztv dokuwiki-stable.tgz Notice the named dated directory ahead of all the other files that looks something like this? ... (more above) dokuwiki-2020-07-29/inc/lang/fr/resetpwd.txt dokuwiki-2020-07-29/inc/lang/fr/draft.txt dokuwiki-2020-07-29/inc/lang/fr/recent.txt ... (more below) We don't want that leading named directory when we decompress the archive, so we are going to use some options with tar to exclude it. The first option is the \"--strip-components=1\" which removes that leading directory. The second option is the \"-C\" option, and that tells tar where we want the archive to be decompressed to. So decompress the archive with this command: tar xzf dokuwiki-stable.tgz --strip-components=1 -C /var/www/sub-domains/com.yourdomain.wiki-doc/html/ Once we have executed this command, all of DokuWiki should be in our DocumentRoot . We need to make a copy of the .htaccess.dist file that came with DokuWiki and keep the old one there too, in case we need to revert to the original in the future. In the process, we will be changing the name of this file to simply .htaccess which is what apache will be looking for. To do this: cp /var/www/sub-domains/com.yourdomain.wiki-doc/html/.htaccess{.dist,} Now we need to change ownership of the new directory and its files to the apache user and group: chown -Rf apache.apache /var/www/sub-domains/com.yourdomain.wiki-doc/html","title":"Installing DokuWiki"},{"location":"guides/cms/dokuwiki_server/#setting-up-dns-or-etchosts","text":"Before you'll be able to access the DokuWiki interface, you'll need to set name resolution for this site. For testing purposes, you can use your /etc/hosts file. In this example, let's assume that DokuWiki will be running on a private IPv4 address of 10.56.233.179. Let's also assume that you are modifying the /etc/hosts file on a Linux workstation. To do this, run: sudo vi /etc/hosts And then modify your hosts file to look something like this (note the IP address above in the below example): 127.0.0.1 localhost 127.0.1.1 myworkstation-home 10.56.233.179 wiki-doc.yourdomain.com wiki-doc # The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters Once you have finished testing and are ready to take things live for everyone, you will need to add this host to a DNS server. You could do this by using a Private DNS Server , or a public-facing DNS server.","title":"Setting Up DNS Or /etc/hosts"},{"location":"guides/cms/dokuwiki_server/#starting-httpd","text":"Before we start httpd let's test to make sure that our configuration is OK: httpd -t You should get: Syntax OK If so, you should be ready to start httpd and then finish the setup. Let's start by enabling httpd to start on boot: systemctl enable httpd And then start it: systemctl start httpd","title":"Starting httpd"},{"location":"guides/cms/dokuwiki_server/#testing-dokuwiki","text":"Now that our host name is set for testing and the web service has been started, the next step is to open up a web browser and type this in the address bar: http://wiki-doc/install.php OR http://wiki-doc.yourdomain.com/install.php Either should work if you set your hosts file as above. This will bring you to the setup screen so that you can finish the setup: In the \"Wiki Name\" field, type the name for our wiki. Example \"Technical Documentation\" In the \"Superuser\" field, type the administrative username. Example \"admin\" In the \"Real name\" field, type the real name for the administrative user. In the \"E-Mail\" field, type the email address of the administrative user. In the \"Password\" field, type the secure password for the administrative user. In the \"once again\" field, re-type that same password. In the \"Initial ACL Policy\" drop down, choose the option that works best for your environment. Choose the appropriate check box for the license you want to put your content under. Leave checked (or uncheck if you prefer) the \"Once a month, send anonymous usage data to the DokuWiki developers\" checkbox Click the \"Save\" button Your wiki is now ready for you to add content.","title":"Testing DokuWiki"},{"location":"guides/cms/dokuwiki_server/#securing-dokuwiki","text":"Besides the ACL policy that you just created, consider:","title":"Securing DokuWiki"},{"location":"guides/cms/dokuwiki_server/#your-firewall","text":"Before you call everything done, you need to think about security. First, you should be running a firewall on the server. We will assume that you are using iptables and have Enabled iptables , but if you want to use firewalld instead, simply modify your firewalld rules accordingly. Instead of everyone having access to the wiki, we are going to assume that anyone on the 10.0.0.0/8 network is on your private Local Area Network, and that those are the only people who need access to the site. A simple iptables firewall script for this is down below. Please note that you may need other rules for other services on this server, and that this example only takes into account the web services. First, modify or create the /etc/firewall.conf file: vi /etc/firewall.conf #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP # web ports iptables -A INPUT -p tcp -m tcp -s 10.0.0.0/8 --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 10.0.0.0/8 --dport 443 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Once the script is created, make sure it is executable: chmod +x /etc/firewall.conf Then execute the script: /etc/firewall.conf This will execute the rules and save them so that they will be reloaded on the next start of iptables or on boot.","title":"Your Firewall"},{"location":"guides/cms/dokuwiki_server/#ssl","text":"For the best security, you should consider using an SSL so that all web traffic is encrypted. You can purchase an SSL from an SSL provider or use Let's Encrypt","title":"SSL"},{"location":"guides/cms/dokuwiki_server/#conclusion","text":"Whether you need to document processes, company policies, program code, or something else, a wiki is a great way to get that done. DokuWiki is a product that is secure, flexible, easy to use, relatively easy to install and deploy, and is a stable project that has been around for many years.","title":"Conclusion"},{"location":"guides/communications/asterisk_installation/","text":"Installing Asterisk on Rocky Linux What is Asterisk? Asterisk is an open source framework for building communications applications. Additionally, Asterisk turns an ordinary computer into a communications server, as well as powering IP PBX systems, VoIP gateways, conference servers and other custom solutions. It is used by small businesses, large businesses, call centers, carriers, and government agencies worldwide. Asterisk is free and open source and is sponsored by Sangoma . Sangoma also offers commercial products that use Asterisk under the hood, and depending on your experience and budget, using these products may be more beneficial than rolling your own. Only you and your organization know that answer. It should be noted that this guide requires the administrator to do a fair amount of research on their own. Installing a communications server is not a difficult process, but running one can be quite complicated. While this guide will get your server up and running, it will not be fully ready for you to use in production. Prerequisites At minimum, you will need the following skills and tools to complete this guide: A machine running Rocky Linux A comfort level with modifying configuration files and issuing commands from the command-line Knowledge of how to use a command line editor (We are using vi here, but feel free to substitute in your favorite editor.) You will need root access, and ideally be signed in as the root user in your terminal The EPEL repositories from Fedora The ability to login as root or run root commands with sudo . All commands here assume a user that has sudo rights, however the configuration and build processes are run with sudo -s . To grab the latest build of Asterisk, you will need to either use curl or wget . This guide uses wget , but feel free to substitute in the appropriate curl string if you want to use that. Update Rocky Linux and Install wget sudo dnf -y update This will get your server up-to-date with all packages that have been released or updated since the last update or install. Then run: sudo dnf install wget Set Hostname Set your host name to the domain you'll be using for Asterisk. sudo hostnamectl set-hostname asterisk.example.com Add Needed Repositories First, install the EPEL (Extra Packages for Enterprise Linux): sudo dnf -y install epel-release Next, enable Rocky Linux' PowerTools: sudo dnf config-manager --set-enabled powertools Install Development Tools sudo dnf group -y install \"Development Tools\" sudo dnf -y install git wget Install Asterisk Downloading and Configuring the Asterisk Build Before you download this script, make sure you have the latest version. To do so, navigate to http://downloads.asterisk.org/pub/telephony/asterisk/ and look for the latest build of Asterisk. Then copy the link location. As of the writing of this document, the following was the latest build: wget http://downloads.asterisk.org/pub/telephony/asterisk/asterisk-18.6.0.tar.gz tar xvfz asterisk-18-current.tar.gz cd asterisk-18.6.0/ Before running the install_prereq below (and the remaining commands), you are going to need to be the superuser or root. It's much easier at this point to get into sudo permanently for a while. We will exit back out of sudo later in the process: sudo -s contrib/scripts/install_prereq install You should see the following when the script completes: ############################################# ## install completed successfully ############################################# Now that all of the required packages are installed, our next step is to configure and build Asterisk: ./configure --libdir=/usr/lib64 --with-jansson-bundled=yes Assuming that the configuration runs without issue, you should get a large ASCII Asterisk emblem, followed by the following on Rocky Linux: configure: Package configured for: configure: OS type : linux-gnu configure: Host CPU : x86_64 configure: build-cpu:vendor:os: x86_64 : pc : linux-gnu : configure: host-cpu:vendor:os: x86_64 : pc : linux-gnu : Set Asterisk menu options [For more options] This is one of the steps where the administrator is going to need to do his homework. There are a lot of menu options that you may or may not need. Running the following command: make menuselect will bring you to a menuselect screen Look through these options carefully and make selections based on your requirements. As stated earlier, this may take some additional homework. Build and Install Asterisk To build, we want to execute the following commands in succession: make make install Installing the documentation isn't required, but unless you are a communications server expert, you'll want them installed: make progdocs Next install the basic PBX and make the config. The basic PBX is just that, very basic! You will probably need to make changes going forward to get your PBX to function as you want it to. make basic-pbx make config Asterisk Configuration Create User & Group You'll need a specific user just for asterisk. Might as well create it now. groupadd asterisk useradd -r -d /var/lib/asterisk -g asterisk asterisk chown -R asterisk.asterisk /etc/asterisk /var/{lib,log,spool}/asterisk /usr/lib64/asterisk restorecon -vr {/etc/asterisk,/var/lib/asterisk,/var/log/asterisk,/var/spool/asterisk} Now that the bulk of our work is completed, go ahead and exit out of the sudo -s command. This will require that most of the remaining commands use sudo again: exit Set Default User & Group sudo vi /etc/sysconfig/asterisk Remove the comments on the two lines below and save: AST_USER=\"asterisk\" AST_GROUP=\"asterisk\" sudo vi /etc/asterisk/asterisk.conf Remove the comments on the two lines below and save: runuser = asterisk ; The user to run as. rungroup = asterisk ; The group to run as. Configure Asterisk Service sudo systemctl enable asterisk Configure Firewall This example uses firewalld for the firewall, which is the default in Rocky Linux. The goal here is to open SIP ports to the world and to open RTP (Realtime Transport Protocol) to the world on ports 10000-20000 as recommended by the Asterisk documentation. Keep in mind that you will almost certainly need other firewall rules for other forward-facing services (HTTP/HTTPS) which you will probably want to limit to your own IP addresses. That is beyond the scope of this document: sudo firewall-cmd --zone=public --add-service sip --permanent sudo firewall-cmd --zone=public --add-port=10000-20000/udp --permanent Since we've made the firewalld commands permanent, we will need to do a reboot of the server. You can do that with: sudo shutdown -r now Test The Asterisk Console To test, let's connect to the Asterisk console: sudo asterisk -r Which will bring you into the Asterisk command-line client. You will see this prompt after the basic Asterisk information is displayed: asterisk*CLI> To change the verbosity of the console, use the following: core set verbose 4 Which should show you the following in the Asterisk console: Console verbose was OFF and is now 4. Show Sample End-Point Authentications At the Asterisk command-line client prompt, type: pjsip show auth 1101 This will return username and password information that you can then use to connect any SIP client with. Conclusion The above will get you up and running with the server, but finishing out the configuration, connecting devices, and further troubleshooting is up to you. Running an Asterisk communications server takes a lot of time and effort and will require a lot of research by any administrator. For more information on how to configure and use Asterisk, take a look at the Asterisk Wiki here.","title":"Installing Asterisk"},{"location":"guides/communications/asterisk_installation/#installing-asterisk-on-rocky-linux","text":"What is Asterisk? Asterisk is an open source framework for building communications applications. Additionally, Asterisk turns an ordinary computer into a communications server, as well as powering IP PBX systems, VoIP gateways, conference servers and other custom solutions. It is used by small businesses, large businesses, call centers, carriers, and government agencies worldwide. Asterisk is free and open source and is sponsored by Sangoma . Sangoma also offers commercial products that use Asterisk under the hood, and depending on your experience and budget, using these products may be more beneficial than rolling your own. Only you and your organization know that answer. It should be noted that this guide requires the administrator to do a fair amount of research on their own. Installing a communications server is not a difficult process, but running one can be quite complicated. While this guide will get your server up and running, it will not be fully ready for you to use in production.","title":"Installing Asterisk on Rocky Linux"},{"location":"guides/communications/asterisk_installation/#prerequisites","text":"At minimum, you will need the following skills and tools to complete this guide: A machine running Rocky Linux A comfort level with modifying configuration files and issuing commands from the command-line Knowledge of how to use a command line editor (We are using vi here, but feel free to substitute in your favorite editor.) You will need root access, and ideally be signed in as the root user in your terminal The EPEL repositories from Fedora The ability to login as root or run root commands with sudo . All commands here assume a user that has sudo rights, however the configuration and build processes are run with sudo -s . To grab the latest build of Asterisk, you will need to either use curl or wget . This guide uses wget , but feel free to substitute in the appropriate curl string if you want to use that.","title":"Prerequisites"},{"location":"guides/communications/asterisk_installation/#update-rocky-linux-and-install-wget","text":"sudo dnf -y update This will get your server up-to-date with all packages that have been released or updated since the last update or install. Then run: sudo dnf install wget","title":"Update Rocky Linux and Install wget"},{"location":"guides/communications/asterisk_installation/#set-hostname","text":"Set your host name to the domain you'll be using for Asterisk. sudo hostnamectl set-hostname asterisk.example.com","title":"Set Hostname"},{"location":"guides/communications/asterisk_installation/#add-needed-repositories","text":"First, install the EPEL (Extra Packages for Enterprise Linux): sudo dnf -y install epel-release Next, enable Rocky Linux' PowerTools: sudo dnf config-manager --set-enabled powertools","title":"Add Needed Repositories"},{"location":"guides/communications/asterisk_installation/#install-development-tools","text":"sudo dnf group -y install \"Development Tools\" sudo dnf -y install git wget","title":"Install Development Tools"},{"location":"guides/communications/asterisk_installation/#install-asterisk","text":"","title":"Install Asterisk"},{"location":"guides/communications/asterisk_installation/#downloading-and-configuring-the-asterisk-build","text":"Before you download this script, make sure you have the latest version. To do so, navigate to http://downloads.asterisk.org/pub/telephony/asterisk/ and look for the latest build of Asterisk. Then copy the link location. As of the writing of this document, the following was the latest build: wget http://downloads.asterisk.org/pub/telephony/asterisk/asterisk-18.6.0.tar.gz tar xvfz asterisk-18-current.tar.gz cd asterisk-18.6.0/ Before running the install_prereq below (and the remaining commands), you are going to need to be the superuser or root. It's much easier at this point to get into sudo permanently for a while. We will exit back out of sudo later in the process: sudo -s contrib/scripts/install_prereq install You should see the following when the script completes: ############################################# ## install completed successfully ############################################# Now that all of the required packages are installed, our next step is to configure and build Asterisk: ./configure --libdir=/usr/lib64 --with-jansson-bundled=yes Assuming that the configuration runs without issue, you should get a large ASCII Asterisk emblem, followed by the following on Rocky Linux: configure: Package configured for: configure: OS type : linux-gnu configure: Host CPU : x86_64 configure: build-cpu:vendor:os: x86_64 : pc : linux-gnu : configure: host-cpu:vendor:os: x86_64 : pc : linux-gnu :","title":"Downloading and Configuring the Asterisk Build"},{"location":"guides/communications/asterisk_installation/#set-asterisk-menu-options-for-more-options","text":"This is one of the steps where the administrator is going to need to do his homework. There are a lot of menu options that you may or may not need. Running the following command: make menuselect will bring you to a menuselect screen Look through these options carefully and make selections based on your requirements. As stated earlier, this may take some additional homework.","title":"Set Asterisk menu options [For more options]"},{"location":"guides/communications/asterisk_installation/#build-and-install-asterisk","text":"To build, we want to execute the following commands in succession: make make install Installing the documentation isn't required, but unless you are a communications server expert, you'll want them installed: make progdocs Next install the basic PBX and make the config. The basic PBX is just that, very basic! You will probably need to make changes going forward to get your PBX to function as you want it to. make basic-pbx make config","title":"Build and Install Asterisk"},{"location":"guides/communications/asterisk_installation/#asterisk-configuration","text":"","title":"Asterisk Configuration"},{"location":"guides/communications/asterisk_installation/#create-user-group","text":"You'll need a specific user just for asterisk. Might as well create it now. groupadd asterisk useradd -r -d /var/lib/asterisk -g asterisk asterisk chown -R asterisk.asterisk /etc/asterisk /var/{lib,log,spool}/asterisk /usr/lib64/asterisk restorecon -vr {/etc/asterisk,/var/lib/asterisk,/var/log/asterisk,/var/spool/asterisk} Now that the bulk of our work is completed, go ahead and exit out of the sudo -s command. This will require that most of the remaining commands use sudo again: exit","title":"Create User &amp; Group"},{"location":"guides/communications/asterisk_installation/#set-default-user-group","text":"sudo vi /etc/sysconfig/asterisk Remove the comments on the two lines below and save: AST_USER=\"asterisk\" AST_GROUP=\"asterisk\" sudo vi /etc/asterisk/asterisk.conf Remove the comments on the two lines below and save: runuser = asterisk ; The user to run as. rungroup = asterisk ; The group to run as.","title":"Set Default User &amp; Group"},{"location":"guides/communications/asterisk_installation/#configure-asterisk-service","text":"sudo systemctl enable asterisk","title":"Configure Asterisk Service"},{"location":"guides/communications/asterisk_installation/#configure-firewall","text":"This example uses firewalld for the firewall, which is the default in Rocky Linux. The goal here is to open SIP ports to the world and to open RTP (Realtime Transport Protocol) to the world on ports 10000-20000 as recommended by the Asterisk documentation. Keep in mind that you will almost certainly need other firewall rules for other forward-facing services (HTTP/HTTPS) which you will probably want to limit to your own IP addresses. That is beyond the scope of this document: sudo firewall-cmd --zone=public --add-service sip --permanent sudo firewall-cmd --zone=public --add-port=10000-20000/udp --permanent Since we've made the firewalld commands permanent, we will need to do a reboot of the server. You can do that with: sudo shutdown -r now","title":"Configure Firewall"},{"location":"guides/communications/asterisk_installation/#test","text":"","title":"Test"},{"location":"guides/communications/asterisk_installation/#the-asterisk-console","text":"To test, let's connect to the Asterisk console: sudo asterisk -r Which will bring you into the Asterisk command-line client. You will see this prompt after the basic Asterisk information is displayed: asterisk*CLI> To change the verbosity of the console, use the following: core set verbose 4 Which should show you the following in the Asterisk console: Console verbose was OFF and is now 4.","title":"The Asterisk Console"},{"location":"guides/communications/asterisk_installation/#show-sample-end-point-authentications","text":"At the Asterisk command-line client prompt, type: pjsip show auth 1101 This will return username and password information that you can then use to connect any SIP client with.","title":"Show Sample End-Point Authentications"},{"location":"guides/communications/asterisk_installation/#conclusion","text":"The above will get you up and running with the server, but finishing out the configuration, connecting devices, and further troubleshooting is up to you. Running an Asterisk communications server takes a lot of time and effort and will require a lot of research by any administrator. For more information on how to configure and use Asterisk, take a look at the Asterisk Wiki here.","title":"Conclusion"},{"location":"guides/containers/lxd_server/","tags":["lxd","enterprise"],"text":"Creating a full LXD Server Introduction LXD is best described on the official website , but think of it as a container system that provides the benefits of virtual servers in a container, or a container on steroids. It is very powerful, and with the right hardware and set up, can be leveraged to run a lot of server instances on a single piece of hardware. If you pair that with a snapshot server, you also have a set of containers that you can spin up almost immediately in the event that your primary server goes down. (You should not think of this as a traditional backup. You still need a regular backup system of some sort, like rsnapshot .) The learning curve for LXD can be a bit steep, but this document will attempt to give you a wealth of knowledge at your fingertips, to help you deploy and use LXD on Rocky Linux. Prerequisites And Assumptions One Rocky Linux server, nicely configured. You should consider a separate hard drive for ZFS disk space (you have to if you are using ZFS) in a production environment. And yes, we are assuming this is a bare metal server, not a VPS. This should be considered an advanced topic, but we have tried our best to make it as easy to understand as possible for everyone. That said, knowing a few basic things about container management will take you a long way. You should be very comfortable at the command line on your machine(s), and fluent in a command line editor. (We are using vi throughout this example, but you can substitute in your favorite editor.) You need to be an unprivileged user for the bulk of the LXD processes. Except where noted, enter LXD commands as your unprivileged user. We are assuming that you are logged in as a user named \"lxdadmin\" for LXD commands. The bulk of the set up is , done as root until you get past the LXD initialization. We will have you create the \"lxdadmin\" user later in the process. For ZFS, make sure that UEFI secure boot is NOT enabled. Otherwise, you will end up having to sign the ZFS module in order to get it to load. We will, for the moment, be using CentOS-based containers, as LXC does not yet have Rocky Linux images. Stay tuned for updates, because this will likely change with time. !!! Note This has changed! Feel free to substitute in Rocky Linux containers in the examples below. Part 1 : Getting The Environment Ready Throughout \"Part 1\" you will need to be the root user or you will need to be able to sudo to root. Install EPEL and OpenZFS Repositories LXD requires the EPEL (Extra Packages for Enterprise Linux) repository, which is easy to install using: dnf install epel-release Once installed, check for updates: dnf update If you're using ZFS, install the OpenZFS repository with: dnf install https://zfsonlinux.org/epel/zfs-release.el8_3.noarch.rpm We also need the GPG key, so use this command to get that: gpg --import --import-options show-only /etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux If there were kernel updates during the update process above, reboot your server Install snapd, dkms And vim LXD must be installed from a snap for Rocky Linux. For this reason, we need to install snapd (and a few other useful programs) with: dnf install snapd dkms vim And now enable and start snapd: systemctl enable snapd And then run: systemctl start snapd Reboot the server before continuing here. Install LXD Installing LXD requires the use of the snap command. At this point, we are just installing it, we are doing no set up: sudo snap install lxd Install OpenZFS dnf install kernel-devel zfs Environment Set up Most server kernel settings are not sufficient to run a large number of containers. If we assume from the beginning that we will be using our server in production, then we need to make these changes up front to avoid errors such as \"Too many open files\" from occurring. Luckily, tweaking the settings for LXD is easy with a few file modifications and a reboot. Modifying limits.conf The first file we need to modify is the limits.conf file. This file is self-documented, so look at the explanations in the file as to what this file does. To make our modifications type: vi /etc/security/limits.conf This entire file is remarked/commented out and, at the bottom, shows the current default settings. In the blank space above the end of file marker (#End of file) we need to add our custom settings. The end of the file will look like this when you are done: # Modifications made for LXD * soft nofile 1048576 * hard nofile 1048576 root soft nofile 1048576 root hard nofile 1048576 * soft memlock unlimited * hard memlock unlimited Save your changes and exit. ( SHIFT:wq! for vi ) Modifying sysctl.conf With 90-lxd.override.conf With systemd , we can make changes to our system's overall configuration and kernel options without modifying the main configuration file. Instead, we'll put our settings in a separate file that will simply override the particular settings we need. To make these kernel changes, we are going to create a file called 90-lxd-override.conf in /etc/sysctl.d. To do this type: vi /etc/sysctl.d/90-lxd-override.conf Place the following content in that file. Note that if you are wondering what we are doing here, the file content below is self-documenting: ## The following changes have been made for LXD ## # fs.inotify.max_queued_events specifies an upper limit on the number of events that can be queued to the corresponding inotify instance - (default is 16384) fs.inotify.max_queued_events = 1048576 # fs.inotify.max_user_instances This specifies an upper limit on the number of inotify instances that can be created per real user ID - (default value is 128) fs.inotify.max_user_instances = 1048576 # fs.inotify.max_user_watches specifies an upper limit on the number of watches that can be created per real user ID - (default is 8192) fs.inotify.max_user_watches = 1048576 # vm.max_map_count contains the maximum number of memory map areas a process may have. Memory map areas are used as a side-effect of cal ling malloc, directly by mmap and mprotect, and also when loading shared libraries - (default is 65530) vm.max_map_count = 262144 # kernel.dmesg_restrict denies container access to the messages in the kernel ring buffer. Please note that this also will deny access t o non-root users on the host system - (default is 0) kernel.dmesg_restrict = 1 # This is the maximum number of entries in ARP table (IPv4). You should increase this if you create over 1024 containers. net.ipv4.neigh.default.gc_thresh3 = 8192 # This is the maximum number of entries in ARP table (IPv6). You should increase this if you plan to create over 1024 containers.Not nee ded if not using IPv6, but... net.ipv6.neigh.default.gc_thresh3 = 8192 # This is a limit on the size of eBPF JIT allocations which is usually set to PAGE_SIZE * 40000. net.core.bpf_jit_limit = 3000000000 # This is the maximum number of keys a non-root user can use, should be higher than the number of containers kernel.keys.maxkeys = 2000 # This is the maximum size of the keyring non-root users can use kernel.keys.maxbytes = 2000000 # This is the maximum number of concurrent async I/O operations. You might need to increase it further if you have a lot of workloads th at use the AIO subsystem (e.g. MySQL) fs.aio-max-nr = 524288 At this point you should reboot the server. Checking sysctl.conf Values Once the reboot has been completed, log back in as to the server. We need to spot check that our override file has actually done the job. This is easy to do. There's no need to check every setting unless you want to, but checking a few will verify that the settings have been changed. This is done with the sysctl command: sysctl net.core.bpf_jit_limit Which should show you: net.core.bpf_jit_limit = 3000000000 Do the same with a few other settings in the override file (above) to verify that changes have been made. Enabling ZFS And Setting Up The Pool If you have UEFI secure boot turned off, this should be fairly easy. First, load the ZFS module with modprobe: /sbin/modprobe zfs This should not return an error, it should simply return to the command prompt when done. If you get an error, stop now and begin troubleshooting. Again, make sure that secure boot is off as that will be the most likely culprit. Next we need to take a look at the disks on our system, determine what has the OS loaded on it, and what is available to use for the ZFS pool. We will do this with lsblk : lsblk Which should return something like this (your system will be different!): AME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 32.3M 1 loop /var/lib/snapd/snap/snapd/11588 loop1 7:1 0 55.5M 1 loop /var/lib/snapd/snap/core18/1997 loop2 7:2 0 68.8M 1 loop /var/lib/snapd/snap/lxd/20037 sda 8:0 0 119.2G 0 disk \u251c\u2500sda1 8:1 0 600M 0 part /boot/efi \u251c\u2500sda2 8:2 0 1G 0 part /boot \u251c\u2500sda3 8:3 0 11.9G 0 part [SWAP] \u251c\u2500sda4 8:4 0 2G 0 part /home \u2514\u2500sda5 8:5 0 103.7G 0 part / sdb 8:16 0 119.2G 0 disk \u251c\u2500sdb1 8:17 0 119.2G 0 part \u2514\u2500sdb9 8:25 0 8M 0 part sdc 8:32 0 149.1G 0 disk \u2514\u2500sdc1 8:33 0 149.1G 0 part In this listing, we can see that /dev/sda is in use by the operating system, so we are going to use /dev/sdb for our zpool. Note that if you have multiple free hard drives, you may wish to consider using raidz (a software raid specifically for ZFS). That falls outside the scope of this document, but should definitely be a consideration for production, as it offers better performance and redundancy. For now, let's create our pool on the single device we have identified: zpool create storage /dev/sdb What this says is to create a pool called \"storage\" that is ZFS on the device /dev/sdb . Once the pool is created, it's a good idea to reboot the server again at this point. LXD Initialization Now that the environment is all set up, we are ready to initialize LXD. This is an automated script that asks a series of questions to get your LXD instance up and running: lxd init Here are the questions and our answers for the script, with a little explanation where warranted: Would you like to use LXD clustering? (yes/no) [default=no]: If you are interested in clustering, do some additional research on that here Do you want to configure a new storage pool? (yes/no) [default=yes]: This may seem counter-intuitive, since we have already created our ZFS pool, but it will be resolved in a later question. Accept the default. Name of the new storage pool [default=default]: storage You could leave this as default if you wanted to, but we have chosen to use the same name we gave our ZFS pool. Name of the storage backend to use (btrfs, dir, lvm, zfs, ceph) [default=zfs]: Obviously we want to accept the default. Create a new ZFS pool? (yes/no) [default=yes]: no Here's where the earlier question about creating a storage pool is resolved. Name of the existing ZFS pool or dataset: storage Would you like to connect to a MAAS server? (yes/no) [default=no]: Metal As A Service (MAAS) is outside the scope of this document. Would you like to create a new local network bridge? (yes/no) [default=yes]: What should the new bridge be called? [default=lxdbr0]: What IPv4 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: What IPv6 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: none If you want to use IPv6 on your LXD containers, you can turn on this option. That is up to you. Would you like the LXD server to be available over the network? (yes/no) [default=no]: yes This is necessary to snapshot the server, so answer \"yes\" here. Address to bind LXD to (not including port) [default=all]: Port to bind LXD to [default=8443]: Trust password for new clients: Again: This trust password is how you will connect to the snapshot server or back from the snapshot server, so set this with something that makes sense in your environment. Save this entry to a secure location, such as a password manager. Would you like stale cached images to be updated automatically? (yes/no) [default=yes] Would you like a YAML \"lxd init\" preseed to be printed? (yes/no) [default=no]: Setting Up User Privileges Before we continue on, we need to create our \"lxdadmin\" user and make sure that it has the privileges it needs. We need the \"lxdadmin\" user to be able to sudo to root and we need it to be a member of the lxd group. To add the user and make sure it is a member of both groups do: useradd -G wheel,lxd lxdadmin Then set the password: passwd lxdadmin As with the other passwords, save this to a secure location. Firewall Set Up - iptables Before continuing, you will want a firewall set up on your server. This example is using iptables and this procedure to disable firewalld . If you prefer to use firewalld , simply substitute in firewalld rules using the instructions below this section. Create your firewall.conf script: vi /etc/firewall.conf We are assuming an LXD server on a LAN network of 192.168.1.0/24 below. Note, too, that we are accepting all traffic from our bridged interface. This is important if you want your containers to get IP addresses from the bridge. This firewall script makes no other assumptions about the network services needed. There is an SSH rule to allow our LAN network IP's to SSH into the server. You can very easily have many more rules needed here, depending on your environment. Later, we will be adding a rule for bi-directional traffic between our production server and the snapshot server. #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -i lxdbr0 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Firewall Set Up - firewalld For firewalld rules, we need to use this basic procedure or be familiar with those concepts. Our assumptions are the same as with the iptables rules above: LAN network of 192.168.1.0/24 and a bridge named lxdbr0. To be clear, you might have multiple interfaces on your LXD server, with one perhaps facing your WAN as well. We are also going to create a zone for the bridged and local networks. This is just for zone clarity sake, as the other names do not really apply. The below assumes that you already know the basics of firewalld . firewall-cmd --new-zone=bridge --permanent You need to reload the firewall after adding a zone: firewall-cmd --reload We want to allow all traffic from the bridge, so let's just add the interface, and then change the target from \"default\" to \"ACCEPT\" and we will be done: !!! attention Changing the target of a firewalld zone *must* be done with the --permanent option, so we might as well just enter that flag in our other commands as well and forgo the --runtime-to-permanent option. !!! Note If you need to create a zone that you want to allow all access to the interface or source, but do not want to have to specify any protocols or services, then you *must* change the target from \"default\" to ACCEPT. The same is true of DROP and REJECT for a particular IP block that you have custom zones for. To be clear, the \"drop\" zone will take care of that for you as long as you aren't using a custom zone. firewall-cmd --zone=bridge --add-interface=lxdbr0 --permanent firewall-cmd --zone=bridge --set-target=ACCEPT --permanent Assuming no errors and everything is still working just do a reload: firewall-cmd --reload If you list out your rules now with firewall-cmd --zone=bridge --list-all you should see something like the following: bridge (active) target: ACCEPT icmp-block-inversion: no interfaces: lxdbr0 sources: services: ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Note from the iptables rules, that we also want to allow our local interface. Again, I do not like the included zones for this, so create a new zone and use the source IP range for the local interface to make sure you have access: firewall-cmd --new-zone=local --permanent firewall-cmd --reload Then we just need to add the source IP's for the local interface, change the target to \"ACCEPT\" and we are done with this as well: firewall-cmd --zone=local --add-source=127.0.0.1/8 --permanent firewall-cmd --zone=local --set-target=ACCEPT --permanent firewall-cmd --reload Go ahead and list out the \"local\" zone to make sure your rules are there with firewall-cmd --zone=local --list all which should show you something like this: local (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 127.0.0.1/8 services: ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Next we want to allow SSH from our trusted network. We will use the source IP's here, just like in our iptables example, and the built-in \"trusted\" zone. The target for this zone is already \"ACCEPT\" by default. firewall-cmd --zone=trusted --add-source=192.168.1.0/24 Then add the service to the zone: firewall-cmd --zone=trusted --add-service=ssh And if everything is working, move your rules to permanent and reload the rules: firewall-cmd --runtime-to-permanent firewall-cmd --reload Listing out your \"trusted\" zone should now show you something like this: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: By default, the \"public\" zone is enabled and has SSH allowed. We don't want this. Make sure that your zones are correct and that the access you are getting to the server is via one of the LAN IP's (in the case of our example) and is allowed to SSH. You could lock yourself out of the server if you don't verify this before continuing. Once you've made sure you have access from the correct interface, remove SSH from the \"public\" zone: firewall-cmd --zone=public --remove-service=ssh Test access and make sure you aren't locked out. If not, then move your rules to permanent, reload, and list out zone \"public\" to be sure that SSH is removed: firewall-cmd --runtime-to-permanent firewall-cmd --reload firewall-cmd --zone=public --list-all There may be other interfaces on your server to consider. You can use built-in zones where appropriate, but if you don't like the names (they don't appear logical, etc.), you can definitely add zones. Just remember that if you have no services or protocols that you need to allow or reject specifically, then you will need to modify the zone target. If it works to use interfaces, as we've done with the bridge, you can do that. If you need more granular access to services, uses source IP's instead. This completes Part 1. You can either continue on to Part 2, or return to the menu . If you are working on the snapshot server, you can head down to Part 5 now. Part 2 : Setting Up And Managing Images Throughout Part 2, and from here on out unless otherwise noted, you will be running commands as your unprivileged user. (\"lxdadmin\" if you are following along with this document). List Available Images Once you have your server environment set up, you'll probably be itching to get started with a container. There are a lot of container OS possibilities. To get a feel for how many possibilities, enter this command: lxc image list images: | more Hit the space bar to page through the list. This list of containers and virtual machines continues to grow. For now, we are sticking with containers. The last thing you want to do is to page through looking for a container image to install, particularly if you know the image that you want to create. Let's modify the command above to show only CentOS Linux install options: lxc image list images: | grep centos/8 This brings up a much more manageable list: | centos/8 (3 more) | 98b4dbef0c29 | yes | Centos 8 amd64 (20210427_07:08) | x86_64 | VIRTUAL-MACHINE | 517.44MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8 (3 more) | 0427669ebee4 | yes | Centos 8 amd64 (20210427_07:08) | x86_64 | CONTAINER | 125.58MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream (3 more) | 961170f8934f | yes | Centos 8-Stream amd64 (20210427_07:08) | x86_64 | VIRTUAL-MACHINE | 586.44MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream (3 more) | e507fdc8935a | yes | Centos 8-Stream amd64 (20210427_07:08) | x86_64 | CONTAINER | 130.33MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/arm64 (1 more) | e5bf98409ac6 | yes | Centos 8-Stream arm64 (20210427_10:33) | aarch64 | CONTAINER | 126.56MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/cloud (1 more) | 5751ca14bf8f | yes | Centos 8-Stream amd64 (20210427_07:08) | x86_64 | CONTAINER | 144.75MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/cloud (1 more) | ccf0bb20b0ca | yes | Centos 8-Stream amd64 (20210427_07:08) | x86_64 | VIRTUAL-MACHINE | 593.31MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/cloud/arm64 | db3d915d12fd | yes | Centos 8-Stream arm64 (20210427_07:08) | aarch64 | CONTAINER | 140.60MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/cloud/ppc64el | 11aa2ab878b2 | yes | Centos 8-Stream ppc64el (20210427_07:08) | ppc64le | CONTAINER | 149.45MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/ppc64el (1 more) | a27665203e47 | yes | Centos 8-Stream ppc64el (20210427_07:08) | ppc64le | CONTAINER | 134.52MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/arm64 (1 more) | d64396d47fa7 | yes | Centos 8 arm64 (20210427_07:08) | aarch64 | CONTAINER | 121.83MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/cloud (1 more) | 84803ca6e32d | yes | Centos 8 amd64 (20210427_07:08) | x86_64 | CONTAINER | 140.42MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/cloud (1 more) | c98196cd9eec | yes | Centos 8 amd64 (20210427_07:08) | x86_64 | VIRTUAL-MACHINE | 536.00MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/cloud/arm64 | 9d06684a9a4e | yes | Centos 8 arm64 (20210427_10:33) | aarch64 | CONTAINER | 136.49MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/cloud/ppc64el | 18c13c448349 | yes | Centos 8 ppc64el (20210427_07:08) | ppc64le | CONTAINER | 144.66MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/ppc64el (1 more) | 130c1c83c36c | yes | Centos 8 ppc64el (20210427_07:08) | ppc64le | CONTAINER | 129.53MB | Apr 27, 2021 at 12:00am (UTC) | Installing, Renaming, And Listing Images For the first container, we are going to choose centos/8. To install it, we could use: lxc launch images:centos/8 centos-test That will create a CentOS-based containter named \"centos-test\". You can rename a container after it has been created, but you first need to stop the container, which starts automatically when it is launched. To start the container manually, use: lxc start centos-test For the purposes of this guide, go ahead and install one more image for now: lxc launch images:ubuntu/20.10 ubuntu-test Now let's take a look at what we have so far by listing our images: lxc list which should return something like this: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | 10.199.182.72 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ LXD Profiles You get a default profile when you install LXD, and this profile cannot be removed or modified. That said, you can use the default profile to create new profiles to use with your containers. If you look at our container listing (above) you will notice that the IP address in each case is assigned from the bridged interface. In a production environment, you may want to use something else. This might be a DHCP assigned address from your LAN interface or even a statically assigned address from your WAN. If you configure your LXD server with two interfaces, and assign each an IP on your WAN and LAN, then it is possible to assign your containers IP addresses based on which interface the container needs to be facing. As of version 8 of Rocky Linux (and really any bug for bug copy of Red Hat Enterprise Linux, such as CentOS in our listing above) the method for assigning IP addresses statically or dynamically using the profiles below, is broken out of the gate. There are ways to get around this, but it is annoying, as the feature that is broken should be part of the Linux kernel. That feature is macvlan. Macvlan allows you to create multiple interfaces with different Layer 2 addresses. For now, just be aware that what we are going to suggest next has drawbacks when choosing container images based on RHEL. Creating A macvlan Profile And Assigning It To create our macvlan profile, simply use this command: lxc profile create macvlan Keep in mind that if we were on a multi-interface machine and wanted more than one macvlan template based on which network we wanted to reach, we could use \"lanmacvlan\" or \"wanmacvlan\" or any other name that we wanted to use to identify the profile. In other words, using \"macvlan\" in our profile create statement is totally up to you. Once the profile is created, we now need to modify it to do what we want. First, we need to make sure that the server's default editor is what we want to use. If we don't do this step, the editor will be whatever the default editor is. We are choosing vim for our editor here: export EDITOR=/usr/bin/vim Now we want to modify the macvlan interface, but before we do, we need to know what the parent interface is for our LXD server. This will be the interface that has a LAN (in this case) assigned IP. To determine which interface that is, use: ip addr And then look for the interface with the LAN IP assignment in the 192.168.1.0/24 network: 2: enp3s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 40:16:7e:a9:94:85 brd ff:ff:ff:ff:ff:ff inet 192.168.1.106/24 brd 192.168.1.255 scope global dynamic noprefixroute enp3s0 valid_lft 4040sec preferred_lft 4040sec inet6 fe80::a308:acfb:fcb3:878f/64 scope link noprefixroute valid_lft forever preferred_lft forever So in this case, the interface would be \"enp3s0\". Now let's modify the profile: lxc profile edit macvlan This file will be self-documented at the top. What we need to do is modify the file as follows below the commented section: config: {} description: \"\" devices: eth0: name: eth0 nictype: macvlan parent: enp3s0 type: nic name: macvlan used_by: [] Obviously, you can use profiles for lots of other things, but assigning a static IP to a container, or using your own DHCP server as a source for an address are very common needs. To assign the macvlan profile to centos-test we need to do the following: lxc profile assign centos-test default,macvlan This simply says, we want the default profile, and then we want to apply the macvlan profile as well. CentOS macvlan In the CentOS implementation of Network Manager, they have managed to break the functionality of macvlan in the kernel, or at least in the kernel applied to their LXD image. This has been this way since CentOS 8 was released and no one appears to be at all concerned about a fix. Simply put, if you want to run CentOS 8 containers (or any other RHEL 1-for-1 release, such as Rocky Linux), you've got to jump through some additional hoops to get macvlan to work. macvlan is part of the kernel, so it should work without the below fixes, but it doesn't. CentOS macvlan - The DHCP Fix Having the profile assigned, however, doesn't change the default configuration, which is set to DHCP by default. To test this, simply do the following: lxc stop centos-test And then: lxc start centos-test Now list your containers again and note that centos-test does not have an IP address anymore: lxc list +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ To further demonstrate the problem here, we need to execute dhclient on the container. You can do this with: lxc exec centos-test dhclient A new listing using lxc list now shows the following: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.138 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ That should have happened with a simple stop and start of the container, but it does not. Assuming that we want to use a DHCP assigned IP address every time, then we can fix this with a simple crontab entry. To do this, we need to gain shell access to the container by entering: lxc exec centos-test bash Next, lets determine the complete path to dhclient : which dhclient which should return: /usr/sbin/dhclient Next, let's modify root's crontab: crontab -e And add this line: @reboot /usr/sbin/dhclient The crontab command entered above, uses vi so to save your changes and exit simply use: SHIFT:wq! Now exit the container and stop centos-test: lxc stop centos-test and then start it again: lxc start centos-test A new listing will reveal that the container has been assigned the DHCP address: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.138 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ CentOS macvlan - The Static IP Fix To statically assign an IP address, things get even more convoluted. The process of setting a static IP address on a CentOS container is through the network-scripts, which we will do now. The IP we will attempt to assign is 192.168.1.200. To do this, we need to gain shell access to the container again: lxc exec centos-test bash The next thing we need to do is to manually modify the interface labelled \"eth0\", and set our IP address. To modify our configuration, do the following: vi /etc/sysconfig/network-scripts/ifcfg-eth0 Which will return this: DEVICE=eth0 BOOTPROTO=dhcp ONBOOT=yes HOSTNAME=centos-test TYPE=Ethernet MTU= DHCP_HOSTNAME=centos-test IPV6INIT=yes We need to modify this file so that it looks like this: DEVICE=eth0 BOOTPROTO=none ONBOOT=yes IPADDR=192.168.1.200 PREFIX=24 GATEWAY=192.168.1.1 DNS1=8.8.8.8 DNS2=8.8.4.4 HOSTNAME=centos-test TYPE=Ethernet MTU= DHCP_HOSTNAME=centos-test IPV6INIT=yes This says we want to set the boot protocol to none (used for static IP assignments), set the IP address to 192.168.1.200, that this address is part of a CLASS C (PREFIX=24) address, that the gateway for this network is 192.168.1.1 and then that we want to use Google's open DNS servers for name resolution. Save your file ( SHIFT:wq! ). We also need to remove our crontab for root, as this isn't what we want for a static IP. To do this, simply crontab -e and remark out the @reboot line with a \"#\", save your changes and exit the container. Stop the container with: lxc stop centos-test and start it again: lxc start centos-test Just like our DHCP assigned address, the statically assigned address will not be assigned when we list the container: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ To fix this requires breaking Network Manager on the container. The following works-at least for now: lxc exec centos-test dhclient Then get into the container: lxc exec centos-test bash Install the old network scripts: dnf install network-scripts Nuke Network Manager: systemctl stop NetworkManager systemctl disable NetworkManager Enable the old Network service: systemctl enable network.service Exit the container and then stop and start the container again: lxc stop centos-test And then run: lxc start centos-test When the container starts, a new listing will show the correct statically assigned IP: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.200 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ The issue with macvlan shown in both of these examples is directly related to containers based on Red Hat Enterprise Linux (Centos 8, Rocky Linux 8). Ubuntu macvlan Luckily, In Ubuntu's implementation of Network Manager, the macvlan stack is NOT broken, so it is much easier to deploy! First, just like with our centos-test container, we need to assign the template to our container: lxc profile assign ubuntu-test default,macvlan That should be all that is necessary to get a DHCP assigned address. To find out, stop and then start the container again: lxc stop ubuntu-test And then run: lxc start ubuntu-test Then list the containers again: +-------------+---------+----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.200 (eth0) | | CONTAINER | 0 | +-------------+---------+----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 192.168.1.139 (eth0) | | CONTAINER | 0 | +-------------+---------+----------------------+------+-----------+-----------+ Success! Configuring the Static IP is just a little different, but not at all hard. We need to modify the .yaml file associated with the container's connection (/10-lxc.yaml). For this static IP, we will use 192.168.1.201: vi /etc/netplan/10-lxc.yaml And change what is there to the following: network: version: 2 ethernets: eth0: dhcp4: false addresses: [192.168.1.201/24] gateway4: 192.168.1.1 nameservers: addresses: [8.8.8.8,8.8.4.4] Save your changes ( SHFT:wq! ) and exit the container. Now stop and start the container: lxc stop ubuntu-test And then run: lxc start ubuntu-test When you list your containers again, you should see our new static IP: +-------------+---------+----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.200 (eth0) | | CONTAINER | 0 | +-------------+---------+----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 192.168.1.201 (eth0) | | CONTAINER | 0 | +-------------+---------+----------------------+------+-----------+-----------+ Success! In the examples used in Part 2, we have intentionally chosen a hard container to configure, and an easy one. There are obviously many more versions of Linux available in the image listing. If you have a favorite, try installing it, assigning the macvlan template, and setting IP's. This completes Part 2. You can either continue on to Part 3, or return to the menu . Part 3 : Container Configuration Options There are a wealth of options for configuring the container once you have it installed. Before we get into how to see those, however, let's take a look at the info command for a container. In this example, we will use the ubuntu-test container: lxc info ubuntu-test This shows something like the following: Name: ubuntu-test Location: none Remote: unix:// Architecture: x86_64 Created: 2021/04/26 15:14 UTC Status: Running Type: container Profiles: default, macvlan Pid: 584710 Ips: eth0: inet 192.168.1.201 enp3s0 eth0: inet6 fe80::216:3eff:fe10:6d6d enp3s0 lo: inet 127.0.0.1 lo: inet6 ::1 Resources: Processes: 13 Disk usage: root: 85.30MB CPU usage: CPU usage (in seconds): 1 Memory usage: Memory (current): 99.16MB Memory (peak): 110.90MB Network usage: eth0: Bytes received: 53.56kB Bytes sent: 2.66kB Packets received: 876 Packets sent: 36 lo: Bytes received: 0B Bytes sent: 0B Packets received: 0 Packets sent: 0 There's a lot of good information there, from the profiles applied, to the memory in use, disk space in use, and more. A Word About Configuration And Some Options By default, LXD will allocate the required system memory, disk space, CPU cores, etc., to the container. But what if we want to be more specific? That is totally possible. There are trade-offs to doing this, though. For instance, if we allocate system memory and the container doesn't actually use it all, then we have kept it from another container that might actually need it. The reverse, though, can happen. If a container is a complete pig on memory, then it can keep other containers from getting enough, thereby pinching their performance. Just keep in mind that every action you make to configure a container can have negative effects somewhere else. Rather than run through all of the options for configuration, use the tab auto-complete to see the options available: lxc config set ubuntu-test and then hit TAB. This shows you all of the options for configuring a container. If you have questions about what one of the configuration options does, head up to the official documentation for LXD and do a search for the configuration parameter, or Google the entire string, such as \"lxc config set limits.memory\" and take a look at the results of the search. We will look at a few of the most used configuration options. For example, if you want to set the max amount of memory that a container can use: lxc config set ubunt-test limits.memory 2GB That says that as long as the memory is available to use, in other words there is 2GB of memory free, then the container can actually use more than 2GB if it's available. It's a soft limit, in other words. lxc config set ubuntu-test limits.memory.enforce 2GB That says that the container can never use more than 2GB of memory, whether it's currently available or not. In this case it's a hard limit. lxc config set ubuntu-test limits.cpu 2 That says to limit the number of cpu cores that the container can use to 2. Remember when we set up our storage pool in the Enabling zfs And Setting Up The Pool above? We named the pool \"storage,\" but we could have named it anything. If we want to look at this, we can use this command: lxc storage show storage This shows the following: config: source: storage volatile.initial_source: storage zfs.pool_name: storage description: \"\" name: storage driver: zfs used_by: - /1.0/images/0cc65b6ca6ab61b7bc025e63ca299f912bf8341a546feb8c2f0fe4e83843f221 - /1.0/images/4f0019aee1515c109746d7da9aca6fb6203b72f252e3ee3e43d50b942cdeb411 - /1.0/images/9954953f2f5bf4047259bf20b9b4f47f64a2c92732dbc91de2be236f416c6e52 - /1.0/instances/centos-test - /1.0/instances/ubuntu-test - /1.0/profiles/default status: Created locations: - none This shows that all of our containers are using our zfs storage pool. When using ZFS, you can also set a disk quota on a container. Let's do this by setting a 2GB disk quota on the ubuntu-test container. You do this with: lxc config device override ubuntu-test root size=2GB As stated earlier, you should use configuration options sparingly, unless you've got a container that wants to use way more than its share of resources. LXD, for the most part, will manage the environment well on its own. There are, of course, many more options that may be of interest to some people. You should do your own research to find out if any of those are of value in your environment. This completes Part 3. You can either continue on to Part 4, or return to the menu . Part 4: Container Snapshots Container snapshots, along with a snapshot server (which we will get to more later), are probably the most important aspect of running a production LXD server. Snapshots ensure quick recovery, and can be used for safety when you are, say, updating the primary software that runs on a particular container. If something happens during the update that breaks that application, you simply restore the snapshot and you are back up and running with only a few seconds worth of downtime. The author used LXD containers for PowerDNS public facing servers, and the process of updating those applications became so much more worry-free, since you can snapshot the container first before continuing. You can even snapshot a container while it is running. We'll start by getting a snapshot of the ubuntu-test container by using this command: lxc snapshot ubuntu-test ubuntu-test-1 Here, we are calling the snapshot \"ubuntu-test-1\", but it can be called anything you like. To make sure that you have the snapshot, do an \"lxc info\" of the container: lxc info ubuntu-test We've looked at an info screen already, so if you scroll to the bottom, you should see: Snapshots: ubuntu-test-1 (taken at 2021/04/29 15:57 UTC) (stateless) Success! Our snapshot is in place. Now, get into the ubuntu-test container: lxc exec ubuntu-test bash And create an empty file with the touch command: touch this_file.txt Now exit the container. Before we restore the container as it was prior to creating the file, the safest way to restore a container, particularly if there have been a lot of changes, is to stop it first: lxc stop ubuntu-test Then restore it: lxc restore ubuntu-test ubuntu-test-1 Then start the container again: lxc start ubuntu-test If you get back into the container again and look, our \"this_file.txt\" that we created is now gone. Once you don't need a snapshot anymore, you can delete it: lxc delete ubuntu-test/ubuntu-test-1 Important: You should always delete snapshots with the container running. Why? Well the lxc delete command also works to delete the entire container. If we had accidentally hit enter after \"ubuntu-test\" in the command above, AND, if the container was stopped, the container would be deleted. No warning is given, it simply does what you ask. If the container is running, however, you will get this message: Error: The instance is currently running, stop it first or pass --force So always delete snapshots with the container running. The process of creating snapshots automatically, setting expiration of the snapshot so that it goes away after a certain length of time, and auto refreshing the snapshots to the snapshot server will be covered in detail in the section dealing with the snapshot server. This completes Part 4. You can either continue on to Part 5, or return to the menu . Part 5: The Snapshot Server As noted at the beginning, the snapshot server for LXD should be a mirror of the production server in every way possible. The reason is that you may need to take it to production in the event of a hardware failure, and having not only backups, but a quick way to bring up production containers, keeps those systems administrator panic phone calls and text messages to a minimum. THAT is ALWAYS good! So the process of building the snapshot server is exactly like the production server. To fully emulate our production server set up, do all of Part 1 again, and when completed, return to this spot. You're back!! Congratulations, this must mean that you have successfully completed Part 1 for the snapshot server. That's great news!! Setting Up The Primary and Snapshot Server Relationship We've got some housekeeping to do before we continue. First, if you are running in a production environment, you probably have access to a DNS server that you can use for setting up IP to name resolution. In our lab, we don't have that luxury. Perhaps you've got the same scenario running. For this reason, we are going to add both servers IP addresses and names to the /etc/hosts file on BOTH the primary and the snapshot server. You'll need to do this as your root (or sudo ) user. In our lab, the primary LXD server is running on 192.168.1.106 and the snapshot LXD server is running on 192.168.1.141. We will SSH into both servers and add the following to the /etc/hosts file: 192.168.1.106 lxd-primary 192.168.1.141 lxd-snapshot Next, we need to allow all traffic between the two servers. To do this, we are going to modify the /etc/firewall.conf file with the following. First, on the lxd-primary server, add this line: IPTABLES -A INPUT -s 192.168.1.141 -j ACCEPT And on the lxd-snapshot server, add this line: IPTABLES -A INPUT -s 192.168.1.106 -j ACCEPT This allows bi-directional traffic of all types to travel between the two servers. Next, as the \"lxdadmin\" user, we need to set the trust relationship between the two machines. This is done by executing the following on lxd-primary: lxc remote add lxd-snapshot This will display the certificate to accept, so do that, and then it will prompt for your password. This is the \"trust password\" that you set up when doing the LXD initialization step. Hopefully, you are securely keeping track of all of these passwords. Once you enter the password, you should receive this: Client certificate stored at server: lxd-snapshot It does not hurt to have this done in reverse as well. In other words, set the trust relationship on the lxd-snapshot server so that, if needed, snapshots can be sent back to the lxd-primary server. Simply repeat the steps and substitute in \"lxd-primary\" for \"lxd-snapshot.\" Migrating Our First Snapshot Before we can migrate our first snapshot, we need to have any profiles created on lxd-snapshot that we have created on the lxd-primary. In our case, this is the \"macvlan\" profile. You'll need to create this for lxd-snapshot, so go back to LXD Profiles and create the \"macvlan\" profile on lxd-snapshot. If your two servers have identical parent interface names (\"enp3s0\" for example) then you can copy the \"macvlan\" profile over to lxd-snapshot without recreating it: lxc profile copy macvlan lxd-snapshot Now that we have all of the relationships and profiles set up, the next step is to actually send a snapshot from lxd-primary over to lxd-snapshot. If you've been following along exactly, you've probably deleted all of your snapshots, so let's create a new one: lxc snapshot centos-test centos-snap1 If you run the \"info\" sub-command for lxc, you can see the new snapshot on the bottom of our listing: lxc info centos-test Which will show something like this at the bottom: centos-snap1 (taken at 2021/05/13 16:34 UTC) (stateless) OK, fingers crossed! Let's try to migrate our snapshot: lxc copy centos-test/centos-snap1 lxd-snapshot:centos-test What this command says is, that within the container centos-test, we want to send the snapshot, centos-snap1 over to lxd-snapshot and copy it as centos-test. After a short period of time has expired, the copy will be complete. Want to find out for sure? Do an \"lxc list\" on the lxd-snapshot server. Which should return the following: +-------------+---------+------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+------+------+-----------+-----------+ | centos-test | STOPPED | | | CONTAINER | 0 | +-------------+---------+------+------+-----------+-----------+ Success! Now let's try starting it. Because we are starting it on the lxd-snapshot server, we need to stop it first on the lxd-primary server: lxc stop centos-test And on the lxd-snapshot server: lxc start centos-test Assuming all of this works without error, stop the container on lxd-snapshot and start it again on lxd-primary. The Snapshot Server - Setting boot.autostart To Off For Containers The snapshots copied to lxd-snapshot will be down when they are migrated, but if you have a power event or need to reboot the snapshot server because of updates or something, you will end up with a problem as those containers will attempt to start on the snapshot server. To eliminate this, we need to set the migrated containers so that they will not start on reboot of the server. For our newly copied centos-test container, this is done with the following: lxc config set centos-test boot.autostart 0 Do this for each snapshot on the lxd-snapshot server. Automating The Snapshot Process Ok, so it's great that you can create snapshots when you need to, and sometimes you do need to manually create a snapshot. You might even want to manually copy it over to lxd-snapshot. BUT, once you've got things going and you've got 25 to 30 containers or more running on your lxd-primary machine, the very last thing you want to do is spend an afternoon deleting snapshots on the snapshot server, creating new snapshots and sending them over. The first thing we need to do is schedule a process to automate snapshot creation on lxd-primary. This has to be done for each container on the lxd-primary server, but once it is set up, it will take care of itself. This is done with the following syntax. Note the similarities to a crontab entry for the timestamp: lxc config set [container_name] snapshots.schedule \"50 20 * * *\" What this is saying is, do a snapshot of the container name every day at 8:50 PM. To apply this to our centos-test container: lxc config set centos-test snapshots.schedule \"50 20 * * *\" We also want to set up the name of the snapshot to be meaningful by our date. LXD uses UTC everywhere, so our best bet to keep track of things, is to set the snapshot name with a date/time stamp that is in a more understandable format: lxc config set centos-test snapshots.pattern \"centos-test-{{ creation_date|date:'2006-01-02_15-04-05' }}\" GREAT, but we certainly don't want a new snapshot every day without getting rid of an old one, right? We'd fill up the drive with snapshots. So next we run: lxc config set centos-test snapshots.expiry 1d Automating The Snapshot Copy Process Again, this process is performed on lxd-primary. First thing we need to do is create a script that will be run by cron in /usr/local/sbin called \"refresh-containers\" : sudo vi /usr/local/sbin/refreshcontainers.sh The script is pretty simple: #!/bin/bash # This script is for doing an lxc copy --refresh against each container, copying # and updating them to the snapshot server. for x in $(/var/lib/snapd/snap/bin/lxc ls -c n --format csv) do echo \"Refreshing $x\" /var/lib/snapd/snap/bin/lxc copy --refresh $x lxd-snapshot:$x done Make it executable: sudo chmod +x /usr/local/sbin/refreshcontainers.sh Change the ownership of this script to your lxdadmin user and group: sudo chown lxdadmin.lxdadmin /usr/local/sbin/refreshcontainers.sh Set up the crontab for the lxdadmin user to run this script, in this case at 10 PM: crontab -e And your entry will look like this: 00 22 * * * /usr/local/sbin/refreshcontainers.sh > /home/lxdadmin/refreshlog 2>&1 Save your changes and exit. This will create a log in lxdadmin's home directory called \"refreshlog\" which will give you knowledge of whether your process worked or not. Very important! The automated procedure will fail sometimes. This generally happens when a particular container fails to refresh. You can manually re-run the refresh with the following command (assuming centos-test here, as our container): lxc copy --refresh centos-test lxd-snapshot:centos-test Conclusions There is a great deal to installing and effectively using LXD. You can certainly install it on your laptop or workstation without all the fuss, as it makes a great developing and testing platform. If you want a more serious approach using production containers, then a primary and snapshot server approach is your best bet. Even though we've touched on a lot of features and settings, we have only scratched the surface of what you can do with LXD. The best way to learn this system, is to install it and try it out with things that you will use. If you find LXD useful, consider installing it in the fashion described in this document for the best possible leveraging of hardware for Linux containers. Rocky Linux works very well for this! You can now exit this document, or return to the menu . You know, if you want.","title":"LXD Server"},{"location":"guides/containers/lxd_server/#creating-a-full-lxd-server","text":"","title":"Creating a full LXD Server"},{"location":"guides/containers/lxd_server/#introduction","text":"LXD is best described on the official website , but think of it as a container system that provides the benefits of virtual servers in a container, or a container on steroids. It is very powerful, and with the right hardware and set up, can be leveraged to run a lot of server instances on a single piece of hardware. If you pair that with a snapshot server, you also have a set of containers that you can spin up almost immediately in the event that your primary server goes down. (You should not think of this as a traditional backup. You still need a regular backup system of some sort, like rsnapshot .) The learning curve for LXD can be a bit steep, but this document will attempt to give you a wealth of knowledge at your fingertips, to help you deploy and use LXD on Rocky Linux.","title":"Introduction"},{"location":"guides/containers/lxd_server/#prerequisites-and-assumptions","text":"One Rocky Linux server, nicely configured. You should consider a separate hard drive for ZFS disk space (you have to if you are using ZFS) in a production environment. And yes, we are assuming this is a bare metal server, not a VPS. This should be considered an advanced topic, but we have tried our best to make it as easy to understand as possible for everyone. That said, knowing a few basic things about container management will take you a long way. You should be very comfortable at the command line on your machine(s), and fluent in a command line editor. (We are using vi throughout this example, but you can substitute in your favorite editor.) You need to be an unprivileged user for the bulk of the LXD processes. Except where noted, enter LXD commands as your unprivileged user. We are assuming that you are logged in as a user named \"lxdadmin\" for LXD commands. The bulk of the set up is , done as root until you get past the LXD initialization. We will have you create the \"lxdadmin\" user later in the process. For ZFS, make sure that UEFI secure boot is NOT enabled. Otherwise, you will end up having to sign the ZFS module in order to get it to load. We will, for the moment, be using CentOS-based containers, as LXC does not yet have Rocky Linux images. Stay tuned for updates, because this will likely change with time. !!! Note This has changed! Feel free to substitute in Rocky Linux containers in the examples below.","title":"Prerequisites And Assumptions"},{"location":"guides/containers/lxd_server/#part-1-getting-the-environment-ready","text":"Throughout \"Part 1\" you will need to be the root user or you will need to be able to sudo to root.","title":"Part 1 : Getting The Environment Ready"},{"location":"guides/containers/lxd_server/#install-epel-and-openzfs-repositories","text":"LXD requires the EPEL (Extra Packages for Enterprise Linux) repository, which is easy to install using: dnf install epel-release Once installed, check for updates: dnf update If you're using ZFS, install the OpenZFS repository with: dnf install https://zfsonlinux.org/epel/zfs-release.el8_3.noarch.rpm We also need the GPG key, so use this command to get that: gpg --import --import-options show-only /etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux If there were kernel updates during the update process above, reboot your server","title":"Install EPEL and OpenZFS Repositories"},{"location":"guides/containers/lxd_server/#install-snapd-dkms-and-vim","text":"LXD must be installed from a snap for Rocky Linux. For this reason, we need to install snapd (and a few other useful programs) with: dnf install snapd dkms vim And now enable and start snapd: systemctl enable snapd And then run: systemctl start snapd Reboot the server before continuing here.","title":"Install snapd, dkms And vim"},{"location":"guides/containers/lxd_server/#install-lxd","text":"Installing LXD requires the use of the snap command. At this point, we are just installing it, we are doing no set up: sudo snap install lxd","title":"Install LXD"},{"location":"guides/containers/lxd_server/#install-openzfs","text":"dnf install kernel-devel zfs","title":"Install OpenZFS"},{"location":"guides/containers/lxd_server/#environment-set-up","text":"Most server kernel settings are not sufficient to run a large number of containers. If we assume from the beginning that we will be using our server in production, then we need to make these changes up front to avoid errors such as \"Too many open files\" from occurring. Luckily, tweaking the settings for LXD is easy with a few file modifications and a reboot.","title":" Environment Set up"},{"location":"guides/containers/lxd_server/#modifying-limitsconf","text":"The first file we need to modify is the limits.conf file. This file is self-documented, so look at the explanations in the file as to what this file does. To make our modifications type: vi /etc/security/limits.conf This entire file is remarked/commented out and, at the bottom, shows the current default settings. In the blank space above the end of file marker (#End of file) we need to add our custom settings. The end of the file will look like this when you are done: # Modifications made for LXD * soft nofile 1048576 * hard nofile 1048576 root soft nofile 1048576 root hard nofile 1048576 * soft memlock unlimited * hard memlock unlimited Save your changes and exit. ( SHIFT:wq! for vi )","title":"Modifying limits.conf"},{"location":"guides/containers/lxd_server/#modifying-sysctlconf-with-90-lxdoverrideconf","text":"With systemd , we can make changes to our system's overall configuration and kernel options without modifying the main configuration file. Instead, we'll put our settings in a separate file that will simply override the particular settings we need. To make these kernel changes, we are going to create a file called 90-lxd-override.conf in /etc/sysctl.d. To do this type: vi /etc/sysctl.d/90-lxd-override.conf Place the following content in that file. Note that if you are wondering what we are doing here, the file content below is self-documenting: ## The following changes have been made for LXD ## # fs.inotify.max_queued_events specifies an upper limit on the number of events that can be queued to the corresponding inotify instance - (default is 16384) fs.inotify.max_queued_events = 1048576 # fs.inotify.max_user_instances This specifies an upper limit on the number of inotify instances that can be created per real user ID - (default value is 128) fs.inotify.max_user_instances = 1048576 # fs.inotify.max_user_watches specifies an upper limit on the number of watches that can be created per real user ID - (default is 8192) fs.inotify.max_user_watches = 1048576 # vm.max_map_count contains the maximum number of memory map areas a process may have. Memory map areas are used as a side-effect of cal ling malloc, directly by mmap and mprotect, and also when loading shared libraries - (default is 65530) vm.max_map_count = 262144 # kernel.dmesg_restrict denies container access to the messages in the kernel ring buffer. Please note that this also will deny access t o non-root users on the host system - (default is 0) kernel.dmesg_restrict = 1 # This is the maximum number of entries in ARP table (IPv4). You should increase this if you create over 1024 containers. net.ipv4.neigh.default.gc_thresh3 = 8192 # This is the maximum number of entries in ARP table (IPv6). You should increase this if you plan to create over 1024 containers.Not nee ded if not using IPv6, but... net.ipv6.neigh.default.gc_thresh3 = 8192 # This is a limit on the size of eBPF JIT allocations which is usually set to PAGE_SIZE * 40000. net.core.bpf_jit_limit = 3000000000 # This is the maximum number of keys a non-root user can use, should be higher than the number of containers kernel.keys.maxkeys = 2000 # This is the maximum size of the keyring non-root users can use kernel.keys.maxbytes = 2000000 # This is the maximum number of concurrent async I/O operations. You might need to increase it further if you have a lot of workloads th at use the AIO subsystem (e.g. MySQL) fs.aio-max-nr = 524288 At this point you should reboot the server.","title":"Modifying sysctl.conf With 90-lxd.override.conf"},{"location":"guides/containers/lxd_server/#checking-sysctlconf-values","text":"Once the reboot has been completed, log back in as to the server. We need to spot check that our override file has actually done the job. This is easy to do. There's no need to check every setting unless you want to, but checking a few will verify that the settings have been changed. This is done with the sysctl command: sysctl net.core.bpf_jit_limit Which should show you: net.core.bpf_jit_limit = 3000000000 Do the same with a few other settings in the override file (above) to verify that changes have been made.","title":"Checking sysctl.conf Values"},{"location":"guides/containers/lxd_server/#enabling-zfs-and-setting-up-the-pool","text":"If you have UEFI secure boot turned off, this should be fairly easy. First, load the ZFS module with modprobe: /sbin/modprobe zfs This should not return an error, it should simply return to the command prompt when done. If you get an error, stop now and begin troubleshooting. Again, make sure that secure boot is off as that will be the most likely culprit. Next we need to take a look at the disks on our system, determine what has the OS loaded on it, and what is available to use for the ZFS pool. We will do this with lsblk : lsblk Which should return something like this (your system will be different!): AME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 32.3M 1 loop /var/lib/snapd/snap/snapd/11588 loop1 7:1 0 55.5M 1 loop /var/lib/snapd/snap/core18/1997 loop2 7:2 0 68.8M 1 loop /var/lib/snapd/snap/lxd/20037 sda 8:0 0 119.2G 0 disk \u251c\u2500sda1 8:1 0 600M 0 part /boot/efi \u251c\u2500sda2 8:2 0 1G 0 part /boot \u251c\u2500sda3 8:3 0 11.9G 0 part [SWAP] \u251c\u2500sda4 8:4 0 2G 0 part /home \u2514\u2500sda5 8:5 0 103.7G 0 part / sdb 8:16 0 119.2G 0 disk \u251c\u2500sdb1 8:17 0 119.2G 0 part \u2514\u2500sdb9 8:25 0 8M 0 part sdc 8:32 0 149.1G 0 disk \u2514\u2500sdc1 8:33 0 149.1G 0 part In this listing, we can see that /dev/sda is in use by the operating system, so we are going to use /dev/sdb for our zpool. Note that if you have multiple free hard drives, you may wish to consider using raidz (a software raid specifically for ZFS). That falls outside the scope of this document, but should definitely be a consideration for production, as it offers better performance and redundancy. For now, let's create our pool on the single device we have identified: zpool create storage /dev/sdb What this says is to create a pool called \"storage\" that is ZFS on the device /dev/sdb . Once the pool is created, it's a good idea to reboot the server again at this point.","title":"Enabling ZFS And Setting Up The Pool"},{"location":"guides/containers/lxd_server/#lxd-initialization","text":"Now that the environment is all set up, we are ready to initialize LXD. This is an automated script that asks a series of questions to get your LXD instance up and running: lxd init Here are the questions and our answers for the script, with a little explanation where warranted: Would you like to use LXD clustering? (yes/no) [default=no]: If you are interested in clustering, do some additional research on that here Do you want to configure a new storage pool? (yes/no) [default=yes]: This may seem counter-intuitive, since we have already created our ZFS pool, but it will be resolved in a later question. Accept the default. Name of the new storage pool [default=default]: storage You could leave this as default if you wanted to, but we have chosen to use the same name we gave our ZFS pool. Name of the storage backend to use (btrfs, dir, lvm, zfs, ceph) [default=zfs]: Obviously we want to accept the default. Create a new ZFS pool? (yes/no) [default=yes]: no Here's where the earlier question about creating a storage pool is resolved. Name of the existing ZFS pool or dataset: storage Would you like to connect to a MAAS server? (yes/no) [default=no]: Metal As A Service (MAAS) is outside the scope of this document. Would you like to create a new local network bridge? (yes/no) [default=yes]: What should the new bridge be called? [default=lxdbr0]: What IPv4 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: What IPv6 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: none If you want to use IPv6 on your LXD containers, you can turn on this option. That is up to you. Would you like the LXD server to be available over the network? (yes/no) [default=no]: yes This is necessary to snapshot the server, so answer \"yes\" here. Address to bind LXD to (not including port) [default=all]: Port to bind LXD to [default=8443]: Trust password for new clients: Again: This trust password is how you will connect to the snapshot server or back from the snapshot server, so set this with something that makes sense in your environment. Save this entry to a secure location, such as a password manager. Would you like stale cached images to be updated automatically? (yes/no) [default=yes] Would you like a YAML \"lxd init\" preseed to be printed? (yes/no) [default=no]:","title":"LXD Initialization"},{"location":"guides/containers/lxd_server/#setting-up-user-privileges","text":"Before we continue on, we need to create our \"lxdadmin\" user and make sure that it has the privileges it needs. We need the \"lxdadmin\" user to be able to sudo to root and we need it to be a member of the lxd group. To add the user and make sure it is a member of both groups do: useradd -G wheel,lxd lxdadmin Then set the password: passwd lxdadmin As with the other passwords, save this to a secure location.","title":"Setting Up User Privileges"},{"location":"guides/containers/lxd_server/#firewall-set-up-iptables","text":"Before continuing, you will want a firewall set up on your server. This example is using iptables and this procedure to disable firewalld . If you prefer to use firewalld , simply substitute in firewalld rules using the instructions below this section. Create your firewall.conf script: vi /etc/firewall.conf We are assuming an LXD server on a LAN network of 192.168.1.0/24 below. Note, too, that we are accepting all traffic from our bridged interface. This is important if you want your containers to get IP addresses from the bridge. This firewall script makes no other assumptions about the network services needed. There is an SSH rule to allow our LAN network IP's to SSH into the server. You can very easily have many more rules needed here, depending on your environment. Later, we will be adding a rule for bi-directional traffic between our production server and the snapshot server. #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -i lxdbr0 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save","title":"Firewall Set Up - iptables"},{"location":"guides/containers/lxd_server/#firewall-set-up-firewalld","text":"For firewalld rules, we need to use this basic procedure or be familiar with those concepts. Our assumptions are the same as with the iptables rules above: LAN network of 192.168.1.0/24 and a bridge named lxdbr0. To be clear, you might have multiple interfaces on your LXD server, with one perhaps facing your WAN as well. We are also going to create a zone for the bridged and local networks. This is just for zone clarity sake, as the other names do not really apply. The below assumes that you already know the basics of firewalld . firewall-cmd --new-zone=bridge --permanent You need to reload the firewall after adding a zone: firewall-cmd --reload We want to allow all traffic from the bridge, so let's just add the interface, and then change the target from \"default\" to \"ACCEPT\" and we will be done: !!! attention Changing the target of a firewalld zone *must* be done with the --permanent option, so we might as well just enter that flag in our other commands as well and forgo the --runtime-to-permanent option. !!! Note If you need to create a zone that you want to allow all access to the interface or source, but do not want to have to specify any protocols or services, then you *must* change the target from \"default\" to ACCEPT. The same is true of DROP and REJECT for a particular IP block that you have custom zones for. To be clear, the \"drop\" zone will take care of that for you as long as you aren't using a custom zone. firewall-cmd --zone=bridge --add-interface=lxdbr0 --permanent firewall-cmd --zone=bridge --set-target=ACCEPT --permanent Assuming no errors and everything is still working just do a reload: firewall-cmd --reload If you list out your rules now with firewall-cmd --zone=bridge --list-all you should see something like the following: bridge (active) target: ACCEPT icmp-block-inversion: no interfaces: lxdbr0 sources: services: ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Note from the iptables rules, that we also want to allow our local interface. Again, I do not like the included zones for this, so create a new zone and use the source IP range for the local interface to make sure you have access: firewall-cmd --new-zone=local --permanent firewall-cmd --reload Then we just need to add the source IP's for the local interface, change the target to \"ACCEPT\" and we are done with this as well: firewall-cmd --zone=local --add-source=127.0.0.1/8 --permanent firewall-cmd --zone=local --set-target=ACCEPT --permanent firewall-cmd --reload Go ahead and list out the \"local\" zone to make sure your rules are there with firewall-cmd --zone=local --list all which should show you something like this: local (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 127.0.0.1/8 services: ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Next we want to allow SSH from our trusted network. We will use the source IP's here, just like in our iptables example, and the built-in \"trusted\" zone. The target for this zone is already \"ACCEPT\" by default. firewall-cmd --zone=trusted --add-source=192.168.1.0/24 Then add the service to the zone: firewall-cmd --zone=trusted --add-service=ssh And if everything is working, move your rules to permanent and reload the rules: firewall-cmd --runtime-to-permanent firewall-cmd --reload Listing out your \"trusted\" zone should now show you something like this: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: By default, the \"public\" zone is enabled and has SSH allowed. We don't want this. Make sure that your zones are correct and that the access you are getting to the server is via one of the LAN IP's (in the case of our example) and is allowed to SSH. You could lock yourself out of the server if you don't verify this before continuing. Once you've made sure you have access from the correct interface, remove SSH from the \"public\" zone: firewall-cmd --zone=public --remove-service=ssh Test access and make sure you aren't locked out. If not, then move your rules to permanent, reload, and list out zone \"public\" to be sure that SSH is removed: firewall-cmd --runtime-to-permanent firewall-cmd --reload firewall-cmd --zone=public --list-all There may be other interfaces on your server to consider. You can use built-in zones where appropriate, but if you don't like the names (they don't appear logical, etc.), you can definitely add zones. Just remember that if you have no services or protocols that you need to allow or reject specifically, then you will need to modify the zone target. If it works to use interfaces, as we've done with the bridge, you can do that. If you need more granular access to services, uses source IP's instead. This completes Part 1. You can either continue on to Part 2, or return to the menu . If you are working on the snapshot server, you can head down to Part 5 now.","title":"Firewall Set Up - firewalld"},{"location":"guides/containers/lxd_server/#part-2-setting-up-and-managing-images","text":"Throughout Part 2, and from here on out unless otherwise noted, you will be running commands as your unprivileged user. (\"lxdadmin\" if you are following along with this document).","title":"Part 2 : Setting Up And Managing Images"},{"location":"guides/containers/lxd_server/#list-available-images","text":"Once you have your server environment set up, you'll probably be itching to get started with a container. There are a lot of container OS possibilities. To get a feel for how many possibilities, enter this command: lxc image list images: | more Hit the space bar to page through the list. This list of containers and virtual machines continues to grow. For now, we are sticking with containers. The last thing you want to do is to page through looking for a container image to install, particularly if you know the image that you want to create. Let's modify the command above to show only CentOS Linux install options: lxc image list images: | grep centos/8 This brings up a much more manageable list: | centos/8 (3 more) | 98b4dbef0c29 | yes | Centos 8 amd64 (20210427_07:08) | x86_64 | VIRTUAL-MACHINE | 517.44MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8 (3 more) | 0427669ebee4 | yes | Centos 8 amd64 (20210427_07:08) | x86_64 | CONTAINER | 125.58MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream (3 more) | 961170f8934f | yes | Centos 8-Stream amd64 (20210427_07:08) | x86_64 | VIRTUAL-MACHINE | 586.44MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream (3 more) | e507fdc8935a | yes | Centos 8-Stream amd64 (20210427_07:08) | x86_64 | CONTAINER | 130.33MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/arm64 (1 more) | e5bf98409ac6 | yes | Centos 8-Stream arm64 (20210427_10:33) | aarch64 | CONTAINER | 126.56MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/cloud (1 more) | 5751ca14bf8f | yes | Centos 8-Stream amd64 (20210427_07:08) | x86_64 | CONTAINER | 144.75MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/cloud (1 more) | ccf0bb20b0ca | yes | Centos 8-Stream amd64 (20210427_07:08) | x86_64 | VIRTUAL-MACHINE | 593.31MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/cloud/arm64 | db3d915d12fd | yes | Centos 8-Stream arm64 (20210427_07:08) | aarch64 | CONTAINER | 140.60MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/cloud/ppc64el | 11aa2ab878b2 | yes | Centos 8-Stream ppc64el (20210427_07:08) | ppc64le | CONTAINER | 149.45MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8-Stream/ppc64el (1 more) | a27665203e47 | yes | Centos 8-Stream ppc64el (20210427_07:08) | ppc64le | CONTAINER | 134.52MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/arm64 (1 more) | d64396d47fa7 | yes | Centos 8 arm64 (20210427_07:08) | aarch64 | CONTAINER | 121.83MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/cloud (1 more) | 84803ca6e32d | yes | Centos 8 amd64 (20210427_07:08) | x86_64 | CONTAINER | 140.42MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/cloud (1 more) | c98196cd9eec | yes | Centos 8 amd64 (20210427_07:08) | x86_64 | VIRTUAL-MACHINE | 536.00MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/cloud/arm64 | 9d06684a9a4e | yes | Centos 8 arm64 (20210427_10:33) | aarch64 | CONTAINER | 136.49MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/cloud/ppc64el | 18c13c448349 | yes | Centos 8 ppc64el (20210427_07:08) | ppc64le | CONTAINER | 144.66MB | Apr 27, 2021 at 12:00am (UTC) | | centos/8/ppc64el (1 more) | 130c1c83c36c | yes | Centos 8 ppc64el (20210427_07:08) | ppc64le | CONTAINER | 129.53MB | Apr 27, 2021 at 12:00am (UTC) |","title":"List Available Images"},{"location":"guides/containers/lxd_server/#installing-renaming-and-listing-images","text":"For the first container, we are going to choose centos/8. To install it, we could use: lxc launch images:centos/8 centos-test That will create a CentOS-based containter named \"centos-test\". You can rename a container after it has been created, but you first need to stop the container, which starts automatically when it is launched. To start the container manually, use: lxc start centos-test For the purposes of this guide, go ahead and install one more image for now: lxc launch images:ubuntu/20.10 ubuntu-test Now let's take a look at what we have so far by listing our images: lxc list which should return something like this: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | 10.199.182.72 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+","title":"Installing, Renaming, And Listing Images"},{"location":"guides/containers/lxd_server/#lxd-profiles","text":"You get a default profile when you install LXD, and this profile cannot be removed or modified. That said, you can use the default profile to create new profiles to use with your containers. If you look at our container listing (above) you will notice that the IP address in each case is assigned from the bridged interface. In a production environment, you may want to use something else. This might be a DHCP assigned address from your LAN interface or even a statically assigned address from your WAN. If you configure your LXD server with two interfaces, and assign each an IP on your WAN and LAN, then it is possible to assign your containers IP addresses based on which interface the container needs to be facing. As of version 8 of Rocky Linux (and really any bug for bug copy of Red Hat Enterprise Linux, such as CentOS in our listing above) the method for assigning IP addresses statically or dynamically using the profiles below, is broken out of the gate. There are ways to get around this, but it is annoying, as the feature that is broken should be part of the Linux kernel. That feature is macvlan. Macvlan allows you to create multiple interfaces with different Layer 2 addresses. For now, just be aware that what we are going to suggest next has drawbacks when choosing container images based on RHEL.","title":"LXD Profiles"},{"location":"guides/containers/lxd_server/#creating-a-macvlan-profile-and-assigning-it","text":"To create our macvlan profile, simply use this command: lxc profile create macvlan Keep in mind that if we were on a multi-interface machine and wanted more than one macvlan template based on which network we wanted to reach, we could use \"lanmacvlan\" or \"wanmacvlan\" or any other name that we wanted to use to identify the profile. In other words, using \"macvlan\" in our profile create statement is totally up to you. Once the profile is created, we now need to modify it to do what we want. First, we need to make sure that the server's default editor is what we want to use. If we don't do this step, the editor will be whatever the default editor is. We are choosing vim for our editor here: export EDITOR=/usr/bin/vim Now we want to modify the macvlan interface, but before we do, we need to know what the parent interface is for our LXD server. This will be the interface that has a LAN (in this case) assigned IP. To determine which interface that is, use: ip addr And then look for the interface with the LAN IP assignment in the 192.168.1.0/24 network: 2: enp3s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 40:16:7e:a9:94:85 brd ff:ff:ff:ff:ff:ff inet 192.168.1.106/24 brd 192.168.1.255 scope global dynamic noprefixroute enp3s0 valid_lft 4040sec preferred_lft 4040sec inet6 fe80::a308:acfb:fcb3:878f/64 scope link noprefixroute valid_lft forever preferred_lft forever So in this case, the interface would be \"enp3s0\". Now let's modify the profile: lxc profile edit macvlan This file will be self-documented at the top. What we need to do is modify the file as follows below the commented section: config: {} description: \"\" devices: eth0: name: eth0 nictype: macvlan parent: enp3s0 type: nic name: macvlan used_by: [] Obviously, you can use profiles for lots of other things, but assigning a static IP to a container, or using your own DHCP server as a source for an address are very common needs. To assign the macvlan profile to centos-test we need to do the following: lxc profile assign centos-test default,macvlan This simply says, we want the default profile, and then we want to apply the macvlan profile as well.","title":"Creating A macvlan Profile And Assigning It"},{"location":"guides/containers/lxd_server/#centos-macvlan","text":"In the CentOS implementation of Network Manager, they have managed to break the functionality of macvlan in the kernel, or at least in the kernel applied to their LXD image. This has been this way since CentOS 8 was released and no one appears to be at all concerned about a fix. Simply put, if you want to run CentOS 8 containers (or any other RHEL 1-for-1 release, such as Rocky Linux), you've got to jump through some additional hoops to get macvlan to work. macvlan is part of the kernel, so it should work without the below fixes, but it doesn't.","title":" CentOS macvlan"},{"location":"guides/containers/lxd_server/#centos-macvlan-the-dhcp-fix","text":"Having the profile assigned, however, doesn't change the default configuration, which is set to DHCP by default. To test this, simply do the following: lxc stop centos-test And then: lxc start centos-test Now list your containers again and note that centos-test does not have an IP address anymore: lxc list +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ To further demonstrate the problem here, we need to execute dhclient on the container. You can do this with: lxc exec centos-test dhclient A new listing using lxc list now shows the following: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.138 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ That should have happened with a simple stop and start of the container, but it does not. Assuming that we want to use a DHCP assigned IP address every time, then we can fix this with a simple crontab entry. To do this, we need to gain shell access to the container by entering: lxc exec centos-test bash Next, lets determine the complete path to dhclient : which dhclient which should return: /usr/sbin/dhclient Next, let's modify root's crontab: crontab -e And add this line: @reboot /usr/sbin/dhclient The crontab command entered above, uses vi so to save your changes and exit simply use: SHIFT:wq! Now exit the container and stop centos-test: lxc stop centos-test and then start it again: lxc start centos-test A new listing will reveal that the container has been assigned the DHCP address: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.138 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+","title":"CentOS macvlan - The DHCP Fix"},{"location":"guides/containers/lxd_server/#centos-macvlan-the-static-ip-fix","text":"To statically assign an IP address, things get even more convoluted. The process of setting a static IP address on a CentOS container is through the network-scripts, which we will do now. The IP we will attempt to assign is 192.168.1.200. To do this, we need to gain shell access to the container again: lxc exec centos-test bash The next thing we need to do is to manually modify the interface labelled \"eth0\", and set our IP address. To modify our configuration, do the following: vi /etc/sysconfig/network-scripts/ifcfg-eth0 Which will return this: DEVICE=eth0 BOOTPROTO=dhcp ONBOOT=yes HOSTNAME=centos-test TYPE=Ethernet MTU= DHCP_HOSTNAME=centos-test IPV6INIT=yes We need to modify this file so that it looks like this: DEVICE=eth0 BOOTPROTO=none ONBOOT=yes IPADDR=192.168.1.200 PREFIX=24 GATEWAY=192.168.1.1 DNS1=8.8.8.8 DNS2=8.8.4.4 HOSTNAME=centos-test TYPE=Ethernet MTU= DHCP_HOSTNAME=centos-test IPV6INIT=yes This says we want to set the boot protocol to none (used for static IP assignments), set the IP address to 192.168.1.200, that this address is part of a CLASS C (PREFIX=24) address, that the gateway for this network is 192.168.1.1 and then that we want to use Google's open DNS servers for name resolution. Save your file ( SHIFT:wq! ). We also need to remove our crontab for root, as this isn't what we want for a static IP. To do this, simply crontab -e and remark out the @reboot line with a \"#\", save your changes and exit the container. Stop the container with: lxc stop centos-test and start it again: lxc start centos-test Just like our DHCP assigned address, the statically assigned address will not be assigned when we list the container: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ To fix this requires breaking Network Manager on the container. The following works-at least for now: lxc exec centos-test dhclient Then get into the container: lxc exec centos-test bash Install the old network scripts: dnf install network-scripts Nuke Network Manager: systemctl stop NetworkManager systemctl disable NetworkManager Enable the old Network service: systemctl enable network.service Exit the container and then stop and start the container again: lxc stop centos-test And then run: lxc start centos-test When the container starts, a new listing will show the correct statically assigned IP: +-------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+-----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.200 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 10.199.182.236 (eth0) | | CONTAINER | 0 | +-------------+---------+-----------------------+------+-----------+-----------+ The issue with macvlan shown in both of these examples is directly related to containers based on Red Hat Enterprise Linux (Centos 8, Rocky Linux 8).","title":"CentOS macvlan - The Static IP Fix"},{"location":"guides/containers/lxd_server/#ubuntu-macvlan","text":"Luckily, In Ubuntu's implementation of Network Manager, the macvlan stack is NOT broken, so it is much easier to deploy! First, just like with our centos-test container, we need to assign the template to our container: lxc profile assign ubuntu-test default,macvlan That should be all that is necessary to get a DHCP assigned address. To find out, stop and then start the container again: lxc stop ubuntu-test And then run: lxc start ubuntu-test Then list the containers again: +-------------+---------+----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.200 (eth0) | | CONTAINER | 0 | +-------------+---------+----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 192.168.1.139 (eth0) | | CONTAINER | 0 | +-------------+---------+----------------------+------+-----------+-----------+ Success! Configuring the Static IP is just a little different, but not at all hard. We need to modify the .yaml file associated with the container's connection (/10-lxc.yaml). For this static IP, we will use 192.168.1.201: vi /etc/netplan/10-lxc.yaml And change what is there to the following: network: version: 2 ethernets: eth0: dhcp4: false addresses: [192.168.1.201/24] gateway4: 192.168.1.1 nameservers: addresses: [8.8.8.8,8.8.4.4] Save your changes ( SHFT:wq! ) and exit the container. Now stop and start the container: lxc stop ubuntu-test And then run: lxc start ubuntu-test When you list your containers again, you should see our new static IP: +-------------+---------+----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+----------------------+------+-----------+-----------+ | centos-test | RUNNING | 192.168.1.200 (eth0) | | CONTAINER | 0 | +-------------+---------+----------------------+------+-----------+-----------+ | ubuntu-test | RUNNING | 192.168.1.201 (eth0) | | CONTAINER | 0 | +-------------+---------+----------------------+------+-----------+-----------+ Success! In the examples used in Part 2, we have intentionally chosen a hard container to configure, and an easy one. There are obviously many more versions of Linux available in the image listing. If you have a favorite, try installing it, assigning the macvlan template, and setting IP's. This completes Part 2. You can either continue on to Part 3, or return to the menu .","title":"Ubuntu macvlan"},{"location":"guides/containers/lxd_server/#part-3-container-configuration-options","text":"There are a wealth of options for configuring the container once you have it installed. Before we get into how to see those, however, let's take a look at the info command for a container. In this example, we will use the ubuntu-test container: lxc info ubuntu-test This shows something like the following: Name: ubuntu-test Location: none Remote: unix:// Architecture: x86_64 Created: 2021/04/26 15:14 UTC Status: Running Type: container Profiles: default, macvlan Pid: 584710 Ips: eth0: inet 192.168.1.201 enp3s0 eth0: inet6 fe80::216:3eff:fe10:6d6d enp3s0 lo: inet 127.0.0.1 lo: inet6 ::1 Resources: Processes: 13 Disk usage: root: 85.30MB CPU usage: CPU usage (in seconds): 1 Memory usage: Memory (current): 99.16MB Memory (peak): 110.90MB Network usage: eth0: Bytes received: 53.56kB Bytes sent: 2.66kB Packets received: 876 Packets sent: 36 lo: Bytes received: 0B Bytes sent: 0B Packets received: 0 Packets sent: 0 There's a lot of good information there, from the profiles applied, to the memory in use, disk space in use, and more.","title":"Part 3 : Container Configuration Options"},{"location":"guides/containers/lxd_server/#a-word-about-configuration-and-some-options","text":"By default, LXD will allocate the required system memory, disk space, CPU cores, etc., to the container. But what if we want to be more specific? That is totally possible. There are trade-offs to doing this, though. For instance, if we allocate system memory and the container doesn't actually use it all, then we have kept it from another container that might actually need it. The reverse, though, can happen. If a container is a complete pig on memory, then it can keep other containers from getting enough, thereby pinching their performance. Just keep in mind that every action you make to configure a container can have negative effects somewhere else. Rather than run through all of the options for configuration, use the tab auto-complete to see the options available: lxc config set ubuntu-test and then hit TAB. This shows you all of the options for configuring a container. If you have questions about what one of the configuration options does, head up to the official documentation for LXD and do a search for the configuration parameter, or Google the entire string, such as \"lxc config set limits.memory\" and take a look at the results of the search. We will look at a few of the most used configuration options. For example, if you want to set the max amount of memory that a container can use: lxc config set ubunt-test limits.memory 2GB That says that as long as the memory is available to use, in other words there is 2GB of memory free, then the container can actually use more than 2GB if it's available. It's a soft limit, in other words. lxc config set ubuntu-test limits.memory.enforce 2GB That says that the container can never use more than 2GB of memory, whether it's currently available or not. In this case it's a hard limit. lxc config set ubuntu-test limits.cpu 2 That says to limit the number of cpu cores that the container can use to 2. Remember when we set up our storage pool in the Enabling zfs And Setting Up The Pool above? We named the pool \"storage,\" but we could have named it anything. If we want to look at this, we can use this command: lxc storage show storage This shows the following: config: source: storage volatile.initial_source: storage zfs.pool_name: storage description: \"\" name: storage driver: zfs used_by: - /1.0/images/0cc65b6ca6ab61b7bc025e63ca299f912bf8341a546feb8c2f0fe4e83843f221 - /1.0/images/4f0019aee1515c109746d7da9aca6fb6203b72f252e3ee3e43d50b942cdeb411 - /1.0/images/9954953f2f5bf4047259bf20b9b4f47f64a2c92732dbc91de2be236f416c6e52 - /1.0/instances/centos-test - /1.0/instances/ubuntu-test - /1.0/profiles/default status: Created locations: - none This shows that all of our containers are using our zfs storage pool. When using ZFS, you can also set a disk quota on a container. Let's do this by setting a 2GB disk quota on the ubuntu-test container. You do this with: lxc config device override ubuntu-test root size=2GB As stated earlier, you should use configuration options sparingly, unless you've got a container that wants to use way more than its share of resources. LXD, for the most part, will manage the environment well on its own. There are, of course, many more options that may be of interest to some people. You should do your own research to find out if any of those are of value in your environment. This completes Part 3. You can either continue on to Part 4, or return to the menu .","title":"A Word About Configuration And Some Options"},{"location":"guides/containers/lxd_server/#part-4-container-snapshots","text":"Container snapshots, along with a snapshot server (which we will get to more later), are probably the most important aspect of running a production LXD server. Snapshots ensure quick recovery, and can be used for safety when you are, say, updating the primary software that runs on a particular container. If something happens during the update that breaks that application, you simply restore the snapshot and you are back up and running with only a few seconds worth of downtime. The author used LXD containers for PowerDNS public facing servers, and the process of updating those applications became so much more worry-free, since you can snapshot the container first before continuing. You can even snapshot a container while it is running. We'll start by getting a snapshot of the ubuntu-test container by using this command: lxc snapshot ubuntu-test ubuntu-test-1 Here, we are calling the snapshot \"ubuntu-test-1\", but it can be called anything you like. To make sure that you have the snapshot, do an \"lxc info\" of the container: lxc info ubuntu-test We've looked at an info screen already, so if you scroll to the bottom, you should see: Snapshots: ubuntu-test-1 (taken at 2021/04/29 15:57 UTC) (stateless) Success! Our snapshot is in place. Now, get into the ubuntu-test container: lxc exec ubuntu-test bash And create an empty file with the touch command: touch this_file.txt Now exit the container. Before we restore the container as it was prior to creating the file, the safest way to restore a container, particularly if there have been a lot of changes, is to stop it first: lxc stop ubuntu-test Then restore it: lxc restore ubuntu-test ubuntu-test-1 Then start the container again: lxc start ubuntu-test If you get back into the container again and look, our \"this_file.txt\" that we created is now gone. Once you don't need a snapshot anymore, you can delete it: lxc delete ubuntu-test/ubuntu-test-1 Important: You should always delete snapshots with the container running. Why? Well the lxc delete command also works to delete the entire container. If we had accidentally hit enter after \"ubuntu-test\" in the command above, AND, if the container was stopped, the container would be deleted. No warning is given, it simply does what you ask. If the container is running, however, you will get this message: Error: The instance is currently running, stop it first or pass --force So always delete snapshots with the container running. The process of creating snapshots automatically, setting expiration of the snapshot so that it goes away after a certain length of time, and auto refreshing the snapshots to the snapshot server will be covered in detail in the section dealing with the snapshot server. This completes Part 4. You can either continue on to Part 5, or return to the menu .","title":"Part 4: Container Snapshots"},{"location":"guides/containers/lxd_server/#part-5-the-snapshot-server","text":"As noted at the beginning, the snapshot server for LXD should be a mirror of the production server in every way possible. The reason is that you may need to take it to production in the event of a hardware failure, and having not only backups, but a quick way to bring up production containers, keeps those systems administrator panic phone calls and text messages to a minimum. THAT is ALWAYS good! So the process of building the snapshot server is exactly like the production server. To fully emulate our production server set up, do all of Part 1 again, and when completed, return to this spot. You're back!! Congratulations, this must mean that you have successfully completed Part 1 for the snapshot server. That's great news!!","title":"Part 5: The Snapshot Server"},{"location":"guides/containers/lxd_server/#setting-up-the-primary-and-snapshot-server-relationship","text":"We've got some housekeeping to do before we continue. First, if you are running in a production environment, you probably have access to a DNS server that you can use for setting up IP to name resolution. In our lab, we don't have that luxury. Perhaps you've got the same scenario running. For this reason, we are going to add both servers IP addresses and names to the /etc/hosts file on BOTH the primary and the snapshot server. You'll need to do this as your root (or sudo ) user. In our lab, the primary LXD server is running on 192.168.1.106 and the snapshot LXD server is running on 192.168.1.141. We will SSH into both servers and add the following to the /etc/hosts file: 192.168.1.106 lxd-primary 192.168.1.141 lxd-snapshot Next, we need to allow all traffic between the two servers. To do this, we are going to modify the /etc/firewall.conf file with the following. First, on the lxd-primary server, add this line: IPTABLES -A INPUT -s 192.168.1.141 -j ACCEPT And on the lxd-snapshot server, add this line: IPTABLES -A INPUT -s 192.168.1.106 -j ACCEPT This allows bi-directional traffic of all types to travel between the two servers. Next, as the \"lxdadmin\" user, we need to set the trust relationship between the two machines. This is done by executing the following on lxd-primary: lxc remote add lxd-snapshot This will display the certificate to accept, so do that, and then it will prompt for your password. This is the \"trust password\" that you set up when doing the LXD initialization step. Hopefully, you are securely keeping track of all of these passwords. Once you enter the password, you should receive this: Client certificate stored at server: lxd-snapshot It does not hurt to have this done in reverse as well. In other words, set the trust relationship on the lxd-snapshot server so that, if needed, snapshots can be sent back to the lxd-primary server. Simply repeat the steps and substitute in \"lxd-primary\" for \"lxd-snapshot.\"","title":"Setting Up The Primary and Snapshot Server Relationship"},{"location":"guides/containers/lxd_server/#migrating-our-first-snapshot","text":"Before we can migrate our first snapshot, we need to have any profiles created on lxd-snapshot that we have created on the lxd-primary. In our case, this is the \"macvlan\" profile. You'll need to create this for lxd-snapshot, so go back to LXD Profiles and create the \"macvlan\" profile on lxd-snapshot. If your two servers have identical parent interface names (\"enp3s0\" for example) then you can copy the \"macvlan\" profile over to lxd-snapshot without recreating it: lxc profile copy macvlan lxd-snapshot Now that we have all of the relationships and profiles set up, the next step is to actually send a snapshot from lxd-primary over to lxd-snapshot. If you've been following along exactly, you've probably deleted all of your snapshots, so let's create a new one: lxc snapshot centos-test centos-snap1 If you run the \"info\" sub-command for lxc, you can see the new snapshot on the bottom of our listing: lxc info centos-test Which will show something like this at the bottom: centos-snap1 (taken at 2021/05/13 16:34 UTC) (stateless) OK, fingers crossed! Let's try to migrate our snapshot: lxc copy centos-test/centos-snap1 lxd-snapshot:centos-test What this command says is, that within the container centos-test, we want to send the snapshot, centos-snap1 over to lxd-snapshot and copy it as centos-test. After a short period of time has expired, the copy will be complete. Want to find out for sure? Do an \"lxc list\" on the lxd-snapshot server. Which should return the following: +-------------+---------+------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +-------------+---------+------+------+-----------+-----------+ | centos-test | STOPPED | | | CONTAINER | 0 | +-------------+---------+------+------+-----------+-----------+ Success! Now let's try starting it. Because we are starting it on the lxd-snapshot server, we need to stop it first on the lxd-primary server: lxc stop centos-test And on the lxd-snapshot server: lxc start centos-test Assuming all of this works without error, stop the container on lxd-snapshot and start it again on lxd-primary.","title":"Migrating Our First Snapshot"},{"location":"guides/containers/lxd_server/#the-snapshot-server-setting-bootautostart-to-off-for-containers","text":"The snapshots copied to lxd-snapshot will be down when they are migrated, but if you have a power event or need to reboot the snapshot server because of updates or something, you will end up with a problem as those containers will attempt to start on the snapshot server. To eliminate this, we need to set the migrated containers so that they will not start on reboot of the server. For our newly copied centos-test container, this is done with the following: lxc config set centos-test boot.autostart 0 Do this for each snapshot on the lxd-snapshot server.","title":"The Snapshot Server - Setting boot.autostart To Off For Containers"},{"location":"guides/containers/lxd_server/#automating-the-snapshot-process","text":"Ok, so it's great that you can create snapshots when you need to, and sometimes you do need to manually create a snapshot. You might even want to manually copy it over to lxd-snapshot. BUT, once you've got things going and you've got 25 to 30 containers or more running on your lxd-primary machine, the very last thing you want to do is spend an afternoon deleting snapshots on the snapshot server, creating new snapshots and sending them over. The first thing we need to do is schedule a process to automate snapshot creation on lxd-primary. This has to be done for each container on the lxd-primary server, but once it is set up, it will take care of itself. This is done with the following syntax. Note the similarities to a crontab entry for the timestamp: lxc config set [container_name] snapshots.schedule \"50 20 * * *\" What this is saying is, do a snapshot of the container name every day at 8:50 PM. To apply this to our centos-test container: lxc config set centos-test snapshots.schedule \"50 20 * * *\" We also want to set up the name of the snapshot to be meaningful by our date. LXD uses UTC everywhere, so our best bet to keep track of things, is to set the snapshot name with a date/time stamp that is in a more understandable format: lxc config set centos-test snapshots.pattern \"centos-test-{{ creation_date|date:'2006-01-02_15-04-05' }}\" GREAT, but we certainly don't want a new snapshot every day without getting rid of an old one, right? We'd fill up the drive with snapshots. So next we run: lxc config set centos-test snapshots.expiry 1d","title":"Automating The Snapshot Process"},{"location":"guides/containers/lxd_server/#automating-the-snapshot-copy-process","text":"Again, this process is performed on lxd-primary. First thing we need to do is create a script that will be run by cron in /usr/local/sbin called \"refresh-containers\" : sudo vi /usr/local/sbin/refreshcontainers.sh The script is pretty simple: #!/bin/bash # This script is for doing an lxc copy --refresh against each container, copying # and updating them to the snapshot server. for x in $(/var/lib/snapd/snap/bin/lxc ls -c n --format csv) do echo \"Refreshing $x\" /var/lib/snapd/snap/bin/lxc copy --refresh $x lxd-snapshot:$x done Make it executable: sudo chmod +x /usr/local/sbin/refreshcontainers.sh Change the ownership of this script to your lxdadmin user and group: sudo chown lxdadmin.lxdadmin /usr/local/sbin/refreshcontainers.sh Set up the crontab for the lxdadmin user to run this script, in this case at 10 PM: crontab -e And your entry will look like this: 00 22 * * * /usr/local/sbin/refreshcontainers.sh > /home/lxdadmin/refreshlog 2>&1 Save your changes and exit. This will create a log in lxdadmin's home directory called \"refreshlog\" which will give you knowledge of whether your process worked or not. Very important! The automated procedure will fail sometimes. This generally happens when a particular container fails to refresh. You can manually re-run the refresh with the following command (assuming centos-test here, as our container): lxc copy --refresh centos-test lxd-snapshot:centos-test","title":"Automating The Snapshot Copy Process"},{"location":"guides/containers/lxd_server/#conclusions","text":"There is a great deal to installing and effectively using LXD. You can certainly install it on your laptop or workstation without all the fuss, as it makes a great developing and testing platform. If you want a more serious approach using production containers, then a primary and snapshot server approach is your best bet. Even though we've touched on a lot of features and settings, we have only scratched the surface of what you can do with LXD. The best way to learn this system, is to install it and try it out with things that you will use. If you find LXD useful, consider installing it in the fashion described in this document for the best possible leveraging of hardware for Linux containers. Rocky Linux works very well for this! You can now exit this document, or return to the menu . You know, if you want.","title":"Conclusions"},{"location":"guides/containers/lxd_web_servers/","text":"Building a Network of Websites/Web Servers With LXD, for Beginners Introduction Okay, so we already have a guide on installing LXD/LXC on Rocky Linux , but that was written by someone who knows what he\u2019s doing, and wanted to build a containerized network of servers and/or apps on a physical machine on his local network. It\u2019s great, and I\u2019ll be straight up stealing bits of it so I don\u2019t have to write as much. But, if you\u2019ve just heard about Linux Containers, and don\u2019t really understand how they work yet, but you want to host some websites, this is the guide for you. This tutorial will teach you how to host basic websites with LXD and LXC on any system, including virtual private servers and cloud hosting. So first, what\u2019s a Linux Container? Well, for the absolute beginner, it\u2019s a way to make one computer pretend that it\u2019s actually a lot more computers. These \u201ccontainers\u201d each house a basic\u2014usually stripped-down\u2014version of an operating system you choose. You can use each container like an individual server; put nginx on one, Apache on another, and even use a third as a database server. The basic advantage is that if one app or website inside its own container experiences severe bugs, a hack, or other problems, it\u2019s unlikely to affect the rest of your server or the other apps and websites. Also, containers are super easy to snapshot, back up, and restore. In this case, we\u2019ll be running Rocky Linux in our containers, on top of our \u201chost\u201d system, which is also Rocky Linux. Conceptually, it\u2019s something like this: If you\u2019ve ever played with VirtualBox to run some Windows apps, it\u2019s like that, but not. Unlike virtual machines, Linux Containers don\u2019t emulate an entire hardware environment for each container. Rather, they all share a few virtual devices by default for networking and storage, though you can add more virtual devices. As a result, they require a lot less overhead (processing power and RAM) than a virtual machine. For those Docker fiends out there (Docker being another container-based system, not a VM system), Linux Containers are less ephemeral than what you\u2019re used to. All data in every container instance is persistent, and any changes you make are permanent unless you revert to a backup. In short, shutting down the container won\u2019t erase your sins. Heh. LXD, specifically, is a command-line application that helps you to set up and manage Linux Containers. That's what we're going to be installing on our Rocky Linux host server today. I'm going to be writing LXC/LXD a lot though, as there's a lot of old documentation which refers to LXC only, and I'm trying to make it easier for people to find updated guides like this one. !!! Note There was a precursor app to LXD which was also called \"LXC\". As it stands today: LXC is the technology, LXD is the app. We\u2019ll be using them both to create an environment that works something like this: Specifically, I\u2019m going to show you how to set up simple Nginx and Apache web servers inside of your server containers, and use another container with Nginx as a reverse proxy. Again, this setup should work in any environment: from local networks to virtual private servers. !!! Note A reverse proxy is a program that takes incoming connections from the internet (or your local network) and routes them to the right server, container, or app. There are also dedicated tools for this job like HaProxy... but weirdly enough, I find Nginx a lot easier to use. Prerequisites And Assumptions Basic familiarity with the Linux command line interface. You should know how to use SSH if you\u2019re installing LXC/LXD on a remote server. An internet-connected server, physical or virtual, with Rocky Linux already running on it. Two domain names pointed right at your server with an A record. Two subdomains would also work just as well. One domain with a wildcard subdomain record would also, or a custom LAN domain... you get the picture. A command-line text editor. nano will do, micro is my favorite, but use whatever makes you comfortable. You can follow this whole tutorial as the root user, but you probably shouldn\u2019t. After the initial installation of LXC/LXD, we\u2019ll guide you in creating an unprivileged user specifically for operating LXD commands. We now have Rocky Linux images to base your containers on, and they\u2019re awesome. If you're not too familiar with Nginx or Apache, you will need to check out some of our other guides if you want to get a full productions server up and running. Don't worry, I'll link them below. Setting Up The Host Server Environment So here\u2019s where I\u2019m going to copy and paste bits from the other LXD guide, for your convenience and mine. All credit for most of this part goes to Steven Spencer. Install the EPEL Repository LXD requires the EPEL (Extra Packages for Enterprise Linux) repository, which is easy to install using: dnf install epel-release Once installed, check for updates: dnf update If there were kernel updates during the update process above, reboot your server Install snapd LXD must be installed from a snap* package for Rocky Linux. For this reason, we need to install snapd with: dnf install snapd And now enable the snapd service to auto-start when your server reboots, and start it running now: systemctl enable snapd And then run: systemctl start snapd Reboot the server before continuing here. You can do this with the reboot command, or from your VPS/cloud hosting admin panel. * snap is a method of packaging applications so they come with all of the dependencies they need, and can run on almost any Linux system. Install LXD Installing LXD requires the use of the snap command. At this point, we are just installing it, we are doing no set up: snap install lxd If you\u2019re running LXD on a physical (AKA \u201cbare metal\u201d) server, you should probably go back to the other guide and read the \u201cEnvironment Setup\u201d section there. There\u2019s a lot of good stuff about kernels and file systems, and so much more. If you\u2019re running LXD in a virtual environment, just reboot and read on. LXD Initialization Now that the environment is all set up, we are ready to initialize LXD. This is an automated script that asks a series of questions to get your LXD instance up and running: lxd init Here are the questions and our answers for the script, with a little explanation where warranted: Would you like to use LXD clustering? (yes/no) [default=no]: If you are interested in clustering, do some additional research on that here . Otherwise, just press \u201cEnter\u201d to accept the default option. Do you want to configure a new storage pool? (yes/no) [default=yes]: Accept the default. Name of the new storage pool [default=default]: server-storage Choose a name for your storage pool. I like to name it after the server LXD is running on. (A storage pool is basically a set amount of hard drive space set aside for your containers.) Name of the storage backend to use (btrfs, dir, lvm, zfs, ceph) [default=zfs]: lvm The above question is about what sort of file system you want to use for storage, and the default may vary depending on what\u2019s available on your system. If you're on a bare metal server, and want to use ZFS, again, refer back to the guide linked above. In a virtual environment, I have found that \u201cLVM\u201d works fine, and it\u2019s usually what I use. You can accept the default on the next question. Create a new LVM pool? (yes/no) [default=yes]: If you have a specific hard drive or partition you\u2019d like to use for the whole storage pool, write \u201cyes\u201d next. If you\u2019re doing all of this on a VPS, you\u2019ll probably have to choose \u201cno\u201d. `Would you like to use an existing empty block device (e.g. a disk or partition)? (yes/no) [default=no]:` Metal As A Service (MAAS) is outside the scope of this document. Accept the defaults for this next bit. Would you like to connect to a MAAS server? (yes/no) [default=no]: And more defaults. It's all good. Would you like to create a new local network bridge? (yes/no) [default=yes]: What should the new bridge be called? [default=lxdbr0]: ` What IPv4 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: If you want to use IPv6 on your LXD containers, you can turn on this next option. That is up to you, but you mostly shouldn\u2019t need to. I think. I tend to leave it on out of laziness. What IPv6 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: This is necessary to easily back up the server, and can allow you to manage your LXD install from other computers. If that all sounds good to you, answer \"yes\" here/ Would you like the LXD server to be available over the network? (yes/no) [default=no]: yes If you did say yes to the last questions, take the defaults here: Address to bind LXD to (not including port) [default=all]: Port to bind LXD to [default=8443]: Now you'll be asked for a trust password. That's how you will connect to the LXC host server from other computers and servers, so set this with something that makes sense in your environment. Save this password to a secure location, such as a password manager. Trust password for new clients: Again: And then keep taking the defaults from here on out: Would you like stale cached images to be updated automatically? (yes/no) [default=yes] Would you like a YAML \"lxd init\" preseed to be printed? (yes/no) [default=no]: Setting Up User Privileges Before we continue on, we need to create our \"lxdadmin\" user and make sure that it has the privileges it needs. We need the \"lxdadmin\" user to be able to use sudo for access to root commands, and we need it to be a member of the \u201clxd\u201d group. To add the user and make sure it is a member of both groups, run: useradd -G wheel,lxd lxdadmin Then set the password: passwd lxdadmin As with the other passwords, save this to a secure location. Setting Up Your Firewall Before we do anything else with containers, you need to be able to access your proxy server from the outside. If your firewall is blocking port 80 (the default port used for HTTP/web traffic), or port 443 (used for HTTPS/ secure web traffic), then you won\u2019t be doing much of anything server-wise. The other LXD guide will show you how to do this with the iptables firewall, if that\u2019s what you want to do. I tend to use the CentOS default firewall: firewalld . So that\u2019s what we\u2019re doing, this time. firewalld is configured via the firewall-cmd command. The absolute first thing we want to do, before we open any ports, is make sure that your containers can be assigned their IP addresses automatically: firewall-cmd --zone=trusted --permanent --change-interface=lxdbr0 !!! Warning If you don't do that last step, your containers will not be able to properly access the internet, or each other. This is crazy-essential, and knowing it will save you *ages* of frustration. Now, to add a new port, just run this: firewall-cmd --permanent --zone=public --add-port=80/tcp Let\u2019s break this down: The -\u2013permanent flag tells the firewall to make sure this configuration is used every time the firewall is restarted, and when the server itself is restarted. \u2013-zone=public tells the firewall to take incoming connections to this port from everyone. Lastly, \u2013-add-port=80/tcp tells the firewall to accept incoming connections over port 80, as long as they\u2019re using the Transmission Control Protocol, which is what you want in this case. To repeat the process for HTTPS traffic, just run the command again, and change the number. firewall-cmd --permanent --zone=public --add-port=443/tcp These configurations won\u2019t take effect until you force the issue. To do that, tell firewalld to reload its configurations, like so: firewall-cmd --reload Now, there\u2019s a very small chance that this won\u2019t work. In those rare cases, make firewalld do your bidding with the old turn-it-off-and-turn-it-on-again. systemctl restart firewalld To make sure the ports have been added properly, run firewall-cmd --list-all . A properly-configured firewall will look a bit like this (I have a few extra ports open on my local server, ignore them): public (active) target: default icmp-block-inversion: no interfaces: enp9s0 sources: services: cockpit dhcpv6-client ssh ports: 81/tcp 444/tcp 15151/tcp 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: And that should be everything you need, firewall-wise. Setting Up The Containers Actually managing containers is pretty easy. Just think of it as being able to conjure up a whole computer on command, and start or stop it at will. You can also log into said \u201ccomputer\u201d and run any commands you like, just as you would with your host server. !!! Note From here on out, every command should be run as the `lxdadmin` user, or whatever you decided to call it, though some will require the use of *sudo* for temporary root privileges. You\u2019re going to need three containers for this tutorial: the reverse proxy server, a test Nginx server, and a test Apache server, all running on Rocky-based containers. If for some reason you need a fully privileged container (and you mostly shouldn\u2019t), you can run all of these commands as root. For this tutorial, you\u2019ll need three containers: We\u2019ll call them \u201cproxy-server\u201d (for the container that will be directing web traffic to the other two containers), \u201cnginx-server\u201d, and \u201capache-server\u201d. Yes, I\u2019ll be showing you how to reverse proxy to both nginx and apache -based servers. Things like docker or NodeJS apps we can wait with until I figure that out myself. We\u2019ll start by figuring out which image we want to base our containers on. For this tutorial, we\u2019re just using Rocky Linux. Using Alpine Linux, for example, can result in much smaller containers (if storage is a concern), but that\u2019s beyond the scope of this particular document. Finding the Image You Want Here\u2019s the short, short method for starting a container with Rocky Linux: lxc launch images:rockylinux/8/amd64 my-container Of course, that \u201cmy-container\u201d bit at the end should be renamed to whatever container name you want, eg. \u201cproxy-server\u201d. The \u201c/amd64\u201d part should be changed to \u201carm64\u201d if you\u2019re doing all of this on something like a Raspberry Pi. Now here\u2019s the long version: to find the images you want, you can use this command to list every available image in the main LXC repositories: lxc image list images: | more Then just press \u201cEnter\u201d to scroll down a massive list of images, and press \u201cControl-C\u201d to get out of the list-viewing mode. Or, you could simplify your life, and specify what kind of Linux you want, like so: lxc image list images: | grep rockylinux That should print out a much shorter list that looks like this: | rockylinux/8 (3 more) | 4e6beda70200 | yes | Rockylinux 8 amd64 (20220129_03:44) | x86_64 | VIRTUAL-MACHINE | 612.19MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8 (3 more) | c04dd2bcf20b | yes | Rockylinux 8 amd64 (20220129_03:44) | x86_64 | CONTAINER | 127.34MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8/arm64 (1 more) | adc0561d6330 | yes | Rockylinux 8 arm64 (20220129_03:44) | aarch64 | CONTAINER | 124.03MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8/cloud (1 more) | 2591d9716b04 | yes | Rockylinux 8 amd64 (20220129_03:43) | x86_64 | CONTAINER | 147.04MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8/cloud (1 more) | c963253fcea9 | yes | Rockylinux 8 amd64 (20220129_03:43) | x86_64 | VIRTUAL-MACHINE | 630.56MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8/cloud/arm64 | 9f49e80afa5b | yes | Rockylinux 8 arm64 (20220129_03:44) | aarch64 | CONTAINER | 143.15MB | Jan 29, 2022 at 12:00am (UTC) | Creating the Containers !!! Note Below, is a quick way to create all of these containers. You may want to wait before creating the proxy-server container. There's a trick I'll show you down below that could save you time. Once you\u2019ve found the image you want, use the lxc launch command as shown above. To make the containers we want for this tutorial, run these commands (modifying them as needed) in succession: lxc launch images:rockylinux/8/amd64 proxy-server lxc launch images:rockylinux/8/amd64 nginx-server lxc launch images:rockylinux/8/amd64 apache-server As you run each command, you should get a notification that your containers have been created, and even started. Then, you\u2019ll want to check on all of them. Run this command to see that they\u2019re all up and running: lxc list That should give you output that looks a bit like this (though, if you opted to use IPv6, it\u2019s going to be a lot more text): +---------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +---------------+---------+-----------------------+------+-----------+-----------+ | proxy-server | RUNNING | 10.199.182.231 (eth0) | | CONTAINER | 0 | +---------------+---------+-----------------------+------+-----------+-----------+ | nginx-server | RUNNING | 10.199.182.232 (eth0) | | CONTAINER | 0 | +---------------+---------+-----------------------+------+-----------+-----------+ | apache-server | RUNNING | 10.199.182.233 (eth0) | | CONTAINER | 0 | +---------------+---------+-----------------------+------+-----------+-----------+ A Word on Container Networking So the other guide linked at the beginning of this one has a whole tutorial on how to set LXC/LXD up to work with Macvlan. This is especially useful if you\u2019re running a local server, and you want each container to have an IP address visible on the local network. When you\u2019re running on a VPS, you don\u2019t often have that option. In fact, you might only have one single IP address that you\u2019re allowed to work with. No biggie. The default networking configuration is designed to accommodate this sort of limitation; answering the lxd init questions as I specified above should take care of everything. Basically, LXD creates a virtual network device called a bridge (usually named \u201clxdbr0\u201d), and all containers get connected to that bridge by default. Through it, they can connect to the internet via your host\u2019s default network device (ethernet, wi-fi, or a virtual network device provided by your VPS). Somewhat more importantly, all of the containers can connect to each other. To ensure this inter-container connection, every container gets an internal domain name . By default, this is just the name of the container plus \u201c.lxd\u201d. So the \u201cproxy-server\u201d container is available to all the other containers at \u201cproxy-server.lxd\u201d. But here\u2019s the really important thing to know: by default \u201c.lxd\u201d domains are only available inside the containers themselves. If you run ping proxy-server.lxd on the host OS (or anywhere else), you\u2019ll get nothing. Those internal domains are going to come in super handy later on, though. You can technically change this, and make the container\u2019s internal domains available on the host\u2026 but I never actually figured that out. It\u2019s probably best to put your reverse proxy server in a container anyway, so you can snapshot and back it up with ease. Managing Your Containers Some things you should know before going forward: Starting & Stopping All containers can be started, stopped, and restarted as needed with the following commands: lxc start mycontainer lxc stop mycontainer lxc restart mycontainer Hey, even Linux needs to reboot sometimes. And heck, you can actually start, stop, and restart all containers at once with the following commands. lxc start --all lxc stop --all lxc restart --all That restart --all option comes in real handy for some of the more obscure temporary bugs. Doing Stuff Inside Your Containers You can control the operating system inside your container in two ways: you can just run commands inside them from the host OS, or you can open a shell. Here\u2019s what I mean. To run a command inside a container, maybe to install Apache , just use lxc exec , like so: lxc exec my-container dnf install httpd -y That will make Apache install on its own, and you will see the output of the command on your host\u2019s terminal. To open a shell (where you can just run all the commands you want as root), use this: lxc exec my-container bash If you\u2019re like me, valuing convenience over storage space, and have installed an alternate shell like fish in all of your containers, just change the command like so: lxc exec my-container fish In almost all instances, you\u2019ll automatically be placed on the root account, and in the /root directory. Finally, if you've opened a shell into a container, you leave it the same way you leave any shell: with a simple exit command. Copying Containers Now, if you have a container you\u2019d like to replicate with minimal effort, you don\u2019t need to start a brand new one and install all of your base applications again. That\u2019d be silly. Just run: lxc copy my-container my-other-container An exact copy of \u201cmy-container\u201d will be created with the name \u201cmy-other-container\u201d. It may not start automatically though, so make any changes you might want to make to your new container\u2019s configuration, then run: lxc start my-other-container At this point, you may want to make some changes, like changing the container\u2019s internal hostname, or something. Configuring Storage & CPU Limits LXC/LXD usually defines how much storage space a container gets, and generally manages resources, but you might want control over that. If you\u2019re worried about keeping your containers small, you can use the lxc config command to shrink and stretch them as needed. The following command will set a \u201csoft\u201d limit of 2GB on a container. A soft limit is actually more of a \u201cminimum storage\u201d, and the container will use more storage if it\u2019s available. As always, change \u201cmy-container\u201d to the name of the actual container. lxc config set my-container limits.memory 2GB You can set a hard limit like so: lxc config set my-container limits.memory.enforce 2GB And if you want to make sure that any given container can\u2019t take over all the processing power available to your server, you can limit the CPU cores it has access to with this command. Just change the number of CPU cores at the end as you see fit. lxc config set my-container limits.cpu 2 Deleting Containers (and How to Keep That From Happening) Lastly, you can delete containers by running this command: lxc delete my-container You won\u2019t be able to delete the container if it\u2019s running, so you can either stop it first, or use the -\u2013force flag to skip that part. lxc delete my-container --force Now, thanks to tab -command-completion, user error, and the fact that \u201cd\u201d sits next to \u201cs\u201d on most keyboards, you can accidentally delete containers. This is known, in the business, as THE BIG OOPS. (Or at least it\u2019ll be known as THE BIG OOPS when I\u2019m done here.) To defend against that, you can set any container to be \u201cprotected\u201d (making the process of deleting them take an extra step) with this command: lxc config set my-container security.protection.delete true To un-protect the container, just run the command again, but change \u201ctrue\u201d to \u201cfalse\u201d. Setting Up The Servers Okay, now that your containers are up and running, it\u2019s time to install what you need. First, make sure all of them are updated with the following commands (skip the \u201cproxy-server\u201d container if you haven\u2019t created it yet): lxc exec proxy-server dnf update -y lxc exec nginx-server dnf update -y lxc exec apache-server dnf update -y Then, jump into each container, and get cracking. You\u2019ll also need a text editor for every container. By default, Rocky Linux comes with vi , but if you want to simplify your life, nano will do. You can install it in each container before you open them up. lxc exec proxy-server dnf install nano -y lxc exec nginx-server dnf install nano -y lxc exec apache-server dnf install nano -y I\u2019ll be using nano in all of the text-editor-related commands going forward, but you do you. The Apache website server We're going to keep this short, for learning and testing purposes. Look below for a link to your full Apache guides. First, open up a shell into your container. Note that by default, containers will drop you into the root account. For our purposes, that's fine, though you may want to create a specific web server user for actual production purposes. lxc exec apache-server bash Once you\u2019re logged in, just install Apache the easy way: dnf install httpd Now, you could follow our Apache Web Server Multi-Site Setup guide from here on out, but that\u2019s actually kind of overkill for our purposes. We don\u2019t usually want to set up Apache for multiple websites in a containerized environment like this. The whole point of containers is a separation of concerns, after all. Also, the SSL certificates are going on the proxy server, so we\u2019re going to keep things simple. Once Apache is installed, make sure it\u2019s running, and can keep running on reboot: systemctl enable --now httpd The --now flag lets you skip the command to start the actual server. For reference, that would be: systemctl start httpd If you have curl installed on your server host, you can make sure the default web page is up and running with: curl [container-ip-address] Remember, you can see all contkainer IPs with lxc list . And if you install curl on all your containers, you could just run: curl localhost Getting real user IPs from the proxy server Now here's a step that you'll need to do to prepare Apache for using the reverse proxy. By default, the actual IP addresses of users will not be logged by the servers in your web server containers. You want those IP addresses to go through because some web apps need user IPs for things like moderation, banning, and troubleshooting. To make your visitor's IP addresses get past the proxy server, you need two parts: the right settings in the proxy server (we'll cover that later), and a simple configuration file for the Apache server. A big thanks goes out to Linode and their own LXD guide for the templates for these config files. Make a new config file: nano /etc/httpd/conf.d/real-ip.conf And add this text to it: RemoteIPHeader X-Real-IP RemoteIPTrustedProxy proxy-server.lxd Remember to change proxy-server.lxd to whatever you called your actual proxy container, if necessary. Now don't restart the Apache server just yet. That configuration file we added could cause problems until we get the proxy server up and running. Exit the shell for now, and let's start on the Nginx server. !!! Note While this technique *does* work (your web apps and websites will get the users' real IPs), Apache's own access logs *will not show the right IPs.* They'll usually show the IP of the container that your reverse proxy is in. This is apparently a problem with how Apache logs things. I've found loads of solutions on Google, and none of them have actually worked for me. Watch this space for someone much smarter than I am to figure it out. In the meantime, you can check the proxy server's access logs if you need to see the IP addresses yourself, or check the logs of whatever web app you're installing. The Nginx website server Again, we're keeping this short. If you want to use the latest (and recommended) version of Nginx in production, check out our beginner's guide to installing Nginx . That covers the full install guide, and some best practices for configuring your server. For testing and learning, you could just install Nginx normally, but I recommend installing the latest version, which is called the \"mainline\" branch. First, log into the container's shell: lxc exec nginx-server bash Then, install the epel-release repository so you can install the latest version of Nginx: dnf install epel-release Once that's done, search for the latest version of Nginx with: dnf module list nginx That should get you a list that looks like this: Rocky Linux 8 - AppStream Name Stream Profiles Summary nginx 1.14 [d] common [d] nginx webserver nginx 1.16 common [d] nginx webserver nginx 1.18 common [d] nginx webserver nginx 1.20 common [d] nginx webserver nginx mainline common [d] nginx webserver The one you want is, you guessed it: the mainline branch. Enable the module with this command: dnf enable module nginx:mainline You'll be asked if you're sure you want to do this, so just choose Y as usual. Then, use the default command to install Nginx: dnf install nginx Then, enable and start Nginx: dnf enable --now nginx !!! Note Remember when I said to wait before creating the proxy container? Here's why: at this point, you can save yourself some time by leaving the \"nginx-server\" container, and copying it to make the \"proxy-server\" container: ```bash lxc copy nginx-server proxy-server ``` Make sure to start the proxy container with `lxc start proxy-server`, and add the proxy ports to the container as detailed below. Again, you can make sure the container is working from the host with: curl [your-container-ip] Getting real user IPs from the proxy server (again) The logs should work this time. Should. To do this, we're putting a very similar file in /etc/nginx/conf.d : nano /etc/nginx/conf.d/real-ip.conf Then put this text in it: real_ip_header X-Real-IP; set_real_ip_from proxy-server.lxd; Lastly, don't restart the server yet . Again, that config file could cause problems until the proxy server is set up. The Reverse Proxy Server So remember when I said you'd need two domains or subdomains? This is where you need them. The subdomains I'm using for this tutorial are: apache.server.test nginx.server.test Change them in all the files and instructions as needed. If you copied the \"proxy-server\" container from your \"nginx-server\" container, and you've added your proxy devices to it, just jump on into the shell. If you created the container earlier, you'll need to repeat all the steps for installing Nginx in the \"proxy-server\" container. Once it's installed and you know it runs okay, you just need to set up a couple of configuration files to direct traffic from your chosen domains to the actual website servers. Before you do that, make sure you can access both servers via their internal domains: curl apache-server.lxd curl nginx-server.lxd If those two commands load the HTML of the default server welcome pages in your terminal, then everything has been set up correctly. Essential Step: Configuring the \u201cproxy-server\u201d Container to Take all Incoming Server Traffic Again, you might want to do this later when you actually create the proxy server, but here are the instructions you'll need: Remember when we opened up ports 80 and 443 in the firewall? Here\u2019s where we make the \u201cproxy-server\u201d container listen to those ports, and take all the traffic directed at them. Just run these two commands in succession: lxc config device add proxy-server myproxy80 proxy listen=tcp:0.0.0.0:80 connect=tcp:127.0.0.1:80 lxc config device add proxy-server myproxy443 proxy listen=tcp:0.0.0.0:443 connect=tcp:127.0.0.1:443 Let\u2019s break that down. Each command is adding a virtual \u201cdevice\u201d to the proxy-server container. Those devices are set to listen on the host OS\u2019 port 80 and port 443, and bind them to the container\u2019s port 80 and port 443. Each device needs a name, so I\u2019ve chosen \u201cmyproxy80\u201d, and \u201cmyproxy443\u201d. The \u201clisten\u201d option is the port on the host OS, and if I\u2019m not mistaken, 0.0.0.0 is the IP address for the host on the \u201clxdbr0\u201d bridge. The \u201cconnect\u201d option is the local IP address and ports being connected to. !!! Note Once these devices have been set up, you should reboot all the containers, just to be sure. These virtual device should ideally be unique. It's usually best not to add a \u201cmyport80\u201d device to another container that's currently running; it\u2019ll have to be called something else. Likewise, only one container can listen on any specific host OS port at a time. Directing traffic to the Apache server In the \"proxy-server\" container, create a configuration file called apache-server.conf in /etc/nginx/conf.d/ : nano /etc/nginx/conf.d/apache-server.conf Then paste this test in, change the domain name as necessary, and save it: upstream apache-server { server apache-server.lxd:80; } server { listen 80 proxy_protocol; listen [::]:80 proxy_protocol; server_name apache.server.test; #< Your domain goes here location / { proxy_pass http://apache-server; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } Let's break that down a little: The upstream section is defining exactly where the reverse proxy is going to send all its traffic. Specifically, it's sending traffic to the \"apache-server\" container's internal domain name: apache-server.lxd . The two lines that start with listen are telling the server to listen to traffic coming in on port 80 with the proxy protocol. The first via IPv4, and the second via IPv6. The server_name function takes all the traffic that's specifically coming to \"apache.server.test\" and routes it through the reverse proxy. The proxy-pass function is the part that actually directs all traffic captured by the server_name variable, and sends it to the server defined in the upstream section. The proxy_redirect function can apparently interfere with reverse proxies, so we're making sure it's turned off. All of the proxy-set-header options are sending information like the user's IP and more to the web server. !!! warning The `proxy_protocol` bit in the `listen` variables is *essential* for the proxy server to work. Never leave it out. For every LXD/website configuration file, you'll need to change the upstream , server , server_name , and proxy_pass settings accordingly. The text after \"http://\" in proxy-pass must match the txt that comes after the upstream text. Reload the server with systemctl restart nginx , then point your browser at whatever domain you're using instead of apache.server.test . If you see a page that looks like this, you're golden: !!! Note You can name the config files whatever you like. I'm using simplified names for the tutorials, but some sysadmins recommend names based on the actual domain, but backwards. It's an alphabetical order-based organization thing. eg. \"apache.server.test\" would get a configuration file named `test.server.apache.conf`. Directing traffic to the Nginx server Just kinda repeat the process. Create a file just like before: nano /etc/nginx/conf.d/nginx-server.conf Add the approriate text: upstream nginx-server { server rocky-nginx.lxd:80; } server { listen 80 proxy_protocol; listen [::]:80 proxy_protocol; server_name nginx.server.test; #< Your domain goes here location / { proxy_pass http://nginx-server; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } Again, reload the proxy server, point your browser at the appropriate address, and hope to whatever deity your prefer that you see this: Restart the servers in your web server containers Exit back out of the \"proxy-server\" container, and restart the servers in your other two containers with one simple command: lxc exec apache-server systemctl restart httpd && lxc exec nginx-server restart nginx That will apply the \"real-ip.conf\" files we made to their respective server configurations. Getting SSL certificates for your websites Getting official, proper SSL certificates is easiest with Let's Encrypt, and a little application called certbot. certbot will automatically detect your websites, get SSL certificates for them, and configure the sites itself. It will even renew the certificates for you every 30 days or so, without any intervention from you or cron jobs. This all has to be done from the \"proxy-server\" container, so log into that shell. Once there, install the EPEL repositories, just like you did on the host. Make sure the container is updated first: dnf update Then, add the EPEL repository: dnf install epel-release Then you just need to install certbot and its Nginx module: dnf install certbot python3-certbot-nginx Once installed, as long as you already have a couple of websites configured, just run: certbot --nginx Certbot will read your Nginx configuration, and figure out how many websites you have and if they need SSL certificates. At this point, you'll be asked a few questions. Do you accept the terms of service, do you want emails, etc? The most important questions are as follows. Enter your email address when you see this: Saving debug log to /var/log/letsencrypt/letsencrypt.log Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): Here you can choose which websites get certificates. Just hit enter to get certificates for all of them. Which names would you like to activate HTTPS for? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1: apache.server.test 2: nginx.server.test - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Select the appropriate numbers separated by commas and/or spaces, or leave input blank to select all options shown (Enter 'c' to cancel): You'll see a bunch of confirmation text, and it'll be done. But if you go to your websites, you might find that they don't work. This is because when certbot creates the updated configuration, it forgets one very important thing. Go into your apache-server.conf and nginx-server.conf files, and find the following two lines: listen [::]:443 ssl ipv6only=on; # managed by Certbot listen 443 ssl; # managed by Certbot Yep, they're missing the proxy_protocol setting, and that's bad. Add it in yourself. listen proxy_protocol [::]:443 ssl ipv6only=on; # managed by Certbot listen proxy_protocol 443 ssl; # managed by Certbot Save the file, restart the server, and your websites should load without any issue. Notes In this tutorial, I didn't mention configuring the actual web servers much. The very least you should do, in production, is change the domains names in the server config files in your actual web server containers, and not just the proxy container. And maybe set up a web server user in each. If you want to know a bit more about managing SSL certificates and SSL server configurations manually, check out our guide to installing certbot and generating SSL certificates . Apps like Nextcloud will require some extra configuration (for security reasons) if you put them in an LXD container behind a proxy. Conclusion There's a lot more to learn about LXC/LXD, containerization, web servers, and running websites, but that should honestly give you a good start. Once you learn how everything should be set up, and how to configure things the way you like, you can even begin to automate the process. You might use Ansible, or you might be like me, and just have a custom-written set of scripts that you run to make everything go faster. You can even create small \"template containers\" with all of your favorite software preinstalled, then just copy them and expand their storage capacity as needed. Okay. This is done. I'm off to play video games. Have fun!","title":"LXD Beginners Guide-Multiple Servers"},{"location":"guides/containers/lxd_web_servers/#building-a-network-of-websitesweb-servers-with-lxd-for-beginners","text":"","title":"Building a Network of Websites/Web Servers With LXD, for Beginners"},{"location":"guides/containers/lxd_web_servers/#introduction","text":"Okay, so we already have a guide on installing LXD/LXC on Rocky Linux , but that was written by someone who knows what he\u2019s doing, and wanted to build a containerized network of servers and/or apps on a physical machine on his local network. It\u2019s great, and I\u2019ll be straight up stealing bits of it so I don\u2019t have to write as much. But, if you\u2019ve just heard about Linux Containers, and don\u2019t really understand how they work yet, but you want to host some websites, this is the guide for you. This tutorial will teach you how to host basic websites with LXD and LXC on any system, including virtual private servers and cloud hosting. So first, what\u2019s a Linux Container? Well, for the absolute beginner, it\u2019s a way to make one computer pretend that it\u2019s actually a lot more computers. These \u201ccontainers\u201d each house a basic\u2014usually stripped-down\u2014version of an operating system you choose. You can use each container like an individual server; put nginx on one, Apache on another, and even use a third as a database server. The basic advantage is that if one app or website inside its own container experiences severe bugs, a hack, or other problems, it\u2019s unlikely to affect the rest of your server or the other apps and websites. Also, containers are super easy to snapshot, back up, and restore. In this case, we\u2019ll be running Rocky Linux in our containers, on top of our \u201chost\u201d system, which is also Rocky Linux. Conceptually, it\u2019s something like this: If you\u2019ve ever played with VirtualBox to run some Windows apps, it\u2019s like that, but not. Unlike virtual machines, Linux Containers don\u2019t emulate an entire hardware environment for each container. Rather, they all share a few virtual devices by default for networking and storage, though you can add more virtual devices. As a result, they require a lot less overhead (processing power and RAM) than a virtual machine. For those Docker fiends out there (Docker being another container-based system, not a VM system), Linux Containers are less ephemeral than what you\u2019re used to. All data in every container instance is persistent, and any changes you make are permanent unless you revert to a backup. In short, shutting down the container won\u2019t erase your sins. Heh. LXD, specifically, is a command-line application that helps you to set up and manage Linux Containers. That's what we're going to be installing on our Rocky Linux host server today. I'm going to be writing LXC/LXD a lot though, as there's a lot of old documentation which refers to LXC only, and I'm trying to make it easier for people to find updated guides like this one. !!! Note There was a precursor app to LXD which was also called \"LXC\". As it stands today: LXC is the technology, LXD is the app. We\u2019ll be using them both to create an environment that works something like this: Specifically, I\u2019m going to show you how to set up simple Nginx and Apache web servers inside of your server containers, and use another container with Nginx as a reverse proxy. Again, this setup should work in any environment: from local networks to virtual private servers. !!! Note A reverse proxy is a program that takes incoming connections from the internet (or your local network) and routes them to the right server, container, or app. There are also dedicated tools for this job like HaProxy... but weirdly enough, I find Nginx a lot easier to use.","title":"Introduction"},{"location":"guides/containers/lxd_web_servers/#prerequisites-and-assumptions","text":"Basic familiarity with the Linux command line interface. You should know how to use SSH if you\u2019re installing LXC/LXD on a remote server. An internet-connected server, physical or virtual, with Rocky Linux already running on it. Two domain names pointed right at your server with an A record. Two subdomains would also work just as well. One domain with a wildcard subdomain record would also, or a custom LAN domain... you get the picture. A command-line text editor. nano will do, micro is my favorite, but use whatever makes you comfortable. You can follow this whole tutorial as the root user, but you probably shouldn\u2019t. After the initial installation of LXC/LXD, we\u2019ll guide you in creating an unprivileged user specifically for operating LXD commands. We now have Rocky Linux images to base your containers on, and they\u2019re awesome. If you're not too familiar with Nginx or Apache, you will need to check out some of our other guides if you want to get a full productions server up and running. Don't worry, I'll link them below.","title":"Prerequisites And Assumptions"},{"location":"guides/containers/lxd_web_servers/#setting-up-the-host-server-environment","text":"So here\u2019s where I\u2019m going to copy and paste bits from the other LXD guide, for your convenience and mine. All credit for most of this part goes to Steven Spencer.","title":"Setting Up The Host Server Environment"},{"location":"guides/containers/lxd_web_servers/#install-the-epel-repository","text":"LXD requires the EPEL (Extra Packages for Enterprise Linux) repository, which is easy to install using: dnf install epel-release Once installed, check for updates: dnf update If there were kernel updates during the update process above, reboot your server","title":"Install the EPEL Repository"},{"location":"guides/containers/lxd_web_servers/#install-snapd","text":"LXD must be installed from a snap* package for Rocky Linux. For this reason, we need to install snapd with: dnf install snapd And now enable the snapd service to auto-start when your server reboots, and start it running now: systemctl enable snapd And then run: systemctl start snapd Reboot the server before continuing here. You can do this with the reboot command, or from your VPS/cloud hosting admin panel. * snap is a method of packaging applications so they come with all of the dependencies they need, and can run on almost any Linux system.","title":"Install snapd"},{"location":"guides/containers/lxd_web_servers/#install-lxd","text":"Installing LXD requires the use of the snap command. At this point, we are just installing it, we are doing no set up: snap install lxd If you\u2019re running LXD on a physical (AKA \u201cbare metal\u201d) server, you should probably go back to the other guide and read the \u201cEnvironment Setup\u201d section there. There\u2019s a lot of good stuff about kernels and file systems, and so much more. If you\u2019re running LXD in a virtual environment, just reboot and read on.","title":"Install LXD"},{"location":"guides/containers/lxd_web_servers/#lxd-initialization","text":"Now that the environment is all set up, we are ready to initialize LXD. This is an automated script that asks a series of questions to get your LXD instance up and running: lxd init Here are the questions and our answers for the script, with a little explanation where warranted: Would you like to use LXD clustering? (yes/no) [default=no]: If you are interested in clustering, do some additional research on that here . Otherwise, just press \u201cEnter\u201d to accept the default option. Do you want to configure a new storage pool? (yes/no) [default=yes]: Accept the default. Name of the new storage pool [default=default]: server-storage Choose a name for your storage pool. I like to name it after the server LXD is running on. (A storage pool is basically a set amount of hard drive space set aside for your containers.) Name of the storage backend to use (btrfs, dir, lvm, zfs, ceph) [default=zfs]: lvm The above question is about what sort of file system you want to use for storage, and the default may vary depending on what\u2019s available on your system. If you're on a bare metal server, and want to use ZFS, again, refer back to the guide linked above. In a virtual environment, I have found that \u201cLVM\u201d works fine, and it\u2019s usually what I use. You can accept the default on the next question. Create a new LVM pool? (yes/no) [default=yes]: If you have a specific hard drive or partition you\u2019d like to use for the whole storage pool, write \u201cyes\u201d next. If you\u2019re doing all of this on a VPS, you\u2019ll probably have to choose \u201cno\u201d. `Would you like to use an existing empty block device (e.g. a disk or partition)? (yes/no) [default=no]:` Metal As A Service (MAAS) is outside the scope of this document. Accept the defaults for this next bit. Would you like to connect to a MAAS server? (yes/no) [default=no]: And more defaults. It's all good. Would you like to create a new local network bridge? (yes/no) [default=yes]: What should the new bridge be called? [default=lxdbr0]: ` What IPv4 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: If you want to use IPv6 on your LXD containers, you can turn on this next option. That is up to you, but you mostly shouldn\u2019t need to. I think. I tend to leave it on out of laziness. What IPv6 address should be used? (CIDR subnet notation, \u201cauto\u201d or \u201cnone\u201d) [default=auto]: This is necessary to easily back up the server, and can allow you to manage your LXD install from other computers. If that all sounds good to you, answer \"yes\" here/ Would you like the LXD server to be available over the network? (yes/no) [default=no]: yes If you did say yes to the last questions, take the defaults here: Address to bind LXD to (not including port) [default=all]: Port to bind LXD to [default=8443]: Now you'll be asked for a trust password. That's how you will connect to the LXC host server from other computers and servers, so set this with something that makes sense in your environment. Save this password to a secure location, such as a password manager. Trust password for new clients: Again: And then keep taking the defaults from here on out: Would you like stale cached images to be updated automatically? (yes/no) [default=yes] Would you like a YAML \"lxd init\" preseed to be printed? (yes/no) [default=no]:","title":"LXD Initialization"},{"location":"guides/containers/lxd_web_servers/#setting-up-user-privileges","text":"Before we continue on, we need to create our \"lxdadmin\" user and make sure that it has the privileges it needs. We need the \"lxdadmin\" user to be able to use sudo for access to root commands, and we need it to be a member of the \u201clxd\u201d group. To add the user and make sure it is a member of both groups, run: useradd -G wheel,lxd lxdadmin Then set the password: passwd lxdadmin As with the other passwords, save this to a secure location.","title":"Setting Up User Privileges"},{"location":"guides/containers/lxd_web_servers/#setting-up-your-firewall","text":"Before we do anything else with containers, you need to be able to access your proxy server from the outside. If your firewall is blocking port 80 (the default port used for HTTP/web traffic), or port 443 (used for HTTPS/ secure web traffic), then you won\u2019t be doing much of anything server-wise. The other LXD guide will show you how to do this with the iptables firewall, if that\u2019s what you want to do. I tend to use the CentOS default firewall: firewalld . So that\u2019s what we\u2019re doing, this time. firewalld is configured via the firewall-cmd command. The absolute first thing we want to do, before we open any ports, is make sure that your containers can be assigned their IP addresses automatically: firewall-cmd --zone=trusted --permanent --change-interface=lxdbr0 !!! Warning If you don't do that last step, your containers will not be able to properly access the internet, or each other. This is crazy-essential, and knowing it will save you *ages* of frustration. Now, to add a new port, just run this: firewall-cmd --permanent --zone=public --add-port=80/tcp Let\u2019s break this down: The -\u2013permanent flag tells the firewall to make sure this configuration is used every time the firewall is restarted, and when the server itself is restarted. \u2013-zone=public tells the firewall to take incoming connections to this port from everyone. Lastly, \u2013-add-port=80/tcp tells the firewall to accept incoming connections over port 80, as long as they\u2019re using the Transmission Control Protocol, which is what you want in this case. To repeat the process for HTTPS traffic, just run the command again, and change the number. firewall-cmd --permanent --zone=public --add-port=443/tcp These configurations won\u2019t take effect until you force the issue. To do that, tell firewalld to reload its configurations, like so: firewall-cmd --reload Now, there\u2019s a very small chance that this won\u2019t work. In those rare cases, make firewalld do your bidding with the old turn-it-off-and-turn-it-on-again. systemctl restart firewalld To make sure the ports have been added properly, run firewall-cmd --list-all . A properly-configured firewall will look a bit like this (I have a few extra ports open on my local server, ignore them): public (active) target: default icmp-block-inversion: no interfaces: enp9s0 sources: services: cockpit dhcpv6-client ssh ports: 81/tcp 444/tcp 15151/tcp 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: And that should be everything you need, firewall-wise.","title":"Setting Up Your Firewall"},{"location":"guides/containers/lxd_web_servers/#setting-up-the-containers","text":"Actually managing containers is pretty easy. Just think of it as being able to conjure up a whole computer on command, and start or stop it at will. You can also log into said \u201ccomputer\u201d and run any commands you like, just as you would with your host server. !!! Note From here on out, every command should be run as the `lxdadmin` user, or whatever you decided to call it, though some will require the use of *sudo* for temporary root privileges. You\u2019re going to need three containers for this tutorial: the reverse proxy server, a test Nginx server, and a test Apache server, all running on Rocky-based containers. If for some reason you need a fully privileged container (and you mostly shouldn\u2019t), you can run all of these commands as root. For this tutorial, you\u2019ll need three containers: We\u2019ll call them \u201cproxy-server\u201d (for the container that will be directing web traffic to the other two containers), \u201cnginx-server\u201d, and \u201capache-server\u201d. Yes, I\u2019ll be showing you how to reverse proxy to both nginx and apache -based servers. Things like docker or NodeJS apps we can wait with until I figure that out myself. We\u2019ll start by figuring out which image we want to base our containers on. For this tutorial, we\u2019re just using Rocky Linux. Using Alpine Linux, for example, can result in much smaller containers (if storage is a concern), but that\u2019s beyond the scope of this particular document.","title":"Setting Up The Containers"},{"location":"guides/containers/lxd_web_servers/#finding-the-image-you-want","text":"Here\u2019s the short, short method for starting a container with Rocky Linux: lxc launch images:rockylinux/8/amd64 my-container Of course, that \u201cmy-container\u201d bit at the end should be renamed to whatever container name you want, eg. \u201cproxy-server\u201d. The \u201c/amd64\u201d part should be changed to \u201carm64\u201d if you\u2019re doing all of this on something like a Raspberry Pi. Now here\u2019s the long version: to find the images you want, you can use this command to list every available image in the main LXC repositories: lxc image list images: | more Then just press \u201cEnter\u201d to scroll down a massive list of images, and press \u201cControl-C\u201d to get out of the list-viewing mode. Or, you could simplify your life, and specify what kind of Linux you want, like so: lxc image list images: | grep rockylinux That should print out a much shorter list that looks like this: | rockylinux/8 (3 more) | 4e6beda70200 | yes | Rockylinux 8 amd64 (20220129_03:44) | x86_64 | VIRTUAL-MACHINE | 612.19MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8 (3 more) | c04dd2bcf20b | yes | Rockylinux 8 amd64 (20220129_03:44) | x86_64 | CONTAINER | 127.34MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8/arm64 (1 more) | adc0561d6330 | yes | Rockylinux 8 arm64 (20220129_03:44) | aarch64 | CONTAINER | 124.03MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8/cloud (1 more) | 2591d9716b04 | yes | Rockylinux 8 amd64 (20220129_03:43) | x86_64 | CONTAINER | 147.04MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8/cloud (1 more) | c963253fcea9 | yes | Rockylinux 8 amd64 (20220129_03:43) | x86_64 | VIRTUAL-MACHINE | 630.56MB | Jan 29, 2022 at 12:00am (UTC) | | rockylinux/8/cloud/arm64 | 9f49e80afa5b | yes | Rockylinux 8 arm64 (20220129_03:44) | aarch64 | CONTAINER | 143.15MB | Jan 29, 2022 at 12:00am (UTC) |","title":"Finding the Image You Want"},{"location":"guides/containers/lxd_web_servers/#creating-the-containers","text":"!!! Note Below, is a quick way to create all of these containers. You may want to wait before creating the proxy-server container. There's a trick I'll show you down below that could save you time. Once you\u2019ve found the image you want, use the lxc launch command as shown above. To make the containers we want for this tutorial, run these commands (modifying them as needed) in succession: lxc launch images:rockylinux/8/amd64 proxy-server lxc launch images:rockylinux/8/amd64 nginx-server lxc launch images:rockylinux/8/amd64 apache-server As you run each command, you should get a notification that your containers have been created, and even started. Then, you\u2019ll want to check on all of them. Run this command to see that they\u2019re all up and running: lxc list That should give you output that looks a bit like this (though, if you opted to use IPv6, it\u2019s going to be a lot more text): +---------------+---------+-----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +---------------+---------+-----------------------+------+-----------+-----------+ | proxy-server | RUNNING | 10.199.182.231 (eth0) | | CONTAINER | 0 | +---------------+---------+-----------------------+------+-----------+-----------+ | nginx-server | RUNNING | 10.199.182.232 (eth0) | | CONTAINER | 0 | +---------------+---------+-----------------------+------+-----------+-----------+ | apache-server | RUNNING | 10.199.182.233 (eth0) | | CONTAINER | 0 | +---------------+---------+-----------------------+------+-----------+-----------+","title":"Creating the Containers"},{"location":"guides/containers/lxd_web_servers/#a-word-on-container-networking","text":"So the other guide linked at the beginning of this one has a whole tutorial on how to set LXC/LXD up to work with Macvlan. This is especially useful if you\u2019re running a local server, and you want each container to have an IP address visible on the local network. When you\u2019re running on a VPS, you don\u2019t often have that option. In fact, you might only have one single IP address that you\u2019re allowed to work with. No biggie. The default networking configuration is designed to accommodate this sort of limitation; answering the lxd init questions as I specified above should take care of everything. Basically, LXD creates a virtual network device called a bridge (usually named \u201clxdbr0\u201d), and all containers get connected to that bridge by default. Through it, they can connect to the internet via your host\u2019s default network device (ethernet, wi-fi, or a virtual network device provided by your VPS). Somewhat more importantly, all of the containers can connect to each other. To ensure this inter-container connection, every container gets an internal domain name . By default, this is just the name of the container plus \u201c.lxd\u201d. So the \u201cproxy-server\u201d container is available to all the other containers at \u201cproxy-server.lxd\u201d. But here\u2019s the really important thing to know: by default \u201c.lxd\u201d domains are only available inside the containers themselves. If you run ping proxy-server.lxd on the host OS (or anywhere else), you\u2019ll get nothing. Those internal domains are going to come in super handy later on, though. You can technically change this, and make the container\u2019s internal domains available on the host\u2026 but I never actually figured that out. It\u2019s probably best to put your reverse proxy server in a container anyway, so you can snapshot and back it up with ease.","title":"A Word on Container Networking"},{"location":"guides/containers/lxd_web_servers/#managing-your-containers","text":"Some things you should know before going forward:","title":"Managing Your Containers"},{"location":"guides/containers/lxd_web_servers/#starting-stopping","text":"All containers can be started, stopped, and restarted as needed with the following commands: lxc start mycontainer lxc stop mycontainer lxc restart mycontainer Hey, even Linux needs to reboot sometimes. And heck, you can actually start, stop, and restart all containers at once with the following commands. lxc start --all lxc stop --all lxc restart --all That restart --all option comes in real handy for some of the more obscure temporary bugs.","title":"Starting &amp; Stopping"},{"location":"guides/containers/lxd_web_servers/#doing-stuff-inside-your-containers","text":"You can control the operating system inside your container in two ways: you can just run commands inside them from the host OS, or you can open a shell. Here\u2019s what I mean. To run a command inside a container, maybe to install Apache , just use lxc exec , like so: lxc exec my-container dnf install httpd -y That will make Apache install on its own, and you will see the output of the command on your host\u2019s terminal. To open a shell (where you can just run all the commands you want as root), use this: lxc exec my-container bash If you\u2019re like me, valuing convenience over storage space, and have installed an alternate shell like fish in all of your containers, just change the command like so: lxc exec my-container fish In almost all instances, you\u2019ll automatically be placed on the root account, and in the /root directory. Finally, if you've opened a shell into a container, you leave it the same way you leave any shell: with a simple exit command.","title":"Doing Stuff Inside Your Containers"},{"location":"guides/containers/lxd_web_servers/#copying-containers","text":"Now, if you have a container you\u2019d like to replicate with minimal effort, you don\u2019t need to start a brand new one and install all of your base applications again. That\u2019d be silly. Just run: lxc copy my-container my-other-container An exact copy of \u201cmy-container\u201d will be created with the name \u201cmy-other-container\u201d. It may not start automatically though, so make any changes you might want to make to your new container\u2019s configuration, then run: lxc start my-other-container At this point, you may want to make some changes, like changing the container\u2019s internal hostname, or something.","title":"Copying Containers"},{"location":"guides/containers/lxd_web_servers/#configuring-storage-cpu-limits","text":"LXC/LXD usually defines how much storage space a container gets, and generally manages resources, but you might want control over that. If you\u2019re worried about keeping your containers small, you can use the lxc config command to shrink and stretch them as needed. The following command will set a \u201csoft\u201d limit of 2GB on a container. A soft limit is actually more of a \u201cminimum storage\u201d, and the container will use more storage if it\u2019s available. As always, change \u201cmy-container\u201d to the name of the actual container. lxc config set my-container limits.memory 2GB You can set a hard limit like so: lxc config set my-container limits.memory.enforce 2GB And if you want to make sure that any given container can\u2019t take over all the processing power available to your server, you can limit the CPU cores it has access to with this command. Just change the number of CPU cores at the end as you see fit. lxc config set my-container limits.cpu 2","title":"Configuring Storage &amp; CPU Limits"},{"location":"guides/containers/lxd_web_servers/#deleting-containers-and-how-to-keep-that-from-happening","text":"Lastly, you can delete containers by running this command: lxc delete my-container You won\u2019t be able to delete the container if it\u2019s running, so you can either stop it first, or use the -\u2013force flag to skip that part. lxc delete my-container --force Now, thanks to tab -command-completion, user error, and the fact that \u201cd\u201d sits next to \u201cs\u201d on most keyboards, you can accidentally delete containers. This is known, in the business, as THE BIG OOPS. (Or at least it\u2019ll be known as THE BIG OOPS when I\u2019m done here.) To defend against that, you can set any container to be \u201cprotected\u201d (making the process of deleting them take an extra step) with this command: lxc config set my-container security.protection.delete true To un-protect the container, just run the command again, but change \u201ctrue\u201d to \u201cfalse\u201d.","title":"Deleting Containers (and How to Keep That From Happening)"},{"location":"guides/containers/lxd_web_servers/#setting-up-the-servers","text":"Okay, now that your containers are up and running, it\u2019s time to install what you need. First, make sure all of them are updated with the following commands (skip the \u201cproxy-server\u201d container if you haven\u2019t created it yet): lxc exec proxy-server dnf update -y lxc exec nginx-server dnf update -y lxc exec apache-server dnf update -y Then, jump into each container, and get cracking. You\u2019ll also need a text editor for every container. By default, Rocky Linux comes with vi , but if you want to simplify your life, nano will do. You can install it in each container before you open them up. lxc exec proxy-server dnf install nano -y lxc exec nginx-server dnf install nano -y lxc exec apache-server dnf install nano -y I\u2019ll be using nano in all of the text-editor-related commands going forward, but you do you.","title":"Setting Up The Servers"},{"location":"guides/containers/lxd_web_servers/#the-apache-website-server","text":"We're going to keep this short, for learning and testing purposes. Look below for a link to your full Apache guides. First, open up a shell into your container. Note that by default, containers will drop you into the root account. For our purposes, that's fine, though you may want to create a specific web server user for actual production purposes. lxc exec apache-server bash Once you\u2019re logged in, just install Apache the easy way: dnf install httpd Now, you could follow our Apache Web Server Multi-Site Setup guide from here on out, but that\u2019s actually kind of overkill for our purposes. We don\u2019t usually want to set up Apache for multiple websites in a containerized environment like this. The whole point of containers is a separation of concerns, after all. Also, the SSL certificates are going on the proxy server, so we\u2019re going to keep things simple. Once Apache is installed, make sure it\u2019s running, and can keep running on reboot: systemctl enable --now httpd The --now flag lets you skip the command to start the actual server. For reference, that would be: systemctl start httpd If you have curl installed on your server host, you can make sure the default web page is up and running with: curl [container-ip-address] Remember, you can see all contkainer IPs with lxc list . And if you install curl on all your containers, you could just run: curl localhost","title":"The Apache website server"},{"location":"guides/containers/lxd_web_servers/#getting-real-user-ips-from-the-proxy-server","text":"Now here's a step that you'll need to do to prepare Apache for using the reverse proxy. By default, the actual IP addresses of users will not be logged by the servers in your web server containers. You want those IP addresses to go through because some web apps need user IPs for things like moderation, banning, and troubleshooting. To make your visitor's IP addresses get past the proxy server, you need two parts: the right settings in the proxy server (we'll cover that later), and a simple configuration file for the Apache server. A big thanks goes out to Linode and their own LXD guide for the templates for these config files. Make a new config file: nano /etc/httpd/conf.d/real-ip.conf And add this text to it: RemoteIPHeader X-Real-IP RemoteIPTrustedProxy proxy-server.lxd Remember to change proxy-server.lxd to whatever you called your actual proxy container, if necessary. Now don't restart the Apache server just yet. That configuration file we added could cause problems until we get the proxy server up and running. Exit the shell for now, and let's start on the Nginx server. !!! Note While this technique *does* work (your web apps and websites will get the users' real IPs), Apache's own access logs *will not show the right IPs.* They'll usually show the IP of the container that your reverse proxy is in. This is apparently a problem with how Apache logs things. I've found loads of solutions on Google, and none of them have actually worked for me. Watch this space for someone much smarter than I am to figure it out. In the meantime, you can check the proxy server's access logs if you need to see the IP addresses yourself, or check the logs of whatever web app you're installing.","title":"Getting real user IPs from the proxy server"},{"location":"guides/containers/lxd_web_servers/#the-nginx-website-server","text":"Again, we're keeping this short. If you want to use the latest (and recommended) version of Nginx in production, check out our beginner's guide to installing Nginx . That covers the full install guide, and some best practices for configuring your server. For testing and learning, you could just install Nginx normally, but I recommend installing the latest version, which is called the \"mainline\" branch. First, log into the container's shell: lxc exec nginx-server bash Then, install the epel-release repository so you can install the latest version of Nginx: dnf install epel-release Once that's done, search for the latest version of Nginx with: dnf module list nginx That should get you a list that looks like this: Rocky Linux 8 - AppStream Name Stream Profiles Summary nginx 1.14 [d] common [d] nginx webserver nginx 1.16 common [d] nginx webserver nginx 1.18 common [d] nginx webserver nginx 1.20 common [d] nginx webserver nginx mainline common [d] nginx webserver The one you want is, you guessed it: the mainline branch. Enable the module with this command: dnf enable module nginx:mainline You'll be asked if you're sure you want to do this, so just choose Y as usual. Then, use the default command to install Nginx: dnf install nginx Then, enable and start Nginx: dnf enable --now nginx !!! Note Remember when I said to wait before creating the proxy container? Here's why: at this point, you can save yourself some time by leaving the \"nginx-server\" container, and copying it to make the \"proxy-server\" container: ```bash lxc copy nginx-server proxy-server ``` Make sure to start the proxy container with `lxc start proxy-server`, and add the proxy ports to the container as detailed below. Again, you can make sure the container is working from the host with: curl [your-container-ip]","title":"The Nginx website server"},{"location":"guides/containers/lxd_web_servers/#getting-real-user-ips-from-the-proxy-server-again","text":"The logs should work this time. Should. To do this, we're putting a very similar file in /etc/nginx/conf.d : nano /etc/nginx/conf.d/real-ip.conf Then put this text in it: real_ip_header X-Real-IP; set_real_ip_from proxy-server.lxd; Lastly, don't restart the server yet . Again, that config file could cause problems until the proxy server is set up.","title":"Getting real user IPs from the proxy server (again)"},{"location":"guides/containers/lxd_web_servers/#the-reverse-proxy-server","text":"So remember when I said you'd need two domains or subdomains? This is where you need them. The subdomains I'm using for this tutorial are: apache.server.test nginx.server.test Change them in all the files and instructions as needed. If you copied the \"proxy-server\" container from your \"nginx-server\" container, and you've added your proxy devices to it, just jump on into the shell. If you created the container earlier, you'll need to repeat all the steps for installing Nginx in the \"proxy-server\" container. Once it's installed and you know it runs okay, you just need to set up a couple of configuration files to direct traffic from your chosen domains to the actual website servers. Before you do that, make sure you can access both servers via their internal domains: curl apache-server.lxd curl nginx-server.lxd If those two commands load the HTML of the default server welcome pages in your terminal, then everything has been set up correctly.","title":"The Reverse Proxy Server"},{"location":"guides/containers/lxd_web_servers/#essential-step-configuring-the-proxy-server-container-to-take-all-incoming-server-traffic","text":"Again, you might want to do this later when you actually create the proxy server, but here are the instructions you'll need: Remember when we opened up ports 80 and 443 in the firewall? Here\u2019s where we make the \u201cproxy-server\u201d container listen to those ports, and take all the traffic directed at them. Just run these two commands in succession: lxc config device add proxy-server myproxy80 proxy listen=tcp:0.0.0.0:80 connect=tcp:127.0.0.1:80 lxc config device add proxy-server myproxy443 proxy listen=tcp:0.0.0.0:443 connect=tcp:127.0.0.1:443 Let\u2019s break that down. Each command is adding a virtual \u201cdevice\u201d to the proxy-server container. Those devices are set to listen on the host OS\u2019 port 80 and port 443, and bind them to the container\u2019s port 80 and port 443. Each device needs a name, so I\u2019ve chosen \u201cmyproxy80\u201d, and \u201cmyproxy443\u201d. The \u201clisten\u201d option is the port on the host OS, and if I\u2019m not mistaken, 0.0.0.0 is the IP address for the host on the \u201clxdbr0\u201d bridge. The \u201cconnect\u201d option is the local IP address and ports being connected to. !!! Note Once these devices have been set up, you should reboot all the containers, just to be sure. These virtual device should ideally be unique. It's usually best not to add a \u201cmyport80\u201d device to another container that's currently running; it\u2019ll have to be called something else. Likewise, only one container can listen on any specific host OS port at a time.","title":"Essential Step: Configuring the \u201cproxy-server\u201d Container to Take all Incoming Server Traffic"},{"location":"guides/containers/lxd_web_servers/#directing-traffic-to-the-apache-server","text":"In the \"proxy-server\" container, create a configuration file called apache-server.conf in /etc/nginx/conf.d/ : nano /etc/nginx/conf.d/apache-server.conf Then paste this test in, change the domain name as necessary, and save it: upstream apache-server { server apache-server.lxd:80; } server { listen 80 proxy_protocol; listen [::]:80 proxy_protocol; server_name apache.server.test; #< Your domain goes here location / { proxy_pass http://apache-server; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } Let's break that down a little: The upstream section is defining exactly where the reverse proxy is going to send all its traffic. Specifically, it's sending traffic to the \"apache-server\" container's internal domain name: apache-server.lxd . The two lines that start with listen are telling the server to listen to traffic coming in on port 80 with the proxy protocol. The first via IPv4, and the second via IPv6. The server_name function takes all the traffic that's specifically coming to \"apache.server.test\" and routes it through the reverse proxy. The proxy-pass function is the part that actually directs all traffic captured by the server_name variable, and sends it to the server defined in the upstream section. The proxy_redirect function can apparently interfere with reverse proxies, so we're making sure it's turned off. All of the proxy-set-header options are sending information like the user's IP and more to the web server. !!! warning The `proxy_protocol` bit in the `listen` variables is *essential* for the proxy server to work. Never leave it out. For every LXD/website configuration file, you'll need to change the upstream , server , server_name , and proxy_pass settings accordingly. The text after \"http://\" in proxy-pass must match the txt that comes after the upstream text. Reload the server with systemctl restart nginx , then point your browser at whatever domain you're using instead of apache.server.test . If you see a page that looks like this, you're golden: !!! Note You can name the config files whatever you like. I'm using simplified names for the tutorials, but some sysadmins recommend names based on the actual domain, but backwards. It's an alphabetical order-based organization thing. eg. \"apache.server.test\" would get a configuration file named `test.server.apache.conf`.","title":"Directing traffic to the Apache server"},{"location":"guides/containers/lxd_web_servers/#directing-traffic-to-the-nginx-server","text":"Just kinda repeat the process. Create a file just like before: nano /etc/nginx/conf.d/nginx-server.conf Add the approriate text: upstream nginx-server { server rocky-nginx.lxd:80; } server { listen 80 proxy_protocol; listen [::]:80 proxy_protocol; server_name nginx.server.test; #< Your domain goes here location / { proxy_pass http://nginx-server; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } Again, reload the proxy server, point your browser at the appropriate address, and hope to whatever deity your prefer that you see this:","title":"Directing traffic to the Nginx server"},{"location":"guides/containers/lxd_web_servers/#restart-the-servers-in-your-web-server-containers","text":"Exit back out of the \"proxy-server\" container, and restart the servers in your other two containers with one simple command: lxc exec apache-server systemctl restart httpd && lxc exec nginx-server restart nginx That will apply the \"real-ip.conf\" files we made to their respective server configurations.","title":"Restart the servers in your web server containers"},{"location":"guides/containers/lxd_web_servers/#getting-ssl-certificates-for-your-websites","text":"Getting official, proper SSL certificates is easiest with Let's Encrypt, and a little application called certbot. certbot will automatically detect your websites, get SSL certificates for them, and configure the sites itself. It will even renew the certificates for you every 30 days or so, without any intervention from you or cron jobs. This all has to be done from the \"proxy-server\" container, so log into that shell. Once there, install the EPEL repositories, just like you did on the host. Make sure the container is updated first: dnf update Then, add the EPEL repository: dnf install epel-release Then you just need to install certbot and its Nginx module: dnf install certbot python3-certbot-nginx Once installed, as long as you already have a couple of websites configured, just run: certbot --nginx Certbot will read your Nginx configuration, and figure out how many websites you have and if they need SSL certificates. At this point, you'll be asked a few questions. Do you accept the terms of service, do you want emails, etc? The most important questions are as follows. Enter your email address when you see this: Saving debug log to /var/log/letsencrypt/letsencrypt.log Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): Here you can choose which websites get certificates. Just hit enter to get certificates for all of them. Which names would you like to activate HTTPS for? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1: apache.server.test 2: nginx.server.test - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Select the appropriate numbers separated by commas and/or spaces, or leave input blank to select all options shown (Enter 'c' to cancel): You'll see a bunch of confirmation text, and it'll be done. But if you go to your websites, you might find that they don't work. This is because when certbot creates the updated configuration, it forgets one very important thing. Go into your apache-server.conf and nginx-server.conf files, and find the following two lines: listen [::]:443 ssl ipv6only=on; # managed by Certbot listen 443 ssl; # managed by Certbot Yep, they're missing the proxy_protocol setting, and that's bad. Add it in yourself. listen proxy_protocol [::]:443 ssl ipv6only=on; # managed by Certbot listen proxy_protocol 443 ssl; # managed by Certbot Save the file, restart the server, and your websites should load without any issue.","title":"Getting SSL certificates for your websites"},{"location":"guides/containers/lxd_web_servers/#notes","text":"In this tutorial, I didn't mention configuring the actual web servers much. The very least you should do, in production, is change the domains names in the server config files in your actual web server containers, and not just the proxy container. And maybe set up a web server user in each. If you want to know a bit more about managing SSL certificates and SSL server configurations manually, check out our guide to installing certbot and generating SSL certificates . Apps like Nextcloud will require some extra configuration (for security reasons) if you put them in an LXD container behind a proxy.","title":"Notes"},{"location":"guides/containers/lxd_web_servers/#conclusion","text":"There's a lot more to learn about LXC/LXD, containerization, web servers, and running websites, but that should honestly give you a good start. Once you learn how everything should be set up, and how to configure things the way you like, you can even begin to automate the process. You might use Ansible, or you might be like me, and just have a custom-written set of scripts that you run to make everything go faster. You can even create small \"template containers\" with all of your favorite software preinstalled, then just copy them and expand their storage capacity as needed. Okay. This is done. I'm off to play video games. Have fun!","title":"Conclusion"},{"location":"guides/containers/podman-nextcloud/","tags":["podman","containers","nextcloud"],"text":"Running Nextcloud as a Podman Container on Rocky Linux Introduction This document explains all the required steps needed to build and run a Nextcloud instance as a Podman container on Rocky Linux. What's more, this entire guide was tested on a Raspberry Pi, so it should be compatible with every Rocky-supported processor architecture. The procedure is broken down into multiple steps, each with its own shell scripts for automation: Installing the podman and buildah packages to manage and build our containers, respectively Creating a base image which will be repurposed for all of the containers we'll need Creating a db-tools container image with the required shell scripts for building and running your MariaDB database Creating and running MariaDB as a Podman container Creating and running Nextcloud as a Podman container, using the MariaDB Podman container as backend You could run most of the commands in the guide manually, but setting up a few bash scripts will make your life a lot easier, especially when you want to repeat these steps with different settings, variables, or container names. !!! Note \"Note for Beginners:\" Podman is tool for managing containers, specifically OCI (Open Containers Initiative) containers. It's designed to be pretty much Docker-compatible, in that most if not all of the same commands will work for both tools. If \"Docker\" means nothing to you\u2014or even if you're just curious\u2014you can read more about Podman and how it works on [Podman's own website](https://podman.io). `buildah` is a tool that builds Podman container images based on \"DockerFiles\". This guide was designed as an exercise to help people get familair with running Podman containers in general, and on Rocky Linux specifically. Prerequisites and Assumptions Here's everything you'll need, or need to know, in order to make this guide work: Familiarity with the command line, bash scripts, and editing Linux configuration files. SSH access if working on a remote machine. A command-line based text editor of your choice. We'll be using vi for this guide. An internet-connected Rocky Linux machine (again, a Raspberry Pi will work nicely). Many of these commands must be run as root, so you'll need a root or sudo-capable user on the machine. Familiarity with web servers and MariaDB would definitely help. Familiarity with containers and maybe Docker would be a definite plus, but is not strictly essential. Step 01: Install podman and buildah First, make sure your system is up-to-date: dnf update Then you'll want to install the epel-release repository for all the extra packages we'll be using. dnf -y install epel-release Once that's done, you can update again (which sometimes helps) or just go ahead and install the packages we need: dnf -y install podman buildah Once they're installed, run podman --version and buildah --version to make sure everything is working correctly. To access Red Hat's registry for downloading container images, you'll need to run: vi /etc/containers/registries.conf Find the section that looks like what you see below. If it's commented out, uncomment it. [registries.insecure] registries = ['registry.access.redhat.com', 'registry.redhat.io', 'docker.io'] insecure = true Step 02: Create the base Container Image In this guide, we're working as the root user, but you can do this in any home directory. Change to the root directory if you're not already there: cd /root Now make all of the directories you'll need for your various container builds: mkdir base db-tools mariadb nextcloud Now change your working directory to the folder for the base image: cd /root/base And make a file called DockerFile. Yes, Podman uses them too. vi Dockerfile Copy and paste the following text into your brand new DockerFile. FROM rockylinux/rockylinux:latest ENV container docker RUN yum -y install epel-release ; yum -y update RUN dnf module enable -y php:7.4 RUN dnf install -y php RUN yum install -y bzip2 unzip lsof wget traceroute nmap tcpdump bridge-utils ; yum -y update RUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == \\ systemd-tmpfiles-setup.service ] || rm -f $i; done); \\ rm -f /lib/systemd/system/multi-user.target.wants/*;\\ rm -f /etc/systemd/system/*.wants/*;\\ rm -f /lib/systemd/system/local-fs.target.wants/*; \\ rm -f /lib/systemd/system/sockets.target.wants/*udev*; \\ rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \\ rm -f /lib/systemd/system/basic.target.wants/*;\\ rm -f /lib/systemd/system/anaconda.target.wants/*; VOLUME [ \"/sys/fs/cgroup\" ] CMD [\"/usr/sbin/init\"] Save and close the previous file, and make a new bash script file: vi build.sh Then paste in this content: #!/bin/bash clear buildah rmi `buildah images -q base` ; buildah bud --no-cache -t base . ; buildah images -a Now make your build script executable with: chmod +x build.sh And run it: ./build.sh Wait until it's done, and move on to the next step. Step 03: Create the db-tools Container Image For the purposes of this guide, we're keeping the database setup as simple as we can. You'll want to keep track of the following, and modify them as needed: Database name: ncdb Database user: nc-user Database pass: nc-pass Your server IP address (we'll be using an example IP below) First, change to the folder where you'll be building the db-tools image: cd /root/db-tools Now set up some bash scripts that will be used inside the Podman container image. First, make the script that will automatically build your database for you: vi db-create.sh Now copy and paste the following code into that file, using your favorite text editor: #!/bin/bash mysql -h 10.1.1.160 -u root -p rockylinux << eof create database ncdb; grant all on ncdb.* to 'nc-user'@'10.1.1.160' identified by 'nc-pass'; flush privileges; eof Save and close, then repeat the steps with the script for deleting databases as needed: vi db-delete.sh Copy and paste this code into the new file: #!/bin/bash mysql -h 10.1.1.160 -u root -p rockylinux << eof drop database ncdb; flush privileges; eof Lastly, let's setup the DockerFile for the db-tools image: vi Dockerfile Copy and paste: FROM localhost/base RUN yum -y install mysql WORKDIR /root COPY db-drop.sh db-drop.sh COPY db-create.sh db-create.sh And last but not least, create the bash script to build your image on command: vi build.sh The code you'll want: #!/bin/bash clear buildah rmi `buildah images -q db-tools` ; buildah bud --no-cache -t db-tools . ; buildah images -a Save and close, then make the file executable: chmod +x build.sh And run it: ./build.sh Step 04: Create the MariaDB container image You're getting the hang of the process, right? It's time to build that actual database container. Change the working directory to /root/mariadb : cd /root/mariadb Make a script to (re)build the container whenever you want: vi db-init.sh And here's the code you'll need: !!! warning For the purposes of this guide, the following script will deleted all Podman Volumes. If you have other applications running with their own volumes, modify/comment the line \"podman volume rm --all\"; #!/bin/bash clear echo \" \" echo \"Deleting existing volumes if any....\" podman volume rm --all ; echo \" \" echo \"Starting mariadb container.....\" podman run --name mariadb --label mariadb -d --net host -e MYSQL_ROOT_PASSWORD=rockylinux -v /sys/fs/cgroup:/sys/fs/cgroup:ro -v mariadb-data:/var/lib/mysql/data:Z mariadb ; echo \" \" echo \"Initializing mariadb (takes 2 minutes).....\" sleep 120 ; echo \" \" echo \"Creating ncdb Database for nextcloud .....\" podman run --rm --net host db-tools /root/db-create.sh ; echo \" \" echo \"Listing podman volumes....\" podman volume ls Here's where you make a script to reset your database whenever you like: vi db-reset.sh And here's the code: #!/bin/bash clear echo \" \" echo \"Deleting ncdb Database for nextcloud .....\" podman run --rm --net host db-tools /root/db-drop.sh ; echo \" \" echo \"Creating ncdb Database for nextcloud .....\" podman run --rm --net host db-tools /root/db-create.sh ; And lastly, here's your build script that'll put the whole mariadb container together: vi build.sh With its code: #!/bin/bash clear buildah rmi `buildah images -q mariadb` ; buildah bud --no-cache -t mariadb . ; buildah images -a Now just make your DockferFile ( vi Dockerfile ), and paste in the following single line: FROM arm64v8/mariadb Now make your build script executable and run it: chmod +x *.sh ./build.sh Step 05: Build and Run the Nextcloud Container We're at the final step, and the process pretty much repeats itself. Change to the Nextcloud image directory: cd /root/nextcloud Set up your DockerFile first this time, for variety: vi Dockerfile !!! note This next bit assumes ARM architexture (for the Raspberry Pi), so if you are using another architexture, remember to change this. And paste in this bit: FROM arm64v8/nextcloud Npw create your build script: vi build.sh And paste in this code: #!/bin/bash clear buildah rmi `buildah images -q nextcloud` ; buildah bud --no-cache -t nextcloud . ; buildah images -a Now, we're going to set up a bunch of local folders on the host server ( not in any Podman container), so that we can rebuild our containers and databases without fear of losing all of our files: mkdir -p /usr/local/nc/nextcloud /usr/local/nc/apps /usr/local/nc/config /usr/local/nc/data Lastly, we're going to create the script that will actually build the Nextcloud container for us: vi run.sh And here's all the code you need for that. Make sure you change the IP address for MYSQL_HOST to the docker container that's running your MariaDB instance. #!/bin/bash clear echo \" \" echo \"Starting nextloud container.....\" podman run --name nextcloud --net host --privileged -d -p 80:80 \\ -e MYSQL_HOST=10.1.1.160 \\ -e MYSQL_DATABASE=ncdb \\ -e MYSQL_USER=nc-user \\ -e MYSQL_PASSWORD=nc-pass \\ -e NEXTCLOUD_ADMIN_USER=admin \\ -e NEXTCLOUD_ADMIN_PASSWORD=rockylinux \\ -e NEXTCLOUD_DATA_DIR=/var/www/html/data \\ -e NEXTCLOUD_TRUSTED_DOMAINS=10.1.1.160 \\ -v /sys/fs/cgroup:/sys/fs/cgroup:ro \\ -v /usr/local/nc/nextcloud:/var/www/html \\ -v /usr/local/nc/apps:/var/www/html/custom_apps \\ -v /usr/local/nc/config:/var/www/html/config \\ -v /usr/local/nc/data:/var/www/html/data \\ nextcloud ; Save and close that out,, make all of your scripts executable, then run the image building script first: chmod +x *.sh ./build.sh To make sure all of your images have been built correctly, run podman images . You should see a list that looks like this: REPOSITORY TAG IMAGE ID CREATED SIZE localhost/db-tools latest 8f7ccb04ecab 6 days ago 557 MB localhost/base latest 03ae68ad2271 6 days ago 465 MB docker.io/arm64v8/mariadb latest 89a126188478 11 days ago 405 MB docker.io/arm64v8/nextcloud latest 579a44c1dc98 3 weeks ago 945 MB If it all looks right, run the final script to get Nextcloud up and going: ./run.sh When you run podman ps -a , you should see a list of running containers that looks like this: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9518756a259a docker.io/arm64v8/mariadb:latest mariadbd 3 minutes ago Up 3 minutes ago mariadb 32534e5a5890 docker.io/arm64v8/nextcloud:latest apache2-foregroun... 12 seconds ago Up 12 seconds ago nextcloud From there, you should be able to point your browser to your server IP address (eg. http://10.1.1.160), and see Nextcloud up and running. Conclusion Obviously, this guide would have to be somewhat modified on a production server, especially if the Nextcloud instance is intended to be public-facing. Still, that should give you a basic idea of how Podman works, and how you can set it up with scripts and multiple base images to make rebuilds easier.","title":"Nextcloud on Podman"},{"location":"guides/containers/podman-nextcloud/#running-nextcloud-as-a-podman-container-on-rocky-linux","text":"","title":"Running Nextcloud as a Podman Container on Rocky Linux"},{"location":"guides/containers/podman-nextcloud/#introduction","text":"This document explains all the required steps needed to build and run a Nextcloud instance as a Podman container on Rocky Linux. What's more, this entire guide was tested on a Raspberry Pi, so it should be compatible with every Rocky-supported processor architecture. The procedure is broken down into multiple steps, each with its own shell scripts for automation: Installing the podman and buildah packages to manage and build our containers, respectively Creating a base image which will be repurposed for all of the containers we'll need Creating a db-tools container image with the required shell scripts for building and running your MariaDB database Creating and running MariaDB as a Podman container Creating and running Nextcloud as a Podman container, using the MariaDB Podman container as backend You could run most of the commands in the guide manually, but setting up a few bash scripts will make your life a lot easier, especially when you want to repeat these steps with different settings, variables, or container names. !!! Note \"Note for Beginners:\" Podman is tool for managing containers, specifically OCI (Open Containers Initiative) containers. It's designed to be pretty much Docker-compatible, in that most if not all of the same commands will work for both tools. If \"Docker\" means nothing to you\u2014or even if you're just curious\u2014you can read more about Podman and how it works on [Podman's own website](https://podman.io). `buildah` is a tool that builds Podman container images based on \"DockerFiles\". This guide was designed as an exercise to help people get familair with running Podman containers in general, and on Rocky Linux specifically.","title":"Introduction"},{"location":"guides/containers/podman-nextcloud/#prerequisites-and-assumptions","text":"Here's everything you'll need, or need to know, in order to make this guide work: Familiarity with the command line, bash scripts, and editing Linux configuration files. SSH access if working on a remote machine. A command-line based text editor of your choice. We'll be using vi for this guide. An internet-connected Rocky Linux machine (again, a Raspberry Pi will work nicely). Many of these commands must be run as root, so you'll need a root or sudo-capable user on the machine. Familiarity with web servers and MariaDB would definitely help. Familiarity with containers and maybe Docker would be a definite plus, but is not strictly essential.","title":"Prerequisites and Assumptions"},{"location":"guides/containers/podman-nextcloud/#step-01-install-podman-and-buildah","text":"First, make sure your system is up-to-date: dnf update Then you'll want to install the epel-release repository for all the extra packages we'll be using. dnf -y install epel-release Once that's done, you can update again (which sometimes helps) or just go ahead and install the packages we need: dnf -y install podman buildah Once they're installed, run podman --version and buildah --version to make sure everything is working correctly. To access Red Hat's registry for downloading container images, you'll need to run: vi /etc/containers/registries.conf Find the section that looks like what you see below. If it's commented out, uncomment it. [registries.insecure] registries = ['registry.access.redhat.com', 'registry.redhat.io', 'docker.io'] insecure = true","title":"Step 01: Install podman and buildah"},{"location":"guides/containers/podman-nextcloud/#step-02-create-the-base-container-image","text":"In this guide, we're working as the root user, but you can do this in any home directory. Change to the root directory if you're not already there: cd /root Now make all of the directories you'll need for your various container builds: mkdir base db-tools mariadb nextcloud Now change your working directory to the folder for the base image: cd /root/base And make a file called DockerFile. Yes, Podman uses them too. vi Dockerfile Copy and paste the following text into your brand new DockerFile. FROM rockylinux/rockylinux:latest ENV container docker RUN yum -y install epel-release ; yum -y update RUN dnf module enable -y php:7.4 RUN dnf install -y php RUN yum install -y bzip2 unzip lsof wget traceroute nmap tcpdump bridge-utils ; yum -y update RUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == \\ systemd-tmpfiles-setup.service ] || rm -f $i; done); \\ rm -f /lib/systemd/system/multi-user.target.wants/*;\\ rm -f /etc/systemd/system/*.wants/*;\\ rm -f /lib/systemd/system/local-fs.target.wants/*; \\ rm -f /lib/systemd/system/sockets.target.wants/*udev*; \\ rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \\ rm -f /lib/systemd/system/basic.target.wants/*;\\ rm -f /lib/systemd/system/anaconda.target.wants/*; VOLUME [ \"/sys/fs/cgroup\" ] CMD [\"/usr/sbin/init\"] Save and close the previous file, and make a new bash script file: vi build.sh Then paste in this content: #!/bin/bash clear buildah rmi `buildah images -q base` ; buildah bud --no-cache -t base . ; buildah images -a Now make your build script executable with: chmod +x build.sh And run it: ./build.sh Wait until it's done, and move on to the next step.","title":"Step 02: Create the base Container Image"},{"location":"guides/containers/podman-nextcloud/#step-03-create-the-db-tools-container-image","text":"For the purposes of this guide, we're keeping the database setup as simple as we can. You'll want to keep track of the following, and modify them as needed: Database name: ncdb Database user: nc-user Database pass: nc-pass Your server IP address (we'll be using an example IP below) First, change to the folder where you'll be building the db-tools image: cd /root/db-tools Now set up some bash scripts that will be used inside the Podman container image. First, make the script that will automatically build your database for you: vi db-create.sh Now copy and paste the following code into that file, using your favorite text editor: #!/bin/bash mysql -h 10.1.1.160 -u root -p rockylinux << eof create database ncdb; grant all on ncdb.* to 'nc-user'@'10.1.1.160' identified by 'nc-pass'; flush privileges; eof Save and close, then repeat the steps with the script for deleting databases as needed: vi db-delete.sh Copy and paste this code into the new file: #!/bin/bash mysql -h 10.1.1.160 -u root -p rockylinux << eof drop database ncdb; flush privileges; eof Lastly, let's setup the DockerFile for the db-tools image: vi Dockerfile Copy and paste: FROM localhost/base RUN yum -y install mysql WORKDIR /root COPY db-drop.sh db-drop.sh COPY db-create.sh db-create.sh And last but not least, create the bash script to build your image on command: vi build.sh The code you'll want: #!/bin/bash clear buildah rmi `buildah images -q db-tools` ; buildah bud --no-cache -t db-tools . ; buildah images -a Save and close, then make the file executable: chmod +x build.sh And run it: ./build.sh","title":"Step 03: Create the db-tools Container Image"},{"location":"guides/containers/podman-nextcloud/#step-04-create-the-mariadb-container-image","text":"You're getting the hang of the process, right? It's time to build that actual database container. Change the working directory to /root/mariadb : cd /root/mariadb Make a script to (re)build the container whenever you want: vi db-init.sh And here's the code you'll need: !!! warning For the purposes of this guide, the following script will deleted all Podman Volumes. If you have other applications running with their own volumes, modify/comment the line \"podman volume rm --all\"; #!/bin/bash clear echo \" \" echo \"Deleting existing volumes if any....\" podman volume rm --all ; echo \" \" echo \"Starting mariadb container.....\" podman run --name mariadb --label mariadb -d --net host -e MYSQL_ROOT_PASSWORD=rockylinux -v /sys/fs/cgroup:/sys/fs/cgroup:ro -v mariadb-data:/var/lib/mysql/data:Z mariadb ; echo \" \" echo \"Initializing mariadb (takes 2 minutes).....\" sleep 120 ; echo \" \" echo \"Creating ncdb Database for nextcloud .....\" podman run --rm --net host db-tools /root/db-create.sh ; echo \" \" echo \"Listing podman volumes....\" podman volume ls Here's where you make a script to reset your database whenever you like: vi db-reset.sh And here's the code: #!/bin/bash clear echo \" \" echo \"Deleting ncdb Database for nextcloud .....\" podman run --rm --net host db-tools /root/db-drop.sh ; echo \" \" echo \"Creating ncdb Database for nextcloud .....\" podman run --rm --net host db-tools /root/db-create.sh ; And lastly, here's your build script that'll put the whole mariadb container together: vi build.sh With its code: #!/bin/bash clear buildah rmi `buildah images -q mariadb` ; buildah bud --no-cache -t mariadb . ; buildah images -a Now just make your DockferFile ( vi Dockerfile ), and paste in the following single line: FROM arm64v8/mariadb Now make your build script executable and run it: chmod +x *.sh ./build.sh","title":"Step 04: Create the MariaDB container image"},{"location":"guides/containers/podman-nextcloud/#step-05-build-and-run-the-nextcloud-container","text":"We're at the final step, and the process pretty much repeats itself. Change to the Nextcloud image directory: cd /root/nextcloud Set up your DockerFile first this time, for variety: vi Dockerfile !!! note This next bit assumes ARM architexture (for the Raspberry Pi), so if you are using another architexture, remember to change this. And paste in this bit: FROM arm64v8/nextcloud Npw create your build script: vi build.sh And paste in this code: #!/bin/bash clear buildah rmi `buildah images -q nextcloud` ; buildah bud --no-cache -t nextcloud . ; buildah images -a Now, we're going to set up a bunch of local folders on the host server ( not in any Podman container), so that we can rebuild our containers and databases without fear of losing all of our files: mkdir -p /usr/local/nc/nextcloud /usr/local/nc/apps /usr/local/nc/config /usr/local/nc/data Lastly, we're going to create the script that will actually build the Nextcloud container for us: vi run.sh And here's all the code you need for that. Make sure you change the IP address for MYSQL_HOST to the docker container that's running your MariaDB instance. #!/bin/bash clear echo \" \" echo \"Starting nextloud container.....\" podman run --name nextcloud --net host --privileged -d -p 80:80 \\ -e MYSQL_HOST=10.1.1.160 \\ -e MYSQL_DATABASE=ncdb \\ -e MYSQL_USER=nc-user \\ -e MYSQL_PASSWORD=nc-pass \\ -e NEXTCLOUD_ADMIN_USER=admin \\ -e NEXTCLOUD_ADMIN_PASSWORD=rockylinux \\ -e NEXTCLOUD_DATA_DIR=/var/www/html/data \\ -e NEXTCLOUD_TRUSTED_DOMAINS=10.1.1.160 \\ -v /sys/fs/cgroup:/sys/fs/cgroup:ro \\ -v /usr/local/nc/nextcloud:/var/www/html \\ -v /usr/local/nc/apps:/var/www/html/custom_apps \\ -v /usr/local/nc/config:/var/www/html/config \\ -v /usr/local/nc/data:/var/www/html/data \\ nextcloud ; Save and close that out,, make all of your scripts executable, then run the image building script first: chmod +x *.sh ./build.sh To make sure all of your images have been built correctly, run podman images . You should see a list that looks like this: REPOSITORY TAG IMAGE ID CREATED SIZE localhost/db-tools latest 8f7ccb04ecab 6 days ago 557 MB localhost/base latest 03ae68ad2271 6 days ago 465 MB docker.io/arm64v8/mariadb latest 89a126188478 11 days ago 405 MB docker.io/arm64v8/nextcloud latest 579a44c1dc98 3 weeks ago 945 MB If it all looks right, run the final script to get Nextcloud up and going: ./run.sh When you run podman ps -a , you should see a list of running containers that looks like this: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9518756a259a docker.io/arm64v8/mariadb:latest mariadbd 3 minutes ago Up 3 minutes ago mariadb 32534e5a5890 docker.io/arm64v8/nextcloud:latest apache2-foregroun... 12 seconds ago Up 12 seconds ago nextcloud From there, you should be able to point your browser to your server IP address (eg. http://10.1.1.160), and see Nextcloud up and running.","title":"Step 05: Build and Run the Nextcloud Container"},{"location":"guides/containers/podman-nextcloud/#conclusion","text":"Obviously, this guide would have to be somewhat modified on a production server, especially if the Nextcloud instance is intended to be public-facing. Still, that should give you a basic idea of how Podman works, and how you can set it up with scripts and multiple base images to make rebuilds easier.","title":"Conclusion"},{"location":"guides/contribute/","text":"../../../README.md","title":"Index"},{"location":"guides/contribute/README.fr/","text":"../../../README.md","title":"README.fr"},{"location":"guides/contribute/mkdocs_lsyncd/","tags":["contribute","local envirmonent lxd"],"text":"Introduction There are several ways to run a copy of mkdocs so that you can see exactly how your Rocky Linux document will appear when it is merged on the live system. This particular document deals with using an LXD container on your local workstation to separate python code in mkdocs from other projects you might be working on. It is recommended to keep projects separate to avoid causing problems with your workstation's code. This is also a partner document to the Docker version here . Prerequisites and Assumptions A few things you should have/know/be: Familiarity and comfort with the command-line Comfortable using tools for editing, SSH, and synchronization, or willing to follow along and learn We will reference LXD - there's a long document on building and using LXD on a server here , but we will be using just a basic install on our Linux workstation. This document assumes that you are already using LXD for other things, and does not cover the build and initialization of LXD. We will be using lsyncd for mirroring files, and you can find documentation on that here You will need public keys generated for your user and the \"root\" user on your local workstation using this document Our bridge interface is running on 10.56.233.1 and our container is running on 10.56.233.189 in our examples below. \"youruser\" in this document represents your user id, so substitute in your own. We are assuming that you are already doing documentation development with a clone of the documentation repository on your workstation. The mkdocs container Create the Container Our first step is to create the LXD container. There's no need to use anything other than defaults here, so allow your container to be built using the bridge interface. We will add a Rocky container to our workstation for mkdocs , so we are just calling it \"mkdocs\": lxc launch images:rockylinux/8 mkdocs The container needs to be set up with a proxy. By default, when mkdocs serve is started, it runs on 127.0.0.1:8000. That's fine when it is on your local workstation without a container. However, when it is in an LXD container on your local workstation, you need to set up the container with a proxy port. This is done with: lxc config device add mkdocs mkdocsport proxy listen=tcp:0.0.0.0:8000 connect=tcp:127.0.0.1:8000 In the line above, \"mkdocs\" is our container name, \"mkdocsport\" is an arbitrary name we are giving to the proxy port, the type is \"proxy\", and then we are listening on all tcp interfaces on port 8000 and connecting to the localhost for that container on port 8000. !!! Note If you're running the lxd instance on another machine in your network, remember to make sure that port 8000 is open in the firewall. Installing Packages First, get into the container with: lxc exec mkdocs bash !!! important \"Changes in requirements.txt for 8.x\" The current `requirements.txt` will require a newer version of Python than what is installed by default in Rocky Linux 8.5 or 8.6. To be able to install all the other dependencies, do the following: ``` sudo dnf module enable python38 sudo dnf install python38 ``` You can then skip installing `python3-pip` in the packages found below. We will need a few packages to accomplish what we need to do: dnf install git openssh-server python3-pip rsync Once installed, we need to enable and start sshd : systemctl enable --now sshd Container Users We need to set a password for our root user, and then add our own user (the user that you use on your local machine) and add it to the sudoers list. We should be the \"root\" user at the moment, so to change the password type: passwd And set the password to something secure and memorable. Next, add your user and set a password: adduser youruser passwd youruser And add your user to the sudoers group: usermod -aG wheel youruser At this point, you should be able to SSH into the container using either the root user or your user from your workstation and entering a password. Make sure that you can do that before continuing. SSH for root and Your user In this procedure, the root user (at minimum) needs to be able to SSH into the container without entering a password; this is because of the lsyncd process we will be implementing. We are assuming here that you can sudo to the root user on your local workstation: sudo -s We are also assuming that the root user has an id_rsa.pub key in the ./ssh directory. If not, generate one using this procedure : ls -al .ssh/ drwx------ 2 root root 4096 Feb 25 08:06 . drwx------ 14 root root 4096 Feb 25 08:10 .. -rw------- 1 root root 2610 Feb 14 2021 id_rsa -rw-r--r-- 1 root root 572 Feb 14 2021 id_rsa.pub -rw-r--r-- 1 root root 222 Feb 25 08:06 known_hosts To get SSH access on our container without having to enter a password, as long as the id_rsa.pub key exists, like it does above, all we need to do is run: ssh-copy-id root@10.56.233.189 In the case of our user, however, we need the entire .ssh/ directory copied to our container. The reason is that we are going to be keeping everything identical for this user so that our access to GitHub over SSH is the same. To copy everything over to our container, we just need to do this as your user, not sudo: scp -r .ssh/ youruser@10.56.233.189:/home/youruser/ Next, SSH into the container as your user: ssh -l youruser 10.56.233.189 We need to make things identical, and this is done with ssh-add . To do this, though, we need to make sure that we have the ssh-agent available. Enter the following: eval \"$(ssh-agent)\" ssh-add Cloning repositories We need two repositories cloned, but there is no need to add any git remotes. The documentation repository here will only be used to display the current documentation (mirrored from your workstation) and the docs. The rockylinux.org repository will be used for running mkdocs serve and will use the mirror as it's source. All of these steps should be done as your non-root user. If you are not able to clone the repositories as your userid, then there IS a problem with your identity as far as git is concerned and you will need to review the last few steps for re-creating your key environment (above). First, clone the documentation: git clone git@github.com:rocky-linux/documentation.git Assuming that worked, then clone the docs.rockylinux.org: git clone git@github.com:rocky-linux/docs.rockylinux.org.git If everything worked as planned, then you can move on. Setting Up mkdocs Installing the needed plugins is all done with pip3 and the \"requirements.txt\" file in the docs.rockylinux.org directory. While this process will argue with you about using the root user for this, in order to write the changes to the system directories, you pretty much have to run it as root. We are doing this with sudo here. Change into the directory: cd docs.rockylinux.org Then run: sudo pip3 install -r requirements.txt Next we need to set up mkdocs with an additional directory. Right now, mkdocs requires a docs directory to be created and then the documentation/docs directory linked beneath it. All this is done with: mkdir docs cd docs ln -s ../../documentation/docs Testing mkdocs Now that we have mkdocs setup, let's try starting the server. Remember, this process is going to argue that it looks like this is production. It's not, so ignore the warning. Start mkdocs serve with: mkdocs serve -a 0.0.0.0:8000 You should see something like this in the console: INFO - Building documentation... WARNING - Config value: 'dev_addr'. Warning: The use of the IP address '0.0.0.0' suggests a production environment or the use of a proxy to connect to the MkDocs server. However, the MkDocs' server is intended for local development purposes only. Please use a third party production-ready server instead. INFO - Adding 'sv' to the 'plugins.search.lang' option INFO - Adding 'it' to the 'plugins.search.lang' option INFO - Adding 'es' to the 'plugins.search.lang' option INFO - Adding 'ja' to the 'plugins.search.lang' option INFO - Adding 'fr' to the 'plugins.search.lang' option INFO - Adding 'pt' to the 'plugins.search.lang' option WARNING - Language 'zh' is not supported by lunr.js, not setting it in the 'plugins.search.lang' option INFO - Adding 'de' to the 'plugins.search.lang' option INFO - Building en documentation INFO - Building de documentation INFO - Building fr documentation INFO - Building es documentation INFO - Building it documentation INFO - Building ja documentation INFO - Building zh documentation INFO - Building sv documentation INFO - Building pt documentation INFO - [14:12:56] Reloading browsers Now for the moment of truth! If you've done everything correctly above, you should be able to open a web browser and go to the IP of your container on port :8000, and see the documentation site. In our example, we would enter the following in the browser address: http://10.56.233.189:8000 lsyncd If you saw the documentation in the web browser, we are almost there. The last step is to keep the documentation that's in your container in synchronization with the one on your local workstation. We are doing this here with lsyncd as noted above. Depending on which Linux version you are using, lsyncd is installed differently. This document covers ways to install it on Rocky Linux, and also from source. If you are using some of the other Linux type (Ubuntu for example) they generally have their own packages, but there are nuances to them. Ubuntu's, for example, names the configuration file differently. Just be aware that if you are using another Linux workstation type other than Rocky Linux, and don't want to install from source, there are probably packages available for your platform. For now, we are assuming that you are using a Rocky Linux workstation and are using the RPM install method from the included document. Configuration !!! Note The root user must run the daemon, so you will need to be root to create the configuration files and logs. For this we are assuming sudo -s . We need to have some log files available for lsyncd to write to: touch /var/log/lsyncd-status.log touch /var/log/lsyncd.log We also need to have an exclude file created, even though in this case we are not excluding anything: touch /etc/lsyncd.exclude Finally we need to create the configuration file. In this example, we are using vi as our editor, but you may use whichever editor you feel comfortable with: vi /etc/lsyncd.conf And then place this content in that file and save it. Be sure to replace \"youruser\" with your actual user, and the IP address with your own container IP: settings { logfile = \"/var/log/lsyncd.log\", statusFile = \"/var/log/lsyncd-status.log\", statusInterval = 20, maxProcesses = 1 } sync { default.rsyncssh, source=\"/home/youruser/documentation\", host=\"root@10.56.233.189\", excludeFrom=\"/etc/lsyncd.exclude\", targetdir=\"/home/youruser/documentation\", rsync = { archive = true, compress = false, whole_file = false }, ssh = { port = 22 } } We are assuming that you enabled lsyncd when you installed it, so at this point we need to just start or restart the process: systemctl restart lsyncd To make sure things are working, check the logs-particularly the lsyncd.log , which should show you something like this if everything started correctly: Fri Feb 25 08:10:16 2022 Normal: --- Startup, daemonizing --- Fri Feb 25 08:10:16 2022 Normal: recursive startup rsync: /home/youruser/documentation/ -> root@10.56.233.189:/home/youruser/documentation/ Fri Feb 25 08:10:41 2022 Normal: Startup of \"/home/youruser/documentation/\" finished: 0 Fri Feb 25 08:15:14 2022 Normal: Calling rsync with filter-list of new/modified files/dirs Conclusion As you work on your workstation documentation now, whether it is a git pull or a branch you create to make a document (like this one!), you will see the changes appear in your documentation on the container, and mkdocs serve will show you the content in your web browser. It's recommended practice that all Python code should be run separate from any other Python code you might be developing. LXD containers can make that a lot easier; give this method a try and see if it works for you.","title":"Local Documentation - LXD"},{"location":"guides/contribute/mkdocs_lsyncd/#introduction","text":"There are several ways to run a copy of mkdocs so that you can see exactly how your Rocky Linux document will appear when it is merged on the live system. This particular document deals with using an LXD container on your local workstation to separate python code in mkdocs from other projects you might be working on. It is recommended to keep projects separate to avoid causing problems with your workstation's code. This is also a partner document to the Docker version here .","title":"Introduction"},{"location":"guides/contribute/mkdocs_lsyncd/#prerequisites-and-assumptions","text":"A few things you should have/know/be: Familiarity and comfort with the command-line Comfortable using tools for editing, SSH, and synchronization, or willing to follow along and learn We will reference LXD - there's a long document on building and using LXD on a server here , but we will be using just a basic install on our Linux workstation. This document assumes that you are already using LXD for other things, and does not cover the build and initialization of LXD. We will be using lsyncd for mirroring files, and you can find documentation on that here You will need public keys generated for your user and the \"root\" user on your local workstation using this document Our bridge interface is running on 10.56.233.1 and our container is running on 10.56.233.189 in our examples below. \"youruser\" in this document represents your user id, so substitute in your own. We are assuming that you are already doing documentation development with a clone of the documentation repository on your workstation.","title":"Prerequisites and Assumptions"},{"location":"guides/contribute/mkdocs_lsyncd/#the-mkdocs-container","text":"","title":"The mkdocs container"},{"location":"guides/contribute/mkdocs_lsyncd/#create-the-container","text":"Our first step is to create the LXD container. There's no need to use anything other than defaults here, so allow your container to be built using the bridge interface. We will add a Rocky container to our workstation for mkdocs , so we are just calling it \"mkdocs\": lxc launch images:rockylinux/8 mkdocs The container needs to be set up with a proxy. By default, when mkdocs serve is started, it runs on 127.0.0.1:8000. That's fine when it is on your local workstation without a container. However, when it is in an LXD container on your local workstation, you need to set up the container with a proxy port. This is done with: lxc config device add mkdocs mkdocsport proxy listen=tcp:0.0.0.0:8000 connect=tcp:127.0.0.1:8000 In the line above, \"mkdocs\" is our container name, \"mkdocsport\" is an arbitrary name we are giving to the proxy port, the type is \"proxy\", and then we are listening on all tcp interfaces on port 8000 and connecting to the localhost for that container on port 8000. !!! Note If you're running the lxd instance on another machine in your network, remember to make sure that port 8000 is open in the firewall.","title":"Create the Container"},{"location":"guides/contribute/mkdocs_lsyncd/#installing-packages","text":"First, get into the container with: lxc exec mkdocs bash !!! important \"Changes in requirements.txt for 8.x\" The current `requirements.txt` will require a newer version of Python than what is installed by default in Rocky Linux 8.5 or 8.6. To be able to install all the other dependencies, do the following: ``` sudo dnf module enable python38 sudo dnf install python38 ``` You can then skip installing `python3-pip` in the packages found below. We will need a few packages to accomplish what we need to do: dnf install git openssh-server python3-pip rsync Once installed, we need to enable and start sshd : systemctl enable --now sshd","title":"Installing Packages"},{"location":"guides/contribute/mkdocs_lsyncd/#container-users","text":"We need to set a password for our root user, and then add our own user (the user that you use on your local machine) and add it to the sudoers list. We should be the \"root\" user at the moment, so to change the password type: passwd And set the password to something secure and memorable. Next, add your user and set a password: adduser youruser passwd youruser And add your user to the sudoers group: usermod -aG wheel youruser At this point, you should be able to SSH into the container using either the root user or your user from your workstation and entering a password. Make sure that you can do that before continuing.","title":"Container Users"},{"location":"guides/contribute/mkdocs_lsyncd/#ssh-for-root-and-your-user","text":"In this procedure, the root user (at minimum) needs to be able to SSH into the container without entering a password; this is because of the lsyncd process we will be implementing. We are assuming here that you can sudo to the root user on your local workstation: sudo -s We are also assuming that the root user has an id_rsa.pub key in the ./ssh directory. If not, generate one using this procedure : ls -al .ssh/ drwx------ 2 root root 4096 Feb 25 08:06 . drwx------ 14 root root 4096 Feb 25 08:10 .. -rw------- 1 root root 2610 Feb 14 2021 id_rsa -rw-r--r-- 1 root root 572 Feb 14 2021 id_rsa.pub -rw-r--r-- 1 root root 222 Feb 25 08:06 known_hosts To get SSH access on our container without having to enter a password, as long as the id_rsa.pub key exists, like it does above, all we need to do is run: ssh-copy-id root@10.56.233.189 In the case of our user, however, we need the entire .ssh/ directory copied to our container. The reason is that we are going to be keeping everything identical for this user so that our access to GitHub over SSH is the same. To copy everything over to our container, we just need to do this as your user, not sudo: scp -r .ssh/ youruser@10.56.233.189:/home/youruser/ Next, SSH into the container as your user: ssh -l youruser 10.56.233.189 We need to make things identical, and this is done with ssh-add . To do this, though, we need to make sure that we have the ssh-agent available. Enter the following: eval \"$(ssh-agent)\" ssh-add","title":"SSH for root and Your user"},{"location":"guides/contribute/mkdocs_lsyncd/#cloning-repositories","text":"We need two repositories cloned, but there is no need to add any git remotes. The documentation repository here will only be used to display the current documentation (mirrored from your workstation) and the docs. The rockylinux.org repository will be used for running mkdocs serve and will use the mirror as it's source. All of these steps should be done as your non-root user. If you are not able to clone the repositories as your userid, then there IS a problem with your identity as far as git is concerned and you will need to review the last few steps for re-creating your key environment (above). First, clone the documentation: git clone git@github.com:rocky-linux/documentation.git Assuming that worked, then clone the docs.rockylinux.org: git clone git@github.com:rocky-linux/docs.rockylinux.org.git If everything worked as planned, then you can move on.","title":"Cloning repositories"},{"location":"guides/contribute/mkdocs_lsyncd/#setting-up-mkdocs","text":"Installing the needed plugins is all done with pip3 and the \"requirements.txt\" file in the docs.rockylinux.org directory. While this process will argue with you about using the root user for this, in order to write the changes to the system directories, you pretty much have to run it as root. We are doing this with sudo here. Change into the directory: cd docs.rockylinux.org Then run: sudo pip3 install -r requirements.txt Next we need to set up mkdocs with an additional directory. Right now, mkdocs requires a docs directory to be created and then the documentation/docs directory linked beneath it. All this is done with: mkdir docs cd docs ln -s ../../documentation/docs","title":"Setting Up mkdocs"},{"location":"guides/contribute/mkdocs_lsyncd/#testing-mkdocs","text":"Now that we have mkdocs setup, let's try starting the server. Remember, this process is going to argue that it looks like this is production. It's not, so ignore the warning. Start mkdocs serve with: mkdocs serve -a 0.0.0.0:8000 You should see something like this in the console: INFO - Building documentation... WARNING - Config value: 'dev_addr'. Warning: The use of the IP address '0.0.0.0' suggests a production environment or the use of a proxy to connect to the MkDocs server. However, the MkDocs' server is intended for local development purposes only. Please use a third party production-ready server instead. INFO - Adding 'sv' to the 'plugins.search.lang' option INFO - Adding 'it' to the 'plugins.search.lang' option INFO - Adding 'es' to the 'plugins.search.lang' option INFO - Adding 'ja' to the 'plugins.search.lang' option INFO - Adding 'fr' to the 'plugins.search.lang' option INFO - Adding 'pt' to the 'plugins.search.lang' option WARNING - Language 'zh' is not supported by lunr.js, not setting it in the 'plugins.search.lang' option INFO - Adding 'de' to the 'plugins.search.lang' option INFO - Building en documentation INFO - Building de documentation INFO - Building fr documentation INFO - Building es documentation INFO - Building it documentation INFO - Building ja documentation INFO - Building zh documentation INFO - Building sv documentation INFO - Building pt documentation INFO - [14:12:56] Reloading browsers Now for the moment of truth! If you've done everything correctly above, you should be able to open a web browser and go to the IP of your container on port :8000, and see the documentation site. In our example, we would enter the following in the browser address: http://10.56.233.189:8000","title":"Testing mkdocs"},{"location":"guides/contribute/mkdocs_lsyncd/#lsyncd","text":"If you saw the documentation in the web browser, we are almost there. The last step is to keep the documentation that's in your container in synchronization with the one on your local workstation. We are doing this here with lsyncd as noted above. Depending on which Linux version you are using, lsyncd is installed differently. This document covers ways to install it on Rocky Linux, and also from source. If you are using some of the other Linux type (Ubuntu for example) they generally have their own packages, but there are nuances to them. Ubuntu's, for example, names the configuration file differently. Just be aware that if you are using another Linux workstation type other than Rocky Linux, and don't want to install from source, there are probably packages available for your platform. For now, we are assuming that you are using a Rocky Linux workstation and are using the RPM install method from the included document.","title":"lsyncd"},{"location":"guides/contribute/mkdocs_lsyncd/#configuration","text":"!!! Note The root user must run the daemon, so you will need to be root to create the configuration files and logs. For this we are assuming sudo -s . We need to have some log files available for lsyncd to write to: touch /var/log/lsyncd-status.log touch /var/log/lsyncd.log We also need to have an exclude file created, even though in this case we are not excluding anything: touch /etc/lsyncd.exclude Finally we need to create the configuration file. In this example, we are using vi as our editor, but you may use whichever editor you feel comfortable with: vi /etc/lsyncd.conf And then place this content in that file and save it. Be sure to replace \"youruser\" with your actual user, and the IP address with your own container IP: settings { logfile = \"/var/log/lsyncd.log\", statusFile = \"/var/log/lsyncd-status.log\", statusInterval = 20, maxProcesses = 1 } sync { default.rsyncssh, source=\"/home/youruser/documentation\", host=\"root@10.56.233.189\", excludeFrom=\"/etc/lsyncd.exclude\", targetdir=\"/home/youruser/documentation\", rsync = { archive = true, compress = false, whole_file = false }, ssh = { port = 22 } } We are assuming that you enabled lsyncd when you installed it, so at this point we need to just start or restart the process: systemctl restart lsyncd To make sure things are working, check the logs-particularly the lsyncd.log , which should show you something like this if everything started correctly: Fri Feb 25 08:10:16 2022 Normal: --- Startup, daemonizing --- Fri Feb 25 08:10:16 2022 Normal: recursive startup rsync: /home/youruser/documentation/ -> root@10.56.233.189:/home/youruser/documentation/ Fri Feb 25 08:10:41 2022 Normal: Startup of \"/home/youruser/documentation/\" finished: 0 Fri Feb 25 08:15:14 2022 Normal: Calling rsync with filter-list of new/modified files/dirs","title":"Configuration"},{"location":"guides/contribute/mkdocs_lsyncd/#conclusion","text":"As you work on your workstation documentation now, whether it is a git pull or a branch you create to make a document (like this one!), you will see the changes appear in your documentation on the container, and mkdocs serve will show you the content in your web browser. It's recommended practice that all Python code should be run separate from any other Python code you might be developing. LXD containers can make that a lot easier; give this method a try and see if it works for you.","title":"Conclusion"},{"location":"guides/contribute/navigation/","tags":["contribute","navigation"],"text":"Navigational Changes - A Process Document for Managers/Editors Reason For This Document When the documentation project got started, it was hoped that menus in Mkdocs would be as automatic as possible, making manual editing of navigation rare. After a few months of generating documents, it became clear that just placing documents in the correct folder and letting Mkdocs generate the navigation could not be depended on to keep things clean and neat. We needed categories, something that Mkdocs does not provide unless the documents are placed in specific folders. Mkdocs will then create a navigation with an alphabetic sort. Creating a folder structure that fixes navigation isn't the entire picture however. Even that will sometimes need additional changes to keep things organized. For instance, capitalization without modifying the lower-case folder structure. Goals Our goals were: Create the folder structure as needed now (new folders may be required in the future). Adjust the navigation so that the the Rocky Installation, Migration, and Contribution areas were at the top. Adjust the navigation to better name some folders, and enable correct capitalization. As an example, \"DNS\" and \"File Sharing Services\", which otherwise show up as \"Dns\" and \"File sharing\" without some manipulation. Make sure that these navigation files are restricted to Managers and Editors. This last item may seem unnecessary to some reading this, but it will become clearer as this document continues. Assumptions It is assumed that you have a local clone of the Rocky GitHub repository: https://github.com/rocky-linux/documentation . Environment Changes With these changes comes a real need to \"see\" how any changes you are making affect content, in the context of the website, BEFORE that content is committed to the document repository, and subsequently goes 'live'. MkDocs is a Python application and the extra packages it uses are also Python code, this means that the environment required to run MkDocs needs to be a correctly configured Python environment . Setting up Python for development tasks (which is what is being done running MkDocs) is not a trivial task, and instructions for that are out of the scope of this document. Some considerations are: The version of Python, it should be >= 3.8, also particular care must be taken not to use the 'system' Python version of a computer if the computer runs Linux/macOS . For example, as of the writing of this document, the system version of Python on macOS is still version 2.7. Running a Python 'virtual environment'. When running Python application project and installing packages, for example MkDocs, it is strongly recommended by the Python community to create an isolated virtual environment for each project. Use a modern IDE (Integrated Development Environment) that supports Python well. Two popular IDEs, which also have integrated support for running virtual environments, are: PyCharm - (free version available) the leading IDE for Python https://www.jetbrains.com/pycharm/ Visual Studio Code- (free version available) from Microsoft https://code.visualstudio.com Doing this effectively requires: Setting up a new Python project which, ideally, uses a virtual environment (above). Installing mkdocs Installing some python plugins Cloning this Rocky GitHub repository: https://github.com/rocky-linux/docs.rockylinux.org Linking to the docs folder within your cloned documentation repository (you can also just modify the mkdocs.yml file if you wish to load the correct folder, but linking keeps your mkdocs environment cleaner) Running mkdocs serve within your clone of docs.rockylinux.org !!! Hint You can build totally separate environments for `mkdocs` by using either of these two procedures as well: * [Local Documentation - Docker](rockydocs_web_dev.md) * [Local Documentation - LXD](mkdocs_lsyncd.md) !!! Note This document was written in a Linux environment. If your environment is different (Windows or Mac), then you will need to do a little research on matching up to some of these steps. An editor or manager reading this can submit changes to it to add in steps for those environments. Installing Install mkdocs with the python environment: pip install mkdocs Install needed plugins: pip install mkdocs-material mkdocs-localsearch mkdocs-awesome-pages-plugin mkdocs-redirects mkdocs-i18n Clone the repository (noted above) Linking and Running mkdocs Inside your docs.rockylinux.org local (clone), do the following. This assumes the location of your documentation clone, so modify as needed: ln -s /home/username/documentation/docs docs Again, if you desire, you can modify the local copy of the mkdocs.yml file to set the path. If using this method, you would modify this line to point to your documentation/docs folder: docs_dir: 'docs/docs' Once completed, you can try running mkdocs serve to see if you get your desired content. This will run on a your localhost on port 8000 example: http://127.0.0.1:8000/ Navigation and Other Changes Navigation is handled with mkdocs .pages files. Are not terribly complex, BUT, if something is left out, it can cause the server to fail to load. That's why this procedure is ONLY for Managers and Editors. These individuals are going to have the tools in place (local install of mkdocs, plus clones of both documentation and docs.rockylinux.org) so that something pushed and merged to GitHub will not break the serving of the documentation website. A contributor cannot be expected to have even one of these requirements in place. .pages Files As already stated, the .pages files are generally pretty simple. They are a YAML formatted file that mkdocs reads before rendering the content. To take a look at one of the more complex .pages files, let's look at the one created to help format the side navigation: --- nav: - ... | index*.md - ... | installation*.md - ... | migrate2rocky*.md - Contribute: contribute - Automation: automation - Backup & Sync: backup - Content Management: cms - Communications: communications - Containers: containers - Database: database - Desktop: desktop - DNS: dns - Email: email - File Sharing Services: file_sharing - Git: git - Interoperability: interoperability - Mirror Management: mirror_management - Network: network - Package Management: package_management - ... Here, the index*md shows the \"Guides Home: \", installation*.md shows the \"Installing Rocky Linux\" document link, and the migrate2rocky*.md shows the \"Migrating To Rocky Linux\" document link. The \"*\" within each of these links allows for that document in any language. Finally, by placing \"Contribute\" next, it falls beneath these items rather than in the normal (alphabetic) sort order. If you look down the list, you can see what each item is doing. Note that after the \"Package Management: package_management\" entry, there are actually two more folders (security and web). These do not require any additional formatting, so we are just telling mkdocs to load them normally with the \"-...\" You can also use YAML formatting within an actual file. A reason for doing this might be that the beginning heading of the file is so long, that it just doesn't display well in the navigation section. As an example, take this document heading \"# mod_ssl on Rocky Linux in an httpd Apache Web-Server Environment\". That is very long. It displays very poorly in the side navigation once the \"Web\" navigation item is opened. To fix this, you can either work with the author to change his heading, or, you can change how it displays in the menu by adding a title before the heading inside the document. For the example document, there is a title added: --- title: Apache With `mod_ssl` --- This changes the title as far as the navigation is concerned, but leaves the author's original title in place within the document. There will probably not be a lot of need for additional .pages files. They should be used economically. Conclusion While the navigational changes that might need to be made are not difficult, the potential for breaking the live documentation exists. For this reason, only managers and editors with the appropriate tooling in place should have the permissions to edit these files. Having a full environment available to view what the live pages are going to look like, keeps the manager or editor from making a mistake while editing these files that also breaks the live documentation.","title":"Navigational Changes"},{"location":"guides/contribute/navigation/#navigational-changes-a-process-document-for-managerseditors","text":"","title":"Navigational Changes - A Process Document for Managers/Editors"},{"location":"guides/contribute/navigation/#reason-for-this-document","text":"When the documentation project got started, it was hoped that menus in Mkdocs would be as automatic as possible, making manual editing of navigation rare. After a few months of generating documents, it became clear that just placing documents in the correct folder and letting Mkdocs generate the navigation could not be depended on to keep things clean and neat. We needed categories, something that Mkdocs does not provide unless the documents are placed in specific folders. Mkdocs will then create a navigation with an alphabetic sort. Creating a folder structure that fixes navigation isn't the entire picture however. Even that will sometimes need additional changes to keep things organized. For instance, capitalization without modifying the lower-case folder structure.","title":"Reason For This Document"},{"location":"guides/contribute/navigation/#goals","text":"Our goals were: Create the folder structure as needed now (new folders may be required in the future). Adjust the navigation so that the the Rocky Installation, Migration, and Contribution areas were at the top. Adjust the navigation to better name some folders, and enable correct capitalization. As an example, \"DNS\" and \"File Sharing Services\", which otherwise show up as \"Dns\" and \"File sharing\" without some manipulation. Make sure that these navigation files are restricted to Managers and Editors. This last item may seem unnecessary to some reading this, but it will become clearer as this document continues.","title":"Goals"},{"location":"guides/contribute/navigation/#assumptions","text":"It is assumed that you have a local clone of the Rocky GitHub repository: https://github.com/rocky-linux/documentation .","title":"Assumptions"},{"location":"guides/contribute/navigation/#environment-changes","text":"With these changes comes a real need to \"see\" how any changes you are making affect content, in the context of the website, BEFORE that content is committed to the document repository, and subsequently goes 'live'. MkDocs is a Python application and the extra packages it uses are also Python code, this means that the environment required to run MkDocs needs to be a correctly configured Python environment . Setting up Python for development tasks (which is what is being done running MkDocs) is not a trivial task, and instructions for that are out of the scope of this document. Some considerations are: The version of Python, it should be >= 3.8, also particular care must be taken not to use the 'system' Python version of a computer if the computer runs Linux/macOS . For example, as of the writing of this document, the system version of Python on macOS is still version 2.7. Running a Python 'virtual environment'. When running Python application project and installing packages, for example MkDocs, it is strongly recommended by the Python community to create an isolated virtual environment for each project. Use a modern IDE (Integrated Development Environment) that supports Python well. Two popular IDEs, which also have integrated support for running virtual environments, are: PyCharm - (free version available) the leading IDE for Python https://www.jetbrains.com/pycharm/ Visual Studio Code- (free version available) from Microsoft https://code.visualstudio.com Doing this effectively requires: Setting up a new Python project which, ideally, uses a virtual environment (above). Installing mkdocs Installing some python plugins Cloning this Rocky GitHub repository: https://github.com/rocky-linux/docs.rockylinux.org Linking to the docs folder within your cloned documentation repository (you can also just modify the mkdocs.yml file if you wish to load the correct folder, but linking keeps your mkdocs environment cleaner) Running mkdocs serve within your clone of docs.rockylinux.org !!! Hint You can build totally separate environments for `mkdocs` by using either of these two procedures as well: * [Local Documentation - Docker](rockydocs_web_dev.md) * [Local Documentation - LXD](mkdocs_lsyncd.md) !!! Note This document was written in a Linux environment. If your environment is different (Windows or Mac), then you will need to do a little research on matching up to some of these steps. An editor or manager reading this can submit changes to it to add in steps for those environments.","title":"Environment Changes"},{"location":"guides/contribute/navigation/#installing","text":"Install mkdocs with the python environment: pip install mkdocs Install needed plugins: pip install mkdocs-material mkdocs-localsearch mkdocs-awesome-pages-plugin mkdocs-redirects mkdocs-i18n Clone the repository (noted above)","title":"Installing"},{"location":"guides/contribute/navigation/#linking-and-running-mkdocs","text":"Inside your docs.rockylinux.org local (clone), do the following. This assumes the location of your documentation clone, so modify as needed: ln -s /home/username/documentation/docs docs Again, if you desire, you can modify the local copy of the mkdocs.yml file to set the path. If using this method, you would modify this line to point to your documentation/docs folder: docs_dir: 'docs/docs' Once completed, you can try running mkdocs serve to see if you get your desired content. This will run on a your localhost on port 8000 example: http://127.0.0.1:8000/","title":"Linking and Running mkdocs"},{"location":"guides/contribute/navigation/#navigation-and-other-changes","text":"Navigation is handled with mkdocs .pages files. Are not terribly complex, BUT, if something is left out, it can cause the server to fail to load. That's why this procedure is ONLY for Managers and Editors. These individuals are going to have the tools in place (local install of mkdocs, plus clones of both documentation and docs.rockylinux.org) so that something pushed and merged to GitHub will not break the serving of the documentation website. A contributor cannot be expected to have even one of these requirements in place.","title":"Navigation and Other Changes"},{"location":"guides/contribute/navigation/#pages-files","text":"As already stated, the .pages files are generally pretty simple. They are a YAML formatted file that mkdocs reads before rendering the content. To take a look at one of the more complex .pages files, let's look at the one created to help format the side navigation: --- nav: - ... | index*.md - ... | installation*.md - ... | migrate2rocky*.md - Contribute: contribute - Automation: automation - Backup & Sync: backup - Content Management: cms - Communications: communications - Containers: containers - Database: database - Desktop: desktop - DNS: dns - Email: email - File Sharing Services: file_sharing - Git: git - Interoperability: interoperability - Mirror Management: mirror_management - Network: network - Package Management: package_management - ... Here, the index*md shows the \"Guides Home: \", installation*.md shows the \"Installing Rocky Linux\" document link, and the migrate2rocky*.md shows the \"Migrating To Rocky Linux\" document link. The \"*\" within each of these links allows for that document in any language. Finally, by placing \"Contribute\" next, it falls beneath these items rather than in the normal (alphabetic) sort order. If you look down the list, you can see what each item is doing. Note that after the \"Package Management: package_management\" entry, there are actually two more folders (security and web). These do not require any additional formatting, so we are just telling mkdocs to load them normally with the \"-...\" You can also use YAML formatting within an actual file. A reason for doing this might be that the beginning heading of the file is so long, that it just doesn't display well in the navigation section. As an example, take this document heading \"# mod_ssl on Rocky Linux in an httpd Apache Web-Server Environment\". That is very long. It displays very poorly in the side navigation once the \"Web\" navigation item is opened. To fix this, you can either work with the author to change his heading, or, you can change how it displays in the menu by adding a title before the heading inside the document. For the example document, there is a title added: --- title: Apache With `mod_ssl` --- This changes the title as far as the navigation is concerned, but leaves the author's original title in place within the document. There will probably not be a lot of need for additional .pages files. They should be used economically.","title":".pages Files"},{"location":"guides/contribute/navigation/#conclusion","text":"While the navigational changes that might need to be made are not difficult, the potential for breaking the live documentation exists. For this reason, only managers and editors with the appropriate tooling in place should have the permissions to edit these files. Having a full environment available to view what the live pages are going to look like, keeps the manager or editor from making a mistake while editing these files that also breaks the live documentation.","title":"Conclusion"},{"location":"guides/contribute/rockydocs_formatting/","tags":["contribute","formatting"],"text":"Rocky Docs Formatting - Introduction Over the last year, a lot has changed with Rocky documentation. This guide is meant to help contributors get familiar with our more advanced formatting options: including admonitions, numbered lists, tables, and more. To be clear, a document may or may not need to contain any of these elements. If you feel that your document will benefit from them, then this guide should help. !!! note \"A Note About Headings\" Headings are not really special formatting characters, but rather standard markdown syntax. They include a **single** level one heading: ``` # This is Level one ``` and any number of sub-heading values, levels 2 through 6: ``` ## A Level 2 heading ### A Level 3 heading #### A Level 4 heading ##### A Level 5 heading ###### A Level 6 heading ``` The key here is that there can be as many of the 2 through 6 headings as you want to use, but only **ONE** level 1 heading. While the documentation will build with more than one level 1 heading, the automatically generated table of contents for the document that appears on the right-hand side, will **NOT** display correctly (or sometimes at all), with more than one. Keep this in mind when writing your documents. Admonitions Admonitions are special visual \"boxes\" that allow you to call attention to important facts and highlight them in a way that makes them stick out from the rest of the text. Admonitions types are as follows: type Description attention renders a light orange text box caution renders a light orange text box danger renders a red text box error renders a red text box hint renders a green text box important renders a green text box note renders a blue text box tip renders a green text box warning renders a orange text box custom 1 always renders a blue text box custom 2 uses a custom title within another type So there is no limit on the types of admonitions you can use as noted in custom 1 above. A custom title can be added to any of the other admonition types to get the colored box you want for a specific admonition, as noted in custom 2 above. An admonition is always entered in this way: !!! admonition_type text of admonition The body text of the admonition must be indented four (4) spaces from the beginning margin. It's easy to see where that is in this case, because it will always line up under the first letter of the admonition type. The extra line between the title and body will not show up, but is required for our translation engine (Crowdin) to function correctly. Here are examples of each admonition type, and how they will look in your document: !!! attention text !!! caution text !!! danger text !!! error text !!! hint text !!! important text !!! note text !!! tip text !!! warning text !!! custom A custom <sub>1</sub> type. Here we've used \"custom\" as our admonition type. Again, this will always render in blue. !!! warning \"custom title\" A custom <sub>2</sub> type. Here we've modified the \"warning\" admonition type with a custom header. Here's what that looks like: ``` !!! warning \"custom title\" ``` Numbered Lists Numbered lists sound like they are easy to create and use, and once you get the hang of them, they really are. If you just have a single list of items with no complexity, then this sort of format works fine: 1. Item 1 2. Item 2 3. Item 3 Item 1 Item 2 Item 3 If you need to add code blocks, multiple lines or even paragraphs of text to a numbered list, then the text should be indented with those same four (4) spaces that we used in the admonitions. You can't use your eyes to line them up under the numbered item, however, as this is one space off. If you are using a good markdown editor, you can set your tab value to four (4), which will make formatting everything a bit easier. Here's an example of a multi-line numbered list with a code block thrown in for good measure: When dealing with numbered lists that are multi line and include things like code blocks, use the space indentation to get what you want. For example: this is indented four (4) spaces and represents a new paragraph of text. And here, we are adding a code block in. It is also indented by the same four (4) spaces as our paragraph: dnf update Here's our second listed item. Because we used the indentation (above) it renders with the next sequence of numbering (in other words, 2), but if we had entered item 1 without the indentation (in the subsequent paragraph and code), then this would show up as item 1 again, which is not what we want. And here's how that looks as raw text: 1. When dealing with numbered lists that are multi line and include things like code blocks, use the space indentation to get what you want. For example: this is indented four (4) spaces and represents a new paragraph of text. And here, we are adding a code block in. It is also indented by the same four (4) spaces as our paragraph: ``` dnf update ``` 2. Here's our second listed item. Because we used the indentation (above) it renders with the next sequence of numbering (in other words, 2), but if we had entered item 1 without the indentation (in the subsequent paragraph and code), then this would show up as item 1 again, which is not what we want. Tables Tables help us to lay out command options, or in the above case, admonition types and descriptions. Here's how the table above is entered: | type | Description | |-----------|-----------------------------------------------------------| | attention | renders a light orange text box | | caution | renders a light orange text box | | danger | renders a red text box | | error | renders a red text box | | hint | renders a green text box | | important | renders a green text box | | note | renders a blue text box | | tip | renders a green text box | | warning | renders a orange text box | | custom <sub>1</sub> | always renders a blue text box | | custom <sub>2</sub> | uses a customer title within another type | Note that it isn't necessary to have each column broken down by size (as we've done in the first part of the table), but it is certainly more readable in the markdown source file. It can get confusing when you string the items together, simply by breaking the columns with the pipe character \"|\" wherever the natural break would be, as you can see in the last two items of the table. Block Quotes Block quotes are actually designed for quoting text from other sources to include in your documentation, but they don't have to be used that way. We've had several people use block quotes instead of tables, for instance, to list out some options. Examples of block quotes in markdown would be: > **an item** - A description of that item > **another item** - Another description of that item To keep the lines from running together, the extra \"spacing\" line is necessary here. That ends up looking like this when the page is rendered: an item - A description of that item another item - Another description of an item Inline and Block-Level Code Blocks Our approach to using code blocks is pretty simple. If your code is short enough that you can (and want to) use it in a sentence like you just saw, use single backticks ` , like so: A sentence with a `commmand of your choosing` in it. Any command that is not used inside of a text paragraph (especially the long bits of code with multiple lines) should be a full code block, defined with triple backticks ` : ```bash sudo dnf install the-kitchen-sink ``` The bash bit of that formatting is a non-essential code identifier, but can help with syntax highlighting. Of course, if you're showcasing Python, PHP, Ruby, HTML, CSS, or any other kind of code, the \"bash\" should be changed to whatever language you're using. Incidentally, if you need to show a code block within a code block, just add one more backtick ` to the parent block, like so: ````markdown ```bash sudo dnf install the-kitchen-sink ``` ```` And yes, the code block you just saw used five backticks at the beginning and end to make it render properly. Keyboard Another way to make sure that you add as much clarity to your documents as possible is to represent keys on the keyboard that must be entered, in the correct manner. This is done with <kbd>key</kbd> . For instance, to represent that you need to hit the escape key in your document, you would use <kbd>ESC</kbd . When you need to indicate that multiple keys must be pressed add a + between them like this: <kbd>CTRL</kbd> + <kbd>F4</kbd> if keys need to be pressed simultaneously, add \"simultaneously\" or \"at the same time\" or some similar phrase to your instructions. Here's an example of a keyboard instruction in your editor: A workstation type installation (with graphical interface) starts this interface on terminal 1. Linux being multi-user, it is possible to connect several users several times, on different **physical terminals** (TTY) or **virtual terminals** (PTS). Virtual terminals are available within a graphical environment. A user switches from one physical terminal to another using <kbd>Alt</kbd> + <kbd>Fx</kbd> from the command line or using <kbd>CTRL</kbd> + <kbd>Alt</kbd> + <kbd>Fx</kbd>. And here's how that renders when displayed: A workstation type installation (with graphical interface) starts this interface on terminal 1. Linux being multi-user, it is possible to connect several users several times, on different physical terminals (TTY) or virtual terminals (PTS). Virtual terminals are available within a graphical environment. A user switches from one physical terminal to another using Alt + Fx from the command line or using CTRL + Alt + Fx . Grouping Different Formatting Types Things really get crazy, when you need to combine multiple elements within another one. For instance, an admonition with a numbered list: !!! note Things can get a little crazy when you are grouping things together. Like when: 1. You add a numbered list of options within an admonition 2. Or you add a numbered list with multiple code blocks: ``` dnf install some-great-package ``` Which is also within a multi-paragraph numbered list. Or what if you have a numbered list, with an additional admonition: This item is something very important Here we are adding a keyboard command to the list item: Press ESC for no particular reason. But this item is something very important and has multiple paragraphs to it And it has an admonition in the middle of it: !!! warning Things can get a little crazy with multiple elements within different formatting types! As long as you keep track of the magic four (4) spaces to indent and separate these items, they will display logically and exactly the way you want them to. Sometimes that is really important. You can even embed a table or block quote (quite literally any formatting item type) within another one. Here we have a numbered list, an admonition, a table and some block quote elements all bundled together: Trying to keep up with everything that's going on in your document can be a real task when there are multiple elements to be considered. If you are feeling overwhelmed, consider: !!! important \"important: I think my brain hurts!\" When combining multiple formatting elements, your brain can go a little crazy. Consider sucking down some extra caffeine before you begin! | type | caffeine daily allowance | |-----------------|----------------------------------| | tea | it will get you there eventually | | coffee | for discerning taste buds | | red bull | tastes terrible - but it will keep you going!| | mountain dew | over hyped | > **sugar** if caffeine isn't to your liking > **suffer** if all else fails, concentrate more There are more examples, but I think you get that everything can be nested within. Just remember the four (4) magic spaces. Here's what this example looks like in your editor: As long as you keep track of the magic four (4) spaces to separate these items, they will display logically and exactly the way you want them to. Sometimes that is really important. You can even embed a table or block quote (quite literally any formatting item type) within another one. Here we have a numbered list, an admonition, a table and some block quote elements all bundled together: 1. Trying to keep up with everything that's going on in your document can be a real task when there are multiple elements to be considered. 2. If you are feeling overwhelmed, consider: !!! important \"important: I think my brain hurts!\" When combining multiple formatting elements, your brain can go a little crazy. Consider sucking down some extra caffeine before you begin! | type | caffeine daily allowance | |-----------------|----------------------------------| | tea | it will get you there eventually | | coffee | for discerning taste buds | | red bull | tastes terrible - but it will keep you going!| | mountain dew | over hyped | > **sugar** if caffeine isn't to your liking > **suffer** if all else fails, concentrate more 3. There are more examples, but I think you get that everything can be nested within. Just remember the four (4) magic spaces. One Final Item - Comments From time to time you may want to add a comment to your markdown that will not display when rendered. There are a lot of reasons why you might want to do this. For instance, if you want to add a placeholder for something that will be added later, you could use a comment to mark your spot. The best way to add a comment to your markdown is to use the square brackets \"[]\" with two forward slashes \"//\" followed by a colon and the content. This would look like this: [//]: This is a comment to be replaced later A comment should have a blank line before and after the comment. More Reading The Rocky Linux how to contribute document More on admonitions Markdown quick reference More quick references for Markdown Conclusion Document formatting with admonitions, tables, numbered lists, and block quotes, can add clarity to your document. When using admonitions, take care to pick the correct type. This can make it easier to visually see the importance of the particular admonition. Overuse of any of these elements can simply add clutter where none is needed. Learning to use these formatting items conservatively and well can be very helpful to get your point across in a document. Lastly, to make formatting easier, consider changing your markdown editor's TAB value to four (4) spaces.","title":"Rocky Docs Formatting"},{"location":"guides/contribute/rockydocs_formatting/#rocky-docs-formatting-introduction","text":"Over the last year, a lot has changed with Rocky documentation. This guide is meant to help contributors get familiar with our more advanced formatting options: including admonitions, numbered lists, tables, and more. To be clear, a document may or may not need to contain any of these elements. If you feel that your document will benefit from them, then this guide should help. !!! note \"A Note About Headings\" Headings are not really special formatting characters, but rather standard markdown syntax. They include a **single** level one heading: ``` # This is Level one ``` and any number of sub-heading values, levels 2 through 6: ``` ## A Level 2 heading ### A Level 3 heading #### A Level 4 heading ##### A Level 5 heading ###### A Level 6 heading ``` The key here is that there can be as many of the 2 through 6 headings as you want to use, but only **ONE** level 1 heading. While the documentation will build with more than one level 1 heading, the automatically generated table of contents for the document that appears on the right-hand side, will **NOT** display correctly (or sometimes at all), with more than one. Keep this in mind when writing your documents.","title":"Rocky Docs Formatting - Introduction"},{"location":"guides/contribute/rockydocs_formatting/#admonitions","text":"Admonitions are special visual \"boxes\" that allow you to call attention to important facts and highlight them in a way that makes them stick out from the rest of the text. Admonitions types are as follows: type Description attention renders a light orange text box caution renders a light orange text box danger renders a red text box error renders a red text box hint renders a green text box important renders a green text box note renders a blue text box tip renders a green text box warning renders a orange text box custom 1 always renders a blue text box custom 2 uses a custom title within another type So there is no limit on the types of admonitions you can use as noted in custom 1 above. A custom title can be added to any of the other admonition types to get the colored box you want for a specific admonition, as noted in custom 2 above. An admonition is always entered in this way: !!! admonition_type text of admonition The body text of the admonition must be indented four (4) spaces from the beginning margin. It's easy to see where that is in this case, because it will always line up under the first letter of the admonition type. The extra line between the title and body will not show up, but is required for our translation engine (Crowdin) to function correctly. Here are examples of each admonition type, and how they will look in your document: !!! attention text !!! caution text !!! danger text !!! error text !!! hint text !!! important text !!! note text !!! tip text !!! warning text !!! custom A custom <sub>1</sub> type. Here we've used \"custom\" as our admonition type. Again, this will always render in blue. !!! warning \"custom title\" A custom <sub>2</sub> type. Here we've modified the \"warning\" admonition type with a custom header. Here's what that looks like: ``` !!! warning \"custom title\" ```","title":"Admonitions"},{"location":"guides/contribute/rockydocs_formatting/#numbered-lists","text":"Numbered lists sound like they are easy to create and use, and once you get the hang of them, they really are. If you just have a single list of items with no complexity, then this sort of format works fine: 1. Item 1 2. Item 2 3. Item 3 Item 1 Item 2 Item 3 If you need to add code blocks, multiple lines or even paragraphs of text to a numbered list, then the text should be indented with those same four (4) spaces that we used in the admonitions. You can't use your eyes to line them up under the numbered item, however, as this is one space off. If you are using a good markdown editor, you can set your tab value to four (4), which will make formatting everything a bit easier. Here's an example of a multi-line numbered list with a code block thrown in for good measure: When dealing with numbered lists that are multi line and include things like code blocks, use the space indentation to get what you want. For example: this is indented four (4) spaces and represents a new paragraph of text. And here, we are adding a code block in. It is also indented by the same four (4) spaces as our paragraph: dnf update Here's our second listed item. Because we used the indentation (above) it renders with the next sequence of numbering (in other words, 2), but if we had entered item 1 without the indentation (in the subsequent paragraph and code), then this would show up as item 1 again, which is not what we want. And here's how that looks as raw text: 1. When dealing with numbered lists that are multi line and include things like code blocks, use the space indentation to get what you want. For example: this is indented four (4) spaces and represents a new paragraph of text. And here, we are adding a code block in. It is also indented by the same four (4) spaces as our paragraph: ``` dnf update ``` 2. Here's our second listed item. Because we used the indentation (above) it renders with the next sequence of numbering (in other words, 2), but if we had entered item 1 without the indentation (in the subsequent paragraph and code), then this would show up as item 1 again, which is not what we want.","title":"Numbered Lists"},{"location":"guides/contribute/rockydocs_formatting/#tables","text":"Tables help us to lay out command options, or in the above case, admonition types and descriptions. Here's how the table above is entered: | type | Description | |-----------|-----------------------------------------------------------| | attention | renders a light orange text box | | caution | renders a light orange text box | | danger | renders a red text box | | error | renders a red text box | | hint | renders a green text box | | important | renders a green text box | | note | renders a blue text box | | tip | renders a green text box | | warning | renders a orange text box | | custom <sub>1</sub> | always renders a blue text box | | custom <sub>2</sub> | uses a customer title within another type | Note that it isn't necessary to have each column broken down by size (as we've done in the first part of the table), but it is certainly more readable in the markdown source file. It can get confusing when you string the items together, simply by breaking the columns with the pipe character \"|\" wherever the natural break would be, as you can see in the last two items of the table.","title":"Tables"},{"location":"guides/contribute/rockydocs_formatting/#block-quotes","text":"Block quotes are actually designed for quoting text from other sources to include in your documentation, but they don't have to be used that way. We've had several people use block quotes instead of tables, for instance, to list out some options. Examples of block quotes in markdown would be: > **an item** - A description of that item > **another item** - Another description of that item To keep the lines from running together, the extra \"spacing\" line is necessary here. That ends up looking like this when the page is rendered: an item - A description of that item another item - Another description of an item","title":"Block Quotes"},{"location":"guides/contribute/rockydocs_formatting/#inline-and-block-level-code-blocks","text":"Our approach to using code blocks is pretty simple. If your code is short enough that you can (and want to) use it in a sentence like you just saw, use single backticks ` , like so: A sentence with a `commmand of your choosing` in it. Any command that is not used inside of a text paragraph (especially the long bits of code with multiple lines) should be a full code block, defined with triple backticks ` : ```bash sudo dnf install the-kitchen-sink ``` The bash bit of that formatting is a non-essential code identifier, but can help with syntax highlighting. Of course, if you're showcasing Python, PHP, Ruby, HTML, CSS, or any other kind of code, the \"bash\" should be changed to whatever language you're using. Incidentally, if you need to show a code block within a code block, just add one more backtick ` to the parent block, like so: ````markdown ```bash sudo dnf install the-kitchen-sink ``` ```` And yes, the code block you just saw used five backticks at the beginning and end to make it render properly.","title":"Inline and Block-Level Code Blocks"},{"location":"guides/contribute/rockydocs_formatting/#keyboard","text":"Another way to make sure that you add as much clarity to your documents as possible is to represent keys on the keyboard that must be entered, in the correct manner. This is done with <kbd>key</kbd> . For instance, to represent that you need to hit the escape key in your document, you would use <kbd>ESC</kbd . When you need to indicate that multiple keys must be pressed add a + between them like this: <kbd>CTRL</kbd> + <kbd>F4</kbd> if keys need to be pressed simultaneously, add \"simultaneously\" or \"at the same time\" or some similar phrase to your instructions. Here's an example of a keyboard instruction in your editor: A workstation type installation (with graphical interface) starts this interface on terminal 1. Linux being multi-user, it is possible to connect several users several times, on different **physical terminals** (TTY) or **virtual terminals** (PTS). Virtual terminals are available within a graphical environment. A user switches from one physical terminal to another using <kbd>Alt</kbd> + <kbd>Fx</kbd> from the command line or using <kbd>CTRL</kbd> + <kbd>Alt</kbd> + <kbd>Fx</kbd>. And here's how that renders when displayed: A workstation type installation (with graphical interface) starts this interface on terminal 1. Linux being multi-user, it is possible to connect several users several times, on different physical terminals (TTY) or virtual terminals (PTS). Virtual terminals are available within a graphical environment. A user switches from one physical terminal to another using Alt + Fx from the command line or using CTRL + Alt + Fx .","title":"Keyboard"},{"location":"guides/contribute/rockydocs_formatting/#grouping-different-formatting-types","text":"Things really get crazy, when you need to combine multiple elements within another one. For instance, an admonition with a numbered list: !!! note Things can get a little crazy when you are grouping things together. Like when: 1. You add a numbered list of options within an admonition 2. Or you add a numbered list with multiple code blocks: ``` dnf install some-great-package ``` Which is also within a multi-paragraph numbered list. Or what if you have a numbered list, with an additional admonition: This item is something very important Here we are adding a keyboard command to the list item: Press ESC for no particular reason. But this item is something very important and has multiple paragraphs to it And it has an admonition in the middle of it: !!! warning Things can get a little crazy with multiple elements within different formatting types! As long as you keep track of the magic four (4) spaces to indent and separate these items, they will display logically and exactly the way you want them to. Sometimes that is really important. You can even embed a table or block quote (quite literally any formatting item type) within another one. Here we have a numbered list, an admonition, a table and some block quote elements all bundled together: Trying to keep up with everything that's going on in your document can be a real task when there are multiple elements to be considered. If you are feeling overwhelmed, consider: !!! important \"important: I think my brain hurts!\" When combining multiple formatting elements, your brain can go a little crazy. Consider sucking down some extra caffeine before you begin! | type | caffeine daily allowance | |-----------------|----------------------------------| | tea | it will get you there eventually | | coffee | for discerning taste buds | | red bull | tastes terrible - but it will keep you going!| | mountain dew | over hyped | > **sugar** if caffeine isn't to your liking > **suffer** if all else fails, concentrate more There are more examples, but I think you get that everything can be nested within. Just remember the four (4) magic spaces. Here's what this example looks like in your editor: As long as you keep track of the magic four (4) spaces to separate these items, they will display logically and exactly the way you want them to. Sometimes that is really important. You can even embed a table or block quote (quite literally any formatting item type) within another one. Here we have a numbered list, an admonition, a table and some block quote elements all bundled together: 1. Trying to keep up with everything that's going on in your document can be a real task when there are multiple elements to be considered. 2. If you are feeling overwhelmed, consider: !!! important \"important: I think my brain hurts!\" When combining multiple formatting elements, your brain can go a little crazy. Consider sucking down some extra caffeine before you begin! | type | caffeine daily allowance | |-----------------|----------------------------------| | tea | it will get you there eventually | | coffee | for discerning taste buds | | red bull | tastes terrible - but it will keep you going!| | mountain dew | over hyped | > **sugar** if caffeine isn't to your liking > **suffer** if all else fails, concentrate more 3. There are more examples, but I think you get that everything can be nested within. Just remember the four (4) magic spaces.","title":"Grouping Different Formatting Types"},{"location":"guides/contribute/rockydocs_formatting/#one-final-item-comments","text":"From time to time you may want to add a comment to your markdown that will not display when rendered. There are a lot of reasons why you might want to do this. For instance, if you want to add a placeholder for something that will be added later, you could use a comment to mark your spot. The best way to add a comment to your markdown is to use the square brackets \"[]\" with two forward slashes \"//\" followed by a colon and the content. This would look like this: [//]: This is a comment to be replaced later A comment should have a blank line before and after the comment.","title":"One Final Item - Comments"},{"location":"guides/contribute/rockydocs_formatting/#more-reading","text":"The Rocky Linux how to contribute document More on admonitions Markdown quick reference More quick references for Markdown","title":"More Reading"},{"location":"guides/contribute/rockydocs_formatting/#conclusion","text":"Document formatting with admonitions, tables, numbered lists, and block quotes, can add clarity to your document. When using admonitions, take care to pick the correct type. This can make it easier to visually see the importance of the particular admonition. Overuse of any of these elements can simply add clutter where none is needed. Learning to use these formatting items conservatively and well can be very helpful to get your point across in a document. Lastly, to make formatting easier, consider changing your markdown editor's TAB value to four (4) spaces.","title":"Conclusion"},{"location":"guides/contribute/rockydocs_web_dev/","text":"Running a local copy of the docs.rockylinux.org website for web development and/or content authors This document walks through how to recreate and run a local copy of the entire docs.rockylinux.org website on your local machine. It is a work-in-progress. Running a local copy of the documentation website might be useful in the following scenarios: You are interested in learning about and contributing to the web development aspects of the docs.rockylinux.org website You are an author and you'd like to see how your documents will render/look on the docs website before contributing them You are a web developer looking to contribute to or help maintain the docs.rockylinux.org website Some notes: The instructions in this guide are NOT a prerequisite for Rocky documentation Authors/Content contributors The entire environment runs in a Docker container and so you'll need a Docker engine on your local machine The container is built on top of the official RockyLinux docker image available here https://hub.docker.com/r/rockylinux/rockylinux The container keeps the documentation content (guides, books, images and so on) separate from the web engine (mkdocs) The container starts a local web server listening on port 8000. And port 8000 will be forwarded to the Docker host Create the content environment Change the current working directory on your local system to a folder where you intend to do your writing. We'll refer to this directory as $ROCKYDOCS in the rest of this guide. For our demo here, $ROCKYDOCS points to ~/projects/rockydocs on our demo system. Create $ROCKYDOCS if it doesn't already exist and then type: cd $ROCKYDOCS Make sure you have git installed ( dnf -y install git ). While in $ROCKYDOCS use git to clone the official Rocky Documentation content repo. Type: git clone https://github.com/rocky-linux/documentation.git You'll now have a $ROCKYDOCS/documentation folder. This folder is a git repository and under git's control. Create and Start the RockyDocs web developmwnt environment Make sure you have Docker up and running on your local machine (you can check with systemctl ) From a terminal type: docker pull wsoyinka/rockydocs:latest Check to make sure the image downloaded successfully. Type: docker image ls Start the RockyDocs container Start a container from the rockydocs image. Type: docker run -it --name rockydoc --rm \\ -p 8000:8000 \\ --mount type=bind,source=\"$(pwd)\"/documentation,target=/documentation \\ wsoyinka/rockydocs:latest Alternatively if you prefer and if you have docker-compose installed, you can create compose file named docker-compose.yml with the following contents: version: \"3.9\" services: rockydocs: image: wsoyinka/rockydocs:latest volumes: - type: bind source: ./documentation target: /documentation container_name: rocky ports: - \"8000:8000\" Save the file with the file name docker-compose.yml in your $ROCKYDOCS working directory. And start the service/container by running: docker-compose up View the local docs.rockylinux.org website With the container up and running, you should now be able to point your web browser to the following URL to view your local copy of the site: http://localhost:8000","title":"Local Documentation - Docker"},{"location":"guides/contribute/rockydocs_web_dev/#running-a-local-copy-of-the-docsrockylinuxorg-website-for-web-development-andor-content-authors","text":"This document walks through how to recreate and run a local copy of the entire docs.rockylinux.org website on your local machine. It is a work-in-progress. Running a local copy of the documentation website might be useful in the following scenarios: You are interested in learning about and contributing to the web development aspects of the docs.rockylinux.org website You are an author and you'd like to see how your documents will render/look on the docs website before contributing them You are a web developer looking to contribute to or help maintain the docs.rockylinux.org website","title":"Running a local copy of the docs.rockylinux.org website for web development and/or content authors"},{"location":"guides/contribute/rockydocs_web_dev/#some-notes","text":"The instructions in this guide are NOT a prerequisite for Rocky documentation Authors/Content contributors The entire environment runs in a Docker container and so you'll need a Docker engine on your local machine The container is built on top of the official RockyLinux docker image available here https://hub.docker.com/r/rockylinux/rockylinux The container keeps the documentation content (guides, books, images and so on) separate from the web engine (mkdocs) The container starts a local web server listening on port 8000. And port 8000 will be forwarded to the Docker host","title":"Some notes:"},{"location":"guides/contribute/rockydocs_web_dev/#create-the-content-environment","text":"Change the current working directory on your local system to a folder where you intend to do your writing. We'll refer to this directory as $ROCKYDOCS in the rest of this guide. For our demo here, $ROCKYDOCS points to ~/projects/rockydocs on our demo system. Create $ROCKYDOCS if it doesn't already exist and then type: cd $ROCKYDOCS Make sure you have git installed ( dnf -y install git ). While in $ROCKYDOCS use git to clone the official Rocky Documentation content repo. Type: git clone https://github.com/rocky-linux/documentation.git You'll now have a $ROCKYDOCS/documentation folder. This folder is a git repository and under git's control.","title":"Create the content environment"},{"location":"guides/contribute/rockydocs_web_dev/#create-and-start-the-rockydocs-web-developmwnt-environment","text":"Make sure you have Docker up and running on your local machine (you can check with systemctl ) From a terminal type: docker pull wsoyinka/rockydocs:latest Check to make sure the image downloaded successfully. Type: docker image ls","title":"Create and Start the RockyDocs web developmwnt environment"},{"location":"guides/contribute/rockydocs_web_dev/#start-the-rockydocs-container","text":"Start a container from the rockydocs image. Type: docker run -it --name rockydoc --rm \\ -p 8000:8000 \\ --mount type=bind,source=\"$(pwd)\"/documentation,target=/documentation \\ wsoyinka/rockydocs:latest Alternatively if you prefer and if you have docker-compose installed, you can create compose file named docker-compose.yml with the following contents: version: \"3.9\" services: rockydocs: image: wsoyinka/rockydocs:latest volumes: - type: bind source: ./documentation target: /documentation container_name: rocky ports: - \"8000:8000\" Save the file with the file name docker-compose.yml in your $ROCKYDOCS working directory. And start the service/container by running: docker-compose up","title":"Start the RockyDocs container"},{"location":"guides/contribute/rockydocs_web_dev/#view-the-local-docsrockylinuxorg-website","text":"With the container up and running, you should now be able to point your web browser to the following URL to view your local copy of the site: http://localhost:8000","title":"View the local docs.rockylinux.org website"},{"location":"guides/database/database_mariadb-server/","tags":["database","mariadb"],"text":"MariaDB Database Server Prerequisites A Rocky Linux server Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of mariadb-server databases is helpful All commands are run as the root user or sudo Introduction The mariadb-server and it's client mariadb are the open source alternatives to mysql-server and mysql , and they share command structure. mariadb-server can be found running on many web servers, due to the popular Wordpress CMS which requires it. This database, though, has many other uses. If you'd like to use this along with other tools for hardening a web server, refer back to the Apache Hardened Web Server guide . Installing mariadb-server We need to install mariadb-server : dnf install mariadb-server Securing mariadb-server To strengthen the security of mariadb-server we need to run a script, but before we do, we need to enable and start mariadb: systemctl enable mariadb And then: systemctl start mariadb Next, run this command: mysql_secure_installation !!! hint The version of mariadb-server that comes enabled by default in Rocky Linux 8.5 is 10.3.32. You can install 10.5.13 by enabling the module: ``` dnf module enable mariadb:10.5 ``` And then installing `mariadb`. As of version 10.4.6 of MariaDB, MariaDB specific commands are available that you can use instead of the old `mysql` prefixed commands. These include the previously mentioned `mysql_secure_installation` which can now be called with the MariaDB version `mariadb-secure-installation`. This brings up a dialog: NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY! In order to log into MariaDB to secure it, we'll need the current password for the root user. If you've just installed MariaDB, and you haven't set the root password yet, the password will be blank, so you should just press enter here. Enter current password for root (enter for none): Since this is a brand new installation, there is no root password set. So just hit enter here. The next part of the dialog continues: OK, successfully used password, moving on... Setting the root password ensures that nobody can log into the MariaDB root user without the proper authorisation. Set root password? [Y/n] You absolutely do want to have a root password set. You'll want to figure out what this should be and document it in a password manager somewhere so that you can pull it up if necessary. Start by hitting 'Enter' to accept the default \"Y\". This will bring up the password dialog: New password: Re-enter new password: Enter your chosen password and then confirm it by entering it again. If this is successful, you will get the following dialog: Password updated successfully! Reloading privilege tables.. ... Success! Next the dialog deals with the anonymous user: By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] The answer here is \"Y\" so just hit 'Enter' to accept the default. The dialog proceeds to the section dealing with allowing the root user to login remotely: ... Success! Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? [Y/n] root should only be needed locally on the machine. So accept this default as well by hitting 'Enter'. The dialog then moves on to the 'test' database that is automatically installed with mariadb-server : ... Success! By default, MariaDB comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? [Y/n] Again, the answer here is the default, so just hit 'Enter' to remove it. Finally, the dialog ask you if you want to reload the privileges: - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] Again, simply hit 'Enter' to do this. If all goes well, you should receive this message: ... Success! Cleaning up... All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! MariaDB should now be ready to use. Rocky Linux 9.0 Changes Rocky Linux 9.0 uses mariadb-server-10.5.13-2 as the default mariadb-server version. As of version 10.4.3, a new plugin is automatically enabled in the server which changes the mariadb-secure-installation dialog. That plugin is unix-socket authentication. This article explains the new feature well. Essentially, using unix-socket authentication uses the credentials of the logged in user to access the database. It makes it so that if the root user, for example, logs in and then uses mysqladmin to create or delete a database (or any other function) that no password is needed for access. Same works with mysql . It also means there is no password to compromise remotely. This depends on the security of the users setup on the server for all of the protection of the database. The second dialog during the mariadb-secure-installation after the password is set for the administrative user is: Switch to unix_socket authentication Y/n Obviously, the default here is \"Y\", but even if you answer \"n\", with the plugin enabled, no password is requested for the user, at least not from the command line interface. You can specify either password or no password and they both work: mysql MariaDB [(none)]> mysql -p Enter password: MariaDB [(none)]> For more information on this feature, refer to the link above. There is a way to switch off this plugin and go back to having the password as a required field, which is also detailed within that link. Conclusion A database server, such as mariadb-server , can be used for many purposes. Because of the popularity of the Wordpress CMS, it is often found on web servers. Before we run the database in production, however, it is a good idea to strengthen its security.","title":"MariaDB Database Server"},{"location":"guides/database/database_mariadb-server/#mariadb-database-server","text":"","title":"MariaDB Database Server"},{"location":"guides/database/database_mariadb-server/#prerequisites","text":"A Rocky Linux server Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of mariadb-server databases is helpful All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/database/database_mariadb-server/#introduction","text":"The mariadb-server and it's client mariadb are the open source alternatives to mysql-server and mysql , and they share command structure. mariadb-server can be found running on many web servers, due to the popular Wordpress CMS which requires it. This database, though, has many other uses. If you'd like to use this along with other tools for hardening a web server, refer back to the Apache Hardened Web Server guide .","title":"Introduction"},{"location":"guides/database/database_mariadb-server/#installing-mariadb-server","text":"We need to install mariadb-server : dnf install mariadb-server","title":"Installing mariadb-server"},{"location":"guides/database/database_mariadb-server/#securing-mariadb-server","text":"To strengthen the security of mariadb-server we need to run a script, but before we do, we need to enable and start mariadb: systemctl enable mariadb And then: systemctl start mariadb Next, run this command: mysql_secure_installation !!! hint The version of mariadb-server that comes enabled by default in Rocky Linux 8.5 is 10.3.32. You can install 10.5.13 by enabling the module: ``` dnf module enable mariadb:10.5 ``` And then installing `mariadb`. As of version 10.4.6 of MariaDB, MariaDB specific commands are available that you can use instead of the old `mysql` prefixed commands. These include the previously mentioned `mysql_secure_installation` which can now be called with the MariaDB version `mariadb-secure-installation`. This brings up a dialog: NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY! In order to log into MariaDB to secure it, we'll need the current password for the root user. If you've just installed MariaDB, and you haven't set the root password yet, the password will be blank, so you should just press enter here. Enter current password for root (enter for none): Since this is a brand new installation, there is no root password set. So just hit enter here. The next part of the dialog continues: OK, successfully used password, moving on... Setting the root password ensures that nobody can log into the MariaDB root user without the proper authorisation. Set root password? [Y/n] You absolutely do want to have a root password set. You'll want to figure out what this should be and document it in a password manager somewhere so that you can pull it up if necessary. Start by hitting 'Enter' to accept the default \"Y\". This will bring up the password dialog: New password: Re-enter new password: Enter your chosen password and then confirm it by entering it again. If this is successful, you will get the following dialog: Password updated successfully! Reloading privilege tables.. ... Success! Next the dialog deals with the anonymous user: By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] The answer here is \"Y\" so just hit 'Enter' to accept the default. The dialog proceeds to the section dealing with allowing the root user to login remotely: ... Success! Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? [Y/n] root should only be needed locally on the machine. So accept this default as well by hitting 'Enter'. The dialog then moves on to the 'test' database that is automatically installed with mariadb-server : ... Success! By default, MariaDB comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? [Y/n] Again, the answer here is the default, so just hit 'Enter' to remove it. Finally, the dialog ask you if you want to reload the privileges: - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] Again, simply hit 'Enter' to do this. If all goes well, you should receive this message: ... Success! Cleaning up... All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! MariaDB should now be ready to use.","title":"Securing mariadb-server"},{"location":"guides/database/database_mariadb-server/#rocky-linux-90-changes","text":"Rocky Linux 9.0 uses mariadb-server-10.5.13-2 as the default mariadb-server version. As of version 10.4.3, a new plugin is automatically enabled in the server which changes the mariadb-secure-installation dialog. That plugin is unix-socket authentication. This article explains the new feature well. Essentially, using unix-socket authentication uses the credentials of the logged in user to access the database. It makes it so that if the root user, for example, logs in and then uses mysqladmin to create or delete a database (or any other function) that no password is needed for access. Same works with mysql . It also means there is no password to compromise remotely. This depends on the security of the users setup on the server for all of the protection of the database. The second dialog during the mariadb-secure-installation after the password is set for the administrative user is: Switch to unix_socket authentication Y/n Obviously, the default here is \"Y\", but even if you answer \"n\", with the plugin enabled, no password is requested for the user, at least not from the command line interface. You can specify either password or no password and they both work: mysql MariaDB [(none)]> mysql -p Enter password: MariaDB [(none)]> For more information on this feature, refer to the link above. There is a way to switch off this plugin and go back to having the password as a required field, which is also detailed within that link.","title":"Rocky Linux 9.0 Changes"},{"location":"guides/database/database_mariadb-server/#conclusion","text":"A database server, such as mariadb-server , can be used for many purposes. Because of the popularity of the Wordpress CMS, it is often found on web servers. Before we run the database in production, however, it is a good idea to strengthen its security.","title":"Conclusion"},{"location":"guides/desktop/mate_installation/","tags":["mate","desktop"],"text":"MATE Desktop Environment The MATE desktop environment was created to fork and continue GNOME2 in the wake of the somewhat negative reception that GNOME3 received when introduced. MATE has a loyal set of followers, who immediately install it on their OS of choice. MATE can be installed on many flavors of Linux, including Rocky Linux. This procedure is designed to get you up and running with Rocky Linux using MATE. !!! Warning MATE does not come from Rocky Linux repositories. It is not officially supported by Rocky Linux. For most users, this procedure will work as expected, but if you have issues, please note that the Rocky developers and test group will do NO work on any failures! If you want MATE badly enough, then troubleshoot your issues and fix as needed. If you find something that you feel should be included in this procedure to help others, push a change to the document. Prerequisites A computer with a screen and everything, preferably with Rocky Linux already installed. Install Rocky Linux Minimal When installing Rocky Linux, we used the following sets of packages: Minimal Standard Enabling Repositories We need the unofficial repository for MATE. You can find more information on that repository here: Stenstorp/MATE Enable this repository by entering: dnf copr enable stenstorp/MATE !!! Warning The `copr` build system creates a repository that is known to work for installing `mate` and `lightdm` (below), but is not maintained by the Rocky Linux community. Use at your own risk! You will get a warning message about the repository, but go ahead and enable it by typing Y to allow. As noted from the link above, you also need the Powertools repository and the EPEL. Go ahead and enable those now: sudo dnf config-manager --set-enabled powertools sudo dnf install epel-release And answer 'Y' to install the EPEL. We also need the Stenstorp Lightdm repository, so lets enable that as well. You can find more on this repository by going to this link: Stenstorp/Lighdm To enable that repository, simply type: sudo dnf copr enable stenstorp/lightdm Again, you will be presented with a warning message about the repository. Go ahead and answer Y to the prompt. Go ahead and run dnf update to make sure all of the enabled repositories are read into the system. Installing Packages The next thing we need are a lot of packages. You can install these by simply copying and pasting the following into the command line on your machine: sudo dnf install NetworkManager-adsl NetworkManager-bluetooth NetworkManager-libreswan-gnome NetworkManager-openvpn-gnome NetworkManager-ovs NetworkManager-ppp NetworkManager-team NetworkManager-wifi NetworkManager-wwan abrt-desktop abrt-java-connector adwaita-gtk2-theme alsa-plugins-pulseaudio atril atril-caja atril-thumbnailer caja caja-actions caja-image-converter caja-open-terminal caja-sendto caja-wallpaper caja-xattr-tags dconf-editor engrampa eom firewall-config gnome-disk-utility gnome-epub-thumbnailer gstreamer1-plugins-ugly-free gtk2-engines gucharmap gvfs-afc gvfs-afp gvfs-archive gvfs-fuse gvfs-gphoto2 gvfs-mtp gvfs-smb initial-setup-gui libmatekbd libmatemixer libmateweather libsecret lm_sensors marco mate-applets mate-backgrounds mate-calc mate-control-center mate-desktop mate-dictionary mate-disk-usage-analyzer mate-icon-theme mate-media mate-menus mate-menus-preferences-category-menu mate-notification-daemon mate-panel mate-polkit mate-power-manager mate-screensaver mate-screenshot mate-search-tool mate-session-manager mate-settings-daemon mate-system-log mate-system-monitor mate-terminal mate-themes mate-user-admin mate-user-guide mozo network-manager-applet nm-connection-editor p7zip p7zip-plugins pluma seahorse seahorse-caja xdg-user-dirs-gtk brisk-menu This will install these needed packages plus all of the dependencies. Let's go ahead and install lightdm-gtk as well: sudo dnf install lightdm-gtk Final Steps Now that we have everything we need installed, the next thing we need to do is set the minimal install to boot into the Graphical User Interface (GUI). We can do this by entering: sudo systemctl set-default graphical.target Now just keep your fingers crossed and reboot: sudo reboot Next, click on your user name on the screen, but before you enter your password and login, click on the gear icon to the left of the \"Sign in\" option. Select \"MATE\" from the available desktop choices and then you can enter your password and login. Future logins will remember your selection. Conclusion Some people are not satisfied with the newer GNOME implementations or simply prefer the older MATE GNOME 2 look and feel. For those people, getting MATE installed in Rocky Linux will provide a nice, stable alternative. !!! attention After further testing, the desktop selection does **NOT** stick, even though MATE remains selected. Attempts to login produce a return to the login screen. To login to a MATE session, you must select MATE again, even though it will already show as selected. This is why the warning exists at the top of this procedure. Please use this guide at your own risk. If you discover a workaround that will help other users continue to use MATE with Rocky Linux, please report your workaround.","title":"MATE Desktop"},{"location":"guides/desktop/mate_installation/#mate-desktop-environment","text":"The MATE desktop environment was created to fork and continue GNOME2 in the wake of the somewhat negative reception that GNOME3 received when introduced. MATE has a loyal set of followers, who immediately install it on their OS of choice. MATE can be installed on many flavors of Linux, including Rocky Linux. This procedure is designed to get you up and running with Rocky Linux using MATE. !!! Warning MATE does not come from Rocky Linux repositories. It is not officially supported by Rocky Linux. For most users, this procedure will work as expected, but if you have issues, please note that the Rocky developers and test group will do NO work on any failures! If you want MATE badly enough, then troubleshoot your issues and fix as needed. If you find something that you feel should be included in this procedure to help others, push a change to the document.","title":"MATE Desktop Environment"},{"location":"guides/desktop/mate_installation/#prerequisites","text":"A computer with a screen and everything, preferably with Rocky Linux already installed.","title":"Prerequisites"},{"location":"guides/desktop/mate_installation/#install-rocky-linux-minimal","text":"When installing Rocky Linux, we used the following sets of packages: Minimal Standard","title":"Install Rocky Linux Minimal"},{"location":"guides/desktop/mate_installation/#enabling-repositories","text":"We need the unofficial repository for MATE. You can find more information on that repository here: Stenstorp/MATE Enable this repository by entering: dnf copr enable stenstorp/MATE !!! Warning The `copr` build system creates a repository that is known to work for installing `mate` and `lightdm` (below), but is not maintained by the Rocky Linux community. Use at your own risk! You will get a warning message about the repository, but go ahead and enable it by typing Y to allow. As noted from the link above, you also need the Powertools repository and the EPEL. Go ahead and enable those now: sudo dnf config-manager --set-enabled powertools sudo dnf install epel-release And answer 'Y' to install the EPEL. We also need the Stenstorp Lightdm repository, so lets enable that as well. You can find more on this repository by going to this link: Stenstorp/Lighdm To enable that repository, simply type: sudo dnf copr enable stenstorp/lightdm Again, you will be presented with a warning message about the repository. Go ahead and answer Y to the prompt. Go ahead and run dnf update to make sure all of the enabled repositories are read into the system.","title":"Enabling Repositories"},{"location":"guides/desktop/mate_installation/#installing-packages","text":"The next thing we need are a lot of packages. You can install these by simply copying and pasting the following into the command line on your machine: sudo dnf install NetworkManager-adsl NetworkManager-bluetooth NetworkManager-libreswan-gnome NetworkManager-openvpn-gnome NetworkManager-ovs NetworkManager-ppp NetworkManager-team NetworkManager-wifi NetworkManager-wwan abrt-desktop abrt-java-connector adwaita-gtk2-theme alsa-plugins-pulseaudio atril atril-caja atril-thumbnailer caja caja-actions caja-image-converter caja-open-terminal caja-sendto caja-wallpaper caja-xattr-tags dconf-editor engrampa eom firewall-config gnome-disk-utility gnome-epub-thumbnailer gstreamer1-plugins-ugly-free gtk2-engines gucharmap gvfs-afc gvfs-afp gvfs-archive gvfs-fuse gvfs-gphoto2 gvfs-mtp gvfs-smb initial-setup-gui libmatekbd libmatemixer libmateweather libsecret lm_sensors marco mate-applets mate-backgrounds mate-calc mate-control-center mate-desktop mate-dictionary mate-disk-usage-analyzer mate-icon-theme mate-media mate-menus mate-menus-preferences-category-menu mate-notification-daemon mate-panel mate-polkit mate-power-manager mate-screensaver mate-screenshot mate-search-tool mate-session-manager mate-settings-daemon mate-system-log mate-system-monitor mate-terminal mate-themes mate-user-admin mate-user-guide mozo network-manager-applet nm-connection-editor p7zip p7zip-plugins pluma seahorse seahorse-caja xdg-user-dirs-gtk brisk-menu This will install these needed packages plus all of the dependencies. Let's go ahead and install lightdm-gtk as well: sudo dnf install lightdm-gtk","title":"Installing Packages"},{"location":"guides/desktop/mate_installation/#final-steps","text":"Now that we have everything we need installed, the next thing we need to do is set the minimal install to boot into the Graphical User Interface (GUI). We can do this by entering: sudo systemctl set-default graphical.target Now just keep your fingers crossed and reboot: sudo reboot Next, click on your user name on the screen, but before you enter your password and login, click on the gear icon to the left of the \"Sign in\" option. Select \"MATE\" from the available desktop choices and then you can enter your password and login. Future logins will remember your selection.","title":"Final Steps"},{"location":"guides/desktop/mate_installation/#conclusion","text":"Some people are not satisfied with the newer GNOME implementations or simply prefer the older MATE GNOME 2 look and feel. For those people, getting MATE installed in Rocky Linux will provide a nice, stable alternative. !!! attention After further testing, the desktop selection does **NOT** stick, even though MATE remains selected. Attempts to login produce a return to the login screen. To login to a MATE session, you must select MATE again, even though it will already show as selected. This is why the warning exists at the top of this procedure. Please use this guide at your own risk. If you discover a workaround that will help other users continue to use MATE with Rocky Linux, please report your workaround.","title":"Conclusion"},{"location":"guides/desktop/xfce_installation/","text":"XFCE Desktop Environment The XFCE desktop environment was created as a fork of the Common Desktop Environment (CDE). Xfce embodies the traditional Unix philosophy of Modularity and Re-usability. XFCE can be installed on almost any version of Linux, including Rocky Linux. This procedure is designed to get you up and running with Rocky Linux using XFCE. Prerequisites A Workstation or Server, preferably with Rocky Linux already installed. You should be in the Root environment or type sudo before all of the commands you enter. Install Rocky Linux Minimal When installing Rocky Linux, we used the following sets of packages: Minimal Standard Run System Update First, run the server update command to let the system rebuild the repository cache, so that it could recognize the packages available in that. dnf update Enabling Repositories We need the unofficial repository for XFCE in the EPEL, to run on Rocky 8.x versions. Enable this repository by entering: dnf install epel-release And answer 'Y' to install the EPEL. You also need the Powertools and lightdm repositories. Go ahead and enable those now: dnf config-manager --set-enabled powertools dnf copr enable stenstorp/lightdm !!! Warning The `copr` build system creates a repository that is known to work for installing `lightdm`, but is not maintained by the Rocky Linux community. Use at your own risk! Again, you will be presented with a warning message about the repository. Go ahead and answer Y to the prompt. Check The Available Environments and Tools in the Group Now that the repositories are enabled, run the following commands to check everything. First, check your repository listing with: dnf repolist You should get the following back showing all of the enabled repositories: appstream Rocky Linux 8 - AppStream baseos Rocky Linux 8 - BaseOS copr:copr.fedorainfracloud.org:stenstorp:lightdm Copr repo for lightdm owned by stenstorp epel Extra Packages for Enterprise Linux 8 - x86_64 epel-modular Extra Packages for Enterprise Linux Modular 8 - x86_64 extras Rocky Linux 8 - Extras powertools Rocky Linux 8 - PowerTools Next run the following command to check for XFCE: dnf grouplist You should see \"Xfce\" at the bottom of the listing. Go ahead and run dnf update one more time to make sure all of the enabled repositories are read into the system. Installing Packages To install XFCE, run: dnf groupinstall \"xfce\" Also install lightdm: dnf install lightdm Final Steps We need to disable gdm , which gets added and enabled during dnf groupinstall \"xfce\" : systemctl disable gdm Now we can enable lightdm : systemctl enable lightdm We need to tell the system after booting use only the graphical user interface, so for that set the default target system to the GUI interface: systemctl set-default graphical.target Then reboot: reboot You should end up with a login prompt in the XFCE GUI, and when you login, you will have all of the XFCE environment. Conclusion XFCE is a light environment with simple interface for those who dislike eye-candy and bloat. This Tutorial will be updated with images soon, showing screenshots to give a visual example of the installation.","title":"XFCE Desktop Environment"},{"location":"guides/desktop/xfce_installation/#xfce-desktop-environment","text":"The XFCE desktop environment was created as a fork of the Common Desktop Environment (CDE). Xfce embodies the traditional Unix philosophy of Modularity and Re-usability. XFCE can be installed on almost any version of Linux, including Rocky Linux. This procedure is designed to get you up and running with Rocky Linux using XFCE.","title":"XFCE Desktop Environment"},{"location":"guides/desktop/xfce_installation/#prerequisites","text":"A Workstation or Server, preferably with Rocky Linux already installed. You should be in the Root environment or type sudo before all of the commands you enter.","title":"Prerequisites"},{"location":"guides/desktop/xfce_installation/#install-rocky-linux-minimal","text":"When installing Rocky Linux, we used the following sets of packages: Minimal Standard","title":"Install Rocky Linux Minimal"},{"location":"guides/desktop/xfce_installation/#run-system-update","text":"First, run the server update command to let the system rebuild the repository cache, so that it could recognize the packages available in that. dnf update","title":"Run System Update"},{"location":"guides/desktop/xfce_installation/#enabling-repositories","text":"We need the unofficial repository for XFCE in the EPEL, to run on Rocky 8.x versions. Enable this repository by entering: dnf install epel-release And answer 'Y' to install the EPEL. You also need the Powertools and lightdm repositories. Go ahead and enable those now: dnf config-manager --set-enabled powertools dnf copr enable stenstorp/lightdm !!! Warning The `copr` build system creates a repository that is known to work for installing `lightdm`, but is not maintained by the Rocky Linux community. Use at your own risk! Again, you will be presented with a warning message about the repository. Go ahead and answer Y to the prompt.","title":"Enabling Repositories"},{"location":"guides/desktop/xfce_installation/#check-the-available-environments-and-tools-in-the-group","text":"Now that the repositories are enabled, run the following commands to check everything. First, check your repository listing with: dnf repolist You should get the following back showing all of the enabled repositories: appstream Rocky Linux 8 - AppStream baseos Rocky Linux 8 - BaseOS copr:copr.fedorainfracloud.org:stenstorp:lightdm Copr repo for lightdm owned by stenstorp epel Extra Packages for Enterprise Linux 8 - x86_64 epel-modular Extra Packages for Enterprise Linux Modular 8 - x86_64 extras Rocky Linux 8 - Extras powertools Rocky Linux 8 - PowerTools Next run the following command to check for XFCE: dnf grouplist You should see \"Xfce\" at the bottom of the listing. Go ahead and run dnf update one more time to make sure all of the enabled repositories are read into the system.","title":"Check The Available Environments and Tools in the Group"},{"location":"guides/desktop/xfce_installation/#installing-packages","text":"To install XFCE, run: dnf groupinstall \"xfce\" Also install lightdm: dnf install lightdm","title":"Installing Packages"},{"location":"guides/desktop/xfce_installation/#final-steps","text":"We need to disable gdm , which gets added and enabled during dnf groupinstall \"xfce\" : systemctl disable gdm Now we can enable lightdm : systemctl enable lightdm We need to tell the system after booting use only the graphical user interface, so for that set the default target system to the GUI interface: systemctl set-default graphical.target Then reboot: reboot You should end up with a login prompt in the XFCE GUI, and when you login, you will have all of the XFCE environment.","title":"Final Steps"},{"location":"guides/desktop/xfce_installation/#conclusion","text":"XFCE is a light environment with simple interface for those who dislike eye-candy and bloat. This Tutorial will be updated with images soon, showing screenshots to give a visual example of the installation.","title":"Conclusion"},{"location":"guides/dns/private_dns_server_using_bind/","tags":["dns","bind"],"text":"Private DNS Server Using Bind Prerequisites and Assumptions A server running Rocky Linux Several internal servers that need to be accessed only locally, but not over the Internet Several workstations that need access to these same servers that exist on the same network A healthy comfort level with entering commands from command line Familarity with a command line editor (we are using vi in this example) Able to use either firewalld or iptables for creating firewall rules. We've provided both iptables and firewalld options. If you plan to use iptables , use the Enabling Iptables Firewall procedure Introduction External, or public, DNS servers are used on the Internet to map host names to IP addresses and, in the case of PTR (known as \"pointer\" or \"reverse\") records, to map the IP to the host name. This is an essential part of the Internet. It makes your mail server, web server, FTP server, or many other servers and services work as expected no matter where you are. On a private network, particularly one that is being used for developing multiple systems, you can use your Rocky Linux workstation's /etc/hosts file to map a name to an IP address. This will work for your workstation, but not for any other machine on your network. If you want to make things universally applied, then the best method is to take some time out and create a local, private DNS server to handle this for all of your machines. If you were creating production-level public DNS servers and resolvers, then this author would probably recommend the more robust PowerDNS authoritative and recursive DNS, which is easily installed on Rocky Linux servers. However, that is simply overkill for a local network that won't be exposing its DNS servers to the outside world. That is why we have chosen bind for this example. The DNS Server Components Explained As stated, DNS separates services into authoritative and recursive servers. These services are now recommended to be separate from each other on separate hardware or containers. The authoritative server is the storage area for all IP addresses and host names, and the recursive server is used to lookup addresses and host names. In the case of our private DNS server, both the authoritative and the recursive server services will run together. Installing and Enabling Bind The first step is to install packages. In the case of bind we need to execute the following command: dnf install bind bind-utils The service daemon for bind is called named , and we need to enable this to start on boot: systemctl enable named And then we need to start it: systemctl start named Configuration Before making changes to any configuration file, it is a good idea to make a backup copy of the original installed working file, in this case named.conf : cp /etc/named.conf /etc/named.conf.orig That will help in the future if errors are introduced into the configuration file. It is always a good idea to make a backup copy before making changes. These changes require us to edit the named.conf file, to do this, we are using vi , but you can substitute your favorite command line editor (the editor nano is also installed in Rocky Linux and is easier to use than vi ): vi /etc/named.conf First thing we want to do is turn off listening on the localhost, this is done by remarking out with a \"#\" sign, these two lines in the \"options\" section. What this does is to effectively shutdown any connection to the outside world. This is helpful, particularly when we go to add this DNS to our workstations, because we want these DNS server to only respond when the IP address requesting the service is local, and simply not respond at all if the service that is being looked up is on the Internet. This way, the other configured DNS servers will take over nearly immediately to look up the Internet based services: options { # listen-on port 53 { 127.0.0.1; }; # listen-on-v6 port 53 { ::1; }; Finally, skip down to the bottom of the named.conf file and add a section for your network. Our example is using ourdomain, so sub in what you want to call your LAN hosts: # primary forwward and reverse zones //forward zone zone \"ourdomain.lan\" IN { type master; file \"ourdomain.lan.db\"; allow-update { none; }; allow-query {any; }; }; //reverse zone zone \"1.168.192.in-addr.arpa\" IN { type master; file \"ourdomain.lan.rev\"; allow-update { none; }; allow-query { any; }; }; Now save your changes (for vi , SHIFT:wq! ) Using IPv4 On Your LAN If you are using IPv4 only on your LAN, then you need to make two changes. The first is in /etc/named.conf and the second is in /etc/sysconfig/named First, get back into the named.conf file again with vi /etc/named.conf . We need to add the following option anywhere in the options section. filter-aaaa-on-v4 yes; This is shown in the image below: Once you've made the change, save it and exit the named.conf (for vi , SHIFT:wq! ) Next we need to make a similar change to /etc/sysconfig/named : vi /etc/sysconfig/named And then add this to the bottom of the file: OPTIONS=\"-4\" Now save those changes (again, for vi , SHIFT:wq! ) The Forward and Reverse Records Next, we need to create two files in /var/named . These files are the ones that you will edit if you add machines to your network that you want to include in the DNS. The first is the forward file to map our IP address to the hostname. Again, we are using \"ourdomain\" as our example here. Note that the IP of our local DNS here is 192.168.1.136. The hosts are added at the bottom of this file. vi /var/named/ourdomain.lan.db The file will look something like this when you are done: $TTL 86400 @ IN SOA dns-primary.ourdomain.lan. admin.ourdomain.lan. ( 2019061800 ;Serial 3600 ;Refresh 1800 ;Retry 604800 ;Expire 86400 ;Minimum TTL ) ;Name Server Information @ IN NS dns-primary.ourdomain.lan. ;IP for Name Server dns-primary IN A 192.168.1.136 ;A Record for IP address to Hostname wiki IN A 192.168.1.13 www IN A 192.168.1.14 devel IN A 192.168.1.15 Add as many hosts as you need to the bottom of the file along with their IP addresses and then save your changes. Next, we need a reverse file to map our hostname to the IP address, In this case, the only part of the IP that you need is the last octet (in an IPv4 address each number separated by a period, is an octet) of the host and then the PTR and hostname. vi /var/named/ourdomain.lan.rev And the file should look something like this when you are done.: $TTL 86400 @ IN SOA dns-primary.ourdomain.lan. admin.ourdomain.lan. ( 2019061800 ;Serial 3600 ;Refresh 1800 ;Retry 604800 ;Expire 86400 ;Minimum TTL ) ;Name Server Information @ IN NS dns-primary.ourdomain.lan. ;Reverse lookup for Name Server 136 IN PTR dns-primary.ourdomain.lan. ;PTR Record IP address to HostName 13 IN PTR wiki.ourdomain.lan. 14 IN PTR www.ourdomain.lan. 15 IN PTR devel.ourdomain.lan. Add all of the hostnames that appear in the forward file and then save your changes. What All Of This Means Now that we have all of this added in and are preparing to restart our bind DNS server, let's just explore some of the terminology that is used in these two files. Just making things work isn't good enough if you don't know what each term means, right? TTL appears in both files and it stands for \"Time To Live.\" TTL tells the DNS server how long to keep its cache in place before requesting a fresh copy. In this case, the TTL is the default setting for all records unless a specific record TTL is set. The default here is 86400 seconds or 24 hours. IN stands for Internet. In this case, we aren't actually using the Internet, so think of this as the Intranet. SOA stands for \"Start Of Authority\" or what the primary DNS server is for the domain. NS stands for \"name server\" Serial is the value used by the DNS server to verify that the contents of the zone file are up-to-date. Refresh specifies how often a slave DNS server should do a zone transfer from the master. Retry specifies the length of time in seconds to wait before trying again on a failed zone transfer. Expire specifies how long a slave server should wait to answer a query when the master is unreachable. A Is the host address or forward record and is only in the forward file (above). PTR Is the pointer record better known as the \"reverse\" and is only in our reverse file (above). Testing Configurations Once we have gotten all of our files created, we need to make sure that the configuration files and zones are in good working order before we start the bind service again. Check the main configuration: named-checkconf This should return an empty result if everything is OK. Then check the forward zone: named-checkzone ourdomain.lan /var/named/ourdomain.lan.db This should return something like this if all is well: zone ourdomain.lan/IN: loaded serial 2019061800 OK And finally check the reverse zone: named-checkzone 192.168.1.136 /var/named/ourdomain.lan.rev Which should return something like this if all is well: zone 192.168.1.136/IN: loaded serial 2019061800 OK Assuming that everything looks good, go ahead and restart bind : systemctl restart named Testing Machines You need to add the DNS server (in our example 192.168.1.136) to each machine that you want to have access to the servers that you added to your new local DNS. We are only going to show you an example of how to do this on a Rocky Linux workstation, but there are similar methods for other Linux distributions, as well as Windows and Mac machines. Keep in mind that you will want to just add the DNS server in the list, as you will still need Internet access, which will require your currently assigned DNS servers. These might be assigned via DHCP (Dynamic Host Configuration Protocol) or statically assigned. On a Rocky Linux workstation where the enabled network interface is eth0, you would use: vi /etc/sysconfig/network-scripts/ifcfg-eth0 If your enabled network interface is different, you will need to substitute that interface name. The configuration file that you open will look something like this for a statically assigned IP (not DHCP as mentioned above). In the example below, our machine's IP address is 192.168.1.151: DEVICE=eth0 BOOTPROTO=none IPADDR=192.168.1.151 PREFIX=24 GATEWAY=192.168.1.1 DNS1=8.8.8.8 DNS2=8.8.4.4 ONBOOT=yes HOSTNAME=tender-kiwi TYPE=Ethernet MTU= We want to substitute in our new DNS server for the primary (DNS1) and then move each of the other DNS servers down one so that it is like this: DEVICE=eth0 BOOTPROTO=none IPADDR=192.168.1.151 PREFIX=24 GATEWAY=192.168.1.1 DNS1=192.168.1.136 DNS2=8.8.8.8 DNS3=8.8.4.4 ONBOOT=yes HOSTNAME=tender-kiwi TYPE=Ethernet MTU= Once you've made the change, either restart the machine or restart networking with: systemctl restart network Now you should be able to get to anything in the ourdomain.lan domain from your workstation, plus still be able to resovle and get to Internet addresses. Firewall Rules Adding The Firewall Rules - iptables First, create a file in /etc called \"firewall.conf\" that will contain the following rules. This is a bare minimum rule set, and you may need to tweak this for your environment: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT # dns rules iptables -A INPUT -p udp -m udp -s 192.168.1.0/24 --dport 53 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Let's evaluate the rules above: The first \"iptables\" line flushes the rules that are currently loaded (-F). Next, we are setting a default policy for the INPUT chain of DROP. This means, if the traffic is not explicitly allowed here, it is dropped. Next, we have an SSH rule for our local network, so that we can get into the DNS server remotely. Then we have our DNS allow rule, only for our local network. Note that DNS uses the UDP protocol (User Datagram Protocol). Next we allow INPUT from the local interface. Then if you have established a connection for something else, we are allowing related packets in as well. And finally we reject everything else. The last line tells iptables to save the rules so that when the machine restarts, the rules will load as well. Once our firewall.conf file is created, we need to make it executable: chmod +x /etc/firewall.conf Then run it: /etc/firewall.conf And this is what you should get in return. If you get something else, take a look at your script for errors: clearing any existing rules and setting default policy.. iptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ] Adding The Firewall Rules - firewalld With firewalld , we are duplicating the rules highlighted in iptables above. We aren't making any other assumptions about the network or services that might be needed. We are turning on SSH access and DNS access for our LAN network only. For this, we will use the firewalld built-in zone, \"trusted\". We will also have to make some service changes to the \"public\" zone in order to limit SSH access to the LAN. The first step is to add our LAN network to the \"trusted\" zone: firewall-cmd --zone=trusted --add-source=192.168.1.0/24 --permanent Next, we need to add our two services to the \"trusted\" zone: firewall-cmd --zone=trusted --add-service=ssh --permanent firewall-cmd --zone=trusted --add-service=dns --permanent Finally, we need to remove the SSH service from our \"public\" zone, which is on by default: firewall-cmd --zone=public --remove-service=ssh --permanent Next, reload the firewall and then list out the zones that we've made changes to: firewall-cmd --reload firewall-cmd --zone=trusted --list-all Which should show that you have correctly added the services and the source network: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: dns ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Listing out the \"public\" zone should show that SSH access is no-longer allowed: firewall-cmd --zone=public --list-all public target: default icmp-block-inversion: no interfaces: sources: services: cockpit dhcpv6-client ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: These rules should get you DNS resolution on your private DNS server from hosts on the 192.168.1.0/24 network. In addition, you should be able to SSH from any of those hosts into your private DNS server. Conclusions While using /etc/hosts on an individual workstation will get you access to a machine on your internal network, you can only use it on that one machine. By adding a private DNS server using bind , you can add hosts to the DNS and as long as the workstations have access to that private DNS server, they will be able to get to these local servers. If you don't need machines to resolve on the Internet, but do need local access from several machines to local servers, then consider using a private DNS server instead.","title":"Bind Private DNS Server"},{"location":"guides/dns/private_dns_server_using_bind/#private-dns-server-using-bind","text":"","title":"Private DNS Server Using Bind"},{"location":"guides/dns/private_dns_server_using_bind/#prerequisites-and-assumptions","text":"A server running Rocky Linux Several internal servers that need to be accessed only locally, but not over the Internet Several workstations that need access to these same servers that exist on the same network A healthy comfort level with entering commands from command line Familarity with a command line editor (we are using vi in this example) Able to use either firewalld or iptables for creating firewall rules. We've provided both iptables and firewalld options. If you plan to use iptables , use the Enabling Iptables Firewall procedure","title":"Prerequisites and Assumptions"},{"location":"guides/dns/private_dns_server_using_bind/#introduction","text":"External, or public, DNS servers are used on the Internet to map host names to IP addresses and, in the case of PTR (known as \"pointer\" or \"reverse\") records, to map the IP to the host name. This is an essential part of the Internet. It makes your mail server, web server, FTP server, or many other servers and services work as expected no matter where you are. On a private network, particularly one that is being used for developing multiple systems, you can use your Rocky Linux workstation's /etc/hosts file to map a name to an IP address. This will work for your workstation, but not for any other machine on your network. If you want to make things universally applied, then the best method is to take some time out and create a local, private DNS server to handle this for all of your machines. If you were creating production-level public DNS servers and resolvers, then this author would probably recommend the more robust PowerDNS authoritative and recursive DNS, which is easily installed on Rocky Linux servers. However, that is simply overkill for a local network that won't be exposing its DNS servers to the outside world. That is why we have chosen bind for this example.","title":"Introduction"},{"location":"guides/dns/private_dns_server_using_bind/#the-dns-server-components-explained","text":"As stated, DNS separates services into authoritative and recursive servers. These services are now recommended to be separate from each other on separate hardware or containers. The authoritative server is the storage area for all IP addresses and host names, and the recursive server is used to lookup addresses and host names. In the case of our private DNS server, both the authoritative and the recursive server services will run together.","title":"The DNS Server Components Explained"},{"location":"guides/dns/private_dns_server_using_bind/#installing-and-enabling-bind","text":"The first step is to install packages. In the case of bind we need to execute the following command: dnf install bind bind-utils The service daemon for bind is called named , and we need to enable this to start on boot: systemctl enable named And then we need to start it: systemctl start named","title":"Installing and Enabling Bind"},{"location":"guides/dns/private_dns_server_using_bind/#configuration","text":"Before making changes to any configuration file, it is a good idea to make a backup copy of the original installed working file, in this case named.conf : cp /etc/named.conf /etc/named.conf.orig That will help in the future if errors are introduced into the configuration file. It is always a good idea to make a backup copy before making changes. These changes require us to edit the named.conf file, to do this, we are using vi , but you can substitute your favorite command line editor (the editor nano is also installed in Rocky Linux and is easier to use than vi ): vi /etc/named.conf First thing we want to do is turn off listening on the localhost, this is done by remarking out with a \"#\" sign, these two lines in the \"options\" section. What this does is to effectively shutdown any connection to the outside world. This is helpful, particularly when we go to add this DNS to our workstations, because we want these DNS server to only respond when the IP address requesting the service is local, and simply not respond at all if the service that is being looked up is on the Internet. This way, the other configured DNS servers will take over nearly immediately to look up the Internet based services: options { # listen-on port 53 { 127.0.0.1; }; # listen-on-v6 port 53 { ::1; }; Finally, skip down to the bottom of the named.conf file and add a section for your network. Our example is using ourdomain, so sub in what you want to call your LAN hosts: # primary forwward and reverse zones //forward zone zone \"ourdomain.lan\" IN { type master; file \"ourdomain.lan.db\"; allow-update { none; }; allow-query {any; }; }; //reverse zone zone \"1.168.192.in-addr.arpa\" IN { type master; file \"ourdomain.lan.rev\"; allow-update { none; }; allow-query { any; }; }; Now save your changes (for vi , SHIFT:wq! )","title":"Configuration"},{"location":"guides/dns/private_dns_server_using_bind/#using-ipv4-on-your-lan","text":"If you are using IPv4 only on your LAN, then you need to make two changes. The first is in /etc/named.conf and the second is in /etc/sysconfig/named First, get back into the named.conf file again with vi /etc/named.conf . We need to add the following option anywhere in the options section. filter-aaaa-on-v4 yes; This is shown in the image below: Once you've made the change, save it and exit the named.conf (for vi , SHIFT:wq! ) Next we need to make a similar change to /etc/sysconfig/named : vi /etc/sysconfig/named And then add this to the bottom of the file: OPTIONS=\"-4\" Now save those changes (again, for vi , SHIFT:wq! )","title":"Using IPv4 On Your LAN"},{"location":"guides/dns/private_dns_server_using_bind/#the-forward-and-reverse-records","text":"Next, we need to create two files in /var/named . These files are the ones that you will edit if you add machines to your network that you want to include in the DNS. The first is the forward file to map our IP address to the hostname. Again, we are using \"ourdomain\" as our example here. Note that the IP of our local DNS here is 192.168.1.136. The hosts are added at the bottom of this file. vi /var/named/ourdomain.lan.db The file will look something like this when you are done: $TTL 86400 @ IN SOA dns-primary.ourdomain.lan. admin.ourdomain.lan. ( 2019061800 ;Serial 3600 ;Refresh 1800 ;Retry 604800 ;Expire 86400 ;Minimum TTL ) ;Name Server Information @ IN NS dns-primary.ourdomain.lan. ;IP for Name Server dns-primary IN A 192.168.1.136 ;A Record for IP address to Hostname wiki IN A 192.168.1.13 www IN A 192.168.1.14 devel IN A 192.168.1.15 Add as many hosts as you need to the bottom of the file along with their IP addresses and then save your changes. Next, we need a reverse file to map our hostname to the IP address, In this case, the only part of the IP that you need is the last octet (in an IPv4 address each number separated by a period, is an octet) of the host and then the PTR and hostname. vi /var/named/ourdomain.lan.rev And the file should look something like this when you are done.: $TTL 86400 @ IN SOA dns-primary.ourdomain.lan. admin.ourdomain.lan. ( 2019061800 ;Serial 3600 ;Refresh 1800 ;Retry 604800 ;Expire 86400 ;Minimum TTL ) ;Name Server Information @ IN NS dns-primary.ourdomain.lan. ;Reverse lookup for Name Server 136 IN PTR dns-primary.ourdomain.lan. ;PTR Record IP address to HostName 13 IN PTR wiki.ourdomain.lan. 14 IN PTR www.ourdomain.lan. 15 IN PTR devel.ourdomain.lan. Add all of the hostnames that appear in the forward file and then save your changes.","title":"The Forward and Reverse Records"},{"location":"guides/dns/private_dns_server_using_bind/#what-all-of-this-means","text":"Now that we have all of this added in and are preparing to restart our bind DNS server, let's just explore some of the terminology that is used in these two files. Just making things work isn't good enough if you don't know what each term means, right? TTL appears in both files and it stands for \"Time To Live.\" TTL tells the DNS server how long to keep its cache in place before requesting a fresh copy. In this case, the TTL is the default setting for all records unless a specific record TTL is set. The default here is 86400 seconds or 24 hours. IN stands for Internet. In this case, we aren't actually using the Internet, so think of this as the Intranet. SOA stands for \"Start Of Authority\" or what the primary DNS server is for the domain. NS stands for \"name server\" Serial is the value used by the DNS server to verify that the contents of the zone file are up-to-date. Refresh specifies how often a slave DNS server should do a zone transfer from the master. Retry specifies the length of time in seconds to wait before trying again on a failed zone transfer. Expire specifies how long a slave server should wait to answer a query when the master is unreachable. A Is the host address or forward record and is only in the forward file (above). PTR Is the pointer record better known as the \"reverse\" and is only in our reverse file (above).","title":"What All Of This Means"},{"location":"guides/dns/private_dns_server_using_bind/#testing-configurations","text":"Once we have gotten all of our files created, we need to make sure that the configuration files and zones are in good working order before we start the bind service again. Check the main configuration: named-checkconf This should return an empty result if everything is OK. Then check the forward zone: named-checkzone ourdomain.lan /var/named/ourdomain.lan.db This should return something like this if all is well: zone ourdomain.lan/IN: loaded serial 2019061800 OK And finally check the reverse zone: named-checkzone 192.168.1.136 /var/named/ourdomain.lan.rev Which should return something like this if all is well: zone 192.168.1.136/IN: loaded serial 2019061800 OK Assuming that everything looks good, go ahead and restart bind : systemctl restart named","title":"Testing Configurations"},{"location":"guides/dns/private_dns_server_using_bind/#testing-machines","text":"You need to add the DNS server (in our example 192.168.1.136) to each machine that you want to have access to the servers that you added to your new local DNS. We are only going to show you an example of how to do this on a Rocky Linux workstation, but there are similar methods for other Linux distributions, as well as Windows and Mac machines. Keep in mind that you will want to just add the DNS server in the list, as you will still need Internet access, which will require your currently assigned DNS servers. These might be assigned via DHCP (Dynamic Host Configuration Protocol) or statically assigned. On a Rocky Linux workstation where the enabled network interface is eth0, you would use: vi /etc/sysconfig/network-scripts/ifcfg-eth0 If your enabled network interface is different, you will need to substitute that interface name. The configuration file that you open will look something like this for a statically assigned IP (not DHCP as mentioned above). In the example below, our machine's IP address is 192.168.1.151: DEVICE=eth0 BOOTPROTO=none IPADDR=192.168.1.151 PREFIX=24 GATEWAY=192.168.1.1 DNS1=8.8.8.8 DNS2=8.8.4.4 ONBOOT=yes HOSTNAME=tender-kiwi TYPE=Ethernet MTU= We want to substitute in our new DNS server for the primary (DNS1) and then move each of the other DNS servers down one so that it is like this: DEVICE=eth0 BOOTPROTO=none IPADDR=192.168.1.151 PREFIX=24 GATEWAY=192.168.1.1 DNS1=192.168.1.136 DNS2=8.8.8.8 DNS3=8.8.4.4 ONBOOT=yes HOSTNAME=tender-kiwi TYPE=Ethernet MTU= Once you've made the change, either restart the machine or restart networking with: systemctl restart network Now you should be able to get to anything in the ourdomain.lan domain from your workstation, plus still be able to resovle and get to Internet addresses.","title":"Testing Machines"},{"location":"guides/dns/private_dns_server_using_bind/#firewall-rules","text":"","title":"Firewall Rules"},{"location":"guides/dns/private_dns_server_using_bind/#adding-the-firewall-rules-iptables","text":"First, create a file in /etc called \"firewall.conf\" that will contain the following rules. This is a bare minimum rule set, and you may need to tweak this for your environment: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT # dns rules iptables -A INPUT -p udp -m udp -s 192.168.1.0/24 --dport 53 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Let's evaluate the rules above: The first \"iptables\" line flushes the rules that are currently loaded (-F). Next, we are setting a default policy for the INPUT chain of DROP. This means, if the traffic is not explicitly allowed here, it is dropped. Next, we have an SSH rule for our local network, so that we can get into the DNS server remotely. Then we have our DNS allow rule, only for our local network. Note that DNS uses the UDP protocol (User Datagram Protocol). Next we allow INPUT from the local interface. Then if you have established a connection for something else, we are allowing related packets in as well. And finally we reject everything else. The last line tells iptables to save the rules so that when the machine restarts, the rules will load as well. Once our firewall.conf file is created, we need to make it executable: chmod +x /etc/firewall.conf Then run it: /etc/firewall.conf And this is what you should get in return. If you get something else, take a look at your script for errors: clearing any existing rules and setting default policy.. iptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ]","title":"Adding The Firewall Rules - iptables"},{"location":"guides/dns/private_dns_server_using_bind/#adding-the-firewall-rules-firewalld","text":"With firewalld , we are duplicating the rules highlighted in iptables above. We aren't making any other assumptions about the network or services that might be needed. We are turning on SSH access and DNS access for our LAN network only. For this, we will use the firewalld built-in zone, \"trusted\". We will also have to make some service changes to the \"public\" zone in order to limit SSH access to the LAN. The first step is to add our LAN network to the \"trusted\" zone: firewall-cmd --zone=trusted --add-source=192.168.1.0/24 --permanent Next, we need to add our two services to the \"trusted\" zone: firewall-cmd --zone=trusted --add-service=ssh --permanent firewall-cmd --zone=trusted --add-service=dns --permanent Finally, we need to remove the SSH service from our \"public\" zone, which is on by default: firewall-cmd --zone=public --remove-service=ssh --permanent Next, reload the firewall and then list out the zones that we've made changes to: firewall-cmd --reload firewall-cmd --zone=trusted --list-all Which should show that you have correctly added the services and the source network: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: dns ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Listing out the \"public\" zone should show that SSH access is no-longer allowed: firewall-cmd --zone=public --list-all public target: default icmp-block-inversion: no interfaces: sources: services: cockpit dhcpv6-client ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: These rules should get you DNS resolution on your private DNS server from hosts on the 192.168.1.0/24 network. In addition, you should be able to SSH from any of those hosts into your private DNS server.","title":"Adding The Firewall Rules - firewalld"},{"location":"guides/dns/private_dns_server_using_bind/#conclusions","text":"While using /etc/hosts on an individual workstation will get you access to a machine on your internal network, you can only use it on that one machine. By adding a private DNS server using bind , you can add hosts to the DNS and as long as the workstations have access to that private DNS server, they will be able to get to these local servers. If you don't need machines to resolve on the Internet, but do need local access from several machines to local servers, then consider using a private DNS server instead.","title":"Conclusions"},{"location":"guides/editors/micro/","tags":["editor","editors","micro"],"text":"Install micro on Rocky Linux Introduction micro is a fantastic little terminal-based text editor that sits between nano and vim in terms of complexity. It has a simple, easily-recognized workflow with several awesome features: All of your usual \u201cControl-C\u201d, \u201dControl-V\u201d, and \u201cControl-F\u201d commands work as they would in a desktop-based text editor. All keybindings can be re-bound, of course. Mouse support \u2014 click and drag to select text, double-click to select words, triple-click to select lines. Over 75 languages supported with syntax highlighting by default. Multiple cursors for when you need to edit multiple lines at a time. Includes a plugin system. Multiple panes. And here\u2019s how it looks in my own terminal: !!! Note You *can* install micro via a snap app. If you're already using snap on your machine.. I mean... why not? But I prefer to get it straight from the source. Prerequisites Any internet-connected Rocky Linux machine or container. A basic knowledge of the command line, and a desire to edit your text there. Some commands will need to be run as root, or with sudo . How to Install micro This is maybe the easiest tutorial I\u2019ve written so far, with exactly three commands. First, you make sure that tar and curl are installed. This should only really be relevant if you\u2019re running a minimal install of Rocky, or running it inside a container. sudo dnf install tar curl Next, you\u2019ll need the installer from micro \u2019s website. The following command will get the installer, and run it for you in whatever directory you\u2019re working in. I know we don\u2019t normally advise copying and pasting commands from websites, but this one has never given me any trouble. curl https://getmic.ro | bash To install the app system-wide (and so you can just type \u201cmicro\u201d to open up the app), you can run the script as root inside of /usr/bin/ . However, if you want to check it out first and be careful about it, you can install the micro to any folder you want, and then move the app later with: sudo mv micro /usr/bin/ And that\u2019s it! Happy text editing. The Really Easy Way I created a dead-simple script that basically just runs all of those commands. You can find it in my Github gists , and either copy/paste the text to a file on your machine, or download it with wget . Uninstalling micro Go to the folder you installed micro in and (using your godly root powers as necessary) run: rm micro Also, micro will leave some configuration files in your home directory (and the home directories of every user who has run it). You can get rid of those with: rm -rf /home/[username]/.config/micro Conclusion If you want a full guide to using micro , check out the main website , and the documentation in the Github repo . You can also press \u201cControl-G\u201d to open the main help file inside of the app itself. micro probably won\u2019t meet the needs of those who have dedicated themselves to the vim or emacs experience, but it\u2019s perfect for people like me. I\u2019ve always wanted that old Sublime Text experience in the terminal, and now I have something really close. Try it out, see if it works for you.","title":"micro"},{"location":"guides/editors/micro/#install-micro-on-rocky-linux","text":"","title":"Install micro on Rocky Linux"},{"location":"guides/editors/micro/#introduction","text":"micro is a fantastic little terminal-based text editor that sits between nano and vim in terms of complexity. It has a simple, easily-recognized workflow with several awesome features: All of your usual \u201cControl-C\u201d, \u201dControl-V\u201d, and \u201cControl-F\u201d commands work as they would in a desktop-based text editor. All keybindings can be re-bound, of course. Mouse support \u2014 click and drag to select text, double-click to select words, triple-click to select lines. Over 75 languages supported with syntax highlighting by default. Multiple cursors for when you need to edit multiple lines at a time. Includes a plugin system. Multiple panes. And here\u2019s how it looks in my own terminal: !!! Note You *can* install micro via a snap app. If you're already using snap on your machine.. I mean... why not? But I prefer to get it straight from the source.","title":"Introduction"},{"location":"guides/editors/micro/#prerequisites","text":"Any internet-connected Rocky Linux machine or container. A basic knowledge of the command line, and a desire to edit your text there. Some commands will need to be run as root, or with sudo .","title":"Prerequisites"},{"location":"guides/editors/micro/#how-to-install-micro","text":"This is maybe the easiest tutorial I\u2019ve written so far, with exactly three commands. First, you make sure that tar and curl are installed. This should only really be relevant if you\u2019re running a minimal install of Rocky, or running it inside a container. sudo dnf install tar curl Next, you\u2019ll need the installer from micro \u2019s website. The following command will get the installer, and run it for you in whatever directory you\u2019re working in. I know we don\u2019t normally advise copying and pasting commands from websites, but this one has never given me any trouble. curl https://getmic.ro | bash To install the app system-wide (and so you can just type \u201cmicro\u201d to open up the app), you can run the script as root inside of /usr/bin/ . However, if you want to check it out first and be careful about it, you can install the micro to any folder you want, and then move the app later with: sudo mv micro /usr/bin/ And that\u2019s it! Happy text editing.","title":"How to Install micro"},{"location":"guides/editors/micro/#the-really-easy-way","text":"I created a dead-simple script that basically just runs all of those commands. You can find it in my Github gists , and either copy/paste the text to a file on your machine, or download it with wget .","title":"The Really Easy Way"},{"location":"guides/editors/micro/#uninstalling-micro","text":"Go to the folder you installed micro in and (using your godly root powers as necessary) run: rm micro Also, micro will leave some configuration files in your home directory (and the home directories of every user who has run it). You can get rid of those with: rm -rf /home/[username]/.config/micro","title":"Uninstalling micro"},{"location":"guides/editors/micro/#conclusion","text":"If you want a full guide to using micro , check out the main website , and the documentation in the Github repo . You can also press \u201cControl-G\u201d to open the main help file inside of the app itself. micro probably won\u2019t meet the needs of those who have dedicated themselves to the vim or emacs experience, but it\u2019s perfect for people like me. I\u2019ve always wanted that old Sublime Text experience in the terminal, and now I have something really close. Try it out, see if it works for you.","title":"Conclusion"},{"location":"guides/email/postfix_reporting/","text":"Using Postfix For Server Process Reporting Prerequisites Complete comfort operating from the command line on a Rocky Linux server Familiarity with an editor of your choice (this document uses the vi editor, but you can substitute in your favorite editor) An understanding of DNS (the Domain Name System) and host names The ability to assign variables in a bash script Knowledge of what the tail , more , grep , and date commands do Introduction Many Rocky Linux server administrators write scripts to perform specific tasks, like backups or file synchronization, and many of these scripts generate logs that have useful and sometimes very important information. Just having the logs, though, is not enough. If a process fails and logs that failure, but the busy administrator does not review the log, then a catastrophe could be in the making. This document shows you how to use the postfix MTA (mail transfer agent) to grab log details from a particular process, and send them to you via email. It also touches on date formats in logs, and helps you identify which format you need to use in the reporting procedure. Keep in mind, though, that this is just the tip of the iceberg as far as what can be done with reporting via postfix. Please note, too, that it is always a good security move to limit running processes to only those that you will need all the time. This document shows you how to enable postfix only for the reporting you need it to do, and then shut it down again. Postfix Defined postfix is a server daemon used for sending email. It is more secure and simpler than sendmail, another MTA that was the default go-to MTA for years. It can be used as part of a full-featured mail server. Installing postfix Aside from postfix, we will need mailx for testing our ability to send emails. To install both, and any dependencies required, enter the following on the Rocky Linux server command line: dnf install postfix mailx Testing And Configuring Postfix Testing Mail First Before we configure postfix, we need to find out how mail will look when it leaves the server, because we will probably want to change this. To do this, start postfix: systemctl start postfix Then test it using mail command that is installed with mailx: mail -s \"Testing from server\" myname@mydomain.com This will bring up a blank line. Simply type your testing message in here: testing from the server Now hit enter, and enter a single period: . The system will respond with: EOT Our purpose for doing this is to check to see how our mail looks to the outside world, which we can get a feel for from the maillog that goes active with the starting of postfix. Use this command to see the output of the log file: tail /var/log/maillog You should see something like this, although the log file may have different domains for the email address, etc: Mar 4 16:51:40 hedgehogct postfix/postfix-script[735]: starting the Postfix mail system Mar 4 16:51:40 hedgehogct postfix/master[737]: daemon started -- version 3.3.1, configuration /etc/postfix Mar 4 16:52:04 hedgehogct postfix/pickup[738]: C9D42EC0ADD: uid=0 from=<root> Mar 4 16:52:04 hedgehogct postfix/cleanup[743]: C9D42EC0ADD: message-id=<20210304165204.C9D42EC0ADD@somehost.localdomain> Mar 4 16:52:04 hedgehogct postfix/qmgr[739]: C9D42EC0ADD: from=<root@somehost.localdomain>, size=457, nrcpt=1 (queue active) Mar 4 16:52:05 hedgehogct postfix/smtp[745]: connect to gmail-smtp-in.l.google.com[2607:f8b0:4001:c03::1a]:25: Network is unreachable Mar 4 16:52:06 hedgehogct postfix/smtp[745]: C9D42EC0ADD: to=<myname@mydomain.com>, relay=gmail-smtp-in.l.google.com[172.217.212.26] :25, delay=1.4, delays=0.02/0.02/0.99/0.32, dsn=2.0.0, status=sent (250 2.0.0 OK 1614876726 z8si17418573ilq.142 - gsmtp) Mar 4 16:52:06 hedgehogct postfix/qmgr[739]: C9D42EC0ADD: removed The \"somehost.localdomain\" shows us that we need to make some changes, so stop the postfix daemon first: systemctl stop postfix Configuring Postfix Since we aren't setting up a complete, fully functional mail server, the configuration options that we will be using are not as extensive. The first thing we need to do is to modify the main.cf file (literally the main configuration file for postfix), so let's make a backup first: cp /etc/postifix/main.cf /etc/postfix/main.cf.bak Then edit it: vi /etc/postfix/main.cf In our example, our server name is going to be \"bruno\" and our domain name is going to be \"ourdomain.com\". Find the line in the file: #myhostname = host.domain.tld You can either remove the remark (#) or you can add a new line under this line. Based on our example, the line would read: myhostname = bruno.ourdomain.com Next, find the line for the domain name: #mydomain = domain.tld Either remove the remark and change it, or add a new line: mydomain = ourdomain.com Finally, go to the bottom of the file and add this line: smtp_generic_maps = hash:/etc/postfix/generic Save your changes (in vi, that will be Shift : wq! ) and exit the file. Before we continue editing the generic file, we need to see how email will look. Specifically, we want to create the \"generic\" file that we referenced in the main.cf file above: vi /etc/postfix/generic This file tells postfix how any email coming from this server should look. Remember our test email and the log file? This is where we fix all of that: root@somehost.localdomain root@bruno.ourdomain.com @somehost.localdomain root@bruno.ourdomain.com Now we need to tell postfix to use all of our changes. This is done with the postmap command: postmap /etc/postfix/generic Now start postfix and test your email again using the same procedure as above. You should now see that all of the \"localdomain\" instances have been changed to your actual domain. The date Command and a Variable Called today Not every application will use the same logging format for the date. This means that you may have to get creative with any script you write for reporting by date. Let's say that you want to look at your system log as an example and pull everything that has to do with dbus-daemon for today's date, and email it to yourself. (It's probably not the greatest example, but it will give you an idea of how we would do this.) We need to use a a variable in our script that we will call \"today\" and we want it to relate to output from the \"date\" command and format it in a specific way, so that we can get the data we need from our system log (in /var/log/messages ). To start with, let's do some investigative work. First, enter the date command in the command line: date This should give you the default system date output, which could be something like this: Thu Mar 4 18:52:28 UTC 2021 Now let's check our system log and see how it records information. To do this, we will use the \"more\" and \"grep\" commands: more /var/log/messages | grep dbus-daemon Which should give you something like this: Mar 4 18:23:53 hedgehogct dbus-daemon[60]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher' Mar 4 18:50:41 hedgehogct dbus-daemon[60]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.freedesktop.nm-dispatcher.service' requested by ':1.1' (uid=0 pid=61 comm=\"/usr/sbin/NetworkManager --no-daemon \" label=\"unconfined\") Mar 4 18:50:41 hedgehogct dbus-daemon[60]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher The date and log outputs need to be exactly the same in our script, so let's look at how to format the date using a variable called \"today\". First, let's look at what we need to do with the date to get the same output as the system log. You can reference the Linux man page or type man date on the command line to pull up the date manual page to get the information you need. What you will find is that in order to format the date the same way that /var/log/messages has it, we need to use the %b and %e format strings, with %b being the 3 character month and %e being the space-padded day. The Script For our bash script, we can see that we are going to use the date command and a variable called \"today\". (Keep in mind that \"today\" is arbitrary. You could call this variable \"late_for_dinner\" if you wanted!). We will call our script in this example, test.sh and place it in /usr/local/sbin : vi /usr/local/sbin/test.sh Let's start with, well, the beginning of our script. Note that even though the comment in our file says we are sending these messages to email, for now, we are just sending them to a standard log output so that we can verify that they are correct. Also, in our first attempt, we are grabbing all of the messages for the current date, not just the dbus-daemon messages. We will deal with that shortly. Another thing to be aware of is that the grep command will return the filename in the output, which we don't want in this case, so we have added the \"-h\" option to grep to remove the prefix of the filename. In addition, once the variable \"today\" is set, we need to look for the entire variable as a string, so we need it all in quotes: #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages That's it for now, so save your changes and then make the script executable: chmod +x /usr/local/sbin/test.sh And then let's test it: /usr/local/sbin/test.sh If all works correctly, you should get a long list of all of the messages in /var/log/messages from today, including but not limited to the dbus-daemon messages. If so, then the next step is to limit the messages to the dbus-daemon messages. So let's modify our script again: vi /usr/local/sbin/test.sh #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages | grep dbus-daemon Running the script again, should get you only the dbus-daemon messages and only the ones that occurred today (whenever you're following this guide). There's one final step, however. Remember, we need to get this emailed to the administrator for review. Also, because we are only using postfix on this server for reporting, we don't want to leave the service running, so we will start it at the beginning of the script and then stop it at the end. We'll introduce the sleep command here to pause for 20 seconds to make sure that the email has been sent before shutting postfix down again. This final edit, adds the stop, start, and sleep issues just discussed, and also pipes the content to the administrator's email. vi /usr/local/sbin/test.sh And modify the script: #!/bin/bash # start postfix /usr/bin/systemctl start postfix # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages | grep dbus-daemon | mail -s \"dbus-daemon messages for today\" myname@mydomain.com # make sure the email has finished before continuing sleep 20 # stop postfix /usr/bin/systemctl stop postfix Run the script again, and you should now have an email from the server with the dbus-daemon message. You can now use a crontab to schedule this to run at a specific time. Conclusion Using postfix can help you keep track of process logs that you want to monitor. You can use it along with bash scripting to gain a firm grasp of your system processes and be informed if there is trouble.","title":"Postfix Process Reporting"},{"location":"guides/email/postfix_reporting/#using-postfix-for-server-process-reporting","text":"","title":"Using Postfix For Server Process Reporting"},{"location":"guides/email/postfix_reporting/#prerequisites","text":"Complete comfort operating from the command line on a Rocky Linux server Familiarity with an editor of your choice (this document uses the vi editor, but you can substitute in your favorite editor) An understanding of DNS (the Domain Name System) and host names The ability to assign variables in a bash script Knowledge of what the tail , more , grep , and date commands do","title":"Prerequisites"},{"location":"guides/email/postfix_reporting/#introduction","text":"Many Rocky Linux server administrators write scripts to perform specific tasks, like backups or file synchronization, and many of these scripts generate logs that have useful and sometimes very important information. Just having the logs, though, is not enough. If a process fails and logs that failure, but the busy administrator does not review the log, then a catastrophe could be in the making. This document shows you how to use the postfix MTA (mail transfer agent) to grab log details from a particular process, and send them to you via email. It also touches on date formats in logs, and helps you identify which format you need to use in the reporting procedure. Keep in mind, though, that this is just the tip of the iceberg as far as what can be done with reporting via postfix. Please note, too, that it is always a good security move to limit running processes to only those that you will need all the time. This document shows you how to enable postfix only for the reporting you need it to do, and then shut it down again.","title":"Introduction"},{"location":"guides/email/postfix_reporting/#postfix-defined","text":"postfix is a server daemon used for sending email. It is more secure and simpler than sendmail, another MTA that was the default go-to MTA for years. It can be used as part of a full-featured mail server.","title":"Postfix Defined"},{"location":"guides/email/postfix_reporting/#installing-postfix","text":"Aside from postfix, we will need mailx for testing our ability to send emails. To install both, and any dependencies required, enter the following on the Rocky Linux server command line: dnf install postfix mailx","title":"Installing postfix"},{"location":"guides/email/postfix_reporting/#testing-and-configuring-postfix","text":"","title":"Testing And Configuring Postfix"},{"location":"guides/email/postfix_reporting/#testing-mail-first","text":"Before we configure postfix, we need to find out how mail will look when it leaves the server, because we will probably want to change this. To do this, start postfix: systemctl start postfix Then test it using mail command that is installed with mailx: mail -s \"Testing from server\" myname@mydomain.com This will bring up a blank line. Simply type your testing message in here: testing from the server Now hit enter, and enter a single period: . The system will respond with: EOT Our purpose for doing this is to check to see how our mail looks to the outside world, which we can get a feel for from the maillog that goes active with the starting of postfix. Use this command to see the output of the log file: tail /var/log/maillog You should see something like this, although the log file may have different domains for the email address, etc: Mar 4 16:51:40 hedgehogct postfix/postfix-script[735]: starting the Postfix mail system Mar 4 16:51:40 hedgehogct postfix/master[737]: daemon started -- version 3.3.1, configuration /etc/postfix Mar 4 16:52:04 hedgehogct postfix/pickup[738]: C9D42EC0ADD: uid=0 from=<root> Mar 4 16:52:04 hedgehogct postfix/cleanup[743]: C9D42EC0ADD: message-id=<20210304165204.C9D42EC0ADD@somehost.localdomain> Mar 4 16:52:04 hedgehogct postfix/qmgr[739]: C9D42EC0ADD: from=<root@somehost.localdomain>, size=457, nrcpt=1 (queue active) Mar 4 16:52:05 hedgehogct postfix/smtp[745]: connect to gmail-smtp-in.l.google.com[2607:f8b0:4001:c03::1a]:25: Network is unreachable Mar 4 16:52:06 hedgehogct postfix/smtp[745]: C9D42EC0ADD: to=<myname@mydomain.com>, relay=gmail-smtp-in.l.google.com[172.217.212.26] :25, delay=1.4, delays=0.02/0.02/0.99/0.32, dsn=2.0.0, status=sent (250 2.0.0 OK 1614876726 z8si17418573ilq.142 - gsmtp) Mar 4 16:52:06 hedgehogct postfix/qmgr[739]: C9D42EC0ADD: removed The \"somehost.localdomain\" shows us that we need to make some changes, so stop the postfix daemon first: systemctl stop postfix","title":"Testing Mail First"},{"location":"guides/email/postfix_reporting/#configuring-postfix","text":"Since we aren't setting up a complete, fully functional mail server, the configuration options that we will be using are not as extensive. The first thing we need to do is to modify the main.cf file (literally the main configuration file for postfix), so let's make a backup first: cp /etc/postifix/main.cf /etc/postfix/main.cf.bak Then edit it: vi /etc/postfix/main.cf In our example, our server name is going to be \"bruno\" and our domain name is going to be \"ourdomain.com\". Find the line in the file: #myhostname = host.domain.tld You can either remove the remark (#) or you can add a new line under this line. Based on our example, the line would read: myhostname = bruno.ourdomain.com Next, find the line for the domain name: #mydomain = domain.tld Either remove the remark and change it, or add a new line: mydomain = ourdomain.com Finally, go to the bottom of the file and add this line: smtp_generic_maps = hash:/etc/postfix/generic Save your changes (in vi, that will be Shift : wq! ) and exit the file. Before we continue editing the generic file, we need to see how email will look. Specifically, we want to create the \"generic\" file that we referenced in the main.cf file above: vi /etc/postfix/generic This file tells postfix how any email coming from this server should look. Remember our test email and the log file? This is where we fix all of that: root@somehost.localdomain root@bruno.ourdomain.com @somehost.localdomain root@bruno.ourdomain.com Now we need to tell postfix to use all of our changes. This is done with the postmap command: postmap /etc/postfix/generic Now start postfix and test your email again using the same procedure as above. You should now see that all of the \"localdomain\" instances have been changed to your actual domain.","title":"Configuring Postfix"},{"location":"guides/email/postfix_reporting/#the-date-command-and-a-variable-called-today","text":"Not every application will use the same logging format for the date. This means that you may have to get creative with any script you write for reporting by date. Let's say that you want to look at your system log as an example and pull everything that has to do with dbus-daemon for today's date, and email it to yourself. (It's probably not the greatest example, but it will give you an idea of how we would do this.) We need to use a a variable in our script that we will call \"today\" and we want it to relate to output from the \"date\" command and format it in a specific way, so that we can get the data we need from our system log (in /var/log/messages ). To start with, let's do some investigative work. First, enter the date command in the command line: date This should give you the default system date output, which could be something like this: Thu Mar 4 18:52:28 UTC 2021 Now let's check our system log and see how it records information. To do this, we will use the \"more\" and \"grep\" commands: more /var/log/messages | grep dbus-daemon Which should give you something like this: Mar 4 18:23:53 hedgehogct dbus-daemon[60]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher' Mar 4 18:50:41 hedgehogct dbus-daemon[60]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.freedesktop.nm-dispatcher.service' requested by ':1.1' (uid=0 pid=61 comm=\"/usr/sbin/NetworkManager --no-daemon \" label=\"unconfined\") Mar 4 18:50:41 hedgehogct dbus-daemon[60]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher The date and log outputs need to be exactly the same in our script, so let's look at how to format the date using a variable called \"today\". First, let's look at what we need to do with the date to get the same output as the system log. You can reference the Linux man page or type man date on the command line to pull up the date manual page to get the information you need. What you will find is that in order to format the date the same way that /var/log/messages has it, we need to use the %b and %e format strings, with %b being the 3 character month and %e being the space-padded day.","title":"The date Command and a Variable Called today"},{"location":"guides/email/postfix_reporting/#the-script","text":"For our bash script, we can see that we are going to use the date command and a variable called \"today\". (Keep in mind that \"today\" is arbitrary. You could call this variable \"late_for_dinner\" if you wanted!). We will call our script in this example, test.sh and place it in /usr/local/sbin : vi /usr/local/sbin/test.sh Let's start with, well, the beginning of our script. Note that even though the comment in our file says we are sending these messages to email, for now, we are just sending them to a standard log output so that we can verify that they are correct. Also, in our first attempt, we are grabbing all of the messages for the current date, not just the dbus-daemon messages. We will deal with that shortly. Another thing to be aware of is that the grep command will return the filename in the output, which we don't want in this case, so we have added the \"-h\" option to grep to remove the prefix of the filename. In addition, once the variable \"today\" is set, we need to look for the entire variable as a string, so we need it all in quotes: #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages That's it for now, so save your changes and then make the script executable: chmod +x /usr/local/sbin/test.sh And then let's test it: /usr/local/sbin/test.sh If all works correctly, you should get a long list of all of the messages in /var/log/messages from today, including but not limited to the dbus-daemon messages. If so, then the next step is to limit the messages to the dbus-daemon messages. So let's modify our script again: vi /usr/local/sbin/test.sh #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages | grep dbus-daemon Running the script again, should get you only the dbus-daemon messages and only the ones that occurred today (whenever you're following this guide). There's one final step, however. Remember, we need to get this emailed to the administrator for review. Also, because we are only using postfix on this server for reporting, we don't want to leave the service running, so we will start it at the beginning of the script and then stop it at the end. We'll introduce the sleep command here to pause for 20 seconds to make sure that the email has been sent before shutting postfix down again. This final edit, adds the stop, start, and sleep issues just discussed, and also pipes the content to the administrator's email. vi /usr/local/sbin/test.sh And modify the script: #!/bin/bash # start postfix /usr/bin/systemctl start postfix # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages | grep dbus-daemon | mail -s \"dbus-daemon messages for today\" myname@mydomain.com # make sure the email has finished before continuing sleep 20 # stop postfix /usr/bin/systemctl stop postfix Run the script again, and you should now have an email from the server with the dbus-daemon message. You can now use a crontab to schedule this to run at a specific time.","title":"The Script"},{"location":"guides/email/postfix_reporting/#conclusion","text":"Using postfix can help you keep track of process logs that you want to monitor. You can use it along with bash scripting to gain a firm grasp of your system processes and be informed if there is trouble.","title":"Conclusion"},{"location":"guides/file_sharing/glusterfs/","text":"High availability cluster with GlusterFS Prerequisites Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties All commands are run as the root user or sudo Introduction GlusterFS is a distributed file system. It allows for storage of large amount of data distributed across clusters of servers with a very high availability. It is composed of a server part to be installed on all the nodes of the server clusters. Clients can access the data via the glusterfs client or the mount command. GlusterFS can operate in two modes: replicated mode: each node of the cluster has all the data. distributed mode: no data redundancy. If a storage fails, the data on the failed node is lost. Both modes can be used together to provide both a replicated and distributed file system as long as you have the right number of servers. Data is stored inside bricks. A Brick is the basic unit of storage in GlusterFS, represented by an export directory on a server in the trusted storage pool. Test platform Our fictitious platform is composed of two servers and a client, all Rocky Linux servers. First node: node1.cluster.local - 192.168.1.10 Second node: node2.cluster.local - 192.168.1.11 Client1: client1.clients.local - 192.168.1.12 !!! Note Make sure you have the necessary bandwidth between the servers of the cluster. Each server in the cluster has a second disk for data storage. Preparation of the disks We will create a new LVM logical volume that will be mounted on /data/glusterfs/vol0 on both of the cluster's servers: $ sudo pvcreate /dev/sdb $ sudo vgcreate vg_data /dev/sdb $ sudo lvcreate -l 100%FREE -n lv_data vg_data $ sudo mkfs.xfs /dev/vg_data/lv_data $ sudo mkdir -p /data/glusterfs/volume1 !!! Note If LVM is not available on your servers, just install it with the following command: ``` $ sudo dnf install lvm2 ``` We can now add that logical volume to the /etc/fstab file: /dev/mapper/vg_data-lv_data /data/glusterfs/volume1 xfs defaults 1 2 And mount it: $ sudo mount -a As the data is stored in a sub-volume called brick, we can create a directory in this new data space dedicated to it: $ sudo mkdir /data/glusterfs/volume1/brick0 Installation At the time of writing this documentation, the original CentOS Storage SIG repository is no longer available and the RockyLinux repository is not yet available. However, we will use (for the time being) the archived version. First of all, it is necessary to add the dedicated repository to gluster (in version 9) on both servers: sudo dnf install centos-release-gluster9 !!! Note Later, when it is ready on the Rocky side, we can change the name of this package. As the repo list and url is not available anymore, let's change the content of the /etc/yum.repos.d/CentOS-Gluster-9.repo : [centos-gluster9] name=CentOS-$releasever - Gluster 9 #mirrorlist=http://mirrorlist.centos.org?arch=$basearch&release=$releasever&repo=storage-gluster-9 baseurl=https://dl.rockylinux.org/vault/centos/8.5.2111/storage/x86_64/gluster-9/ gpgcheck=1 enabled=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-Storage We are now ready to install the glusterfs server: $ sudo dnf install glusterfs glusterfs-libs glusterfs-server Firewall rules A few rules are necessary for the service to work: $ sudo firewall-cmd --zone=public --add-service=glusterfs --permanent $ sudo firewall-cmd --reload or: $ sudo firewall-cmd --zone=public --add-port=24007-24008/tcp --permanent $ sudo firewall-cmd --zone=public --add-port=49152/tcp --permanent $ sudo firewall-cmd --reload Name resolution You can let DNS handle the name resolution of the servers in your cluster, or you can choose to relieve the servers of this task by inserting records for each of them in your /etc/hosts files. This will also keep things running even in the event of a DNS failure. 192.168.10.10 node1.cluster.local 192.168.10.11 node2.cluster.local Starting the service Without further delay, let's start the service: $ sudo systemctl enable glusterfsd.service glusterd.service $ sudo systemctl start glusterfsd.service glusterd.service We are ready to join the two nodes to the same pool. This command is to be performed only once on a single node (here on node1): sudo gluster peer probe node2.cluster.local peer probe: success Verify: node1 $ sudo gluster peer status Number of Peers: 1 Hostname: node2.cluster.local Uuid: c4ff108d-0682-43b2-bc0c-311a0417fae2 State: Peer in Cluster (Connected) Other names: 192.168.10.11 node2 $ sudo gluster peer status Number of Peers: 1 Hostname: node1.cluster.local Uuid: 6375e3c2-4f25-42de-bbb6-ab6a859bf55f State: Peer in Cluster (Connected) Other names: 192.168.10.10 We can now create a volume with 2 replicas: $ sudo gluster volume create volume1 replica 2 node1.cluster.local:/data/glusterfs/volume1/brick0/ node2.cluster.local:/data/glusterfs/volume1/brick0/ Replica 2 volumes are prone to split-brain. Use Arbiter or Replica 3 to avoid this. See: http://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/. Do you still want to continue? (y/n) y volume create: volume1: success: please start the volume to access data !!! Note As the return command says, a 2-node cluster is not the best idea in the world against split brain. But this will suffice for the purposes of our test platform. We can now start the volume to access data: $ sudo gluster volume start volume1 volume start: volume1: success Check the volume state: $ sudo gluster volume status Status of volume: volume1 Gluster process TCP Port RDMA Port Online Pid ------------------------------------------------------------------------------ Brick node1.cluster.local:/data/glusterfs/v olume1/brick0 49152 0 Y 1210 Brick node2.cluster.local:/data/glusterfs/v olume1/brick0 49152 0 Y 1135 Self-heal Daemon on localhost N/A N/A Y 1227 Self-heal Daemon on node2.cluster.local N/A N/A Y 1152 Task Status of Volume volume1 ------------------------------------------------------------------------------ There are no active volume tasks $ sudo gluster volume info Volume Name: volume1 Type: Replicate Volume ID: f51ca783-e815-4474-b256-3444af2c40c4 Status: Started Snapshot Count: 0 Number of Bricks: 1 x 2 = 2 Transport-type: tcp Bricks: Brick1: node1.cluster.local:/data/glusterfs/volume1/brick0 Brick2: node2.cluster.local:/data/glusterfs/volume1/brick0 Options Reconfigured: cluster.granular-entry-heal: on storage.fips-mode-rchecksum: on transport.address-family: inet nfs.disable: on performance.client-io-threads: off The status must be \"Started\". We can already restrict access on the volume a little bit: $ sudo gluster volume set volume1 auth.allow 192.168.10.* It's as simple as that Clients access There are several ways to access our data from a client. The preferred method: $ sudo dnf install glusterfs-client $ sudo mkdir /data $ sudo mount.glusterfs node1.cluster.local:/volume1 /data There are no additional repositories to configure. The client is already present in the base repos. Create a file and check that it is present on all the nodes of the cluster: On client: sudo touch /data/test On both servers: $ ll /data/glusterfs/volume1/brick0/ total 0 -rw-r--r--. 2 root root 0 Feb 3 19:21 test Sound good! But what happens if the node 1 fails? It is the one that was specified when mounting the remote access. Let's stop the node one: $ sudo shutdown -h now Check status on node2: $ sudo gluster peer status Number of Peers: 1 Hostname: node1.cluster.local Uuid: 6375e3c2-4f25-42de-bbb6-ab6a859bf55f State: Peer in Cluster (Disconnected) Other names: 192.168.10.10 [antoine@node2 ~]$ sudo gluster volume status Status of volume: volume1 Gluster process TCP Port RDMA Port Online Pid ------------------------------------------------------------------------------ Brick node2.cluster.local:/data/glusterfs/v olume1/brick0 49152 0 Y 1135 Self-heal Daemon on localhost N/A N/A Y 1152 Task Status of Volume volume1 ------------------------------------------------------------------------------ There are no active volume tasks The node1 is away. And on client: $ ll /data/test -rw-r--r--. 1 root root 0 Feb 4 16:41 /data/test File is already there. Upon connection, the glusterfs client receives a list of nodes it can address, which explains the transparent switchover we just witnessed. Conclusions While there are no current repositories, using the archived repositories that CentOS had for GlusterFS will still work. As outlined, GlusterFS is pretty easy to install and maintain. Using the command line tools is a pretty straight forward process. GlusterFS will help with creating and maintaining high-availability clusters for data storage and redundancy. You can find more information on GlusterFS and tool usage from the official documentation pages.","title":"Clustering-GlusterFS"},{"location":"guides/file_sharing/glusterfs/#high-availability-cluster-with-glusterfs","text":"","title":"High availability cluster with GlusterFS"},{"location":"guides/file_sharing/glusterfs/#prerequisites","text":"Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/file_sharing/glusterfs/#introduction","text":"GlusterFS is a distributed file system. It allows for storage of large amount of data distributed across clusters of servers with a very high availability. It is composed of a server part to be installed on all the nodes of the server clusters. Clients can access the data via the glusterfs client or the mount command. GlusterFS can operate in two modes: replicated mode: each node of the cluster has all the data. distributed mode: no data redundancy. If a storage fails, the data on the failed node is lost. Both modes can be used together to provide both a replicated and distributed file system as long as you have the right number of servers. Data is stored inside bricks. A Brick is the basic unit of storage in GlusterFS, represented by an export directory on a server in the trusted storage pool.","title":"Introduction"},{"location":"guides/file_sharing/glusterfs/#test-platform","text":"Our fictitious platform is composed of two servers and a client, all Rocky Linux servers. First node: node1.cluster.local - 192.168.1.10 Second node: node2.cluster.local - 192.168.1.11 Client1: client1.clients.local - 192.168.1.12 !!! Note Make sure you have the necessary bandwidth between the servers of the cluster. Each server in the cluster has a second disk for data storage.","title":"Test platform"},{"location":"guides/file_sharing/glusterfs/#preparation-of-the-disks","text":"We will create a new LVM logical volume that will be mounted on /data/glusterfs/vol0 on both of the cluster's servers: $ sudo pvcreate /dev/sdb $ sudo vgcreate vg_data /dev/sdb $ sudo lvcreate -l 100%FREE -n lv_data vg_data $ sudo mkfs.xfs /dev/vg_data/lv_data $ sudo mkdir -p /data/glusterfs/volume1 !!! Note If LVM is not available on your servers, just install it with the following command: ``` $ sudo dnf install lvm2 ``` We can now add that logical volume to the /etc/fstab file: /dev/mapper/vg_data-lv_data /data/glusterfs/volume1 xfs defaults 1 2 And mount it: $ sudo mount -a As the data is stored in a sub-volume called brick, we can create a directory in this new data space dedicated to it: $ sudo mkdir /data/glusterfs/volume1/brick0","title":"Preparation of the disks"},{"location":"guides/file_sharing/glusterfs/#installation","text":"At the time of writing this documentation, the original CentOS Storage SIG repository is no longer available and the RockyLinux repository is not yet available. However, we will use (for the time being) the archived version. First of all, it is necessary to add the dedicated repository to gluster (in version 9) on both servers: sudo dnf install centos-release-gluster9 !!! Note Later, when it is ready on the Rocky side, we can change the name of this package. As the repo list and url is not available anymore, let's change the content of the /etc/yum.repos.d/CentOS-Gluster-9.repo : [centos-gluster9] name=CentOS-$releasever - Gluster 9 #mirrorlist=http://mirrorlist.centos.org?arch=$basearch&release=$releasever&repo=storage-gluster-9 baseurl=https://dl.rockylinux.org/vault/centos/8.5.2111/storage/x86_64/gluster-9/ gpgcheck=1 enabled=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-Storage We are now ready to install the glusterfs server: $ sudo dnf install glusterfs glusterfs-libs glusterfs-server","title":"Installation"},{"location":"guides/file_sharing/glusterfs/#firewall-rules","text":"A few rules are necessary for the service to work: $ sudo firewall-cmd --zone=public --add-service=glusterfs --permanent $ sudo firewall-cmd --reload or: $ sudo firewall-cmd --zone=public --add-port=24007-24008/tcp --permanent $ sudo firewall-cmd --zone=public --add-port=49152/tcp --permanent $ sudo firewall-cmd --reload","title":"Firewall rules"},{"location":"guides/file_sharing/glusterfs/#name-resolution","text":"You can let DNS handle the name resolution of the servers in your cluster, or you can choose to relieve the servers of this task by inserting records for each of them in your /etc/hosts files. This will also keep things running even in the event of a DNS failure. 192.168.10.10 node1.cluster.local 192.168.10.11 node2.cluster.local","title":"Name resolution"},{"location":"guides/file_sharing/glusterfs/#starting-the-service","text":"Without further delay, let's start the service: $ sudo systemctl enable glusterfsd.service glusterd.service $ sudo systemctl start glusterfsd.service glusterd.service We are ready to join the two nodes to the same pool. This command is to be performed only once on a single node (here on node1): sudo gluster peer probe node2.cluster.local peer probe: success Verify: node1 $ sudo gluster peer status Number of Peers: 1 Hostname: node2.cluster.local Uuid: c4ff108d-0682-43b2-bc0c-311a0417fae2 State: Peer in Cluster (Connected) Other names: 192.168.10.11 node2 $ sudo gluster peer status Number of Peers: 1 Hostname: node1.cluster.local Uuid: 6375e3c2-4f25-42de-bbb6-ab6a859bf55f State: Peer in Cluster (Connected) Other names: 192.168.10.10 We can now create a volume with 2 replicas: $ sudo gluster volume create volume1 replica 2 node1.cluster.local:/data/glusterfs/volume1/brick0/ node2.cluster.local:/data/glusterfs/volume1/brick0/ Replica 2 volumes are prone to split-brain. Use Arbiter or Replica 3 to avoid this. See: http://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/. Do you still want to continue? (y/n) y volume create: volume1: success: please start the volume to access data !!! Note As the return command says, a 2-node cluster is not the best idea in the world against split brain. But this will suffice for the purposes of our test platform. We can now start the volume to access data: $ sudo gluster volume start volume1 volume start: volume1: success Check the volume state: $ sudo gluster volume status Status of volume: volume1 Gluster process TCP Port RDMA Port Online Pid ------------------------------------------------------------------------------ Brick node1.cluster.local:/data/glusterfs/v olume1/brick0 49152 0 Y 1210 Brick node2.cluster.local:/data/glusterfs/v olume1/brick0 49152 0 Y 1135 Self-heal Daemon on localhost N/A N/A Y 1227 Self-heal Daemon on node2.cluster.local N/A N/A Y 1152 Task Status of Volume volume1 ------------------------------------------------------------------------------ There are no active volume tasks $ sudo gluster volume info Volume Name: volume1 Type: Replicate Volume ID: f51ca783-e815-4474-b256-3444af2c40c4 Status: Started Snapshot Count: 0 Number of Bricks: 1 x 2 = 2 Transport-type: tcp Bricks: Brick1: node1.cluster.local:/data/glusterfs/volume1/brick0 Brick2: node2.cluster.local:/data/glusterfs/volume1/brick0 Options Reconfigured: cluster.granular-entry-heal: on storage.fips-mode-rchecksum: on transport.address-family: inet nfs.disable: on performance.client-io-threads: off The status must be \"Started\". We can already restrict access on the volume a little bit: $ sudo gluster volume set volume1 auth.allow 192.168.10.* It's as simple as that","title":"Starting the service"},{"location":"guides/file_sharing/glusterfs/#clients-access","text":"There are several ways to access our data from a client. The preferred method: $ sudo dnf install glusterfs-client $ sudo mkdir /data $ sudo mount.glusterfs node1.cluster.local:/volume1 /data There are no additional repositories to configure. The client is already present in the base repos. Create a file and check that it is present on all the nodes of the cluster: On client: sudo touch /data/test On both servers: $ ll /data/glusterfs/volume1/brick0/ total 0 -rw-r--r--. 2 root root 0 Feb 3 19:21 test Sound good! But what happens if the node 1 fails? It is the one that was specified when mounting the remote access. Let's stop the node one: $ sudo shutdown -h now Check status on node2: $ sudo gluster peer status Number of Peers: 1 Hostname: node1.cluster.local Uuid: 6375e3c2-4f25-42de-bbb6-ab6a859bf55f State: Peer in Cluster (Disconnected) Other names: 192.168.10.10 [antoine@node2 ~]$ sudo gluster volume status Status of volume: volume1 Gluster process TCP Port RDMA Port Online Pid ------------------------------------------------------------------------------ Brick node2.cluster.local:/data/glusterfs/v olume1/brick0 49152 0 Y 1135 Self-heal Daemon on localhost N/A N/A Y 1152 Task Status of Volume volume1 ------------------------------------------------------------------------------ There are no active volume tasks The node1 is away. And on client: $ ll /data/test -rw-r--r--. 1 root root 0 Feb 4 16:41 /data/test File is already there. Upon connection, the glusterfs client receives a list of nodes it can address, which explains the transparent switchover we just witnessed.","title":"Clients access"},{"location":"guides/file_sharing/glusterfs/#conclusions","text":"While there are no current repositories, using the archived repositories that CentOS had for GlusterFS will still work. As outlined, GlusterFS is pretty easy to install and maintain. Using the command line tools is a pretty straight forward process. GlusterFS will help with creating and maintaining high-availability clusters for data storage and redundancy. You can find more information on GlusterFS and tool usage from the official documentation pages.","title":"Conclusions"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/","tags":["security","ftp","vsftpd"],"text":"Secure FTP Server - vsftpd Prerequisites Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of PAM, as well as openssl commands is helpful. All commands are run as the root user or sudo Introduction vsftpd is the Very Secure FTP Daemon (FTP being the file transfer protocol). It has been available for many years now, and is actually the default FTP daemon in Rocky Linux, as well as many other Linux distributions. vsftpd allows for the use of virtual users with pluggable authentication modules (PAM). These virtual users don't exist in the system, and have no other permissions except to use FTP. This means that if a virtual user gets compromised, the person with those credentials would have no other permissions once they gained access. Using this setup is very secure indeed, but does require a bit of extra work. !!! hint \"Consider sftp \" Even with the security settings used here to set up `vsftpd`, you may want to consider `sftp` instead. `sftp` will encrypt the entire connection stream and is more secure for this reason. We've created a document [here](../sftp) that deals with setting up `sftp` and the locking down SSH. Installing vsftpd We also need to make sure openssl is installed. If you are running a web server, this probably is already installed, but just to make sure, you can run: dnf install vsftpd openssl You will also want to enable the vsftpd service: systemctl enable vsftpd But don't start the service just yet. Configuring vsftpd We want to make sure that some settings are disabled and that others are enabled. Generally, when you install vsftpd , it comes with the most sane options already set, but it is a good idea to make sure. To check the configuration file and make changes as necessary, run: vi /etc/vsftpd/vsftpd.conf Look for the line \"anonymous_enable=\" and make sure that it is set to \"NO\" and that it is NOT remarked/commented out. (Remarking out this line will enable anonymous logins). The line should look like this when it is correct: anonymous_enable=NO Make sure that local_enable is set to yes: local_enable=YES Add a line for the local root user. If the server that you are installing this on is a web server, we assume that you will be using the Apache Web Server Multi-Site Setup , and that your local root will reflect that. If your setup is different, or if this is not a web server, adjust the local_root setting: local_root=/var/www/sub-domains Make sure that write_enable is set to yes as well: write_enable=YES Find the line to \"chroot_local_users\", and remove the remark. Then add two lines below so that it looks like this: chroot_local_user=YES allow_writeable_chroot=YES hide_ids=YES Beneath this, we want to add an entirely new section that will deal with virtual users: # Virtual User Settings user_config_dir=/etc/vsftpd/vsftpd_user_conf guest_enable=YES virtual_use_local_privs=YES pam_service_name=vsftpd nopriv_user=vsftpd guest_username=vsftpd We need to add a section near the bottom of the file to force passwords sent over the internet to be encrypted. We need openssl installed and we will need to create the certificate file for this as well. Start by adding these lines at the bottom of the file: rsa_cert_file=/etc/vsftpd/vsftpd.pem rsa_private_key_file=/etc/vsftpd/vsftpd.key ssl_enable=YES allow_anon_ssl=NO force_local_data_ssl=YES force_local_logins_ssl=YES ssl_tlsv1=YES ssl_sslv2=NO ssl_sslv3=NO pasv_min_port=7000 pasv_max_port=7500 Now save your configuration. (That's SHIFT:wq if using vi .) Setting Up The RSA Certificate We need to create the vsftpd RSA certificate file. The author generally figures that a server is good for 4 or 5 years, so set the number of days for this certificate based on the number of years you believe you'll have the server up and running on this hardware. Edit the number of days as you see fit, and then use the below format of the command to create the certificate and private key files: openssl req -x509 -nodes -days 1825 -newkey rsa:2048 -keyout /etc/vsftpd/vsftpd.key -out /etc/vsftpd/vsftpd.pem Like all certificate creation processes, this will start a script that will ask you for some information. This is not a difficult process. Many fields can be left blank. The first field is the country code field, fill this one in with your country two letter code: Country Name (2 letter code) [XX]: Next comes the state or province, fill this in by typing the whole name, not the abbreviation: State or Province Name (full name) []: Next is the locality name. This is your city: Locality Name (eg, city) [Default City]: Next is the company or organizational name. You can leave this blank or fill it in as you see fit: Organization Name (eg, company) [Default Company Ltd]: Next is the organizational unit name. You can fill this in if the server is for a specific division, or leave it blank: Organizational Unit Name (eg, section) []: The next field should be filled in, however you can decide how you want to fill it in. This is the common name of your server. Example: webftp.domainname.ext : Common Name (eg, your name or your server's hostname) []: Finally, there is the email field, which you can certainly leave blank without issue: Email Address []: Once you have completed the form, the certificate will be created. Setting Up Virtual Users As stated earlier, using virtual users for vsftpd is much more secure, because they have no system privileges at all. That said, we need to add a user for the virtual users to use. We also need to add a group: groupadd nogroup And then: useradd --home-dir /home/vsftpd --gid nogroup -m --shell /bin/false vsftpd The user must match the guest_username= line in the vsftpd.conf file. Now navigate to the configuration directory for vsftpd : cd /etc/vsftpd We need to create a new password database that will be used to authenticate our virtual users. We need to create a file to read the virtual users and passwords from. This will create the database. In the future, when adding new users, we will want to duplicate this process as well: vi vusers.txt The user and password are line separated, so simply type the user, hit enter, and then type the password. Continue until you have added all of the users you currently want to have access to the system. Example: user_name_a user_password_a user_name_b user_password_b Once the text file is created, we now want to generate the password database that vsftpd will use for the virtual users. This is done with db_load . db_load is provided by libdb-utils which should be loaded on your system, but if it is not, you can simply install it with: dnf install libdb-utils Create the database from the text file with: db_load -T -t hash -f vusers.txt vsftpd-virtual-user.db We need to take just a moment here to reference what db_load is doing here: The -T is used to easily allow the import of a text file into the database. The -t says to specify the underlying access method. The hash is the underlying access method we are specifying. The -f says to read from a specified file. The specified file is vusers.txt . And the database we are creating or adding to is vsftpd-virtual-user.db . Change the default permissions of the database file: chmod 600 vsftpd-virtual-user.db And remove the vusers.txt file: rm vusers.txt When adding new users, simply use vi to create a new vusers.txt file, and re-run the db_load command, which will add the new user/s to the database. Setting Up PAM vsftpd installs a default pam file when you install the package. We are going to replace this with our own content, so always make a backup copy of the old file first. Make a directory for your backup file in /root: mkdir /root/backup_vsftpd_pam Then copy the pam file to this directory: cp /etc/pam.d/vsftpd /root/backup_vsftpd_pam/ Now edit the original file: vi /etc/pam.d/vsftpd Remove everything in this file except the \"#%PAM-1.0\" and then add in the following lines: auth required pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user account required pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user session required pam_loginuid.so Save your changes and exit ( SHIFT:wq in vi ). This will enable login for your virtual users defined in vsftpd-virtual-user.db , and will disable local logins. Setting Up The Virtual User's Configuration Each virtual user has their own configuration file, which specifies their own local_root directory. This local root must be owned by the user \"vsftpd\" and the group \"nogroup\". Remember that this was set up in the Setting Up Virtual Users section above. To change the ownership for the directory, simply type this at the command line: chown vsftpd.nogroup /var/www/sub-domains/whatever_the_domain_name_is/html We need to create the file that contains the virtual user's configuration: vi /etc/vsftpd/vsftpd_user_conf/username This will have a single line in it that specifies the virtual user's local_root: local_root=/var/www/sub-domains/com.testdomain/html This file path is specified in the \"Virtual User\" section of the vsftpd.conf file. Starting vsftpd Once all of this is completed, start the vsftpd service and then test your users, assuming that the service starts correctly: systemctl restart vsftpd Testing vsftpd You can test your setup using the command line on a machine and test access to the machine using FTP. That said, the easiest way to test is to test with an FTP client, such as FileZilla . When you test with a virtual user to the server running vsftpd , you should get an SSL certificate trust message. This trust message is saying to the person using the FTP client that the server uses a certificate and asks them to approve the certificate before continuing. Once connected as a virtual user, you should be able to place files in the \"local_root\" folder that we setup for that user. If you are unable to upload a file, then you may need to go back and make sure that each of the above steps is completed. For instance, it could be that the ownership permissions for the \"local_root\" have not been set to the \"vsftpd\" user and the \"nogroup\" group. Conclusion vsftpd is a popular and common ftp server and can be set up as a stand alone server, or as part of an Apache Hardened Web Server . If set up to use virtual users and a certificate, it is quite secure. While there are quite a number of steps to setting up vsftpd as outlined in this document, taking the extra time to set it up correctly will ensure that your server is as secure as it can be.","title":"Secure FTP Server - vsftpd"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#secure-ftp-server-vsftpd","text":"","title":"Secure FTP Server - vsftpd"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#prerequisites","text":"Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of PAM, as well as openssl commands is helpful. All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#introduction","text":"vsftpd is the Very Secure FTP Daemon (FTP being the file transfer protocol). It has been available for many years now, and is actually the default FTP daemon in Rocky Linux, as well as many other Linux distributions. vsftpd allows for the use of virtual users with pluggable authentication modules (PAM). These virtual users don't exist in the system, and have no other permissions except to use FTP. This means that if a virtual user gets compromised, the person with those credentials would have no other permissions once they gained access. Using this setup is very secure indeed, but does require a bit of extra work. !!! hint \"Consider sftp \" Even with the security settings used here to set up `vsftpd`, you may want to consider `sftp` instead. `sftp` will encrypt the entire connection stream and is more secure for this reason. We've created a document [here](../sftp) that deals with setting up `sftp` and the locking down SSH.","title":"Introduction"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#installing-vsftpd","text":"We also need to make sure openssl is installed. If you are running a web server, this probably is already installed, but just to make sure, you can run: dnf install vsftpd openssl You will also want to enable the vsftpd service: systemctl enable vsftpd But don't start the service just yet.","title":"Installing vsftpd"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#configuring-vsftpd","text":"We want to make sure that some settings are disabled and that others are enabled. Generally, when you install vsftpd , it comes with the most sane options already set, but it is a good idea to make sure. To check the configuration file and make changes as necessary, run: vi /etc/vsftpd/vsftpd.conf Look for the line \"anonymous_enable=\" and make sure that it is set to \"NO\" and that it is NOT remarked/commented out. (Remarking out this line will enable anonymous logins). The line should look like this when it is correct: anonymous_enable=NO Make sure that local_enable is set to yes: local_enable=YES Add a line for the local root user. If the server that you are installing this on is a web server, we assume that you will be using the Apache Web Server Multi-Site Setup , and that your local root will reflect that. If your setup is different, or if this is not a web server, adjust the local_root setting: local_root=/var/www/sub-domains Make sure that write_enable is set to yes as well: write_enable=YES Find the line to \"chroot_local_users\", and remove the remark. Then add two lines below so that it looks like this: chroot_local_user=YES allow_writeable_chroot=YES hide_ids=YES Beneath this, we want to add an entirely new section that will deal with virtual users: # Virtual User Settings user_config_dir=/etc/vsftpd/vsftpd_user_conf guest_enable=YES virtual_use_local_privs=YES pam_service_name=vsftpd nopriv_user=vsftpd guest_username=vsftpd We need to add a section near the bottom of the file to force passwords sent over the internet to be encrypted. We need openssl installed and we will need to create the certificate file for this as well. Start by adding these lines at the bottom of the file: rsa_cert_file=/etc/vsftpd/vsftpd.pem rsa_private_key_file=/etc/vsftpd/vsftpd.key ssl_enable=YES allow_anon_ssl=NO force_local_data_ssl=YES force_local_logins_ssl=YES ssl_tlsv1=YES ssl_sslv2=NO ssl_sslv3=NO pasv_min_port=7000 pasv_max_port=7500 Now save your configuration. (That's SHIFT:wq if using vi .)","title":"Configuring vsftpd"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#setting-up-the-rsa-certificate","text":"We need to create the vsftpd RSA certificate file. The author generally figures that a server is good for 4 or 5 years, so set the number of days for this certificate based on the number of years you believe you'll have the server up and running on this hardware. Edit the number of days as you see fit, and then use the below format of the command to create the certificate and private key files: openssl req -x509 -nodes -days 1825 -newkey rsa:2048 -keyout /etc/vsftpd/vsftpd.key -out /etc/vsftpd/vsftpd.pem Like all certificate creation processes, this will start a script that will ask you for some information. This is not a difficult process. Many fields can be left blank. The first field is the country code field, fill this one in with your country two letter code: Country Name (2 letter code) [XX]: Next comes the state or province, fill this in by typing the whole name, not the abbreviation: State or Province Name (full name) []: Next is the locality name. This is your city: Locality Name (eg, city) [Default City]: Next is the company or organizational name. You can leave this blank or fill it in as you see fit: Organization Name (eg, company) [Default Company Ltd]: Next is the organizational unit name. You can fill this in if the server is for a specific division, or leave it blank: Organizational Unit Name (eg, section) []: The next field should be filled in, however you can decide how you want to fill it in. This is the common name of your server. Example: webftp.domainname.ext : Common Name (eg, your name or your server's hostname) []: Finally, there is the email field, which you can certainly leave blank without issue: Email Address []: Once you have completed the form, the certificate will be created.","title":"Setting Up The RSA Certificate"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#setting-up-virtual-users","text":"As stated earlier, using virtual users for vsftpd is much more secure, because they have no system privileges at all. That said, we need to add a user for the virtual users to use. We also need to add a group: groupadd nogroup And then: useradd --home-dir /home/vsftpd --gid nogroup -m --shell /bin/false vsftpd The user must match the guest_username= line in the vsftpd.conf file. Now navigate to the configuration directory for vsftpd : cd /etc/vsftpd We need to create a new password database that will be used to authenticate our virtual users. We need to create a file to read the virtual users and passwords from. This will create the database. In the future, when adding new users, we will want to duplicate this process as well: vi vusers.txt The user and password are line separated, so simply type the user, hit enter, and then type the password. Continue until you have added all of the users you currently want to have access to the system. Example: user_name_a user_password_a user_name_b user_password_b Once the text file is created, we now want to generate the password database that vsftpd will use for the virtual users. This is done with db_load . db_load is provided by libdb-utils which should be loaded on your system, but if it is not, you can simply install it with: dnf install libdb-utils Create the database from the text file with: db_load -T -t hash -f vusers.txt vsftpd-virtual-user.db We need to take just a moment here to reference what db_load is doing here: The -T is used to easily allow the import of a text file into the database. The -t says to specify the underlying access method. The hash is the underlying access method we are specifying. The -f says to read from a specified file. The specified file is vusers.txt . And the database we are creating or adding to is vsftpd-virtual-user.db . Change the default permissions of the database file: chmod 600 vsftpd-virtual-user.db And remove the vusers.txt file: rm vusers.txt When adding new users, simply use vi to create a new vusers.txt file, and re-run the db_load command, which will add the new user/s to the database.","title":"Setting Up Virtual Users"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#setting-up-pam","text":"vsftpd installs a default pam file when you install the package. We are going to replace this with our own content, so always make a backup copy of the old file first. Make a directory for your backup file in /root: mkdir /root/backup_vsftpd_pam Then copy the pam file to this directory: cp /etc/pam.d/vsftpd /root/backup_vsftpd_pam/ Now edit the original file: vi /etc/pam.d/vsftpd Remove everything in this file except the \"#%PAM-1.0\" and then add in the following lines: auth required pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user account required pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user session required pam_loginuid.so Save your changes and exit ( SHIFT:wq in vi ). This will enable login for your virtual users defined in vsftpd-virtual-user.db , and will disable local logins.","title":"Setting Up PAM"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#setting-up-the-virtual-users-configuration","text":"Each virtual user has their own configuration file, which specifies their own local_root directory. This local root must be owned by the user \"vsftpd\" and the group \"nogroup\". Remember that this was set up in the Setting Up Virtual Users section above. To change the ownership for the directory, simply type this at the command line: chown vsftpd.nogroup /var/www/sub-domains/whatever_the_domain_name_is/html We need to create the file that contains the virtual user's configuration: vi /etc/vsftpd/vsftpd_user_conf/username This will have a single line in it that specifies the virtual user's local_root: local_root=/var/www/sub-domains/com.testdomain/html This file path is specified in the \"Virtual User\" section of the vsftpd.conf file.","title":"Setting Up The Virtual User's Configuration"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#starting-vsftpd","text":"Once all of this is completed, start the vsftpd service and then test your users, assuming that the service starts correctly: systemctl restart vsftpd","title":"Starting vsftpd"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#testing-vsftpd","text":"You can test your setup using the command line on a machine and test access to the machine using FTP. That said, the easiest way to test is to test with an FTP client, such as FileZilla . When you test with a virtual user to the server running vsftpd , you should get an SSL certificate trust message. This trust message is saying to the person using the FTP client that the server uses a certificate and asks them to approve the certificate before continuing. Once connected as a virtual user, you should be able to place files in the \"local_root\" folder that we setup for that user. If you are unable to upload a file, then you may need to go back and make sure that each of the above steps is completed. For instance, it could be that the ownership permissions for the \"local_root\" have not been set to the \"vsftpd\" user and the \"nogroup\" group.","title":"Testing vsftpd"},{"location":"guides/file_sharing/secure_ftp_server_vsftpd/#conclusion","text":"vsftpd is a popular and common ftp server and can be set up as a stand alone server, or as part of an Apache Hardened Web Server . If set up to use virtual users and a certificate, it is quite secure. While there are quite a number of steps to setting up vsftpd as outlined in this document, taking the extra time to set it up correctly will ensure that your server is as secure as it can be.","title":"Conclusion"},{"location":"guides/file_sharing/sftp/","tags":["security","file transfer","sftp","ssh","web","multisite"],"text":"Secure Server - SFTP with SSH Lock Down Procedures Introduction It may seem strange to have a document dedicated to the \"secure\" use of SFTP (a part of openssh-server package) when the SSH proptocol is itself secure. I hear what you are thinking. But most system administrators do not want to open up SSH to everyone in order to implement SFTP for everyone. This document will describe how to implement a change root jail 1 for SFTP while keeping SSH access limited. There are many documents out there that deal with creating an SFTP change root jail, but most do not take into account a use case where the user that is set up would be accessing a web directory on a server with multiple websites. This document deals with that. If that isn't your use case, you can easily adapt these concepts to use in different situations. The author also feels that it is necessary when making the change root jail document for SFTP to also discuss the other things that you should do as a system administrator to minimize the target that you offer to the world via SSH. For this reason, this document is divided into four parts: The first deals with the general information that we will use for the entire document. The second deals with the setup of the change root jail, and if you decide that you want to stop there, that's totally up to you. The third part deals with setting up public/private key SSH access for your system administrators and turning off remote password based authentication. The fourth, and last section of this document deals with turning off remote root logins. Taking all of these steps will allow you to offer secure SFTP access for your customers while also minimizing the possibility that port 22 (the one reserved for SSH access) will be compromised by a bad actor. !!! Note \" 1 Change root jails for beginners:\" Change root (or chroot) jails are a way to restrict what a process and all of its various child processes can do on your computer. It essentially allows you to choose a specific directory/folder on your machine, and make that the \"root\" dirtectory for any given process or program. From there on, that process or program can *only* access that folder and its subfolders. !!! hint \"Updates for Rocky Linux 8.6\" This document has been updated to include new changes that came out with version 8.6 that will make this procedure even safer. If you are using 8.6, then there are specific sections in the document below, prefixed with \"8.6 -\". For clarity sake, the sections specific to Rocky Linux 8.5 have been prefixed with \"8.5 - \". Other than those sections specifically prefixed, this document is generic for both versions of the OS. Part 1: General Information Assumptions and Conventions We assume that: you are comfortable executing commands at the command line. you can use a command line editor, such as vi (used here), nano , micro , etc. you understand basic Linux commands used for adding groups and users, or can follow along well. your multisite website is set up like this: Apache Multisite httpd (Apache) has already been installed on the server. !!! note You can apply these concepts to any server set up, and to any web daemon. While we are assuming Apache here, you can definitely use this for Nginx as well. Sites, Users, Administrators Everything is made up here. Any resemblance to persons or sites that are real, is purely accidental: Sites: mybrokenaxel.com user = mybroken myfixedaxel.com user = myfixed Administrators Steve Simpson = ssimpson Laura Blakely = lblakely Part 2: SFTP Change Root Jail Installation Installation is simple. You just need to have openssh-server installed, which is probably installed already. Enter this command to be sure: dnf install openssh-server Setup Directories The directory path structure will be /var/www/sub-domains/[ext.domainname]/html and the html directory in this path will be the change root jail for the SFTP user. Creating the configuration directories: mkdir -p /etc/httpd/sites-available mkdir -p /etc/httpd/sites-enabled Creating the web directories: mkdir -p /var/www/sub-domains/com.mybrokenaxel/html mkdir -p /var/www/sub-domains/com.myfixedaxel/html We will deal with the ownership of these directories in the script application found below. httpd Configuration We need to modify the built-in httpd.conf file to make it load the configuration files in the /etc/httpd/sites-enabled directory. This is done with one line at the bottom of the httpd.conf file. Edit the file with your favorite editor. I'm using vi here: vi /etc/httpd/conf/httpd.conf and add this at the very bottom of the file: Include /etc/httpd/sites-enabled Then save the file and exit. Website Configuration We need two sites created. We will create the configurations in /etc/httpd/sites-available and then link them to ../sites-enabled : vi /etc/httpd/sites-available/com.mybrokenaxel !!! note We are only using the HTTP protocol for our example. Any real website would need an HTTPS protocol configuration, SSL certificates, and possibly more. <VirtualHost *:80> ServerName www.mybrokenaxel.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.mybrokenaxel/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ CustomLog \"/var/log/httpd/com.mybrokenaxel.www-access_log\" combined ErrorLog \"/var/log/httpd/com.mybrokenaxel.www-error_log\" <Directory /var/www/sub-domains/com.mybrokenaxel/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Save this file and exit. vi /etc/httpd/sites-available/com.myfixedaxel <VirtualHost *:80> ServerName www.myfixedaxel.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.myfixedaxel/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ CustomLog \"/var/log/httpd/com.myfixedaxel.www-access_log\" combined ErrorLog \"/var/log/httpd/com.myfixedaxel.www-error_log\" <Directory /var/www/sub-domains/com.myfixedaxel/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Save this file and exit. Once the two configuration files are created, go ahead and link them from within /etc/httpd/sites-enabled : ln -s ../sites-available/com.mybrokenaxel ln -s ../sites-available/com.myfixedaxel Now enable and start the httpd process: systemctl enable --now httpd User Creation For our example environment, we are assuming that none of the users are set up. Let's start with our administrative users. Note that at this point in our process, we can still log in as the root user to add the other users and set them up the way we want. We will remove root logins once we have the users set up and tested. Administrators useradd -g wheel ssimpson useradd -g wheel lblakely By adding our users to the group \"wheel\" we give them sudo access. You still need a password for sudo access. There are ways around this, but none are all that secure. Frankly, if you have problems with security using sudo on your server, then you've got much bigger problems with your entire setup. Set the two administrative passwords with secure passwords: passwd ssimpson Changing password for user ssimpson. New password: Retype new password: passwd: all authentication tokens updated successfully. passwd lblakely Changing password for user lblakely. New password: Retype new password: passwd: all authentication tokens updated successfully. Now test access to the server via ssh for your two administrative users. You should be able to: use ssh to log in as one of the administrative users to the server. (Example: ssh lblakely@192.168.1.116 or ssh lblakely@mywebserver.com ) once the server is accessed, you should be able to access root with sudo -s and entering the administrative user's password. If this works for both administrative users, you should be ready to go to the next step. Web Users (SFTP) We need to add our web users. That ../html directory structure already exists, so we don't want to create it when we add the user, but we do want to specify it. We also do not want any login other than via SFTP so we need to use a shell that denies logins. useradd -M -d /var/www/sub-domains/com.mybrokenaxel/html -g apache -s /usr/sbin/nologin mybroken useradd -M -d /var/www/sub-domains/com.myfixedaxel/html -g apache -s /usr/sbin/nologin myfixed Let's break down those commands a bit: The -M option says to not create the standard home directory for the user. -d specifies that what comes after is the actual home directory. -g says that the group that this user belongs to is apache . -s says that the shell the user is assigned is /usr/sbin/nologin At the end is the actual username for the user. Note: For an Nginx server, you would use nginx as the group. Our SFTP users still need a password. So let's go ahead and setup a secure password for each now. Since we have already seen the command output above, we won't be repeating it here: passwd mybroken passwd myfixed SSH Configuration !!! caution Before we start this next process, it is highly recommended that you make a backup of the system file we are going to be modifying: `/etc/ssh/sshd_config`. Breaking this file and not being able to go back to the original could cause you a world of heartache! ``` cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak ``` We need to make one change to the /etc/ssh/sshd_config file and then we are going to build a template so that we can make our web directory changes outside of the configuration file and script the additions we are going to need. First, let's make the manual change we need: vi /etc/ssh/sshd_config Near the bottom of the file, you will find this: # override default of no subsystems Subsystem sftp /usr/libexec/openssh/sftp-server We want to change that to read as follows: # override default of no subsystems # Subsystem sftp /usr/libexec/openssh/sftp-server Subsystem sftp internal-sftp Save and exit the file. Just like before, let's describe what we are doing a little here. Both the sftp-server and internal-sftp are part of OpenSSH. The internal-sftp , while not too different from the sftp-server , simplifies configurations using ChrootDirectory to force a different file system root on clients. So that is why we want to use internal-sftp . 8.5 - The Template And The Script Why are we creating a template and a script for this next part? The reason is simply to avoid human error as much as possible. We aren't done modifying that /etc/ssh/sshd_config file yet, but we want to eliminate as many errors as possible whenever we need to make these modifications. We will create all of this in /usr/local/sbin . The Template First, let's create our template: vi /usr/local/sbin/sshd_template This template should have the following: Match User replaceuser PasswordAuthentication yes ChrootDirectory replacedirectory ForceCommand internal-sftp AllowTcpForwarding no X11Forwarding no !!! note The `PasswordAuthentication yes` would not normally be required for the change root jail, BUT, we will be turning off `PasswordAuthentication` later on for everyone else, so it is important to have this line in the template. We want a directory for our user files that we will create from the template too: mkdir /usr/local/sbin/templates 8.5 - The Script Now let's create our script: vi /usr/local/sbin/webuser And put this code in it: #!/bin/bash # script to populate the SSHD configuration for web users. # Set variables tempfile=\"/usr/local/sbin/sshd_template\" dompath=\"/var/www/sub-domains/\" # Prompt for user and domain in reverse (ext.domainname): clear echo -n \"Enter the web sftp user: \" read sftpuser echo -n \"Enter the domain in reverse. Example: com.domainname: \" read dom echo -n \"Is all of this correct: sftpuser = $sftpuser and domain = $dom (Y/N)? \" read yn if [ \"$yn\" = \"n\" ] || [ \"$yn\" = \"N\" ] then exit fi if [ \"$yn\" = \"y\" ] || [ \"$yn\" = \"Y\" ] then /usr/bin/cat $tempfile > /usr/local/sbin/templates/$dom.txt /usr/bin/sed -i \"s,replaceuser,$sftpuser,g\" /usr/local/sbin/templates/$dom.txt /usr/bin/sed -i \"s,replacedirectory,$dompath$dom,g\" /usr/local/sbin/templates/$dom.txt /usr/bin/chown -R $sftpuser.apache $dompath$dom/html fi ## Make a backup of /etc/ssh/sshd_config /usr/bin/rm -f /etc/ssh/sshd_config.bak /usr/bin/cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak ## Now append our new user information to to the file cat /usr/local/sbin/templates/$dom.txt >> /etc/ssh/sshd_config ## Restart sshd /usr/bin/systemctl restart sshd echo \" \" echo \"Please check the status of sshd with systemctl status sshd.\" echo \"You can verify that your information was added to the sshd_config by doing a more of the sshd_config\" echo \"A backup of the working sshd_config was created when this script was run: sshd_config.bak\" 8.6 - The Template And The Script With the release of Rocky Linux 8.6, a new option is available for the sshd_config file that allows for drop in configurations. This is a GREAT change. What this means is that for 8.6, we will make a single additional change to the sshd_config file, and then our script will build out sftp changes in a separate configuration file. While the 8.5 procedure above is pretty darned safe, this new change makes things even safer. Safety is good!! 8.6 The Template There are no changes between 8.5 and 8.6 as far as the template is concerned. So use that procedure above and then return here for the script. 8.6 - The Script and sshd_config Changes Because of the changes allowed for the sshd_config file in Rocky Linux 8.6, our script will use a new drop in configuration file: /etc/ssh/sftp/sftp_config . To start with, create that directory: mkdir /etc/ssh/sftp Now make a backup copy of the sshd_config : cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak And finally edit the sshd_config file, scroll to the very bottom of the file, and add this line: Include /etc/ssh/sftp/sftp_config Save your changes and exit the file. We will need to restart sshd but our script will do that for us after we update sftp_config file, so let's create the script and run it. vi /usr/local/sbin/webuser And put this code in it: #!/bin/bash # script to populate the SSHD configuration for web users. # Set variables tempfile=\"/usr/local/sbin/sshd_template\" dompath=\"/var/www/sub-domains/\" # Prompt for user and domain in reverse (ext.domainname): clear echo -n \"Enter the web sftp user: \" read sftpuser echo -n \"Enter the domain in reverse. Example: com.domainname: \" read dom echo -n \"Is all of this correct: sftpuser = $sftpuser and domain = $dom (Y/N)? \" read yn if [ \"$yn\" = \"n\" ] || [ \"$yn\" = \"N\" ] then exit fi if [ \"$yn\" = \"y\" ] || [ \"$yn\" = \"Y\" ] then /usr/bin/cat $tempfile > /usr/local/sbin/templates/$dom.txt /usr/bin/sed -i \"s,replaceuser,$sftpuser,g\" /usr/local/sbin/templates/$dom.txt /usr/bin/sed -i \"s,replacedirectory,$dompath$dom,g\" /usr/local/sbin/templates/$dom.txt /usr/bin/chown -R $sftpuser.apache $dompath$dom/html fi ## Make a backup of /etc/ssh/sftp/sftp_config /usr/bin/rm -f /etc/ssh/sftp/sftp_config.bak /usr/bin/cp /etc/ssh/sftp/sftp_config /etc/ssh/sftp/sftp_config.bak ## Now append our new user information to to the file cat /usr/local/sbin/templates/$dom.txt >> /etc/ssh/sftp/sftp_config ## Restart sshd /usr/bin/systemctl restart sshd echo \" \" echo \"Please check the status of sshd with systemctl status sshd.\" echo \"You can verify that your information was added by doing a more of the sftp_config\" echo \"A backup of the working sftp_config was created when this script was run: sftp_config.bak\" Final Changes and Script Notes for both 8.5 and 8.6 !!! tip If you take a look at either of the scripts above, you will note that we have changed the delimiter that `sed` uses by default from `/` to `,`. `sed` allows you to use any single-byte character as a delimiter. What we are searching for in the file has a bunch of \"/\" characters in it, and we would have had to escape each one (add a \"\\\" in front of them) to search and replace these strings. Changing the delimiter makes this infinitely easier to do because it eliminates the need to do those escapes. A couple of things to know about the script and about an SFTP change root in general. First, we are prompting for the needed information and then echoing it back to the user so they can verify it. If we answer \"N\" to the confirmation question, the script bails and does nothing. The script for 8.5 makes a backup of sshd_config ( /etc/ssh/sshd_config.bak ) the way it was prior to our running of the script. The 8.6 script does the same for the sftp_config file ( /etc/ssh/sftp/sftp_config.bak ). In this way, if we screw something up with an entry, we can simply restore the appropriate backup file and then restart sshd to get things working again. The SFTP change root requires that the path given in the sshd_config is owned by root. For this reason we do not need the html directory added to the end of the path. Once the user is authenticated, the change root will switch the user's home directory, in this case the ../html , directory to whichever domain we are entering. Our script has appropriately changed the owner of the ../html directory to the sftpuser and the apache group. !!! attention \"Script Compatibility\" While you can use the script that we created for Rocky Linxux 8.5 on either 8.5 or 8.6 successfully, the same cannot be said for the 8.6 script. Since the drop in configuration file option (`Include` directive) was not enabled in 8.5, attempting to use the 8.6 script in Rocky Linux 8.5 will fail. Now that our script is created, let's make it executable: chmod +x /usr/local/sbin/webuser Then run the script for our two test domains. Testing SSH Denial and SFTP Access First, test using ssh from another machine to our host machine as one of the SFTP users. You should receive this after entering a password: This service allows sftp connections only. Graphical Tool Testing If you do receive that message, then the next thing is to test SFTP access. If you would like to do things the easy way, you can use a graphical FTP application that supports SFTP such as Filezilla. In such cases, your fields would look something like this: Host: sftp://hostname_or_IP_of_the_server Username: (Example: myfixed) Password: (the password of the SFTP user) Port: (You shouldn't need to enter one, provided you are using SSH and SFTP on the default port 22) Once filled in, you can click the \"Quickconnect\" (Filezilla) button and you should be connected to the ../html directory of the appropriate site. Then double-click on the \"html\" directory to put yourself inside it, and try to drop a file into the directory. If you are successful, then you are good. Command Line Tool Testing You can obviously do all of this from the command line on a machine that has SSH installed. (most Linux installations). Here's a very brief overview of the command line method for connection and a few options: sftp username (Example: myfixed@ hostname or IP of the server: sftp myfixed@192.168.1.116) Enter the password when prompted cd html (change to the html directory) pwd (should show that you are in the html directory) lpwd (should show your local working directory) lcd PATH (should change your local working directory to something you want to use) put filename (will copy a file to ..html directory) For an exhaustive list of options and more, take a look at the SFTP manual page . Web Test Files For our dummy domains, we want to create a couple of index.html files that we can populate the ../html directory with. Once these are created, you simply need to put them in the directory for each domain using the SFTP credentials for that domain. These files are super simple. We just want something so that we can see definitively that our sites are up and running and that the SFTP portion is working as expected. Here's an example of this file. You can of course modify it as you like: <!DOCTYPE html> <html> <head> <title>My Broken Axel</title> </head> <body> <h1>My Broken Axel</h1> <p>A test page for the site.</p> </body> </html> Web Tests To test that these files show up and load as expected, you simply need to modify your hosts file on your workstation. For Linux, that would be sudo vi /etc/hosts and then simply add in the IP and host names we are testing with like this: 127.0.0.1 localhost 192.168.1.116 www.mybrokenaxel.com mybrokenaxel.com 192.168.1.116 www.myfixedaxel.com myfixedaxel.com # The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters !!! hint For real domains, you would want to populate your DNS server's with the hosts above. You can, though, use this *Poor Man's DNS* for testing any domain, even one that hasn't been taken live on real DNS servers. Now, open your web browser and check to make sure that your index.html file for each domain displays by entering the URL in your browser's address bar. Example: \"http://mybrokenaxel.com\" if your test index files load, everything is working correctly. Part 3: Administrative Access with SSH key pairs Please note that we will be using concepts discussed in the document SSH Public and Private Keys in this section, but also improving on it. If you are new to the process, feel free to read that article first before continuing. Creating the public/private Key Pairs From one of the administrative user's workstations command line, (Example: lblakely) do the following: ssh-keygen -t rsa Which will give you this: Generating public/private rsa key pair. Enter file in which to save the key (/home/lblakely/.ssh/id_rsa): Hit enter to create the private key in the location shown. This will give you this dialog: Enter passphrase (empty for no passphrase): You will need to decide personally whether you need a passphrase for this step. The author always just hits enter here. Enter same passphrase again: Repeat whatever passphrase you entered earlier or hit enter for none. At this point both the public and private keys have been created. Repeat this step for our other system administrator example user. Transferring The Public key to the SFTP Server The next step is to export our key to the server. In reality, a system administrator responsible for managing multiple servers would transfer his public key to all of the servers he/she is responsible for. Once the key is created, the user can send the key to the server securely with ssh-id-copy : ssh-id-copy lblakely@192.168.1.116 The server will prompt for the user's password one time, and then copy the key into authorized_keys. You'll get this message as well: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh 'lblakely@192.168.1.116'\" and check to make sure that only the key(s) you wanted were added. If you are able to login with this account, repeat the process with the other administrator. Allowing ONLY key-based Logins Assuming that all of the above has worked out as planned and our keys for our administrators are now in place on the SFTP server, let's turn off password authentication on the server. For safety sake, make sure that you have two connections to the server so that you can reverse any changes if you have unintended consequences. To accomplish this step, we need to modify the sshd_config once again, and just like before, we want to make a backup of the file first: cp -f /etc/ssh/sshd_config /etc/ssh/sshd_config.bak Next, edit the sshd_config file: vi /etc/ssh/sshd_config We want to turn off tunneled passwords so find this line in the configuration: PasswordAuthentication yes And change it so that it says \"no\" - note that just remarking out this line will fail, as the default is always \"yes\". PasswordAuthentication no Public key authentication is on by default, but let's make sure that it is evident when you look at the file by removing the remark in front of this line: #PubkeyAuthentication yes So that it reads: PubkeyAuthentication yes This makes our sshd_config file self-documenting to a degree. Save your changes. Cross your fingers, and restart sshd : systemctl restart sshd Attempting to login as one of your administrative users to the server using their keys should work just like before. If not, restore your backup, make sure that you've followed all of the steps, and try again. Part 4: Turn Off Remote root Login Essentially, we have functionally done that already. If you attempt to login with the root user to the server now, you will get the following: root@192.168.1.116: Permission denied (publickey,gssapi-keyex,gssapi-with-mic). But we want to make sure that someone cannot create a public/private key for the root user and access the server that way. So there's one final step we need to perform and we need to do that...You guessed it! ... in the sshd_config file. Since we are making a change to this file, just like every other step here, we want to make a backup copy of the file before continuing: cp -f /etc/ssh/sshd_config /etc/ssh/sshd_config.bak Again, we want to edit the sshd_config : vi /etc/ssh/sshd_config Then we want to find this line: PermitRootLogin yes And change it to \"no\" so it reads: PermitRootLogin no Then save and quit out of the file and restart sshd : systemctl restart sshd Now anyone attempting to login as the root user remotely over ssh will get the same denial message as before, but will still not be able to access the server even if they have a public/private key pair for root. Addendum: New System Administrators One thing that we haven't discussed yet is what happens when a new system administrator comes on board? With password authentication off, ssh-copy-id will not work. Here's what the author recommends for these situations. Note that there is more than one solution: Solution One - Sneaker Net This solution assumes physical access to the server and that the server is physical hardware and not virtual (container or VM): Add the user to the \"wheel\" group on the SFTP server Have the user generate his SSH public and private keys Using a USB drive, copy the public key to the drive and physically walk it over to the server and install it manually in the new system administrators /home/[username]/.ssh directory Solution Two - Temporarily Edit The sshd_config This solution is prone to human error, but since it isn't done often, it would probably be OK if carefully done: Add the user to the \"wheel\" group on the SFTP server Have another system administrator who already has key based authentication, temporarily turn on \"PasswordAuthentication yes\" in the sshd_config file and restart sshd Have the new system administrator run ssh-copy-id using his/her password to copy the ssh key to the server. Solution Three - Script The Process This is the author's favorite. It uses a system administrator which already has key-based access and a script that must be run with bash [script-name] to accomplish the same thing as \"Solution Two\" above: manually edit the sshd_config file and remove the remarked out line that looks like this: #PasswordAuthentication no . This line is documenting the process of turning password authentication off, but it will get in the way of the script below, because our script will look for the first occurrence of PasswordAuthentication no and later the first occurrence of PasswordAuthentication yes . If you remove this one line, our script will work fine. create a script on the SFTP server called \"quickswitch\", or whatever you want to call it. The contents of this script would look like this: #!/bin/bash # for use in adding a new system administrator /usr/bin/cp -f /etc/ssh/sshd_config /etc/ssh/sshd_config.bak /usr/bin/sed -i '0,/PasswordAuthentication no/ s/PasswordAuthentication no/PasswordAuthentication yes/' /etc/ssh/sshd_config /usr/bin/systemctl restart sshd echo \"Have the user send his keys, and then hit enter.\" read yn /usr/bin/sed -i '0,/PasswordAuthentication yes/ s/PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config /usr/bin/systemctl restart sshd echo \"Changes reversed\" Script explanation: We don't make this script executable. The reason is that we don't want it accidentally run. The script would need to be run (as noted above) like this: bash /usr/local/sbin/quickswitch . This script makes a backup copy of the sshd_config file just like all of our other examples above. It then edits the sshd_config file in place and searches for the FIRST occurrence of PasswordAuthentication no and changes it to PasswordAuthentication yes then restarts sshd and waits for the script user to hit ENTER before continuing. The system administrator running the script would be in communication with the new system administrator, and once that new system administrator runs ssh-copy-id to copy his key to the server, the system administrator who is running the script hits enter and the change is reversed. Conclusion We've covered a lot of bits and pieces in this document but they are all designed to make a multisite web server more secure and less prone to attack vectors over SSH when turning on SFTP for customer access. Turning on and using SFTP is much more secure than using FTP, even if you are using really GOOD ftp servers and have them set up as securely as possible as noted in this document on VSFTPD . By implementing all of the steps in this document, you can feel comfortable opening up port 22 (SSH) to your public zone and still know that your environment is secure.","title":"Secure Server - sftp"},{"location":"guides/file_sharing/sftp/#secure-server-sftp-with-ssh-lock-down-procedures","text":"","title":"Secure Server - SFTP with SSH Lock Down Procedures"},{"location":"guides/file_sharing/sftp/#introduction","text":"It may seem strange to have a document dedicated to the \"secure\" use of SFTP (a part of openssh-server package) when the SSH proptocol is itself secure. I hear what you are thinking. But most system administrators do not want to open up SSH to everyone in order to implement SFTP for everyone. This document will describe how to implement a change root jail 1 for SFTP while keeping SSH access limited. There are many documents out there that deal with creating an SFTP change root jail, but most do not take into account a use case where the user that is set up would be accessing a web directory on a server with multiple websites. This document deals with that. If that isn't your use case, you can easily adapt these concepts to use in different situations. The author also feels that it is necessary when making the change root jail document for SFTP to also discuss the other things that you should do as a system administrator to minimize the target that you offer to the world via SSH. For this reason, this document is divided into four parts: The first deals with the general information that we will use for the entire document. The second deals with the setup of the change root jail, and if you decide that you want to stop there, that's totally up to you. The third part deals with setting up public/private key SSH access for your system administrators and turning off remote password based authentication. The fourth, and last section of this document deals with turning off remote root logins. Taking all of these steps will allow you to offer secure SFTP access for your customers while also minimizing the possibility that port 22 (the one reserved for SSH access) will be compromised by a bad actor. !!! Note \" 1 Change root jails for beginners:\" Change root (or chroot) jails are a way to restrict what a process and all of its various child processes can do on your computer. It essentially allows you to choose a specific directory/folder on your machine, and make that the \"root\" dirtectory for any given process or program. From there on, that process or program can *only* access that folder and its subfolders. !!! hint \"Updates for Rocky Linux 8.6\" This document has been updated to include new changes that came out with version 8.6 that will make this procedure even safer. If you are using 8.6, then there are specific sections in the document below, prefixed with \"8.6 -\". For clarity sake, the sections specific to Rocky Linux 8.5 have been prefixed with \"8.5 - \". Other than those sections specifically prefixed, this document is generic for both versions of the OS.","title":"Introduction"},{"location":"guides/file_sharing/sftp/#part-1-general-information","text":"","title":"Part 1: General Information"},{"location":"guides/file_sharing/sftp/#assumptions-and-conventions","text":"We assume that: you are comfortable executing commands at the command line. you can use a command line editor, such as vi (used here), nano , micro , etc. you understand basic Linux commands used for adding groups and users, or can follow along well. your multisite website is set up like this: Apache Multisite httpd (Apache) has already been installed on the server. !!! note You can apply these concepts to any server set up, and to any web daemon. While we are assuming Apache here, you can definitely use this for Nginx as well.","title":"Assumptions and Conventions"},{"location":"guides/file_sharing/sftp/#sites-users-administrators","text":"Everything is made up here. Any resemblance to persons or sites that are real, is purely accidental: Sites: mybrokenaxel.com user = mybroken myfixedaxel.com user = myfixed Administrators Steve Simpson = ssimpson Laura Blakely = lblakely","title":"Sites, Users, Administrators"},{"location":"guides/file_sharing/sftp/#part-2-sftp-change-root-jail","text":"","title":"Part 2: SFTP Change Root Jail"},{"location":"guides/file_sharing/sftp/#installation","text":"Installation is simple. You just need to have openssh-server installed, which is probably installed already. Enter this command to be sure: dnf install openssh-server","title":"Installation"},{"location":"guides/file_sharing/sftp/#setup","text":"","title":"Setup"},{"location":"guides/file_sharing/sftp/#directories","text":"The directory path structure will be /var/www/sub-domains/[ext.domainname]/html and the html directory in this path will be the change root jail for the SFTP user. Creating the configuration directories: mkdir -p /etc/httpd/sites-available mkdir -p /etc/httpd/sites-enabled Creating the web directories: mkdir -p /var/www/sub-domains/com.mybrokenaxel/html mkdir -p /var/www/sub-domains/com.myfixedaxel/html We will deal with the ownership of these directories in the script application found below.","title":"Directories"},{"location":"guides/file_sharing/sftp/#httpd-configuration","text":"We need to modify the built-in httpd.conf file to make it load the configuration files in the /etc/httpd/sites-enabled directory. This is done with one line at the bottom of the httpd.conf file. Edit the file with your favorite editor. I'm using vi here: vi /etc/httpd/conf/httpd.conf and add this at the very bottom of the file: Include /etc/httpd/sites-enabled Then save the file and exit.","title":"httpd Configuration"},{"location":"guides/file_sharing/sftp/#website-configuration","text":"We need two sites created. We will create the configurations in /etc/httpd/sites-available and then link them to ../sites-enabled : vi /etc/httpd/sites-available/com.mybrokenaxel !!! note We are only using the HTTP protocol for our example. Any real website would need an HTTPS protocol configuration, SSL certificates, and possibly more. <VirtualHost *:80> ServerName www.mybrokenaxel.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.mybrokenaxel/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ CustomLog \"/var/log/httpd/com.mybrokenaxel.www-access_log\" combined ErrorLog \"/var/log/httpd/com.mybrokenaxel.www-error_log\" <Directory /var/www/sub-domains/com.mybrokenaxel/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Save this file and exit. vi /etc/httpd/sites-available/com.myfixedaxel <VirtualHost *:80> ServerName www.myfixedaxel.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.myfixedaxel/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ CustomLog \"/var/log/httpd/com.myfixedaxel.www-access_log\" combined ErrorLog \"/var/log/httpd/com.myfixedaxel.www-error_log\" <Directory /var/www/sub-domains/com.myfixedaxel/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Save this file and exit. Once the two configuration files are created, go ahead and link them from within /etc/httpd/sites-enabled : ln -s ../sites-available/com.mybrokenaxel ln -s ../sites-available/com.myfixedaxel Now enable and start the httpd process: systemctl enable --now httpd","title":"Website Configuration"},{"location":"guides/file_sharing/sftp/#user-creation","text":"For our example environment, we are assuming that none of the users are set up. Let's start with our administrative users. Note that at this point in our process, we can still log in as the root user to add the other users and set them up the way we want. We will remove root logins once we have the users set up and tested.","title":"User Creation"},{"location":"guides/file_sharing/sftp/#administrators","text":"useradd -g wheel ssimpson useradd -g wheel lblakely By adding our users to the group \"wheel\" we give them sudo access. You still need a password for sudo access. There are ways around this, but none are all that secure. Frankly, if you have problems with security using sudo on your server, then you've got much bigger problems with your entire setup. Set the two administrative passwords with secure passwords: passwd ssimpson Changing password for user ssimpson. New password: Retype new password: passwd: all authentication tokens updated successfully. passwd lblakely Changing password for user lblakely. New password: Retype new password: passwd: all authentication tokens updated successfully. Now test access to the server via ssh for your two administrative users. You should be able to: use ssh to log in as one of the administrative users to the server. (Example: ssh lblakely@192.168.1.116 or ssh lblakely@mywebserver.com ) once the server is accessed, you should be able to access root with sudo -s and entering the administrative user's password. If this works for both administrative users, you should be ready to go to the next step.","title":"Administrators"},{"location":"guides/file_sharing/sftp/#web-users-sftp","text":"We need to add our web users. That ../html directory structure already exists, so we don't want to create it when we add the user, but we do want to specify it. We also do not want any login other than via SFTP so we need to use a shell that denies logins. useradd -M -d /var/www/sub-domains/com.mybrokenaxel/html -g apache -s /usr/sbin/nologin mybroken useradd -M -d /var/www/sub-domains/com.myfixedaxel/html -g apache -s /usr/sbin/nologin myfixed Let's break down those commands a bit: The -M option says to not create the standard home directory for the user. -d specifies that what comes after is the actual home directory. -g says that the group that this user belongs to is apache . -s says that the shell the user is assigned is /usr/sbin/nologin At the end is the actual username for the user. Note: For an Nginx server, you would use nginx as the group. Our SFTP users still need a password. So let's go ahead and setup a secure password for each now. Since we have already seen the command output above, we won't be repeating it here: passwd mybroken passwd myfixed","title":"Web Users (SFTP)"},{"location":"guides/file_sharing/sftp/#ssh-configuration","text":"!!! caution Before we start this next process, it is highly recommended that you make a backup of the system file we are going to be modifying: `/etc/ssh/sshd_config`. Breaking this file and not being able to go back to the original could cause you a world of heartache! ``` cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak ``` We need to make one change to the /etc/ssh/sshd_config file and then we are going to build a template so that we can make our web directory changes outside of the configuration file and script the additions we are going to need. First, let's make the manual change we need: vi /etc/ssh/sshd_config Near the bottom of the file, you will find this: # override default of no subsystems Subsystem sftp /usr/libexec/openssh/sftp-server We want to change that to read as follows: # override default of no subsystems # Subsystem sftp /usr/libexec/openssh/sftp-server Subsystem sftp internal-sftp Save and exit the file. Just like before, let's describe what we are doing a little here. Both the sftp-server and internal-sftp are part of OpenSSH. The internal-sftp , while not too different from the sftp-server , simplifies configurations using ChrootDirectory to force a different file system root on clients. So that is why we want to use internal-sftp .","title":"SSH Configuration"},{"location":"guides/file_sharing/sftp/#85-the-template-and-the-script","text":"Why are we creating a template and a script for this next part? The reason is simply to avoid human error as much as possible. We aren't done modifying that /etc/ssh/sshd_config file yet, but we want to eliminate as many errors as possible whenever we need to make these modifications. We will create all of this in /usr/local/sbin .","title":"8.5 - The Template And The Script"},{"location":"guides/file_sharing/sftp/#the-template","text":"First, let's create our template: vi /usr/local/sbin/sshd_template This template should have the following: Match User replaceuser PasswordAuthentication yes ChrootDirectory replacedirectory ForceCommand internal-sftp AllowTcpForwarding no X11Forwarding no !!! note The `PasswordAuthentication yes` would not normally be required for the change root jail, BUT, we will be turning off `PasswordAuthentication` later on for everyone else, so it is important to have this line in the template. We want a directory for our user files that we will create from the template too: mkdir /usr/local/sbin/templates","title":"The Template"},{"location":"guides/file_sharing/sftp/#85-the-script","text":"Now let's create our script: vi /usr/local/sbin/webuser And put this code in it: #!/bin/bash # script to populate the SSHD configuration for web users. # Set variables tempfile=\"/usr/local/sbin/sshd_template\" dompath=\"/var/www/sub-domains/\" # Prompt for user and domain in reverse (ext.domainname): clear echo -n \"Enter the web sftp user: \" read sftpuser echo -n \"Enter the domain in reverse. Example: com.domainname: \" read dom echo -n \"Is all of this correct: sftpuser = $sftpuser and domain = $dom (Y/N)? \" read yn if [ \"$yn\" = \"n\" ] || [ \"$yn\" = \"N\" ] then exit fi if [ \"$yn\" = \"y\" ] || [ \"$yn\" = \"Y\" ] then /usr/bin/cat $tempfile > /usr/local/sbin/templates/$dom.txt /usr/bin/sed -i \"s,replaceuser,$sftpuser,g\" /usr/local/sbin/templates/$dom.txt /usr/bin/sed -i \"s,replacedirectory,$dompath$dom,g\" /usr/local/sbin/templates/$dom.txt /usr/bin/chown -R $sftpuser.apache $dompath$dom/html fi ## Make a backup of /etc/ssh/sshd_config /usr/bin/rm -f /etc/ssh/sshd_config.bak /usr/bin/cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak ## Now append our new user information to to the file cat /usr/local/sbin/templates/$dom.txt >> /etc/ssh/sshd_config ## Restart sshd /usr/bin/systemctl restart sshd echo \" \" echo \"Please check the status of sshd with systemctl status sshd.\" echo \"You can verify that your information was added to the sshd_config by doing a more of the sshd_config\" echo \"A backup of the working sshd_config was created when this script was run: sshd_config.bak\"","title":"8.5 - The Script"},{"location":"guides/file_sharing/sftp/#86-the-template-and-the-script","text":"With the release of Rocky Linux 8.6, a new option is available for the sshd_config file that allows for drop in configurations. This is a GREAT change. What this means is that for 8.6, we will make a single additional change to the sshd_config file, and then our script will build out sftp changes in a separate configuration file. While the 8.5 procedure above is pretty darned safe, this new change makes things even safer. Safety is good!!","title":"8.6 - The Template And The Script"},{"location":"guides/file_sharing/sftp/#86-the-template","text":"There are no changes between 8.5 and 8.6 as far as the template is concerned. So use that procedure above and then return here for the script.","title":"8.6 The Template"},{"location":"guides/file_sharing/sftp/#86-the-script-and-sshd_config-changes","text":"Because of the changes allowed for the sshd_config file in Rocky Linux 8.6, our script will use a new drop in configuration file: /etc/ssh/sftp/sftp_config . To start with, create that directory: mkdir /etc/ssh/sftp Now make a backup copy of the sshd_config : cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak And finally edit the sshd_config file, scroll to the very bottom of the file, and add this line: Include /etc/ssh/sftp/sftp_config Save your changes and exit the file. We will need to restart sshd but our script will do that for us after we update sftp_config file, so let's create the script and run it. vi /usr/local/sbin/webuser And put this code in it: #!/bin/bash # script to populate the SSHD configuration for web users. # Set variables tempfile=\"/usr/local/sbin/sshd_template\" dompath=\"/var/www/sub-domains/\" # Prompt for user and domain in reverse (ext.domainname): clear echo -n \"Enter the web sftp user: \" read sftpuser echo -n \"Enter the domain in reverse. Example: com.domainname: \" read dom echo -n \"Is all of this correct: sftpuser = $sftpuser and domain = $dom (Y/N)? \" read yn if [ \"$yn\" = \"n\" ] || [ \"$yn\" = \"N\" ] then exit fi if [ \"$yn\" = \"y\" ] || [ \"$yn\" = \"Y\" ] then /usr/bin/cat $tempfile > /usr/local/sbin/templates/$dom.txt /usr/bin/sed -i \"s,replaceuser,$sftpuser,g\" /usr/local/sbin/templates/$dom.txt /usr/bin/sed -i \"s,replacedirectory,$dompath$dom,g\" /usr/local/sbin/templates/$dom.txt /usr/bin/chown -R $sftpuser.apache $dompath$dom/html fi ## Make a backup of /etc/ssh/sftp/sftp_config /usr/bin/rm -f /etc/ssh/sftp/sftp_config.bak /usr/bin/cp /etc/ssh/sftp/sftp_config /etc/ssh/sftp/sftp_config.bak ## Now append our new user information to to the file cat /usr/local/sbin/templates/$dom.txt >> /etc/ssh/sftp/sftp_config ## Restart sshd /usr/bin/systemctl restart sshd echo \" \" echo \"Please check the status of sshd with systemctl status sshd.\" echo \"You can verify that your information was added by doing a more of the sftp_config\" echo \"A backup of the working sftp_config was created when this script was run: sftp_config.bak\"","title":"8.6 - The Script and sshd_config Changes"},{"location":"guides/file_sharing/sftp/#final-changes-and-script-notes-for-both-85-and-86","text":"!!! tip If you take a look at either of the scripts above, you will note that we have changed the delimiter that `sed` uses by default from `/` to `,`. `sed` allows you to use any single-byte character as a delimiter. What we are searching for in the file has a bunch of \"/\" characters in it, and we would have had to escape each one (add a \"\\\" in front of them) to search and replace these strings. Changing the delimiter makes this infinitely easier to do because it eliminates the need to do those escapes. A couple of things to know about the script and about an SFTP change root in general. First, we are prompting for the needed information and then echoing it back to the user so they can verify it. If we answer \"N\" to the confirmation question, the script bails and does nothing. The script for 8.5 makes a backup of sshd_config ( /etc/ssh/sshd_config.bak ) the way it was prior to our running of the script. The 8.6 script does the same for the sftp_config file ( /etc/ssh/sftp/sftp_config.bak ). In this way, if we screw something up with an entry, we can simply restore the appropriate backup file and then restart sshd to get things working again. The SFTP change root requires that the path given in the sshd_config is owned by root. For this reason we do not need the html directory added to the end of the path. Once the user is authenticated, the change root will switch the user's home directory, in this case the ../html , directory to whichever domain we are entering. Our script has appropriately changed the owner of the ../html directory to the sftpuser and the apache group. !!! attention \"Script Compatibility\" While you can use the script that we created for Rocky Linxux 8.5 on either 8.5 or 8.6 successfully, the same cannot be said for the 8.6 script. Since the drop in configuration file option (`Include` directive) was not enabled in 8.5, attempting to use the 8.6 script in Rocky Linux 8.5 will fail. Now that our script is created, let's make it executable: chmod +x /usr/local/sbin/webuser Then run the script for our two test domains.","title":"Final Changes and Script Notes for both 8.5 and 8.6"},{"location":"guides/file_sharing/sftp/#testing-ssh-denial-and-sftp-access","text":"First, test using ssh from another machine to our host machine as one of the SFTP users. You should receive this after entering a password: This service allows sftp connections only.","title":"Testing SSH Denial and SFTP Access"},{"location":"guides/file_sharing/sftp/#graphical-tool-testing","text":"If you do receive that message, then the next thing is to test SFTP access. If you would like to do things the easy way, you can use a graphical FTP application that supports SFTP such as Filezilla. In such cases, your fields would look something like this: Host: sftp://hostname_or_IP_of_the_server Username: (Example: myfixed) Password: (the password of the SFTP user) Port: (You shouldn't need to enter one, provided you are using SSH and SFTP on the default port 22) Once filled in, you can click the \"Quickconnect\" (Filezilla) button and you should be connected to the ../html directory of the appropriate site. Then double-click on the \"html\" directory to put yourself inside it, and try to drop a file into the directory. If you are successful, then you are good.","title":"Graphical Tool Testing"},{"location":"guides/file_sharing/sftp/#command-line-tool-testing","text":"You can obviously do all of this from the command line on a machine that has SSH installed. (most Linux installations). Here's a very brief overview of the command line method for connection and a few options: sftp username (Example: myfixed@ hostname or IP of the server: sftp myfixed@192.168.1.116) Enter the password when prompted cd html (change to the html directory) pwd (should show that you are in the html directory) lpwd (should show your local working directory) lcd PATH (should change your local working directory to something you want to use) put filename (will copy a file to ..html directory) For an exhaustive list of options and more, take a look at the SFTP manual page .","title":"Command Line Tool Testing"},{"location":"guides/file_sharing/sftp/#web-test-files","text":"For our dummy domains, we want to create a couple of index.html files that we can populate the ../html directory with. Once these are created, you simply need to put them in the directory for each domain using the SFTP credentials for that domain. These files are super simple. We just want something so that we can see definitively that our sites are up and running and that the SFTP portion is working as expected. Here's an example of this file. You can of course modify it as you like: <!DOCTYPE html> <html> <head> <title>My Broken Axel</title> </head> <body> <h1>My Broken Axel</h1> <p>A test page for the site.</p> </body> </html>","title":"Web Test Files"},{"location":"guides/file_sharing/sftp/#web-tests","text":"To test that these files show up and load as expected, you simply need to modify your hosts file on your workstation. For Linux, that would be sudo vi /etc/hosts and then simply add in the IP and host names we are testing with like this: 127.0.0.1 localhost 192.168.1.116 www.mybrokenaxel.com mybrokenaxel.com 192.168.1.116 www.myfixedaxel.com myfixedaxel.com # The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters !!! hint For real domains, you would want to populate your DNS server's with the hosts above. You can, though, use this *Poor Man's DNS* for testing any domain, even one that hasn't been taken live on real DNS servers. Now, open your web browser and check to make sure that your index.html file for each domain displays by entering the URL in your browser's address bar. Example: \"http://mybrokenaxel.com\" if your test index files load, everything is working correctly.","title":"Web Tests"},{"location":"guides/file_sharing/sftp/#part-3-administrative-access-with-ssh-key-pairs","text":"Please note that we will be using concepts discussed in the document SSH Public and Private Keys in this section, but also improving on it. If you are new to the process, feel free to read that article first before continuing.","title":"Part 3: Administrative Access with SSH key pairs"},{"location":"guides/file_sharing/sftp/#creating-the-publicprivate-key-pairs","text":"From one of the administrative user's workstations command line, (Example: lblakely) do the following: ssh-keygen -t rsa Which will give you this: Generating public/private rsa key pair. Enter file in which to save the key (/home/lblakely/.ssh/id_rsa): Hit enter to create the private key in the location shown. This will give you this dialog: Enter passphrase (empty for no passphrase): You will need to decide personally whether you need a passphrase for this step. The author always just hits enter here. Enter same passphrase again: Repeat whatever passphrase you entered earlier or hit enter for none. At this point both the public and private keys have been created. Repeat this step for our other system administrator example user.","title":"Creating the public/private Key Pairs"},{"location":"guides/file_sharing/sftp/#transferring-the-public-key-to-the-sftp-server","text":"The next step is to export our key to the server. In reality, a system administrator responsible for managing multiple servers would transfer his public key to all of the servers he/she is responsible for. Once the key is created, the user can send the key to the server securely with ssh-id-copy : ssh-id-copy lblakely@192.168.1.116 The server will prompt for the user's password one time, and then copy the key into authorized_keys. You'll get this message as well: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh 'lblakely@192.168.1.116'\" and check to make sure that only the key(s) you wanted were added. If you are able to login with this account, repeat the process with the other administrator.","title":"Transferring The Public key to the SFTP Server"},{"location":"guides/file_sharing/sftp/#allowing-only-key-based-logins","text":"Assuming that all of the above has worked out as planned and our keys for our administrators are now in place on the SFTP server, let's turn off password authentication on the server. For safety sake, make sure that you have two connections to the server so that you can reverse any changes if you have unintended consequences. To accomplish this step, we need to modify the sshd_config once again, and just like before, we want to make a backup of the file first: cp -f /etc/ssh/sshd_config /etc/ssh/sshd_config.bak Next, edit the sshd_config file: vi /etc/ssh/sshd_config We want to turn off tunneled passwords so find this line in the configuration: PasswordAuthentication yes And change it so that it says \"no\" - note that just remarking out this line will fail, as the default is always \"yes\". PasswordAuthentication no Public key authentication is on by default, but let's make sure that it is evident when you look at the file by removing the remark in front of this line: #PubkeyAuthentication yes So that it reads: PubkeyAuthentication yes This makes our sshd_config file self-documenting to a degree. Save your changes. Cross your fingers, and restart sshd : systemctl restart sshd Attempting to login as one of your administrative users to the server using their keys should work just like before. If not, restore your backup, make sure that you've followed all of the steps, and try again.","title":"Allowing ONLY key-based Logins"},{"location":"guides/file_sharing/sftp/#part-4-turn-off-remote-root-login","text":"Essentially, we have functionally done that already. If you attempt to login with the root user to the server now, you will get the following: root@192.168.1.116: Permission denied (publickey,gssapi-keyex,gssapi-with-mic). But we want to make sure that someone cannot create a public/private key for the root user and access the server that way. So there's one final step we need to perform and we need to do that...You guessed it! ... in the sshd_config file. Since we are making a change to this file, just like every other step here, we want to make a backup copy of the file before continuing: cp -f /etc/ssh/sshd_config /etc/ssh/sshd_config.bak Again, we want to edit the sshd_config : vi /etc/ssh/sshd_config Then we want to find this line: PermitRootLogin yes And change it to \"no\" so it reads: PermitRootLogin no Then save and quit out of the file and restart sshd : systemctl restart sshd Now anyone attempting to login as the root user remotely over ssh will get the same denial message as before, but will still not be able to access the server even if they have a public/private key pair for root.","title":"Part 4: Turn Off Remote root Login"},{"location":"guides/file_sharing/sftp/#addendum-new-system-administrators","text":"One thing that we haven't discussed yet is what happens when a new system administrator comes on board? With password authentication off, ssh-copy-id will not work. Here's what the author recommends for these situations. Note that there is more than one solution:","title":"Addendum: New System Administrators"},{"location":"guides/file_sharing/sftp/#solution-one-sneaker-net","text":"This solution assumes physical access to the server and that the server is physical hardware and not virtual (container or VM): Add the user to the \"wheel\" group on the SFTP server Have the user generate his SSH public and private keys Using a USB drive, copy the public key to the drive and physically walk it over to the server and install it manually in the new system administrators /home/[username]/.ssh directory","title":"Solution One - Sneaker Net"},{"location":"guides/file_sharing/sftp/#solution-two-temporarily-edit-the-sshd_config","text":"This solution is prone to human error, but since it isn't done often, it would probably be OK if carefully done: Add the user to the \"wheel\" group on the SFTP server Have another system administrator who already has key based authentication, temporarily turn on \"PasswordAuthentication yes\" in the sshd_config file and restart sshd Have the new system administrator run ssh-copy-id using his/her password to copy the ssh key to the server.","title":"Solution Two - Temporarily Edit The sshd_config"},{"location":"guides/file_sharing/sftp/#solution-three-script-the-process","text":"This is the author's favorite. It uses a system administrator which already has key-based access and a script that must be run with bash [script-name] to accomplish the same thing as \"Solution Two\" above: manually edit the sshd_config file and remove the remarked out line that looks like this: #PasswordAuthentication no . This line is documenting the process of turning password authentication off, but it will get in the way of the script below, because our script will look for the first occurrence of PasswordAuthentication no and later the first occurrence of PasswordAuthentication yes . If you remove this one line, our script will work fine. create a script on the SFTP server called \"quickswitch\", or whatever you want to call it. The contents of this script would look like this: #!/bin/bash # for use in adding a new system administrator /usr/bin/cp -f /etc/ssh/sshd_config /etc/ssh/sshd_config.bak /usr/bin/sed -i '0,/PasswordAuthentication no/ s/PasswordAuthentication no/PasswordAuthentication yes/' /etc/ssh/sshd_config /usr/bin/systemctl restart sshd echo \"Have the user send his keys, and then hit enter.\" read yn /usr/bin/sed -i '0,/PasswordAuthentication yes/ s/PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config /usr/bin/systemctl restart sshd echo \"Changes reversed\" Script explanation: We don't make this script executable. The reason is that we don't want it accidentally run. The script would need to be run (as noted above) like this: bash /usr/local/sbin/quickswitch . This script makes a backup copy of the sshd_config file just like all of our other examples above. It then edits the sshd_config file in place and searches for the FIRST occurrence of PasswordAuthentication no and changes it to PasswordAuthentication yes then restarts sshd and waits for the script user to hit ENTER before continuing. The system administrator running the script would be in communication with the new system administrator, and once that new system administrator runs ssh-copy-id to copy his key to the server, the system administrator who is running the script hits enter and the change is reversed.","title":"Solution Three - Script The Process"},{"location":"guides/file_sharing/sftp/#conclusion","text":"We've covered a lot of bits and pieces in this document but they are all designed to make a multisite web server more secure and less prone to attack vectors over SSH when turning on SFTP for customer access. Turning on and using SFTP is much more secure than using FTP, even if you are using really GOOD ftp servers and have them set up as securely as possible as noted in this document on VSFTPD . By implementing all of the steps in this document, you can feel comfortable opening up port 22 (SSH) to your public zone and still know that your environment is secure.","title":"Conclusion"},{"location":"guides/git/git_wf_git-cola_atom/","text":"git Workflow for Documentation: git, Git Cola, and Atom So, you want to submit some documentation to this repository. Well, git experts can always just get cracking and work how they usually do, then push their suggested changes to us. But if you're more of a beginner, and are looking for an example workflow, this guide can help. It should be noted at the outset that this is by no means a definitive. There are many git workflow options; you may not find this one to your liking, and that is fine. You might find parts of this workflow that you like and other parts that just don't work for you. That's fine too. This is one method, and the author is hopeful that others will share their git workflows as well, providing a wealth of options for anyone who wants to contribute to the documentation for Rocky Linux. Prerequisites and Assumptions A Rocky Linux desktop (This guide will work on other RHEL-based distros, and likely on Fedora, too.) Familiarity with the command line A GitHub account with SSH key access The Components This particular workflow uses the following components: A personal fork of the documentation repository found here A local cloned copy of the repository on a Linux workstation Git Cola: a visual client for git branching and staging (optional) The Atom editor (optional) !!! Note While both Atom and Git Cola are described as optional, you'll need at least one of them for this particular workflow. This author likes to use both: one for the GitHub portion (Git Cola), and one for the editing portion (Atom). Installing Repositories Only a couple of repositories are really required. The EPEL (Extra Packages for Enterprise Linux) and the Atom editor repository. To install the EPEL, run: sudo dnf install epel-release Next, we need the GPG key for Atom and the repository: sudo rpm --import https://packagecloud.io/AtomEditor/atom/gpgkey And then: sudo sh -c 'echo -e \"[Atom]\\nname=Atom Editor\\nbaseurl=https://packagecloud.io/AtomEditor/atom/el/7/\\$basearch\\nenabled=1\\ngpgcheck=0\\nrepo_gpgcheck=1\\ngpgkey=https://packagecloud.io/AtomEditor/atom/gpgkey\" > /etc/yum.repos.d/atom.repo' Then update the system: sudo dnf update Installing Packages Run the following command to install the packages we need with dnf : sudo dnf install git git-cola There will be a number of other packages installed as dependencies so simply answer 'Y' to allow the installation. Next, install the Atom editor: sudo dnf install atom Forking the Rocky Linux Documentation Repository You will need your own fork of the repository. This will become one of your git remotes for this workflow. We are already assuming that you've created your GitHub account, have SSH key access, and are logged in to Documentation . On the right-hand side of the page, click on \"Fork\" shown here: When this completes, you should have a fork with a URL that has your username in it. If your git username was \"alphaomega\" then the URL would be: https://github.com/alphaomega/documentation Cloning a Local copy of the Repository Next we need a local copy of the repository, which is easy enough to do. Again, from the Rocky Linux Documentation , look for the green \"Code\" button and click on it: Once open, click on SSH and then copy the URL: On your Linux workstation in a terminal window, enter the following at the command line: git clone And then paste the URL into the command line so you should have this when done: git clone git@github.com:rocky-linux/documentation.git When this command is completed, you should now have a local copy of the documentation repository. This creates a directory called \"documentation\" in your home directory: home:~/documentation Setting Up Git Cola Next, if you want to set up Git Cola, we need to open the \"documentation\" repository we just created locally, and we need to set up the remotes. This is an optional step, but I like to do it. You can set your remotes with git via the command line as well, but I find this method easier, because for me, I want the Rocky Linux remote to be called something different from \"origin\" which is what it will be named by default. For me, I think of my fork as the \"origin\" and the Rocky Linux documentation as the \"upstream\" repository. You may disagree. When you first open Git Cola, it asks you to select your repository. You could have several on your machine, but the one you are looking for is the one called \"documentation.\" So click on this one and open it. Once you have your repository open, setup the remotes by clicking on File and Edit Remotes . By default, it will already show you your Rocky Linux remote as \"origin\". To change this, simply click in the field, backspace over the top of \"origin,\" replace it with \"upstream\" and click \"Save.\" Next, we actually want to create a new remote that is your fork. Click the green plus sign (+) in the left-hand corner of the bottom of the screen and a new remote dialog will open. Type \"origin\" for the name, and then, assuming our GitHub username is \"alphaomega\" again, your URL will look like this: git@github.com:alphaomega/documentation.git Save this and you are done. Testing that your Workflow will actually workflow Do this all from the command line. Change into your documentation directory: cd documentation Then type: git pull upstream main This will test that you have everything setup and working to pull from Rocky Linux upstream. If there are no problems, next type the following: git push origin main This will test access to your fork of the Rocky Linux documentation. If there are no errors, then this command can be strung together in the future with: git pull upstream main && git push origin main This command should be run before any branches are created or any work is done, to keep your branches in sync. A Note about Atom and Git Cola and why the author uses both The Atom editor has integration with git and GitHub. In fact, you can use Atom without the need for Git Cola at all. That said, the visualizations that Git Cola provides are clearer from the author's view. The editor features in Atom far outweigh those that are specifically designed as markdown editors (again, the author's opinion). If you so choose, you can eliminate the need for Git Cola and simply use Atom if you like. You can always eliminate Atom and use a different markdown editor. I use Git Cola for setting up the remotes (as we have already seen), branching, and committing changes. Atom is used as a text editor and markdown preview only. Pushes and pulls are done from the command line. Branching with Git Cola You always want to create a branch by using the \"main\" as the template. Make sure that \"main\" is selected in the \"Branches\" listing on the right-hand side of Git Cola, then click \"Branch\" top menu item and \"Create.\" Type a name for your new branch. !!! Note When naming branches, consider using descriptive names. These will help add clarity when you push them upstream. For instance, the author uses an \"rl_\" prefix when creating a new document, and then appends the a descriptive short name for what the document is. For edits, the author uses \"edit_\" as the prefix followed by a short name about what the edit is for. As an example, below you can see the \"Branches\" listing, which shows \"rl_git_workflow\": As you create and save your changes in Atom, you will see the \"Unstaged Changes\" listing in the git view change: These changes also show up in Git Cola under the \"Status\" in the left-hand window: Staging the Files with Git Cola Once our document is done and we are ready to create the pull request, the first thing we need to do is to write a commit statement. In most cases typing it all up before committing the files is easier, because as soon as you stage your files, the changes will disappear from view. You want your commit statement to be as clear as possible. The Commit summary should say what you are committing. For example: \"Document to Present a git Workflow.\" The extended description should give bullet points of the highlights of the document, for instance: git workflow using Git Cola and Atom Includes corresponding images Once you've written the commit but before you hit the \"Commit\" button, you need to stage all of your unstaged files. To do this, select all of the files, then right-click and click on \"Stage Selected.\" Now click the \"Commit\" button. Before you get out of Git Cola, in the \"Branches\" section on the right, right-click \"main\" and click \"Checkout.\" We want to be checked out to main before we push our files. Pushing To Your Fork Now that all of the document creation work is done, you need to push your branch to your fork. If you followed along as we created the remotes before, then you have created your fork as the \"origin.\" We need to get into the documentation directory in the terminal window. In other words, into the clone of the Rocky Documentation repository. From a terminal window type: cd documentation You should see your home directory and your cursor inside documentation: home:~/documentation$ Now we need to push our changes: git push origin rl_git_workflow This says we are pushing to our fork, the branch that we just created and put a document into. When we enter this command, we get back a message from git that says you can create a Pull Request. It will look something like this: Enumerating objects: 16, done. Counting objects: 100% (16/16), done. Delta compression using up to 6 threads Compressing objects: 100% (12/12), done. Writing objects: 100% (12/12), 122.01 KiB | 2.22 MiB/s, done. Total 12 (delta 4), reused 0 (delta 0) remote: Resolving deltas: 100% (4/4), completed with 4 local objects. remote: remote: Create a pull request for 'rl_git_workflow' on GitHub by visiting: remote: https://github.com/alphaomega/documentation/pull/new/rl_git_workflow remote: To github.com:alphaomega/documentation.git * [new branch] rl_git_workflow -> rl_git_workflow Adding to the Document If you suddenly realize that you have more to add to your document, and don't want to do the PR as yet, that's no problem. Go back to Git Cola, right-click on your branch (in this case \"rl_git_workflow\") and click \"Checkout\" then go back to Atom, open your document again and make whatever additions you need to add. Any changes you make to the file or files, will again have to be staged, and a new commit will need to be written. You will need to right-click the \"main\" branch when done and click \"Checkout\" again, and you will need to push your changes to your fork again. The difference is that since the URL for doing the pull request (PR) has already been sent, you will not get this again. You need to use the original link that was sent before. Waiting For Your PR to be Merged An editor has to give your document a once over. They need to be certain that everything you have done and written matches the guidelines, and maybe make some edits. Conclusion Everyone who uses git has a slightly different workflow. This is the author's. If you have a favorite workflow, please post it!","title":"git Using Git Cola and Atom"},{"location":"guides/git/git_wf_git-cola_atom/#git-workflow-for-documentation-git-git-cola-and-atom","text":"So, you want to submit some documentation to this repository. Well, git experts can always just get cracking and work how they usually do, then push their suggested changes to us. But if you're more of a beginner, and are looking for an example workflow, this guide can help. It should be noted at the outset that this is by no means a definitive. There are many git workflow options; you may not find this one to your liking, and that is fine. You might find parts of this workflow that you like and other parts that just don't work for you. That's fine too. This is one method, and the author is hopeful that others will share their git workflows as well, providing a wealth of options for anyone who wants to contribute to the documentation for Rocky Linux.","title":"git Workflow for Documentation: git, Git Cola, and Atom"},{"location":"guides/git/git_wf_git-cola_atom/#prerequisites-and-assumptions","text":"A Rocky Linux desktop (This guide will work on other RHEL-based distros, and likely on Fedora, too.) Familiarity with the command line A GitHub account with SSH key access","title":"Prerequisites and Assumptions"},{"location":"guides/git/git_wf_git-cola_atom/#the-components","text":"This particular workflow uses the following components: A personal fork of the documentation repository found here A local cloned copy of the repository on a Linux workstation Git Cola: a visual client for git branching and staging (optional) The Atom editor (optional) !!! Note While both Atom and Git Cola are described as optional, you'll need at least one of them for this particular workflow. This author likes to use both: one for the GitHub portion (Git Cola), and one for the editing portion (Atom).","title":"The Components"},{"location":"guides/git/git_wf_git-cola_atom/#installing-repositories","text":"Only a couple of repositories are really required. The EPEL (Extra Packages for Enterprise Linux) and the Atom editor repository. To install the EPEL, run: sudo dnf install epel-release Next, we need the GPG key for Atom and the repository: sudo rpm --import https://packagecloud.io/AtomEditor/atom/gpgkey And then: sudo sh -c 'echo -e \"[Atom]\\nname=Atom Editor\\nbaseurl=https://packagecloud.io/AtomEditor/atom/el/7/\\$basearch\\nenabled=1\\ngpgcheck=0\\nrepo_gpgcheck=1\\ngpgkey=https://packagecloud.io/AtomEditor/atom/gpgkey\" > /etc/yum.repos.d/atom.repo' Then update the system: sudo dnf update","title":"Installing Repositories"},{"location":"guides/git/git_wf_git-cola_atom/#installing-packages","text":"Run the following command to install the packages we need with dnf : sudo dnf install git git-cola There will be a number of other packages installed as dependencies so simply answer 'Y' to allow the installation. Next, install the Atom editor: sudo dnf install atom","title":"Installing Packages"},{"location":"guides/git/git_wf_git-cola_atom/#forking-the-rocky-linux-documentation-repository","text":"You will need your own fork of the repository. This will become one of your git remotes for this workflow. We are already assuming that you've created your GitHub account, have SSH key access, and are logged in to Documentation . On the right-hand side of the page, click on \"Fork\" shown here: When this completes, you should have a fork with a URL that has your username in it. If your git username was \"alphaomega\" then the URL would be: https://github.com/alphaomega/documentation","title":"Forking the Rocky Linux Documentation Repository"},{"location":"guides/git/git_wf_git-cola_atom/#cloning-a-local-copy-of-the-repository","text":"Next we need a local copy of the repository, which is easy enough to do. Again, from the Rocky Linux Documentation , look for the green \"Code\" button and click on it: Once open, click on SSH and then copy the URL: On your Linux workstation in a terminal window, enter the following at the command line: git clone And then paste the URL into the command line so you should have this when done: git clone git@github.com:rocky-linux/documentation.git When this command is completed, you should now have a local copy of the documentation repository. This creates a directory called \"documentation\" in your home directory: home:~/documentation","title":"Cloning a Local copy of the Repository"},{"location":"guides/git/git_wf_git-cola_atom/#setting-up-git-cola","text":"Next, if you want to set up Git Cola, we need to open the \"documentation\" repository we just created locally, and we need to set up the remotes. This is an optional step, but I like to do it. You can set your remotes with git via the command line as well, but I find this method easier, because for me, I want the Rocky Linux remote to be called something different from \"origin\" which is what it will be named by default. For me, I think of my fork as the \"origin\" and the Rocky Linux documentation as the \"upstream\" repository. You may disagree. When you first open Git Cola, it asks you to select your repository. You could have several on your machine, but the one you are looking for is the one called \"documentation.\" So click on this one and open it. Once you have your repository open, setup the remotes by clicking on File and Edit Remotes . By default, it will already show you your Rocky Linux remote as \"origin\". To change this, simply click in the field, backspace over the top of \"origin,\" replace it with \"upstream\" and click \"Save.\" Next, we actually want to create a new remote that is your fork. Click the green plus sign (+) in the left-hand corner of the bottom of the screen and a new remote dialog will open. Type \"origin\" for the name, and then, assuming our GitHub username is \"alphaomega\" again, your URL will look like this: git@github.com:alphaomega/documentation.git Save this and you are done.","title":"Setting Up Git Cola"},{"location":"guides/git/git_wf_git-cola_atom/#testing-that-your-workflow-will-actually-workflow","text":"Do this all from the command line. Change into your documentation directory: cd documentation Then type: git pull upstream main This will test that you have everything setup and working to pull from Rocky Linux upstream. If there are no problems, next type the following: git push origin main This will test access to your fork of the Rocky Linux documentation. If there are no errors, then this command can be strung together in the future with: git pull upstream main && git push origin main This command should be run before any branches are created or any work is done, to keep your branches in sync.","title":"Testing that your Workflow will actually workflow"},{"location":"guides/git/git_wf_git-cola_atom/#a-note-about-atom-and-git-cola-and-why-the-author-uses-both","text":"The Atom editor has integration with git and GitHub. In fact, you can use Atom without the need for Git Cola at all. That said, the visualizations that Git Cola provides are clearer from the author's view. The editor features in Atom far outweigh those that are specifically designed as markdown editors (again, the author's opinion). If you so choose, you can eliminate the need for Git Cola and simply use Atom if you like. You can always eliminate Atom and use a different markdown editor. I use Git Cola for setting up the remotes (as we have already seen), branching, and committing changes. Atom is used as a text editor and markdown preview only. Pushes and pulls are done from the command line.","title":"A Note about Atom and Git Cola and why the author uses both"},{"location":"guides/git/git_wf_git-cola_atom/#branching-with-git-cola","text":"You always want to create a branch by using the \"main\" as the template. Make sure that \"main\" is selected in the \"Branches\" listing on the right-hand side of Git Cola, then click \"Branch\" top menu item and \"Create.\" Type a name for your new branch. !!! Note When naming branches, consider using descriptive names. These will help add clarity when you push them upstream. For instance, the author uses an \"rl_\" prefix when creating a new document, and then appends the a descriptive short name for what the document is. For edits, the author uses \"edit_\" as the prefix followed by a short name about what the edit is for. As an example, below you can see the \"Branches\" listing, which shows \"rl_git_workflow\": As you create and save your changes in Atom, you will see the \"Unstaged Changes\" listing in the git view change: These changes also show up in Git Cola under the \"Status\" in the left-hand window:","title":"Branching with Git Cola"},{"location":"guides/git/git_wf_git-cola_atom/#staging-the-files-with-git-cola","text":"Once our document is done and we are ready to create the pull request, the first thing we need to do is to write a commit statement. In most cases typing it all up before committing the files is easier, because as soon as you stage your files, the changes will disappear from view. You want your commit statement to be as clear as possible. The Commit summary should say what you are committing. For example: \"Document to Present a git Workflow.\" The extended description should give bullet points of the highlights of the document, for instance: git workflow using Git Cola and Atom Includes corresponding images Once you've written the commit but before you hit the \"Commit\" button, you need to stage all of your unstaged files. To do this, select all of the files, then right-click and click on \"Stage Selected.\" Now click the \"Commit\" button. Before you get out of Git Cola, in the \"Branches\" section on the right, right-click \"main\" and click \"Checkout.\" We want to be checked out to main before we push our files.","title":"Staging the Files with Git Cola"},{"location":"guides/git/git_wf_git-cola_atom/#pushing-to-your-fork","text":"Now that all of the document creation work is done, you need to push your branch to your fork. If you followed along as we created the remotes before, then you have created your fork as the \"origin.\" We need to get into the documentation directory in the terminal window. In other words, into the clone of the Rocky Documentation repository. From a terminal window type: cd documentation You should see your home directory and your cursor inside documentation: home:~/documentation$ Now we need to push our changes: git push origin rl_git_workflow This says we are pushing to our fork, the branch that we just created and put a document into. When we enter this command, we get back a message from git that says you can create a Pull Request. It will look something like this: Enumerating objects: 16, done. Counting objects: 100% (16/16), done. Delta compression using up to 6 threads Compressing objects: 100% (12/12), done. Writing objects: 100% (12/12), 122.01 KiB | 2.22 MiB/s, done. Total 12 (delta 4), reused 0 (delta 0) remote: Resolving deltas: 100% (4/4), completed with 4 local objects. remote: remote: Create a pull request for 'rl_git_workflow' on GitHub by visiting: remote: https://github.com/alphaomega/documentation/pull/new/rl_git_workflow remote: To github.com:alphaomega/documentation.git * [new branch] rl_git_workflow -> rl_git_workflow","title":"Pushing To Your Fork"},{"location":"guides/git/git_wf_git-cola_atom/#adding-to-the-document","text":"If you suddenly realize that you have more to add to your document, and don't want to do the PR as yet, that's no problem. Go back to Git Cola, right-click on your branch (in this case \"rl_git_workflow\") and click \"Checkout\" then go back to Atom, open your document again and make whatever additions you need to add. Any changes you make to the file or files, will again have to be staged, and a new commit will need to be written. You will need to right-click the \"main\" branch when done and click \"Checkout\" again, and you will need to push your changes to your fork again. The difference is that since the URL for doing the pull request (PR) has already been sent, you will not get this again. You need to use the original link that was sent before.","title":"Adding to the Document"},{"location":"guides/git/git_wf_git-cola_atom/#waiting-for-your-pr-to-be-merged","text":"An editor has to give your document a once over. They need to be certain that everything you have done and written matches the guidelines, and maybe make some edits.","title":"Waiting For Your PR to be Merged"},{"location":"guides/git/git_wf_git-cola_atom/#conclusion","text":"Everyone who uses git has a slightly different workflow. This is the author's. If you have a favorite workflow, please post it!","title":"Conclusion"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/","text":"Import Rocky Linux to WSL2 with Docker Prerequisites Either Linux PC running VirtualBox - VirtualBox will not run under windows 10 with WSL2, which is needed for later steps. You can also use a dual boot PC, or a live distribution, but make sure you have VirtualBox available. Or Docker Desktop for Windows 10 (or any docker installation) Required * Windows 10 PC running WSL2 * Internet access Introduction This guide shows the steps to create a tar image for a Docker container, and how to import that image into the Windows Subsystem for Linux (WSL). The steps outlined below are largely taken from Microsoft's Import any Linux distribution to use with WSL and from Docker's Create a base image , and adapted to the new distribution. Please note that you need Virtual Box (to create the container for yourself) OR Docker to just pull the existing image from Docker Hub. This guide assumes the user is familiar with VirtualBox or Docker, and knows how to perform tasks like installing the VirtualBoxAdditions, and mounting shared drives. It is also important to be familiar with the limitations of WSL, which will cause some functionality to break, work slowly, or work in unexpected ways. Depending on what you want to accomplish, the resulting distribution may or may not do what you want it to do. There are no guarantees. Install Steps Get Rocky Container Image Pull From Docker Hub (on the same PC as your WSL2 install) From powershell or another WSL2 distro create a rocky container using the version you wish to start with. Replace the tag with your desired tag docker run --name rocky-container rockylinux/rockylinux:8.5 Confirm the container exists docker container list --all | Select-String rocky-container Export container as tar docker export rocky-container -o rocky-container.tar Note: You don't have to be on the same system as your WSL2 install, you just need to be able to get that tar file to the system. Create Your Own On Linux PC with VirtualBox Download the minimal image from Rocky Linux . Boot and install Rocky Linux on a new VirtualBox VM. The default settings are fine. Install VirtualBoxAdditions on your VM. This will require installing additional packages (as shown in the suggested command): $ sudo yum install gcc make kernel-devel bzip2 binutils patch libgomp glibc-headers glibc-devel kernel-headers elfutils-libelf-devel tar Make a working directory, and copy files to be used for the tar image. $ mkdir wsl_tar $ cd wsl_tar $ cp -p /etc/yum.conf . $ cp -p /etc/yum.repos.d/Rocky-BaseOS.repo . Edit your copy of yum.conf and add this line to it (modify the path as needed): reposdir=/home/<your_username>/wsl_tar/ Download the script to create a base image from Docker GitHub. The script is called mkimage-yum.sh . Modify the script to create a tar file at the end, instead of starting Docker. Here are the suggested changes to the file: ## Change line 143 to simply create the tar file, without invoking Docker tar --numeric-owner -c -C \"$target\" . -f <path-to-the-new-tar-file> ## Comment out line 145 Execute the script using this command (modify the path as needed): $ sudo ./mkimage-yum.sh -y /home/<your_username>/wsl_tar/yum.conf baseos After the script finishes, your new tar file will be in the path you entered in the script above. Mount a shared drive with the host and move the tar file there. You could also move the file to a USB drive or folder accessible to the Windows 10 PC. After moving the file to an external drive or folder, you won't need the VM anymore. You can delete it or modify it for other purposes. Import into WSL2 Create a directory to hold the Rocky Linux filesystem. In a PowerShell prompt, import Rocky Linux (it's named rocky_rc here, but you can name it anything you like). wsl --import rocky_rc <Path to RockyLinuxDirectory from step 1> <Path to tar file from previous sections> Verify Rocky Linux is installed with: wsl -l -v Launch Rocky Linux with wsl -d rocky_rc Set up Rocky Linux with the following bash commands (you'll need to be running as root). yum update yum install glibc-langpack-en -y yum install passwd sudo -y yum reinstall cracklib-dicts -y newUsername=<your new username> adduser -G wheel $newUsername echo -e \"[user]\\ndefault=$newUsername\" >> /etc/wsl.conf passwd $newUsername Exit the bash prompt (Ctrl+D or exit). Back in a PowerShell prompt, shutdown all WSL running instances and start Rocky. wsl --shutdown wsl -d rocky_rc Test and enjoy! If you have Windows Terminal installed, the new WSL distro name will appear as an option on the pull-down menu, which is quite handy to launch it in the future. You can then customize it with colors, fonts, etc. Even though you need WSL2 in order to perform the steps above, you can use the distro as WSL 1 or 2, by converting it with PowerShell commands.","title":"Import to WSL2 with Docker"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/#import-rocky-linux-to-wsl2-with-docker","text":"","title":"Import Rocky Linux to WSL2 with Docker"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/#prerequisites","text":"Either Linux PC running VirtualBox - VirtualBox will not run under windows 10 with WSL2, which is needed for later steps. You can also use a dual boot PC, or a live distribution, but make sure you have VirtualBox available. Or Docker Desktop for Windows 10 (or any docker installation) Required * Windows 10 PC running WSL2 * Internet access","title":"Prerequisites"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/#introduction","text":"This guide shows the steps to create a tar image for a Docker container, and how to import that image into the Windows Subsystem for Linux (WSL). The steps outlined below are largely taken from Microsoft's Import any Linux distribution to use with WSL and from Docker's Create a base image , and adapted to the new distribution. Please note that you need Virtual Box (to create the container for yourself) OR Docker to just pull the existing image from Docker Hub. This guide assumes the user is familiar with VirtualBox or Docker, and knows how to perform tasks like installing the VirtualBoxAdditions, and mounting shared drives. It is also important to be familiar with the limitations of WSL, which will cause some functionality to break, work slowly, or work in unexpected ways. Depending on what you want to accomplish, the resulting distribution may or may not do what you want it to do. There are no guarantees.","title":"Introduction"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/#install-steps","text":"","title":"Install Steps"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/#get-rocky-container-image","text":"","title":"Get Rocky Container Image"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/#pull-from-docker-hub-on-the-same-pc-as-your-wsl2-install","text":"From powershell or another WSL2 distro create a rocky container using the version you wish to start with. Replace the tag with your desired tag docker run --name rocky-container rockylinux/rockylinux:8.5 Confirm the container exists docker container list --all | Select-String rocky-container Export container as tar docker export rocky-container -o rocky-container.tar Note: You don't have to be on the same system as your WSL2 install, you just need to be able to get that tar file to the system.","title":"Pull From Docker Hub (on the same PC as your WSL2 install)"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/#create-your-own-on-linux-pc-with-virtualbox","text":"Download the minimal image from Rocky Linux . Boot and install Rocky Linux on a new VirtualBox VM. The default settings are fine. Install VirtualBoxAdditions on your VM. This will require installing additional packages (as shown in the suggested command): $ sudo yum install gcc make kernel-devel bzip2 binutils patch libgomp glibc-headers glibc-devel kernel-headers elfutils-libelf-devel tar Make a working directory, and copy files to be used for the tar image. $ mkdir wsl_tar $ cd wsl_tar $ cp -p /etc/yum.conf . $ cp -p /etc/yum.repos.d/Rocky-BaseOS.repo . Edit your copy of yum.conf and add this line to it (modify the path as needed): reposdir=/home/<your_username>/wsl_tar/ Download the script to create a base image from Docker GitHub. The script is called mkimage-yum.sh . Modify the script to create a tar file at the end, instead of starting Docker. Here are the suggested changes to the file: ## Change line 143 to simply create the tar file, without invoking Docker tar --numeric-owner -c -C \"$target\" . -f <path-to-the-new-tar-file> ## Comment out line 145 Execute the script using this command (modify the path as needed): $ sudo ./mkimage-yum.sh -y /home/<your_username>/wsl_tar/yum.conf baseos After the script finishes, your new tar file will be in the path you entered in the script above. Mount a shared drive with the host and move the tar file there. You could also move the file to a USB drive or folder accessible to the Windows 10 PC. After moving the file to an external drive or folder, you won't need the VM anymore. You can delete it or modify it for other purposes.","title":"Create Your Own On Linux PC with VirtualBox"},{"location":"guides/interoperability/import_rocky_to_wsl_howto/#import-into-wsl2","text":"Create a directory to hold the Rocky Linux filesystem. In a PowerShell prompt, import Rocky Linux (it's named rocky_rc here, but you can name it anything you like). wsl --import rocky_rc <Path to RockyLinuxDirectory from step 1> <Path to tar file from previous sections> Verify Rocky Linux is installed with: wsl -l -v Launch Rocky Linux with wsl -d rocky_rc Set up Rocky Linux with the following bash commands (you'll need to be running as root). yum update yum install glibc-langpack-en -y yum install passwd sudo -y yum reinstall cracklib-dicts -y newUsername=<your new username> adduser -G wheel $newUsername echo -e \"[user]\\ndefault=$newUsername\" >> /etc/wsl.conf passwd $newUsername Exit the bash prompt (Ctrl+D or exit). Back in a PowerShell prompt, shutdown all WSL running instances and start Rocky. wsl --shutdown wsl -d rocky_rc Test and enjoy! If you have Windows Terminal installed, the new WSL distro name will appear as an option on the pull-down menu, which is quite handy to launch it in the future. You can then customize it with colors, fonts, etc. Even though you need WSL2 in order to perform the steps above, you can use the distro as WSL 1 or 2, by converting it with PowerShell commands.","title":"Import into WSL2"},{"location":"guides/interoperability/rocky_to_wsl_howto/","text":"Import Rocky Linux to WSL with WSL and rinse Prerequisites A Windows 10 PC with WSL 2 enabled. (*see note below). Ubuntu, or any debian-based distribution, installed and running on WSL. This guide was tested using Ubuntu 20.04 LTS from the Microsoft store. Introduction This guide is for Windows users who would like to run Rocky Linux (RL) in the Windows Subsystem for Linux (WSL). It assumes the reader is familiar with the command line and has WSL enabled and running in their Windows 10 PC. The process uses rinse , a perl script for creating images of distributions that use the package manager YUM. Please keep in mind that WSL has significant limitations and quirks, and the resulting distribution may or may not work as you expect it. It may be too slow, or be unpredictable for some applications. With computers, as with life, there are no guarantees. Steps Launch your Ubuntu distribution in WSL, update the package manager and install rinse $ sudo apt-get update $ sudo apt-get install rinse rinse is not aware of RL, so we need to modify its configuration to add the package repositories and so on. Copy the CentOS 8 packages file and prepare it for RL $ sudo cp -p /etc/rinse/centos-8.packages /etc/rinse/rocky-8.packages Edit the new file and change all the entries for 'centos' to 'rocky'. Next, add the following lines to it. The order in the file is not important, the entries can be added anywhere. Here you can also add any other packages that you may want to have in your image (servers, utilities like which , etc) glibc-langpack-en libmodulemd libzstd passwd sudo cracklib-dicts openssh-clients python3-dbus dbus-glib Edit the rinse config file at /etc/rinse/rinse.conf and add the following lines, which are the entry for RL mirrors. As of this writing, we have a direct download, but this will be changed to a mirror as soon as available. # Rocky Linux 8 [rocky-8] mirror.amd64 = http://dl.rockylinux.org/pub/rocky/8/BaseOS/x86_64/os/Packages/ Copy the post-install script for CentOS so it can be modified for RL $ sudo cp -pR /usr/lib/rinse/centos-8 /usr/lib/rinse/rocky-8 Edit /usr/lib/rinse/rocky-8/post-install.sh and add the following lines at line 14. This is needed to make sure TLS/SSL works as expected for YUM and dnf . echo \" Extracting CA certs...\" $CH /usr/bin/update-ca-trust Edit the rinse script at /usr/sbin/rinse , and at line 1248 remove the text --extract-over-symlinks . This option was deprecated in the program called and breaks the script. Don't close the file yet. On the same file, go to line 1249 and replace 'centos' for 'rocky'. Save and close the file. Make a directory to hold the new RL filesystem (any name is fine). $ mkdir rocky_rc Execute rinse with the following command $ sudo rinse --arch amd64 --directory ./rocky_rc --distribution rocky-8 After the script completes downloading and extracting all the packages, you will have a full Rocky Linux file system in the directory you created. Now it's time to package it to pass it to Windows for importing into a new WSL distro. Use this command, creating the tar file in a Windows folder (starting with /mnt/c/ or similar to have it readily available for the next step). $ sudo tar --numeric-owner -c -C ./rocky_rc . -f <path to new tar file> Close your WSL session with Ctrl+D or by typing exit . Open a PowerShell prompt (does not need to be admin), and create a folder to hold your new RL distro. Import the tar file with this command: wsl --import rocky_rc <path to folder from step 9> <path to tar file> Note: Default location of WSL is %LOCALAPPDATA%\\Packages\\ e.g. for Ubuntu - C:\\Users\\tahder\\AppData\\Local\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhks2fndhsd\\LocalState\\rootfs\\home\\txunil\\rocky_rc In the PowerShell prompt, launch your new distro with: wsl -d rocky_rc You are now root in your new RL distro. Run these commands to finish setting everything up: yum update yum reinstall passwd sudo cracklib-dicts -y newUsername=<your new username> adduser -G wheel $newUsername echo -e \"[user]\\ndefault=$newUsername\" >> /etc/wsl.conf passwd $newUsername Exit the bash prompt (Ctrl+D or type exit ). Back in PowerShell, shutdown WSL and relaunch your new distro. wsl --shutdown wsl -d rocky_rc Test and enjoy! Cleanup All the downloaded packages are still stored in the debian distro you used at the beginning of the process. You can remove the files from /var/cache/rinse , and you can also delete all the files from the rocky_rc directory. Next time you want to create a new, updated or modified image, simply make your changes and run the commands from step 10 on. Known issues There are some quirky things that result from extracting packages, rather than installing them. Running yum reinstall in some packages fixes the issues, as is the case for passwd . The rinse script simply extracts the packages and does not execute post-install commands (although it is capable of doing so). Please leave comments for other users if you run into problems and know how to fix them, so that others can benefit from your experience. Notes Most of the rinse script runs under WSL 1, but the very last part, where dnf is invoked, runs into memory issues and corrupts the rpm database. This ruins the distro, and repair attempts fail, even under WSL. If you know how to get dnf to work under WSL 1, please let us know, but there are lots of BDB issues related to WSL 1 on different forums on the web. WSL 2 solved those issues with the native Linux kernel.","title":"Import To WSL with WSL and rinse"},{"location":"guides/interoperability/rocky_to_wsl_howto/#import-rocky-linux-to-wsl-with-wsl-and-rinse","text":"","title":"Import Rocky Linux to WSL with WSL and rinse"},{"location":"guides/interoperability/rocky_to_wsl_howto/#prerequisites","text":"A Windows 10 PC with WSL 2 enabled. (*see note below). Ubuntu, or any debian-based distribution, installed and running on WSL. This guide was tested using Ubuntu 20.04 LTS from the Microsoft store.","title":"Prerequisites"},{"location":"guides/interoperability/rocky_to_wsl_howto/#introduction","text":"This guide is for Windows users who would like to run Rocky Linux (RL) in the Windows Subsystem for Linux (WSL). It assumes the reader is familiar with the command line and has WSL enabled and running in their Windows 10 PC. The process uses rinse , a perl script for creating images of distributions that use the package manager YUM. Please keep in mind that WSL has significant limitations and quirks, and the resulting distribution may or may not work as you expect it. It may be too slow, or be unpredictable for some applications. With computers, as with life, there are no guarantees.","title":"Introduction"},{"location":"guides/interoperability/rocky_to_wsl_howto/#steps","text":"Launch your Ubuntu distribution in WSL, update the package manager and install rinse $ sudo apt-get update $ sudo apt-get install rinse rinse is not aware of RL, so we need to modify its configuration to add the package repositories and so on. Copy the CentOS 8 packages file and prepare it for RL $ sudo cp -p /etc/rinse/centos-8.packages /etc/rinse/rocky-8.packages Edit the new file and change all the entries for 'centos' to 'rocky'. Next, add the following lines to it. The order in the file is not important, the entries can be added anywhere. Here you can also add any other packages that you may want to have in your image (servers, utilities like which , etc) glibc-langpack-en libmodulemd libzstd passwd sudo cracklib-dicts openssh-clients python3-dbus dbus-glib Edit the rinse config file at /etc/rinse/rinse.conf and add the following lines, which are the entry for RL mirrors. As of this writing, we have a direct download, but this will be changed to a mirror as soon as available. # Rocky Linux 8 [rocky-8] mirror.amd64 = http://dl.rockylinux.org/pub/rocky/8/BaseOS/x86_64/os/Packages/ Copy the post-install script for CentOS so it can be modified for RL $ sudo cp -pR /usr/lib/rinse/centos-8 /usr/lib/rinse/rocky-8 Edit /usr/lib/rinse/rocky-8/post-install.sh and add the following lines at line 14. This is needed to make sure TLS/SSL works as expected for YUM and dnf . echo \" Extracting CA certs...\" $CH /usr/bin/update-ca-trust Edit the rinse script at /usr/sbin/rinse , and at line 1248 remove the text --extract-over-symlinks . This option was deprecated in the program called and breaks the script. Don't close the file yet. On the same file, go to line 1249 and replace 'centos' for 'rocky'. Save and close the file. Make a directory to hold the new RL filesystem (any name is fine). $ mkdir rocky_rc Execute rinse with the following command $ sudo rinse --arch amd64 --directory ./rocky_rc --distribution rocky-8 After the script completes downloading and extracting all the packages, you will have a full Rocky Linux file system in the directory you created. Now it's time to package it to pass it to Windows for importing into a new WSL distro. Use this command, creating the tar file in a Windows folder (starting with /mnt/c/ or similar to have it readily available for the next step). $ sudo tar --numeric-owner -c -C ./rocky_rc . -f <path to new tar file> Close your WSL session with Ctrl+D or by typing exit . Open a PowerShell prompt (does not need to be admin), and create a folder to hold your new RL distro. Import the tar file with this command: wsl --import rocky_rc <path to folder from step 9> <path to tar file> Note: Default location of WSL is %LOCALAPPDATA%\\Packages\\ e.g. for Ubuntu - C:\\Users\\tahder\\AppData\\Local\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhks2fndhsd\\LocalState\\rootfs\\home\\txunil\\rocky_rc In the PowerShell prompt, launch your new distro with: wsl -d rocky_rc You are now root in your new RL distro. Run these commands to finish setting everything up: yum update yum reinstall passwd sudo cracklib-dicts -y newUsername=<your new username> adduser -G wheel $newUsername echo -e \"[user]\\ndefault=$newUsername\" >> /etc/wsl.conf passwd $newUsername Exit the bash prompt (Ctrl+D or type exit ). Back in PowerShell, shutdown WSL and relaunch your new distro. wsl --shutdown wsl -d rocky_rc Test and enjoy!","title":"Steps"},{"location":"guides/interoperability/rocky_to_wsl_howto/#cleanup","text":"All the downloaded packages are still stored in the debian distro you used at the beginning of the process. You can remove the files from /var/cache/rinse , and you can also delete all the files from the rocky_rc directory. Next time you want to create a new, updated or modified image, simply make your changes and run the commands from step 10 on.","title":"Cleanup"},{"location":"guides/interoperability/rocky_to_wsl_howto/#known-issues","text":"There are some quirky things that result from extracting packages, rather than installing them. Running yum reinstall in some packages fixes the issues, as is the case for passwd . The rinse script simply extracts the packages and does not execute post-install commands (although it is capable of doing so). Please leave comments for other users if you run into problems and know how to fix them, so that others can benefit from your experience.","title":"Known issues"},{"location":"guides/interoperability/rocky_to_wsl_howto/#notes","text":"Most of the rinse script runs under WSL 1, but the very last part, where dnf is invoked, runs into memory issues and corrupts the rpm database. This ruins the distro, and repair attempts fail, even under WSL. If you know how to get dnf to work under WSL 1, please let us know, but there are lots of BDB issues related to WSL 1 on different forums on the web. WSL 2 solved those issues with the native Linux kernel.","title":"Notes"},{"location":"guides/mirror_management/add_mirror_manager/","text":"Adding a public mirror to Rocky's mirror manager Minimal requirements for public mirrors We always welcome new public mirrors. But they should be well maintained and hosted in a 24/7 data center like environment. Available bandwidth should be at least 1 GBit/s. We prefer mirrors offering dual-stack (IPv4 & IPv6). Please do not submit mirrors configured using dynamic DNS. If you are offering a mirror in a region that has only few mirrors, we will also accept slower speeds. Please do not submit mirrors which are hosted in a Anycast-CDN like Cloudflare, etc. as this can lead to sub-optimal performance with the selection of fastest mirror in dnf . Please note that we are not allowed to accept public mirrors in countries subject to US export regulations. You can find a list of those countries here: https://www.bis.doc.gov/index.php/policy-guidance/country-guidance/sanctioned-destinations Hard disk space requirements are around 500 GB at the moment but expect it to grow over time. 600 GB space should be sufficient for the next few years. Our master mirror is rsync://msync.rockylinux.org/rocky/mirror/pub/rocky/ For your first synchronization use a mirror near to you. You can find all official mirrors here: https://mirrors.rockylinux.org Please note that we might restrict access to the official master mirror to official public mirrors in the future. So please consider rsyncing from a public mirror close to you if you are running a private mirror. Also local mirrors might be faster to sync from. Setting up your mirror Please set up a cron job to synchronize your mirror periodically and let it run around 6 times a day. But be sure to sync off the hour to help distribute the load over time. If you only check against changes of fullfiletimelist-rocky and only do a full sync if this file has changed you can synchronize every hour. Here are some crontab examples for you: #This will synchronize your mirror at 0:50, 4:50, 8:50, 12:50, 16:50, 20:50 50 */6 * * * /path/to/your/rocky-rsync-mirror.sh > /dev/null 2>&1 #This will synchronize your mirror at 2:25, 6:25, 10:25, 14:25, 18:25, 22:25 25 2,6,10,14,18,22 * * * /path/to/your/rocky-rsync-mirror.sh > /dev/null 2>&1 #This will synchronize your mirror every hour at 15 minutes past the hour. #Only use if you are using our example script 15 * * * * /path/to/your/rocky-rsync-mirror.sh > /dev/null 2>&1 For a simple synchronization you can use the following rsync command: rsync -aqH --delete source-mirror destination-dir Consider using a locking mechanism to avoid running more than one rsync job simultaneously when we push a new release. You can also use and modify our example script implementing locking and full sync if required. It can be found at https://github.com/rocky-linux/rocky-tools/blob/main/mirror/mirrorsync.sh . After your first complete synchronization check that everything is fine with your mirror. Most importantly check all files and dirs got synchronized, your cron job is working properly and your mirror is reachable from the public Internet. Double check your firewall rules! To avoid any problems do not enforce http to https redirection. If you have any questions setting up your mirror join https://chat.rockylinux.org/rocky-linux/channels/infrastructure When you are done head over to the next section and propose your mirror to become public! What You Need An account on https://accounts.rockylinux.org/ Creating a site Rocky uses Fedora's Mirror Manager for organizing community mirrors. Access Rocky's Mirror Manager here: https://mirrors.rockylinux.org/mirrormanager/ After a successful login, your profile will be on the top right. Select the drop down then click \"My sites\". A new page will load listing all of the sites under the account. The first time it will be empty. Click \"Register a new site\". A new page will load with an important Export Compliance statement to read. Then fill out the following information: \"Site Name\" \"Site Password\" - used by report_mirrors script, you make this anything you want \"Organization URL\" - Company/School/Organization URL e.g. https://rockylinux.org/ \"Private\" - Checking this box hides your mirror from public use. \"User active\" - Uncheck this box to temporarily disable this site, it will be removed from public listings. \"All sites can pull from me?\" - Enable all mirror sites to pull from me without explicitly adding them to my list. \"Comments for downstream siteadmins. Please include your synchronization source here to avoid dependency loops.\" Upon clicking \"Submit\" you will be returned to the main mirror page. Configuring the site From the main mirror page, select the drop down then click \"My sites\". The account site page will load and the site should be listed. Click on it to go to the Information Site. All of the options from the last section are listed again. At the bottom of the page are three new options: Admins, Hosts, and Delete site. Click on the \"Hosts [add]\". Create new host Fill out the following options that are appropriate for the site: \"Host name\" - required: FQDN of server as seen by a public end user \"User active\" - Uncheck this box to temporarily disable this host, it will be removed from public listings. \"Country\" - required: 2-letter ISO country code \"Bandwidth\" - required: integer megabits/sec, how much bandwidth this host can serve \"Private\" - e.g. not available to the public, an internal private mirror \"Internet2\" - on Internet2 \"Internet2 clients\" - serves Internet2 clients, even if private \"ASN - Autonomous System Number, used in BGP routing tables. Only if you are an ISP. \"ASN Clients? - Serve all clients from the same ASN. Used for ISPs, companies, or schools, not personal networks. \"Robot email\" - email address, will receive notice of upstream content updates \"Comment\" - text, anything else you'd like a public end user to know about your mirror \"Max connections\" - Maximum parallel download connections per client, suggested via metalinks. Click \"Create\" and it will redirect back to the Information site for the host. Update host At the bottom of the Information site, the option for \"Hosts\" should now display the host title next to it. Click on the name to load the host page. All of the same options from the previous step are listed again. There are new options at the bottom. \"Site-local Netblocks\": Netblocks are used to try to guide and end user to a site-specific mirror. For example, a university might list their netblocks, and the mirrorlist CGI would return the university-local mirror rather than a country-local mirror. Format is one of 18.0.0.0/255.0.0.0, 18.0.0.0/8, an IPv6 prefix/length, or a DNS hostname. Values must be public IP addresses (no RFC1918 private space addresses). Use only if you are an ISP and/or own a publicly routeable netblock! \"Peer ASNs\": Peer ASNs are used to guide an end user on nearby networks to our mirror. For example, a university might list their peer ASNs, and the mirrorlist CGI would return the university-local mirror rather than a country-local mirror. You must be in the MirrorManager administrators group in order to create new entries here. \"Countries Allowed\": Some mirrors need to restrict themselves to serving only end users from their country. If you're one of these, list the 2-letter ISO code for the countries you will allow end users to be from. The mirrorlist CGI will honor this. \"Categories Carried\": Hosts carry categories of software. Example Fedora categories include Fedora and Fedora Archive. Click on the \"[add]\" link under \"Categories Carried\". Categories Carried For the Category, select \"Rocky Linux\" then \"Create\" to load the URL page. Then click \"[add]\" to load the \"Add host category URL\" page. There is one option. Repeat as needed for each of the mirrors supported protocols. \"URL\" - URL (rsync, https, http) pointing to the top directory Examples: * http://rocky.example.com * https://rocky.example.com * rsync://rocky.example.com Wrap up Once the information is filled out, the site should appear on the mirror list as soon as the next mirror refresh occurs.","title":"Adding a Rocky Mirror"},{"location":"guides/mirror_management/add_mirror_manager/#adding-a-public-mirror-to-rockys-mirror-manager","text":"","title":"Adding a public mirror to Rocky's mirror manager"},{"location":"guides/mirror_management/add_mirror_manager/#minimal-requirements-for-public-mirrors","text":"We always welcome new public mirrors. But they should be well maintained and hosted in a 24/7 data center like environment. Available bandwidth should be at least 1 GBit/s. We prefer mirrors offering dual-stack (IPv4 & IPv6). Please do not submit mirrors configured using dynamic DNS. If you are offering a mirror in a region that has only few mirrors, we will also accept slower speeds. Please do not submit mirrors which are hosted in a Anycast-CDN like Cloudflare, etc. as this can lead to sub-optimal performance with the selection of fastest mirror in dnf . Please note that we are not allowed to accept public mirrors in countries subject to US export regulations. You can find a list of those countries here: https://www.bis.doc.gov/index.php/policy-guidance/country-guidance/sanctioned-destinations Hard disk space requirements are around 500 GB at the moment but expect it to grow over time. 600 GB space should be sufficient for the next few years. Our master mirror is rsync://msync.rockylinux.org/rocky/mirror/pub/rocky/ For your first synchronization use a mirror near to you. You can find all official mirrors here: https://mirrors.rockylinux.org Please note that we might restrict access to the official master mirror to official public mirrors in the future. So please consider rsyncing from a public mirror close to you if you are running a private mirror. Also local mirrors might be faster to sync from.","title":"Minimal requirements for public mirrors"},{"location":"guides/mirror_management/add_mirror_manager/#setting-up-your-mirror","text":"Please set up a cron job to synchronize your mirror periodically and let it run around 6 times a day. But be sure to sync off the hour to help distribute the load over time. If you only check against changes of fullfiletimelist-rocky and only do a full sync if this file has changed you can synchronize every hour. Here are some crontab examples for you: #This will synchronize your mirror at 0:50, 4:50, 8:50, 12:50, 16:50, 20:50 50 */6 * * * /path/to/your/rocky-rsync-mirror.sh > /dev/null 2>&1 #This will synchronize your mirror at 2:25, 6:25, 10:25, 14:25, 18:25, 22:25 25 2,6,10,14,18,22 * * * /path/to/your/rocky-rsync-mirror.sh > /dev/null 2>&1 #This will synchronize your mirror every hour at 15 minutes past the hour. #Only use if you are using our example script 15 * * * * /path/to/your/rocky-rsync-mirror.sh > /dev/null 2>&1 For a simple synchronization you can use the following rsync command: rsync -aqH --delete source-mirror destination-dir Consider using a locking mechanism to avoid running more than one rsync job simultaneously when we push a new release. You can also use and modify our example script implementing locking and full sync if required. It can be found at https://github.com/rocky-linux/rocky-tools/blob/main/mirror/mirrorsync.sh . After your first complete synchronization check that everything is fine with your mirror. Most importantly check all files and dirs got synchronized, your cron job is working properly and your mirror is reachable from the public Internet. Double check your firewall rules! To avoid any problems do not enforce http to https redirection. If you have any questions setting up your mirror join https://chat.rockylinux.org/rocky-linux/channels/infrastructure When you are done head over to the next section and propose your mirror to become public!","title":"Setting up your mirror"},{"location":"guides/mirror_management/add_mirror_manager/#what-you-need","text":"An account on https://accounts.rockylinux.org/","title":"What You Need"},{"location":"guides/mirror_management/add_mirror_manager/#creating-a-site","text":"Rocky uses Fedora's Mirror Manager for organizing community mirrors. Access Rocky's Mirror Manager here: https://mirrors.rockylinux.org/mirrormanager/ After a successful login, your profile will be on the top right. Select the drop down then click \"My sites\". A new page will load listing all of the sites under the account. The first time it will be empty. Click \"Register a new site\". A new page will load with an important Export Compliance statement to read. Then fill out the following information: \"Site Name\" \"Site Password\" - used by report_mirrors script, you make this anything you want \"Organization URL\" - Company/School/Organization URL e.g. https://rockylinux.org/ \"Private\" - Checking this box hides your mirror from public use. \"User active\" - Uncheck this box to temporarily disable this site, it will be removed from public listings. \"All sites can pull from me?\" - Enable all mirror sites to pull from me without explicitly adding them to my list. \"Comments for downstream siteadmins. Please include your synchronization source here to avoid dependency loops.\" Upon clicking \"Submit\" you will be returned to the main mirror page.","title":"Creating a site"},{"location":"guides/mirror_management/add_mirror_manager/#configuring-the-site","text":"From the main mirror page, select the drop down then click \"My sites\". The account site page will load and the site should be listed. Click on it to go to the Information Site. All of the options from the last section are listed again. At the bottom of the page are three new options: Admins, Hosts, and Delete site. Click on the \"Hosts [add]\".","title":"Configuring the site"},{"location":"guides/mirror_management/add_mirror_manager/#create-new-host","text":"Fill out the following options that are appropriate for the site: \"Host name\" - required: FQDN of server as seen by a public end user \"User active\" - Uncheck this box to temporarily disable this host, it will be removed from public listings. \"Country\" - required: 2-letter ISO country code \"Bandwidth\" - required: integer megabits/sec, how much bandwidth this host can serve \"Private\" - e.g. not available to the public, an internal private mirror \"Internet2\" - on Internet2 \"Internet2 clients\" - serves Internet2 clients, even if private \"ASN - Autonomous System Number, used in BGP routing tables. Only if you are an ISP. \"ASN Clients? - Serve all clients from the same ASN. Used for ISPs, companies, or schools, not personal networks. \"Robot email\" - email address, will receive notice of upstream content updates \"Comment\" - text, anything else you'd like a public end user to know about your mirror \"Max connections\" - Maximum parallel download connections per client, suggested via metalinks. Click \"Create\" and it will redirect back to the Information site for the host.","title":"Create new host"},{"location":"guides/mirror_management/add_mirror_manager/#update-host","text":"At the bottom of the Information site, the option for \"Hosts\" should now display the host title next to it. Click on the name to load the host page. All of the same options from the previous step are listed again. There are new options at the bottom. \"Site-local Netblocks\": Netblocks are used to try to guide and end user to a site-specific mirror. For example, a university might list their netblocks, and the mirrorlist CGI would return the university-local mirror rather than a country-local mirror. Format is one of 18.0.0.0/255.0.0.0, 18.0.0.0/8, an IPv6 prefix/length, or a DNS hostname. Values must be public IP addresses (no RFC1918 private space addresses). Use only if you are an ISP and/or own a publicly routeable netblock! \"Peer ASNs\": Peer ASNs are used to guide an end user on nearby networks to our mirror. For example, a university might list their peer ASNs, and the mirrorlist CGI would return the university-local mirror rather than a country-local mirror. You must be in the MirrorManager administrators group in order to create new entries here. \"Countries Allowed\": Some mirrors need to restrict themselves to serving only end users from their country. If you're one of these, list the 2-letter ISO code for the countries you will allow end users to be from. The mirrorlist CGI will honor this. \"Categories Carried\": Hosts carry categories of software. Example Fedora categories include Fedora and Fedora Archive. Click on the \"[add]\" link under \"Categories Carried\".","title":"Update host"},{"location":"guides/mirror_management/add_mirror_manager/#categories-carried","text":"For the Category, select \"Rocky Linux\" then \"Create\" to load the URL page. Then click \"[add]\" to load the \"Add host category URL\" page. There is one option. Repeat as needed for each of the mirrors supported protocols. \"URL\" - URL (rsync, https, http) pointing to the top directory Examples: * http://rocky.example.com * https://rocky.example.com * rsync://rocky.example.com","title":"Categories Carried"},{"location":"guides/mirror_management/add_mirror_manager/#wrap-up","text":"Once the information is filled out, the site should appear on the mirror list as soon as the next mirror refresh occurs.","title":"Wrap up"},{"location":"guides/mirror_management/add_mirror_manager.sv/","text":"L\u00e4gg till en publik spegel till Rocky's spegelhanterare Rocky anv\u00e4nder Fedora's spegelhanterare f\u00f6r att organisera gemenskapspeglar.. Vad du beh\u00f6ver Ett konto p\u00e5 https://accounts.rockylinux.org/ Skapa en sajt G\u00e5 till Rockys Spegelhanterare h\u00e4r: https://mirrors.rockylinux.org/mirrormanager/ Efter en lyckad inloggning, s\u00e5 kommer din profil att synas uppe till h\u00f6ger. V\u00e4lj rullgardinsmenyn och klicka sedan p\u00e5 \"Mina sajter\". En ny sida kommer att laddas som listar alla sajter under ditt konto. F\u00f6rsta g\u00e5ngen kommer sidan vara tom. Klicka p\u00e5 \"Registrera en ny sajt\". En ny sida kommer att ladda med ett viktigt uttalande om export\u00f6verensst\u00e4mmelse att l\u00e4sa. Fyll sedan i f\u00f6ljande information: * \"Sajtnamn\" * \"Sajtl\u00f6senord\" - anv\u00e4nds av report_mirrors skriptet, du kan v\u00e4lja vilket l\u00f6senord du vill ha * \"Organisation URL\" - F\u00f6retag/Skola/Organisation URL t.ex. https://rockylinux.org/ * \"Privat\" - Om du markerar den h\u00e4r rutan d\u00f6ljs denna sajt f\u00f6r allm\u00e4n anv\u00e4ndning. * \"Anv\u00e4ndaraktiv\" - Avmarkera den h\u00e4r rutan f\u00f6r att tillf\u00e4lligt inaktivera den h\u00e4r sajten, den tas bort fr\u00e5n offentliga listor. * \"Alla sajta kan h\u00e4mta fr\u00e5n mig??\" - Aktiverar alla spegelsajter att h\u00e4mta fr\u00e5n mig utan att uttryckligen l\u00e4gga till dem i min lista. * \"Kommentarer till nedstr\u00f6ms sajtadmins\" N\u00e4r du klickar p\u00e5 \"Skicka\" kommer du tillbaka till huvudspegelsidan. Konfigurera din sajt Fr\u00e5n huvudspegelsidan v\u00e4ljer du rullgardinsmenyn och klickar sedan p\u00e5 \"Mina sajter\". Kontosidan laddas och webbplatsen b\u00f6r listas. Klicka p\u00e5 den f\u00f6r att g\u00e5 till informationssidan. Alla alternativ fr\u00e5n den sista sektionen listas igen. L\u00e4ngst ner p\u00e5 sidan finns tre alternativ: Administrat\u00f6rer, V\u00e4rdar, och Ta bort sajt. Klicka p\u00e5 \"V\u00e4rdar [l\u00e4gg till]\". Skapa en ny v\u00e4rd Fyll i f\u00f6ljande alternativ som \u00e4r l\u00e4mpliga f\u00f6r sajten: * \"V\u00e4rdnamn\" - kr\u00e4ver: FQDN f\u00f6r servern som det ser ut f\u00f6r en offentlig slutanv\u00e4ndare * \"Anv\u00e4ndaraktiv\" - Avmarkera den h\u00e4r rutan f\u00f6r att tillf\u00e4lligt inaktivera den h\u00e4r v\u00e4rden, den tas bort fr\u00e5n offentliga listor. * \"Land\" - kr\u00e4vs: 2-bokst\u00e4vers ISO Landskod * \"Bandbredd\" - kr\u00e4vs: heltal megabit/sek, hur mycket bandbredd denna v\u00e4rd kan tj\u00e4na * \"Privat\" - t.ex. inte tillg\u00e4nglig f\u00f6r allm\u00e4nheten, en intern privat spegel * \"Internet2\" - p\u00e5 Internet2 * \"Internet2 klienter\" - serverar Internet2-klienter, \u00e4ven om de \u00e4r privata * \"ASN - Autonomous System Nummer, anv\u00e4nds i BGP routingtabeller. * \"ASN Klienter? - Servera alla klienter fr\u00e5n samma ASN. Anv\u00e4nds f\u00f6r ISPs, f\u00f6retag, eller skolor, inte personliga n\u00e4tverk. * \"Robot email\" - e-postadress, som kommer att f\u00e5 meddelanden om uppdateringar av uppstr\u00f6msinneh\u00e5ll * \"Kommentar\" - text, allt annat du vill att en allm\u00e4n slutanv\u00e4ndare ska veta om din spegel * \"Max anslutningar\" - Maximala parallella nedladdningsanslutningar per klient, f\u00f6reslagna via metalinks. Klicka \"Skapa\" och du kommer att bli omdirigerad tillbaka till informationssidan f\u00f6r v\u00e4rden. Uppdatera v\u00e4rden L\u00e4ngst ner p\u00e5 informationssidan, alternativet f\u00f6r \"V\u00e4rd\" ska nu visa v\u00e4rdtiteln bredvid den. Klicka p\u00e5 namnet f\u00f6r att ladda v\u00e4rdsidan. Alla samma alternativ fr\u00e5n f\u00f6reg\u00e5ende steg listas igen. Det finns nya alternativ l\u00e4ngst ner. \"Sajt-lokala n\u00e4tblock\": N\u00e4tblock anv\u00e4nds f\u00f6r att f\u00f6rs\u00f6ka att v\u00e4gleda en slutanv\u00e4ndare till en platsspecifik spegel. F\u00f6r exempel, ett universitet kan lista sina n\u00e4tblock, och spegellistan CGI skulle returnera den universitets specifika spegeln ist\u00e4llet f\u00f6r en landets-lokala spegel. Format \u00e4r en av 18.0.0.0/255.0.0.0, 18.0.0.0/8, en IPv6 prefix/l\u00e4ngd, eller ett DNS v\u00e4rdnamn. V\u00e4rden m\u00e5ste vara publika IP-adresser (inga RFC1918-adresser i privat utrymme). \"Peer ASNs\": Peer ASNs anv\u00e4nds f\u00f6r att v\u00e4gleda en slutanv\u00e4ndare i n\u00e4rliggande n\u00e4tverk till v\u00e5r spegel. t.ex., ett universitet kan lista deras peer ASNs, och spegellistan CGI kommer skicka den universitets-lokala spegeln snarare \u00e4n en lands-lokal spegel.. Du m\u00e5ste vara i MirrorManager-administrat\u00f6rs gruppen f\u00f6r att skapa nya poster h\u00e4r. \"Land till\u00e5tna\": Vissa speglar m\u00e5ste begr\u00e4nsa sig till att endast betj\u00e4na slutanv\u00e4ndare fr\u00e5n deras land. Om du \u00e4r en av dessa, lista 2-bokst\u00e4vers ISOkoder f\u00f6r dom l\u00e4nderna du vill till\u00e5ta slutanv\u00e4ndare att vara fr\u00e5n. spegellistan CGI kommer att acceptera detta. \"Paketkategorier \": V\u00e4rdar har flera olika kategorier av programvara. Exempel p\u00e5 Fedora-kategorier inkluderar Fedora och Fedora arkiv Klicka p\u00e5 \"[l\u00e4gg till]\" l\u00e4nken under \"Paketkategorier\". Paketkategorier F\u00f6r kategorin, v\u00e4lj \"Rocky Linux\" sen klicka p\u00e5 \"Skapa\" f\u00f6r att ladda URL sidan. Klicka sedan p\u00e5 \"[l\u00e4gg till]\" f\u00f6r att ladda \"L\u00e4gg till v\u00e4rdkategori URL\" sidan. Det finns ett alternativ. Upprepa efter behov f\u00f6r vart och ett av de protokoll som st\u00f6ds av speglarna. \"URL\" - URL (rsync, https, http) pekar p\u00e5 den \u00f6versta katalogen Exempel: * http://rocky.example.com * https://rocky.example.com * rsync://rocky.example.com Sammanfattning N\u00e4r informationen \u00e4r ifylld, s\u00e5 ska din sajt dyka upp p\u00e5 spegellistan s\u00e5 snart n\u00e4sta spegeluppdatering sker. Synkronisera din spegel fr\u00e5n rsync://msync.rockylinux.org","title":"L\u00e4gg till en publik spegel till Rocky's spegelhanterare"},{"location":"guides/mirror_management/add_mirror_manager.sv/#lagg-till-en-publik-spegel-till-rockys-spegelhanterare","text":"Rocky anv\u00e4nder Fedora's spegelhanterare f\u00f6r att organisera gemenskapspeglar..","title":"L\u00e4gg till en publik spegel till Rocky's spegelhanterare"},{"location":"guides/mirror_management/add_mirror_manager.sv/#vad-du-behover","text":"Ett konto p\u00e5 https://accounts.rockylinux.org/","title":"Vad du beh\u00f6ver"},{"location":"guides/mirror_management/add_mirror_manager.sv/#skapa-en-sajt","text":"G\u00e5 till Rockys Spegelhanterare h\u00e4r: https://mirrors.rockylinux.org/mirrormanager/ Efter en lyckad inloggning, s\u00e5 kommer din profil att synas uppe till h\u00f6ger. V\u00e4lj rullgardinsmenyn och klicka sedan p\u00e5 \"Mina sajter\". En ny sida kommer att laddas som listar alla sajter under ditt konto. F\u00f6rsta g\u00e5ngen kommer sidan vara tom. Klicka p\u00e5 \"Registrera en ny sajt\". En ny sida kommer att ladda med ett viktigt uttalande om export\u00f6verensst\u00e4mmelse att l\u00e4sa. Fyll sedan i f\u00f6ljande information: * \"Sajtnamn\" * \"Sajtl\u00f6senord\" - anv\u00e4nds av report_mirrors skriptet, du kan v\u00e4lja vilket l\u00f6senord du vill ha * \"Organisation URL\" - F\u00f6retag/Skola/Organisation URL t.ex. https://rockylinux.org/ * \"Privat\" - Om du markerar den h\u00e4r rutan d\u00f6ljs denna sajt f\u00f6r allm\u00e4n anv\u00e4ndning. * \"Anv\u00e4ndaraktiv\" - Avmarkera den h\u00e4r rutan f\u00f6r att tillf\u00e4lligt inaktivera den h\u00e4r sajten, den tas bort fr\u00e5n offentliga listor. * \"Alla sajta kan h\u00e4mta fr\u00e5n mig??\" - Aktiverar alla spegelsajter att h\u00e4mta fr\u00e5n mig utan att uttryckligen l\u00e4gga till dem i min lista. * \"Kommentarer till nedstr\u00f6ms sajtadmins\" N\u00e4r du klickar p\u00e5 \"Skicka\" kommer du tillbaka till huvudspegelsidan.","title":"Skapa en sajt"},{"location":"guides/mirror_management/add_mirror_manager.sv/#konfigurera-din-sajt","text":"Fr\u00e5n huvudspegelsidan v\u00e4ljer du rullgardinsmenyn och klickar sedan p\u00e5 \"Mina sajter\". Kontosidan laddas och webbplatsen b\u00f6r listas. Klicka p\u00e5 den f\u00f6r att g\u00e5 till informationssidan. Alla alternativ fr\u00e5n den sista sektionen listas igen. L\u00e4ngst ner p\u00e5 sidan finns tre alternativ: Administrat\u00f6rer, V\u00e4rdar, och Ta bort sajt. Klicka p\u00e5 \"V\u00e4rdar [l\u00e4gg till]\".","title":"Konfigurera din sajt"},{"location":"guides/mirror_management/add_mirror_manager.sv/#skapa-en-ny-vard","text":"Fyll i f\u00f6ljande alternativ som \u00e4r l\u00e4mpliga f\u00f6r sajten: * \"V\u00e4rdnamn\" - kr\u00e4ver: FQDN f\u00f6r servern som det ser ut f\u00f6r en offentlig slutanv\u00e4ndare * \"Anv\u00e4ndaraktiv\" - Avmarkera den h\u00e4r rutan f\u00f6r att tillf\u00e4lligt inaktivera den h\u00e4r v\u00e4rden, den tas bort fr\u00e5n offentliga listor. * \"Land\" - kr\u00e4vs: 2-bokst\u00e4vers ISO Landskod * \"Bandbredd\" - kr\u00e4vs: heltal megabit/sek, hur mycket bandbredd denna v\u00e4rd kan tj\u00e4na * \"Privat\" - t.ex. inte tillg\u00e4nglig f\u00f6r allm\u00e4nheten, en intern privat spegel * \"Internet2\" - p\u00e5 Internet2 * \"Internet2 klienter\" - serverar Internet2-klienter, \u00e4ven om de \u00e4r privata * \"ASN - Autonomous System Nummer, anv\u00e4nds i BGP routingtabeller. * \"ASN Klienter? - Servera alla klienter fr\u00e5n samma ASN. Anv\u00e4nds f\u00f6r ISPs, f\u00f6retag, eller skolor, inte personliga n\u00e4tverk. * \"Robot email\" - e-postadress, som kommer att f\u00e5 meddelanden om uppdateringar av uppstr\u00f6msinneh\u00e5ll * \"Kommentar\" - text, allt annat du vill att en allm\u00e4n slutanv\u00e4ndare ska veta om din spegel * \"Max anslutningar\" - Maximala parallella nedladdningsanslutningar per klient, f\u00f6reslagna via metalinks. Klicka \"Skapa\" och du kommer att bli omdirigerad tillbaka till informationssidan f\u00f6r v\u00e4rden.","title":"Skapa en ny v\u00e4rd"},{"location":"guides/mirror_management/add_mirror_manager.sv/#uppdatera-varden","text":"L\u00e4ngst ner p\u00e5 informationssidan, alternativet f\u00f6r \"V\u00e4rd\" ska nu visa v\u00e4rdtiteln bredvid den. Klicka p\u00e5 namnet f\u00f6r att ladda v\u00e4rdsidan. Alla samma alternativ fr\u00e5n f\u00f6reg\u00e5ende steg listas igen. Det finns nya alternativ l\u00e4ngst ner. \"Sajt-lokala n\u00e4tblock\": N\u00e4tblock anv\u00e4nds f\u00f6r att f\u00f6rs\u00f6ka att v\u00e4gleda en slutanv\u00e4ndare till en platsspecifik spegel. F\u00f6r exempel, ett universitet kan lista sina n\u00e4tblock, och spegellistan CGI skulle returnera den universitets specifika spegeln ist\u00e4llet f\u00f6r en landets-lokala spegel. Format \u00e4r en av 18.0.0.0/255.0.0.0, 18.0.0.0/8, en IPv6 prefix/l\u00e4ngd, eller ett DNS v\u00e4rdnamn. V\u00e4rden m\u00e5ste vara publika IP-adresser (inga RFC1918-adresser i privat utrymme). \"Peer ASNs\": Peer ASNs anv\u00e4nds f\u00f6r att v\u00e4gleda en slutanv\u00e4ndare i n\u00e4rliggande n\u00e4tverk till v\u00e5r spegel. t.ex., ett universitet kan lista deras peer ASNs, och spegellistan CGI kommer skicka den universitets-lokala spegeln snarare \u00e4n en lands-lokal spegel.. Du m\u00e5ste vara i MirrorManager-administrat\u00f6rs gruppen f\u00f6r att skapa nya poster h\u00e4r. \"Land till\u00e5tna\": Vissa speglar m\u00e5ste begr\u00e4nsa sig till att endast betj\u00e4na slutanv\u00e4ndare fr\u00e5n deras land. Om du \u00e4r en av dessa, lista 2-bokst\u00e4vers ISOkoder f\u00f6r dom l\u00e4nderna du vill till\u00e5ta slutanv\u00e4ndare att vara fr\u00e5n. spegellistan CGI kommer att acceptera detta. \"Paketkategorier \": V\u00e4rdar har flera olika kategorier av programvara. Exempel p\u00e5 Fedora-kategorier inkluderar Fedora och Fedora arkiv Klicka p\u00e5 \"[l\u00e4gg till]\" l\u00e4nken under \"Paketkategorier\".","title":"Uppdatera v\u00e4rden"},{"location":"guides/mirror_management/add_mirror_manager.sv/#paketkategorier","text":"F\u00f6r kategorin, v\u00e4lj \"Rocky Linux\" sen klicka p\u00e5 \"Skapa\" f\u00f6r att ladda URL sidan. Klicka sedan p\u00e5 \"[l\u00e4gg till]\" f\u00f6r att ladda \"L\u00e4gg till v\u00e4rdkategori URL\" sidan. Det finns ett alternativ. Upprepa efter behov f\u00f6r vart och ett av de protokoll som st\u00f6ds av speglarna. \"URL\" - URL (rsync, https, http) pekar p\u00e5 den \u00f6versta katalogen Exempel: * http://rocky.example.com * https://rocky.example.com * rsync://rocky.example.com","title":"Paketkategorier"},{"location":"guides/mirror_management/add_mirror_manager.sv/#sammanfattning","text":"N\u00e4r informationen \u00e4r ifylld, s\u00e5 ska din sajt dyka upp p\u00e5 spegellistan s\u00e5 snart n\u00e4sta spegeluppdatering sker. Synkronisera din spegel fr\u00e5n rsync://msync.rockylinux.org","title":"Sammanfattning"},{"location":"guides/network/basic_network_configuration.fr/","text":"Configuration r\u00e9seau de base Pr\u00e9requis \u00catre \u00e0 l'aise avec le fonctionnement depuis la ligne de commande Toutes les op\u00e9rations n\u00e9cessitent un acc\u00e8s root Facultatif: \u00eatre familier des concepts de mise en r\u00e9seau Introduction De nos jours, un ordinateur est presque inutile \u00e0 lui seul. Que vous ayez besoin de mettre \u00e0 jour les packages d\u00e9finis sur un serveur ou de naviguer sur le Web depuis votre ordinateur portable, vous aurez besoin d'un acc\u00e8s r\u00e9seau. Ce guide vise \u00e0 fournir aux utilisateurs de Rocky Linux les connaissances de base sur la configuration de la connectivit\u00e9 r\u00e9seau sur un syst\u00e8me Rocky Linux. Utilisation du service NetworkManager Au niveau de l'utilisateur, la pile r\u00e9seau est g\u00e9r\u00e9e par NetworkManager . Cet outil s'ex\u00e9cute en tant que service, vous pouvez v\u00e9rifier son \u00e9tat avec la commande suivante: systemctl status NetworkManager Fichiers de configuration NetworkManager applique simplement une configuration lue \u00e0 partir des fichiers trouv\u00e9s dans /etc/sysconfig/network-scripts/ifcfg-<IFACE_NAME> . Chaque interface r\u00e9seau a son fichier de configuration. Voici par exemple une configuration par d\u00e9faut d'un serveur: TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=ens18 UUID=74c5ccee-c1f4-4f45-883f-fc4f765a8477 DEVICE=ens18 ONBOOT=yes IPADDR=192.168.0.1 PREFIX=24 GATEWAY=192.168.0.254 DNS1=192.168.0.254 DNS2=1.1.1.1 IPV6_DISABLED=yes Le nom de l'interface est ens18 donc le nom de ce fichier sera /etc/sysconfig/network-scripts/ifcfg-ens18 . Adresse IP Ici, il n'y a pas d'attribution d'adresse IP dynamique (DHCP) car le param\u00e8tre BOOTPROTO est r\u00e9gl\u00e9 sur none . Pour l'activer, r\u00e9glez-le sur dhcp et supprimez les lignes IPADDR , PREFIX et GATEWAY . Pour configurer une attribution d'adresse IP statique, d\u00e9finissez les \u00e9l\u00e9ments suivants: IPADDR: l'adresse IP pour attribuer l'interface PREFIX: le masque de sous-r\u00e9seau en notation CIDR GATEWAY: la passerelle par d\u00e9faut Le param\u00e8tre ONBOOT r\u00e9gl\u00e9 sur yes indique que cette connexion sera activ\u00e9e pendant le d\u00e9marrage. R\u00e9solution DNS Pour obtenir une r\u00e9solution de nom fonctionnelle, les param\u00e8tres suivants doivent \u00eatre d\u00e9finis: DNS1: l'adresse IP du serveur de noms principal DNS2: l'adresse IP du serveur de noms secondaire (facultatif) NetworkManager utilisera la configuration des serveurs de noms et remplira /etc/resolv.conf avec ces param\u00e8tres. Appliquer la configuration Pour appliquer la configuration r\u00e9seau, la commande nmcli peut \u00eatre utilis\u00e9e: nmcli connection up ens18 Pour obtenir l'\u00e9tat de la connexion, utilisez simplement: nmcli connection show Vous pouvez \u00e9galement utiliser les commandes ifup et ifdown pour activer ou d\u00e9sactiver l'interface (ce sont de simples wrappers autour de nmcli ): ifup ens18 ifdown ens18 V\u00e9rification de la configuration Vous pouvez v\u00e9rifier que la configuration a \u00e9t\u00e9 correctement appliqu\u00e9e avec la commande nmcli suivante: nmcli device show ens18 qui devrait vous donner la sortie suivante: GENERAL.DEVICE: ens18 GENERAL.TYPE: ethernet GENERAL.HWADDR: 6E:86:C0:4E:15:DB GENERAL.MTU: 1500 GENERAL.STATE: 100 (connect\u00e9) GENERAL.CONNECTION: ens18 GENERAL.CON-PATH: /org/freedesktop/NetworkManager/ActiveConnection/1 WIRED-PROPERTIES.CARRIER: marche IP4.ADDRESS[1]: 192.168.0.1/24 IP4.GATEWAY: 192.168.0.254 IP4.ROUTE[1]: dst = 192.168.0.0/24, nh = 0.0.0.0, mt = 100 IP4.ROUTE[2]: dst = 0.0.0.0/0, nh = 192.168.0.254, mt = 100 IP4.DNS[1]: 192.168.0.254 IP4.DNS[2]: 1.1.1.1 IP6.GATEWAY: -- Utilisation de l'utilitaire ip La commande ip (fournie par le package iproute2 ) est un outil puissant pour obtenir des informations et configurer le r\u00e9seau d'un syst\u00e8me Linux moderne tel que Rocky Linux. Dans cet exemple, nous utiliserons les param\u00e8tres suivants en guise d'exemple: nom de l'interface: ens19 adresse IP: 192.168.20.10 masque de sous-r\u00e9seau: 24 passerelle: 192.168.20.254 Obtenir des informations g\u00e9n\u00e9rales Pour voir l'\u00e9tat d\u00e9taill\u00e9 de toutes les interfaces, utilisez: ip a Petites astuces: * utilisez l'option -c pour obtenir une sortie color\u00e9e plus lisible: ip -c a . * ip accepte les abr\u00e9viations donc ip a , ip addr et ip address sont \u00e9quivalents. D\u00e9marrer ou arr\u00eater l'interface Pour activer l'interface ens19 , utilisez simplement ip link set ens19 up et pour l'arr\u00eater, utilisez ip link set ens19 down . Attribuer une adresse statique \u00e0 l'interface La commande \u00e0 utiliser est de la forme suivante: ip addr add <IP ADDRESS/CIDR> dev <IFACE NAME> o\u00f9 est l'adresse IP avec son suffixe de sous-r\u00e9seau et < IFACE NAME> le nom de l'interface cibl\u00e9e. Pour attribuer les param\u00e8tres d'exemple ci-dessus, nous utiliserons donc: ip a add 192.168.20.10/24 dev ens19 Ensuite, v\u00e9rifiez le r\u00e9sultat avec: ip a show dev ens19 qui affichera: 3: ens19: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 4a:f2:f5:b6:aa:9f brd ff:ff:ff:ff:ff:ff inet 192.168.20.10/24 scope global ens19 valid_lft forever preferred_lft foreve Notre interface est en place et configur\u00e9e, mais il nous manque quelque chose, la configuration de la passerelle (voir ci-dessous). Utilisation de l'utilitaire ifcfg Pour configurer l'interface ens19 avec notre adresse IP et l'utilitaire ifcfg , utilisez la commande suivante: ifcfg ens19 add 192.168.20.10/24 Pour supprimer l'adresse: ifcfg ens19 del 192.168.20.10/24 Pour d\u00e9sactiver compl\u00e8tement l'adressage IP sur cette interface: ifcfg ens19 stop Notez que cela ne d\u00e9sactive pas l'interface, cela d\u00e9sassigne simplement toutes les adresses IP de l'interface. Configuration de la passerelle Maintenant que l'interface a une adresse, nous devons d\u00e9finir sa route par d\u00e9faut, cela peut \u00eatre fait avec: ip route add default via 192.168.20.254 dev ens1 La table de routage du noyau peut \u00eatre affich\u00e9e avec ip route ou ip r pour faire court. V\u00e9rification de la connectivit\u00e9 r\u00e9seau \u00c0 ce stade, vous devriez avoir votre interface r\u00e9seau en place et correctement configur\u00e9e. Il existe plusieurs fa\u00e7ons de v\u00e9rifier votre connectivit\u00e9. En utilisant ping vers une autre adresse IP dans le m\u00eame r\u00e9seau (nous utiliserons 192.168.20.42 comme exemple): ping -c3 192.168.20.42 Cette commande \u00e9mettra 3 pings (connus sous le nom de requ\u00eate ICMP) et attendra une r\u00e9ponse. Si tout s'est bien pass\u00e9, vous devriez obtenir cette sortie: PING 192.168.20.42 (192.168.20.42) 56(84) bytes of data. 64 bytes from 192.168.20.42: icmp_seq=1 ttl=64 time=1.07 ms 64 bytes from 192.168.20.42: icmp_seq=2 ttl=64 time=0.915 ms 64 bytes from 192.168.20.42: icmp_seq=3 ttl=64 time=0.850 ms --- 192.168.20.42 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 5ms rtt min/avg/max/mdev = 0.850/0.946/1.074/0.097 ms Ensuite, pour vous assurer que votre configuration de routage est correcte, essayez de faire un ping vers un h\u00f4te externe, tel que ce r\u00e9solveur DNS public bien connu: ping -c3 8.8.8.8 Si votre machine dispose de plusieurs interfaces r\u00e9seau et que vous souhaitez faire une requ\u00eate ICMP via une interface sp\u00e9cifique, vous pouvez utiliser l'option -I : ping -I ens19 -c3 192.168.20.42 Il est maintenant temps de s'assurer que la r\u00e9solution DNS fonctionne correctement. Pour rappel, la r\u00e9solution DNS est un m\u00e9canisme utilis\u00e9 pour convertir les noms de machines (faciles \u00e0 retenir pour les humains) en leurs adresses IP et inversement (DNS invers\u00e9). Si le fichier /etc/resolv.conf indique un serveur DNS accessible, alors ce qui suit devrait fonctionner: host rockylinux.org R\u00e9sultat: rockylinux.org has address 76.76.21.21","title":"Configuration r\u00e9seau de base"},{"location":"guides/network/basic_network_configuration.fr/#configuration-reseau-de-base","text":"","title":"Configuration r\u00e9seau de base"},{"location":"guides/network/basic_network_configuration.fr/#prerequis","text":"\u00catre \u00e0 l'aise avec le fonctionnement depuis la ligne de commande Toutes les op\u00e9rations n\u00e9cessitent un acc\u00e8s root Facultatif: \u00eatre familier des concepts de mise en r\u00e9seau","title":"Pr\u00e9requis"},{"location":"guides/network/basic_network_configuration.fr/#introduction","text":"De nos jours, un ordinateur est presque inutile \u00e0 lui seul. Que vous ayez besoin de mettre \u00e0 jour les packages d\u00e9finis sur un serveur ou de naviguer sur le Web depuis votre ordinateur portable, vous aurez besoin d'un acc\u00e8s r\u00e9seau. Ce guide vise \u00e0 fournir aux utilisateurs de Rocky Linux les connaissances de base sur la configuration de la connectivit\u00e9 r\u00e9seau sur un syst\u00e8me Rocky Linux.","title":"Introduction"},{"location":"guides/network/basic_network_configuration.fr/#utilisation-du-service-networkmanager","text":"Au niveau de l'utilisateur, la pile r\u00e9seau est g\u00e9r\u00e9e par NetworkManager . Cet outil s'ex\u00e9cute en tant que service, vous pouvez v\u00e9rifier son \u00e9tat avec la commande suivante: systemctl status NetworkManager","title":"Utilisation du service NetworkManager"},{"location":"guides/network/basic_network_configuration.fr/#fichiers-de-configuration","text":"NetworkManager applique simplement une configuration lue \u00e0 partir des fichiers trouv\u00e9s dans /etc/sysconfig/network-scripts/ifcfg-<IFACE_NAME> . Chaque interface r\u00e9seau a son fichier de configuration. Voici par exemple une configuration par d\u00e9faut d'un serveur: TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=ens18 UUID=74c5ccee-c1f4-4f45-883f-fc4f765a8477 DEVICE=ens18 ONBOOT=yes IPADDR=192.168.0.1 PREFIX=24 GATEWAY=192.168.0.254 DNS1=192.168.0.254 DNS2=1.1.1.1 IPV6_DISABLED=yes Le nom de l'interface est ens18 donc le nom de ce fichier sera /etc/sysconfig/network-scripts/ifcfg-ens18 .","title":"Fichiers de configuration"},{"location":"guides/network/basic_network_configuration.fr/#adresse-ip","text":"Ici, il n'y a pas d'attribution d'adresse IP dynamique (DHCP) car le param\u00e8tre BOOTPROTO est r\u00e9gl\u00e9 sur none . Pour l'activer, r\u00e9glez-le sur dhcp et supprimez les lignes IPADDR , PREFIX et GATEWAY . Pour configurer une attribution d'adresse IP statique, d\u00e9finissez les \u00e9l\u00e9ments suivants: IPADDR: l'adresse IP pour attribuer l'interface PREFIX: le masque de sous-r\u00e9seau en notation CIDR GATEWAY: la passerelle par d\u00e9faut Le param\u00e8tre ONBOOT r\u00e9gl\u00e9 sur yes indique que cette connexion sera activ\u00e9e pendant le d\u00e9marrage.","title":"Adresse IP"},{"location":"guides/network/basic_network_configuration.fr/#resolution-dns","text":"Pour obtenir une r\u00e9solution de nom fonctionnelle, les param\u00e8tres suivants doivent \u00eatre d\u00e9finis: DNS1: l'adresse IP du serveur de noms principal DNS2: l'adresse IP du serveur de noms secondaire (facultatif) NetworkManager utilisera la configuration des serveurs de noms et remplira /etc/resolv.conf avec ces param\u00e8tres.","title":"R\u00e9solution DNS"},{"location":"guides/network/basic_network_configuration.fr/#appliquer-la-configuration","text":"Pour appliquer la configuration r\u00e9seau, la commande nmcli peut \u00eatre utilis\u00e9e: nmcli connection up ens18 Pour obtenir l'\u00e9tat de la connexion, utilisez simplement: nmcli connection show Vous pouvez \u00e9galement utiliser les commandes ifup et ifdown pour activer ou d\u00e9sactiver l'interface (ce sont de simples wrappers autour de nmcli ): ifup ens18 ifdown ens18","title":"Appliquer la configuration"},{"location":"guides/network/basic_network_configuration.fr/#verification-de-la-configuration","text":"Vous pouvez v\u00e9rifier que la configuration a \u00e9t\u00e9 correctement appliqu\u00e9e avec la commande nmcli suivante: nmcli device show ens18 qui devrait vous donner la sortie suivante: GENERAL.DEVICE: ens18 GENERAL.TYPE: ethernet GENERAL.HWADDR: 6E:86:C0:4E:15:DB GENERAL.MTU: 1500 GENERAL.STATE: 100 (connect\u00e9) GENERAL.CONNECTION: ens18 GENERAL.CON-PATH: /org/freedesktop/NetworkManager/ActiveConnection/1 WIRED-PROPERTIES.CARRIER: marche IP4.ADDRESS[1]: 192.168.0.1/24 IP4.GATEWAY: 192.168.0.254 IP4.ROUTE[1]: dst = 192.168.0.0/24, nh = 0.0.0.0, mt = 100 IP4.ROUTE[2]: dst = 0.0.0.0/0, nh = 192.168.0.254, mt = 100 IP4.DNS[1]: 192.168.0.254 IP4.DNS[2]: 1.1.1.1 IP6.GATEWAY: --","title":"V\u00e9rification de la configuration"},{"location":"guides/network/basic_network_configuration.fr/#utilisation-de-lutilitaire-ip","text":"La commande ip (fournie par le package iproute2 ) est un outil puissant pour obtenir des informations et configurer le r\u00e9seau d'un syst\u00e8me Linux moderne tel que Rocky Linux. Dans cet exemple, nous utiliserons les param\u00e8tres suivants en guise d'exemple: nom de l'interface: ens19 adresse IP: 192.168.20.10 masque de sous-r\u00e9seau: 24 passerelle: 192.168.20.254","title":"Utilisation de l'utilitaire ip"},{"location":"guides/network/basic_network_configuration.fr/#obtenir-des-informations-generales","text":"Pour voir l'\u00e9tat d\u00e9taill\u00e9 de toutes les interfaces, utilisez: ip a Petites astuces: * utilisez l'option -c pour obtenir une sortie color\u00e9e plus lisible: ip -c a . * ip accepte les abr\u00e9viations donc ip a , ip addr et ip address sont \u00e9quivalents.","title":"Obtenir des informations g\u00e9n\u00e9rales"},{"location":"guides/network/basic_network_configuration.fr/#demarrer-ou-arreter-linterface","text":"Pour activer l'interface ens19 , utilisez simplement ip link set ens19 up et pour l'arr\u00eater, utilisez ip link set ens19 down .","title":"D\u00e9marrer ou arr\u00eater l'interface"},{"location":"guides/network/basic_network_configuration.fr/#attribuer-une-adresse-statique-a-linterface","text":"La commande \u00e0 utiliser est de la forme suivante: ip addr add <IP ADDRESS/CIDR> dev <IFACE NAME> o\u00f9 est l'adresse IP avec son suffixe de sous-r\u00e9seau et < IFACE NAME> le nom de l'interface cibl\u00e9e. Pour attribuer les param\u00e8tres d'exemple ci-dessus, nous utiliserons donc: ip a add 192.168.20.10/24 dev ens19 Ensuite, v\u00e9rifiez le r\u00e9sultat avec: ip a show dev ens19 qui affichera: 3: ens19: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 4a:f2:f5:b6:aa:9f brd ff:ff:ff:ff:ff:ff inet 192.168.20.10/24 scope global ens19 valid_lft forever preferred_lft foreve Notre interface est en place et configur\u00e9e, mais il nous manque quelque chose, la configuration de la passerelle (voir ci-dessous).","title":"Attribuer une adresse statique \u00e0 l'interface"},{"location":"guides/network/basic_network_configuration.fr/#utilisation-de-lutilitaire-ifcfg","text":"Pour configurer l'interface ens19 avec notre adresse IP et l'utilitaire ifcfg , utilisez la commande suivante: ifcfg ens19 add 192.168.20.10/24 Pour supprimer l'adresse: ifcfg ens19 del 192.168.20.10/24 Pour d\u00e9sactiver compl\u00e8tement l'adressage IP sur cette interface: ifcfg ens19 stop Notez que cela ne d\u00e9sactive pas l'interface, cela d\u00e9sassigne simplement toutes les adresses IP de l'interface.","title":"Utilisation de l'utilitaire ifcfg"},{"location":"guides/network/basic_network_configuration.fr/#configuration-de-la-passerelle","text":"Maintenant que l'interface a une adresse, nous devons d\u00e9finir sa route par d\u00e9faut, cela peut \u00eatre fait avec: ip route add default via 192.168.20.254 dev ens1 La table de routage du noyau peut \u00eatre affich\u00e9e avec ip route ou ip r pour faire court.","title":"Configuration de la passerelle"},{"location":"guides/network/basic_network_configuration.fr/#verification-de-la-connectivite-reseau","text":"\u00c0 ce stade, vous devriez avoir votre interface r\u00e9seau en place et correctement configur\u00e9e. Il existe plusieurs fa\u00e7ons de v\u00e9rifier votre connectivit\u00e9. En utilisant ping vers une autre adresse IP dans le m\u00eame r\u00e9seau (nous utiliserons 192.168.20.42 comme exemple): ping -c3 192.168.20.42 Cette commande \u00e9mettra 3 pings (connus sous le nom de requ\u00eate ICMP) et attendra une r\u00e9ponse. Si tout s'est bien pass\u00e9, vous devriez obtenir cette sortie: PING 192.168.20.42 (192.168.20.42) 56(84) bytes of data. 64 bytes from 192.168.20.42: icmp_seq=1 ttl=64 time=1.07 ms 64 bytes from 192.168.20.42: icmp_seq=2 ttl=64 time=0.915 ms 64 bytes from 192.168.20.42: icmp_seq=3 ttl=64 time=0.850 ms --- 192.168.20.42 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 5ms rtt min/avg/max/mdev = 0.850/0.946/1.074/0.097 ms Ensuite, pour vous assurer que votre configuration de routage est correcte, essayez de faire un ping vers un h\u00f4te externe, tel que ce r\u00e9solveur DNS public bien connu: ping -c3 8.8.8.8 Si votre machine dispose de plusieurs interfaces r\u00e9seau et que vous souhaitez faire une requ\u00eate ICMP via une interface sp\u00e9cifique, vous pouvez utiliser l'option -I : ping -I ens19 -c3 192.168.20.42 Il est maintenant temps de s'assurer que la r\u00e9solution DNS fonctionne correctement. Pour rappel, la r\u00e9solution DNS est un m\u00e9canisme utilis\u00e9 pour convertir les noms de machines (faciles \u00e0 retenir pour les humains) en leurs adresses IP et inversement (DNS invers\u00e9). Si le fichier /etc/resolv.conf indique un serveur DNS accessible, alors ce qui suit devrait fonctionner: host rockylinux.org R\u00e9sultat: rockylinux.org has address 76.76.21.21","title":"V\u00e9rification de la connectivit\u00e9 r\u00e9seau"},{"location":"guides/network/basic_network_configuration/","tags":["networking","configuration","network"],"text":"Networking configuration Prerequisites A certain amount of comfort operating from the command line Elevated or administrative privileges on the system (For example root, sudo and so on) Optional: familiarity with networking concepts Introduction Nowadays a computer without network connectivity is almost useless by itself. Whether you need to update the packages on a server or simply browse external Websites from your laptop - you will need network access! This guide aims to provide Rocky Linux users the basic knowledge on how to setup network connectivity on a Rocky Linux system. Using NetworkManager service At the user level, the networking stack is managed by NetworkManager . This tool runs as a service, and you can check its state with the following command: systemctl status NetworkManager Configuration files NetworkManager simply applies a configuration read from the files found in /etc/sysconfig/network-scripts/ifcfg-<IFACE_NAME> . Each network interface has its configuration file. The following shows an example for the default configuration of a server: TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=enp1s0 UUID=74c5ccee-c1f4-4f45-883f-fc4f765a8477 DEVICE=enp1s0 ONBOOT=yes IPADDR=10.0.0.10 PREFIX=24 GATEWAY=10.0.0.1 DNS1=10.0.0.1 DNS2=1.1.1.1 IPV6_DISABLED=yes The interface's name is enp1s0 so this file's name will be /etc/sysconfig/network-scripts/ifcfg-enp1s0 . !!! hint \" Tips: \" There are a few ways or mechanisms by which systems can be assigned their IP configuration information. The two most common methods are - **Static IP configuration** scheme and **Dynamic IP configuration** scheme. The static IP configuration scheme is very popular on server class systems or networks. The dynamic IP approach is popular on home and office networks - or workstation and desktop class systems. The dynamic scheme usually needs _something_ extra that is locally available that can supply proper IP configuration information to requesting workstations and desktops. This _something_ is called the Dynamic Host Configuration Protocol (DHCP). Very often, home/office users don't have to worry or know about DHCP. This is because the somebody or something else is automagically taking care of that in the background. The only thing that the end user needs to do is to physically or wirelessly connect to the right network (and of course make sure that their systems are powered on)! IP Address In the previous /etc/sysconfig/network-scripts/ifcfg-enp1s0 listing, we see that the value of the BOOTPROTO parameter or key is set to none . This means that the system being configured is set to a static IP address scheme. If instead you want to configure the system to use a dynamic IP address scheme, you will have to change the value of the BOOTPROTO parameter from none to dhcp and also remove the IPADDR , PREFIX and GATEWAY lines. This is necessary because all of that information will be automaically obtained from any available DHCP server. To configure a static IP address attribution, set the following: IPADDR: the IP address to assign the interface PREFIX: the subnet mask in CIDR notation GATEWAY: the default gateway The ONBOOT parameter set to yes indicates that this connection will be activated during boot time. DNS resolution To get proper name resolution, the following parameters must be set: DNS1: IP address of the main nameserver DNS2: the secondary nameserver IP address Checking configuration You can check that the configuration has been correctly applied with the following nmcli command: [user@server ~]$ sudo nmcli device show enp1s0 which should give you the following output: GENERAL.DEVICE: enp1s0 GENERAL.TYPE: ethernet GENERAL.HWADDR: 6E:86:C0:4E:15:DB GENERAL.MTU: 1500 GENERAL.STATE: 100 (connect\u00e9) GENERAL.CONNECTION: enp1s0 GENERAL.CON-PATH: /org/freedesktop/NetworkManager/ActiveConnection/1 WIRED-PROPERTIES.CARRIER: marche IP4.ADDRESS[1]: 10.0.0.10/24 IP4.GATEWAY: 10.0.0.1 IP4.ROUTE[1]: dst = 10.0.0.0/24, nh = 0.0.0.0, mt = 100 IP4.ROUTE[2]: dst = 0.0.0.0/0, nh = 10.0.0.1, mt = 100 IP4.DNS[1]: 10.0.0.1 IP4.DNS[2]: 1.1.1.1 IP6.GATEWAY: -- CLI NetworkManager's primary function is managing \"connections\", which map a physical device to more logical network components like an IP address and DNS settings. To view the existing connections NetworkManager maintains, you can run nmcli connection show . [user@server ~]$ sudo nmcli connection show NAME UUID TYPE DEVICE enp1s0 625a8aef-175d-4692-934c-2c4a85f11b8c ethernet enp1s0 From the output above, we can determine that NetworkManager manages a connection ( NAME ) called enp1s0 that maps to the physical device ( DEVICE ) enp1s0 . !!! hint \"Connection name\" In this example, both the connection and device share the same name, but this may not always be the case. It is common to see a connection called `System eth0` that maps to a device called `eth0`, for example. Now that we know the name of our connection, we can view the settings for it. To do this, use the nmcli connection show [connection] command, which will print out all of the settings NetworkManager registers for the given connection. [user@server ~]$ sudo nmcli connection show enp1s0 ... ipv4.method: auto ipv4.dns: -- ipv4.dns-search: -- ipv4.dns-options: -- ipv4.dns-priority: 0 ipv4.addresses: -- ipv4.gateway: -- ipv4.routes: -- ipv4.route-metric: -1 ipv4.route-table: 0 (unspec) ipv4.routing-rules: -- ipv4.ignore-auto-routes: no ipv4.ignore-auto-dns: no ipv4.dhcp-client-id: -- ipv4.dhcp-iaid: -- ipv4.dhcp-timeout: 0 (default) ipv4.dhcp-send-hostname: yes ... Down the left-hand column, we see the name of the setting, and down the right we see the value. For example, we can see that the ipv4.method here is currently set to auto . There are many allowed values for the ipv4.method setting, but the main two you will most likely see are: auto : the appropriate automatic method (DHCP, PPP, etc) is used for the interface and most other properties can be left unset. manual : static IP addressing is used and at least one IP address must be given in the 'addresses' property. If instead you want to configure the system to use a static IP address scheme, you will have to change the value of ipv4.method to manual , and also specify the ipv4.gateway and ipv4.addresses . To modify a setting, you can use the nmcli command nmcli connection modify [connection] [setting] [value] . # set 10.0.0.10 as the static ipv4 address [user@server ~]$ sudo nmcli connection modify enp1s0 ipv4.addresses 10.0.0.10 # set 10.0.0.1 as the ipv4 gateway [user@server ~]$ sudo nmcli connection modify enp1s0 ipv4.gateway 10.0.0.1 # change ipv4 method to use static assignments (set in the previous two commands) [user@server ~]$ sudo nmcli connection modify enp1s0 ipv4.method manual !!!hint \"When does the connection get updated?\" `nmcli connection modify` will not modify the *runtime* configuration, but update the `/etc/sysconfig/network-scripts` configuration files with the appropriate values based on what you have told `nmcli` to configure. To configure your DNS servers with NetworkManager via the CLI, you can modify the ipv4.dns setting. # set 10.0.0.1 and 1.1.1.1 as the primary and secondary DNS servers [user@server ~]$ sudo nmcli connection modify enp1s0 ipv4.dns '10.0.0.1 1.1.1.1' Apply configuration To apply the network configuration, you can use the nmcli connection up [connection] command. [user@server ~]$ sudo nmcli connection up enp1s0 Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/2) To get the connection state, simply use: [user@server ~]$ sudo nmcli connection show NAME UUID TYPE DEVICE enp1s0 625a8aef-175d-4692-934c-2c4a85f11b8c ethernet enp1s0 You can also use the ifup and ifdown commands to bring the interface up and down (they are simple wrappers around nmcli ): [user@server ~]$ sudo ifup enp1s0 [user@server ~]$ sudo ifdown enp1s0 Using ip utility The ip command (provided by the iproute2 package) is a powerful tool to get information and configure the network of a modern Linux system such as Rocky Linux. In this example, we will assume the following parameters: interface name: ens19 ip address: 192.168.20.10 subnet mask: 24 gateway: 192.168.20.254 Get general information To see the detailed state of all interfaces, use ip a !!! hint \" Pro tips: \" * use the `-c` flag to get a more readable coloured output: `ip -c a`. * `ip` accepts abbreviation so `ip a`, `ip addr` and `ip address` are equivalent Bring interface up or down To bring the ens19 interface up, simply use ip link set ens19 up and to bring it down, use ip link set ens19 down . Assign the interface a static address The command to be used is of the form: ip addr add <IP ADDRESS/CIDR> dev <IFACE NAME> To assign the above example parameters, we will use: ip a add 192.168.20.10/24 dev ens19 Then, checking the result with: ip a show dev ens19 will output: 3: ens19: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 4a:f2:f5:b6:aa:9f brd ff:ff:ff:ff:ff:ff inet 192.168.20.10/24 scope global ens19 valid_lft forever preferred_lft forever Our interface is up and configured, but is still lacking something! Using ifcfg utility To add the ens19 interface our new example IP address, use the following command: ifcfg ens19 add 192.168.20.10/24 To remove the address: ifcfg ens19 del 192.168.20.10/24 To completely disable IP addressing on this interface: ifcfg ens19 stop Note that this does not bring the interface down, it simply unassigns all IP addresses from the interface. Gateway configuration Now that the interface has an address, we have to set its default route, this can be done with: ip route add default via 192.168.20.254 dev ens19 The kernel routing table can be displayed with ip route or ip r for short. Checking network connectivity At this point, you should have your network interface up and properly configured. There are several ways to verify your connectivity. By pinging another IP address in the same network (we will use 192.168.20.42 as an example): ping -c3 192.168.20.42 This command will issue 3 pings (known as ICMP request) and wait for a reply. If everything went fine, you should get this output: PING 192.168.20.42 (192.168.20.42) 56(84) bytes of data. 64 bytes from 192.168.20.42: icmp_seq=1 ttl=64 time=1.07 ms 64 bytes from 192.168.20.42: icmp_seq=2 ttl=64 time=0.915 ms 64 bytes from 192.168.20.42: icmp_seq=3 ttl=64 time=0.850 ms --- 192.168.20.42 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 5ms rtt min/avg/max/mdev = 0.850/0.946/1.074/0.097 ms Then, to make sure your routing configuration is fine, try to ping a external host, such as this well known public DNS resolver: ping -c3 8.8.8.8 If your machine has several network interface and you want to make ICMP request via a specific interface, you can use the -I flag: ping -I ens19 -c3 192.168.20.42 It is now time to make sure that DNS resolution is working correctly. As a reminder, DNS resolution is a mechanism used to convert human friendly machine names into their IP addresses and the other way round (reverse DNS). If the /etc/resolv.conf file indicates a reachable DNS server, then the following should work: host rockylinux.org The result should be: rockylinux.org has address 76.76.21.21","title":"Networking Configuration"},{"location":"guides/network/basic_network_configuration/#networking-configuration","text":"","title":"Networking configuration"},{"location":"guides/network/basic_network_configuration/#prerequisites","text":"A certain amount of comfort operating from the command line Elevated or administrative privileges on the system (For example root, sudo and so on) Optional: familiarity with networking concepts","title":"Prerequisites"},{"location":"guides/network/basic_network_configuration/#introduction","text":"Nowadays a computer without network connectivity is almost useless by itself. Whether you need to update the packages on a server or simply browse external Websites from your laptop - you will need network access! This guide aims to provide Rocky Linux users the basic knowledge on how to setup network connectivity on a Rocky Linux system.","title":"Introduction"},{"location":"guides/network/basic_network_configuration/#using-networkmanager-service","text":"At the user level, the networking stack is managed by NetworkManager . This tool runs as a service, and you can check its state with the following command: systemctl status NetworkManager","title":"Using NetworkManager service"},{"location":"guides/network/basic_network_configuration/#configuration-files","text":"NetworkManager simply applies a configuration read from the files found in /etc/sysconfig/network-scripts/ifcfg-<IFACE_NAME> . Each network interface has its configuration file. The following shows an example for the default configuration of a server: TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=enp1s0 UUID=74c5ccee-c1f4-4f45-883f-fc4f765a8477 DEVICE=enp1s0 ONBOOT=yes IPADDR=10.0.0.10 PREFIX=24 GATEWAY=10.0.0.1 DNS1=10.0.0.1 DNS2=1.1.1.1 IPV6_DISABLED=yes The interface's name is enp1s0 so this file's name will be /etc/sysconfig/network-scripts/ifcfg-enp1s0 . !!! hint \" Tips: \" There are a few ways or mechanisms by which systems can be assigned their IP configuration information. The two most common methods are - **Static IP configuration** scheme and **Dynamic IP configuration** scheme. The static IP configuration scheme is very popular on server class systems or networks. The dynamic IP approach is popular on home and office networks - or workstation and desktop class systems. The dynamic scheme usually needs _something_ extra that is locally available that can supply proper IP configuration information to requesting workstations and desktops. This _something_ is called the Dynamic Host Configuration Protocol (DHCP). Very often, home/office users don't have to worry or know about DHCP. This is because the somebody or something else is automagically taking care of that in the background. The only thing that the end user needs to do is to physically or wirelessly connect to the right network (and of course make sure that their systems are powered on)!","title":"Configuration files"},{"location":"guides/network/basic_network_configuration/#ip-address","text":"In the previous /etc/sysconfig/network-scripts/ifcfg-enp1s0 listing, we see that the value of the BOOTPROTO parameter or key is set to none . This means that the system being configured is set to a static IP address scheme. If instead you want to configure the system to use a dynamic IP address scheme, you will have to change the value of the BOOTPROTO parameter from none to dhcp and also remove the IPADDR , PREFIX and GATEWAY lines. This is necessary because all of that information will be automaically obtained from any available DHCP server. To configure a static IP address attribution, set the following: IPADDR: the IP address to assign the interface PREFIX: the subnet mask in CIDR notation GATEWAY: the default gateway The ONBOOT parameter set to yes indicates that this connection will be activated during boot time.","title":"IP Address"},{"location":"guides/network/basic_network_configuration/#dns-resolution","text":"To get proper name resolution, the following parameters must be set: DNS1: IP address of the main nameserver DNS2: the secondary nameserver IP address","title":"DNS resolution"},{"location":"guides/network/basic_network_configuration/#checking-configuration","text":"You can check that the configuration has been correctly applied with the following nmcli command: [user@server ~]$ sudo nmcli device show enp1s0 which should give you the following output: GENERAL.DEVICE: enp1s0 GENERAL.TYPE: ethernet GENERAL.HWADDR: 6E:86:C0:4E:15:DB GENERAL.MTU: 1500 GENERAL.STATE: 100 (connect\u00e9) GENERAL.CONNECTION: enp1s0 GENERAL.CON-PATH: /org/freedesktop/NetworkManager/ActiveConnection/1 WIRED-PROPERTIES.CARRIER: marche IP4.ADDRESS[1]: 10.0.0.10/24 IP4.GATEWAY: 10.0.0.1 IP4.ROUTE[1]: dst = 10.0.0.0/24, nh = 0.0.0.0, mt = 100 IP4.ROUTE[2]: dst = 0.0.0.0/0, nh = 10.0.0.1, mt = 100 IP4.DNS[1]: 10.0.0.1 IP4.DNS[2]: 1.1.1.1 IP6.GATEWAY: --","title":"Checking configuration"},{"location":"guides/network/basic_network_configuration/#cli","text":"NetworkManager's primary function is managing \"connections\", which map a physical device to more logical network components like an IP address and DNS settings. To view the existing connections NetworkManager maintains, you can run nmcli connection show . [user@server ~]$ sudo nmcli connection show NAME UUID TYPE DEVICE enp1s0 625a8aef-175d-4692-934c-2c4a85f11b8c ethernet enp1s0 From the output above, we can determine that NetworkManager manages a connection ( NAME ) called enp1s0 that maps to the physical device ( DEVICE ) enp1s0 . !!! hint \"Connection name\" In this example, both the connection and device share the same name, but this may not always be the case. It is common to see a connection called `System eth0` that maps to a device called `eth0`, for example. Now that we know the name of our connection, we can view the settings for it. To do this, use the nmcli connection show [connection] command, which will print out all of the settings NetworkManager registers for the given connection. [user@server ~]$ sudo nmcli connection show enp1s0 ... ipv4.method: auto ipv4.dns: -- ipv4.dns-search: -- ipv4.dns-options: -- ipv4.dns-priority: 0 ipv4.addresses: -- ipv4.gateway: -- ipv4.routes: -- ipv4.route-metric: -1 ipv4.route-table: 0 (unspec) ipv4.routing-rules: -- ipv4.ignore-auto-routes: no ipv4.ignore-auto-dns: no ipv4.dhcp-client-id: -- ipv4.dhcp-iaid: -- ipv4.dhcp-timeout: 0 (default) ipv4.dhcp-send-hostname: yes ... Down the left-hand column, we see the name of the setting, and down the right we see the value. For example, we can see that the ipv4.method here is currently set to auto . There are many allowed values for the ipv4.method setting, but the main two you will most likely see are: auto : the appropriate automatic method (DHCP, PPP, etc) is used for the interface and most other properties can be left unset. manual : static IP addressing is used and at least one IP address must be given in the 'addresses' property. If instead you want to configure the system to use a static IP address scheme, you will have to change the value of ipv4.method to manual , and also specify the ipv4.gateway and ipv4.addresses . To modify a setting, you can use the nmcli command nmcli connection modify [connection] [setting] [value] . # set 10.0.0.10 as the static ipv4 address [user@server ~]$ sudo nmcli connection modify enp1s0 ipv4.addresses 10.0.0.10 # set 10.0.0.1 as the ipv4 gateway [user@server ~]$ sudo nmcli connection modify enp1s0 ipv4.gateway 10.0.0.1 # change ipv4 method to use static assignments (set in the previous two commands) [user@server ~]$ sudo nmcli connection modify enp1s0 ipv4.method manual !!!hint \"When does the connection get updated?\" `nmcli connection modify` will not modify the *runtime* configuration, but update the `/etc/sysconfig/network-scripts` configuration files with the appropriate values based on what you have told `nmcli` to configure. To configure your DNS servers with NetworkManager via the CLI, you can modify the ipv4.dns setting. # set 10.0.0.1 and 1.1.1.1 as the primary and secondary DNS servers [user@server ~]$ sudo nmcli connection modify enp1s0 ipv4.dns '10.0.0.1 1.1.1.1'","title":"CLI"},{"location":"guides/network/basic_network_configuration/#apply-configuration","text":"To apply the network configuration, you can use the nmcli connection up [connection] command. [user@server ~]$ sudo nmcli connection up enp1s0 Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/2) To get the connection state, simply use: [user@server ~]$ sudo nmcli connection show NAME UUID TYPE DEVICE enp1s0 625a8aef-175d-4692-934c-2c4a85f11b8c ethernet enp1s0 You can also use the ifup and ifdown commands to bring the interface up and down (they are simple wrappers around nmcli ): [user@server ~]$ sudo ifup enp1s0 [user@server ~]$ sudo ifdown enp1s0","title":"Apply configuration"},{"location":"guides/network/basic_network_configuration/#using-ip-utility","text":"The ip command (provided by the iproute2 package) is a powerful tool to get information and configure the network of a modern Linux system such as Rocky Linux. In this example, we will assume the following parameters: interface name: ens19 ip address: 192.168.20.10 subnet mask: 24 gateway: 192.168.20.254","title":"Using ip utility"},{"location":"guides/network/basic_network_configuration/#get-general-information","text":"To see the detailed state of all interfaces, use ip a !!! hint \" Pro tips: \" * use the `-c` flag to get a more readable coloured output: `ip -c a`. * `ip` accepts abbreviation so `ip a`, `ip addr` and `ip address` are equivalent","title":"Get general information"},{"location":"guides/network/basic_network_configuration/#bring-interface-up-or-down","text":"To bring the ens19 interface up, simply use ip link set ens19 up and to bring it down, use ip link set ens19 down .","title":"Bring interface up or down"},{"location":"guides/network/basic_network_configuration/#assign-the-interface-a-static-address","text":"The command to be used is of the form: ip addr add <IP ADDRESS/CIDR> dev <IFACE NAME> To assign the above example parameters, we will use: ip a add 192.168.20.10/24 dev ens19 Then, checking the result with: ip a show dev ens19 will output: 3: ens19: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 4a:f2:f5:b6:aa:9f brd ff:ff:ff:ff:ff:ff inet 192.168.20.10/24 scope global ens19 valid_lft forever preferred_lft forever Our interface is up and configured, but is still lacking something!","title":"Assign the interface a static address"},{"location":"guides/network/basic_network_configuration/#using-ifcfg-utility","text":"To add the ens19 interface our new example IP address, use the following command: ifcfg ens19 add 192.168.20.10/24 To remove the address: ifcfg ens19 del 192.168.20.10/24 To completely disable IP addressing on this interface: ifcfg ens19 stop Note that this does not bring the interface down, it simply unassigns all IP addresses from the interface.","title":"Using ifcfg utility"},{"location":"guides/network/basic_network_configuration/#gateway-configuration","text":"Now that the interface has an address, we have to set its default route, this can be done with: ip route add default via 192.168.20.254 dev ens19 The kernel routing table can be displayed with ip route or ip r for short.","title":"Gateway configuration"},{"location":"guides/network/basic_network_configuration/#checking-network-connectivity","text":"At this point, you should have your network interface up and properly configured. There are several ways to verify your connectivity. By pinging another IP address in the same network (we will use 192.168.20.42 as an example): ping -c3 192.168.20.42 This command will issue 3 pings (known as ICMP request) and wait for a reply. If everything went fine, you should get this output: PING 192.168.20.42 (192.168.20.42) 56(84) bytes of data. 64 bytes from 192.168.20.42: icmp_seq=1 ttl=64 time=1.07 ms 64 bytes from 192.168.20.42: icmp_seq=2 ttl=64 time=0.915 ms 64 bytes from 192.168.20.42: icmp_seq=3 ttl=64 time=0.850 ms --- 192.168.20.42 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 5ms rtt min/avg/max/mdev = 0.850/0.946/1.074/0.097 ms Then, to make sure your routing configuration is fine, try to ping a external host, such as this well known public DNS resolver: ping -c3 8.8.8.8 If your machine has several network interface and you want to make ICMP request via a specific interface, you can use the -I flag: ping -I ens19 -c3 192.168.20.42 It is now time to make sure that DNS resolution is working correctly. As a reminder, DNS resolution is a mechanism used to convert human friendly machine names into their IP addresses and the other way round (reverse DNS). If the /etc/resolv.conf file indicates a reachable DNS server, then the following should work: host rockylinux.org The result should be: rockylinux.org has address 76.76.21.21","title":"Checking network connectivity"},{"location":"guides/network/librenms_monitoring_server/","text":"LibreNMS Monitoring Server Introduction Network and systems administrators almost always need some form of monitoring. This can include graphing bandwidth usage at router end points, monitoring the up/down of services running on various servers, and much, much more. There are many monitoring options out there, but one option that is very good and has many, if not all, of the monitoring components available under one roof, is LibreNMS. This document will only get you started with LibreNMS, but we will point you to the projects excellent (and extensive) documentation to get you going further. There are lots of other options for monitoring out there that this author has used before, Nagios and Cacti being two, but LibreNMS offers what these two project offer individually, in one spot. While the installation will follow pretty closely to the official install instructions found here , we've added some explanation and even some minor changes, which make this procedure preferable to that excellent document. Prerequisites, Assumptions and Conventions A server or container (yes, LibreNMS will run in a container, however if you have a lot to monitor, your best bet would be to install on its own hardware) running Rocky Linux. All commands assume a fresh install of Rocky Linux. Assumption: that you are able to execute commands as root or can sudo to do so Working knowledge of command-line tools, including editors, such as vi We are assuming the use of SNMP v2. If you want to use SNMP v3, it is supported by LibreNMS and will work. You'll just need to switch up the SNMP configuration and options on your devices to match up to v3. While we have included the SELinux procedure in this document, the container that we are using in the lab does not include it by default. For this reason, the SELinux procedure has not been lab tested. Throughout this document, the examples use the vi editor as mentioned. When the document says to save your changes and exit, this is done with SHIFT:wq! Some trouble-shooting skills, including log monitoring, web testing, and more, are required. Installing Packages These commands should be entered as the root user. Before we begin, note that this installation procedure focuses on httpd, rather than nginx. If you prefer to use the latter, head up to the Librenms Install Instructions and follow the guide there. We are assuming a fresh install, so we need to do a few things with the repositories before we can continue. First, we need to install the EPEL repository (Extra Packages for Enterprise Linux): dnf install -y epel-release Next, we need to tell the repositories to enable PHP 7.3 as the default PHP: dnf module reset php dnf module enable php:7.3 This will return a listing for httpd, nginx, and php, just answer \"y\" to the prompt to continue. Next, we need to install a bunch of packages: dnf install bash-completion cronie fping git httpd ImageMagick mariadb-server mtr net-snmp net-snmp-utils nmap php-fpm php-cli php-common php-curl php-gd php-json php-mbstring php-process php-snmp php-xml php-zip php-mysqlnd python3 python3-PyMySQL python3-redis python3-memcached python3-pip python3-systemd rrdtool unzip All of these packages represent some portion of the LibreNMS feature set. Setting Up The librenms User To do this, copy and paste (or type) the following: useradd librenms -d /opt/librenms -M -r -s \"$(which bash)\" With this command, we are setting the default directory for our new user to \"/opt/librenms\" however the \"-M\" option says \"don't create the directory.\" The reason, of course, is that we will be creating it when we install libreNMS. The \"-r\" says to make this user a system account and the \"-s\" says to set the shell (in this case, to \"bash\") Download LibreNMS and Set Permissions The download is all done through git. You may be familiar with the process as it is used for many projects these days. First, switch over to the /opt directory: cd /opt Then clone the repository: git clone https://github.com/librenms/librenms.git Next change permissions for the directory: chown -R librenms:librenms /opt/librenms chmod 771 /opt/librenms setfacl -d -m g::rwx /opt/librenms/rrd /opt/librenms/logs /opt/librenms/bootstrap/cache/ /opt/librenms/storage/ setfacl -R -m g::rwx /opt/librenms/rrd /opt/librenms/logs /opt/librenms/bootstrap/cache/ /opt/librenms/storage/ The setfacl command stands for \"set file access control lists\" and is another way of securing directories and files. Install PHP Dependencies As librenms All of the above commands were executed as root or sudo , but the PHP dependencies within LibreNMS need to be installed as the librenms user. To do this, su - librenms And then enter the following: ./scripts/composer_wrapper.php install --no-dev Once the script is completed, exit back to root: exit Failure Of PHP Dependency Install Workaround LibreNMS documentation says that when you are behind a proxy server, the above procedure may fail. If so, use this procedure as a workaround. Note, too, that this workaround would have to be run as the root user, because it makes modifications to /usr/bin: wget https://getcomposer.org/composer-stable.phar mv composer-stable.phar /usr/bin/composer chmod +x /usr/bin/composer Set Timezone We need to make sure that this is set correctly, both for the system and for PHP. You can find a list of valid timezone settings for PHP here . For instance, for the Central timezone, a common entry would be \"America/Chicago\". Let's start by editing the php.ini file: vi /etc/php.ini Find the date.timezone line and modify it. Note that it is remarked out, so remove the \";\" from the beginning of the line and add your timezone after the \"=\" sign. For our Central timezone example we will use: date.timezone = America/Chicago Save your changes and exit the php.ini file. We also need to make sure that the system timezone is correct. Again, using our Central timezone as the example, we would do this with: timedatectl set-timezone America/Chicago MariaDB Setup Before we get into the database setup required for LibreNMS, run through the MariaDB procedure and specifically the section for \"Securing mariadb-server\", and then come back here for these specific settings. The first thing we need to do is modify the mariadb-server.cnf file: vi /etc/my.cnf.d/mariadb-server.cnf And add the following lines to the \"[Mysqld]\" section: innodb_file_per_table=1 lower_case_table_names=0 Then enable and restart the mariadb server: systemctl enable mariadb systemctl restart mariadb Now gain access to mariadb as the root user. Remember to use the password that you created when folloing the \"Securing mariadb-server\" section that you performed above: mysql -u root -p The next thing we need to do is make some specific changes for LibreNMS. With the command below, remember to change the password \"password\" to something secure and document what that is in a safe spot, such as a password manager, so that you will have it later. At the mysql prompt do: CREATE DATABASE librenms CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; CREATE USER 'librenms'@'localhost' IDENTIFIED BY 'password'; GRANT ALL PRIVILEGES ON librenms.* TO 'librenms'@'localhost'; FLUSH PRIVILEGES; Once you've done this, type \"exit\" to exit back out of mariadb. Configure PHP-FPM This section is basically unchanged from the official documentation. First, copy the www.conf: cp /etc/php-fpm.d/www.conf /etc/php-fpm.d/librenms.conf Next modify the librenms.conf file: vi /etc/php-fpm.d/librenms.conf Near the top, add these two lines to fix a path issue for the librenms user that will come up later: ; Set the ENV path to fix broken Centos web page issue env[PATH] = /usr/local/bin:/usr/bin:/bin Change \"[www]\" to [\"librenms]\" Change the user and group to \"librenms\": user = librenms group = librenms And finally change the \"listen\" line to reflect a unique name: listen = /run/php-fpm-librenms.sock Save your changes and exit the file. If this is the only web service that will be running on this machine, feel free to remove the old www.conf file that we copied: rm -f /etc/php-fpm.d/www.conf Configure Apache Normally, we would use the Apache sites-enabled procedure to set up any web services, but in this case, we are just going with the default setup. Note that if you want to use that procedure, you simply need to place the configuration file in /etc/httpd/sites-available and then follow the procedure to link it to sites-enabled. The default document root, however, would not be /var/www/sub-domains/librenms/html, but instead it would be /opt/librenms/html. Again, in this case we aren't using that procedure and just going with the default, suggested setup. To do this, start by creating this file: vi /etc/httpd/conf.d/librenms.conf And placing the following in that file: <VirtualHost *:80> DocumentRoot /opt/librenms/html/ ServerName librenms.example.com AllowEncodedSlashes NoDecode <Directory \"/opt/librenms/html/\"> Require all granted AllowOverride All Options FollowSymLinks MultiViews </Directory> # Enable http authorization headers <IfModule setenvif_module> SetEnvIfNoCase ^Authorization$ \"(.+)\" HTTP_AUTHORIZATION=$1 </IfModule> <FilesMatch \".+\\.php$\"> SetHandler \"proxy:unix:/run/php-fpm-librenms.sock|fcgi://localhost\" </FilesMatch> </VirtualHost> You should also remove the old default site, welcome.conf: rm /etc/httpd/conf.d/welcome.conf Finally, we need to enable both httpd and php-fpm : systemctl enable --now httpd systemctl enable --now php-fpm SELinux Please note that if you don't plan on using SELinux, skip this and head to the next section. This might also apply to you if you use LibreNMS on a container that does not support SELinux at the container level, or does not include it by default. To setup everything with SELinux, you'll need an additional package installed: dnf install policycoreutils-python-utils Configure LibreNMS Contexts You'll need to set the following contexts for LibreNMS to work properly with SELinux: semanage fcontext -a -t httpd_sys_content_t '/opt/librenms/html(/.*)?' semanage fcontext -a -t httpd_sys_rw_content_t '/opt/librenms/(logs|rrd|storage)(/.*)?' restorecon -RFvv /opt/librenms setsebool -P httpd_can_sendmail=1 setsebool -P httpd_execmem 1 chcon -t httpd_sys_rw_content_t /opt/librenms/.env Allow fping Create a file called http_fping.tt anywhere and it will be installed via a command later. The contents of this file are: module http_fping 1.0; require { type httpd_t; class capability net_raw; class rawip_socket { getopt create setopt write read }; } #============= httpd_t ============== allow httpd_t self:capability net_raw; allow httpd_t self:rawip_socket { getopt create setopt write read }; Now install the contents of this file with the following commands: checkmodule -M -m -o http_fping.mod http_fping.tt semodule_package -o http_fping.pp -m http_fping.mod semodule -i http_fping.pp If you run into problems and you suspect it might be due to an SELinux issue, run the following: audit2why < /var/log/audit/audit.log Firewall Configuration We will include the firewalld instructions from the official documentation, however we will be using iptables in the lab, so will also include those instructions. To use iptables simply follow this procedure and then use the iptables script found in this procedure, and make modifications to it for your network. firewalld The command to use for firewalld allow rules are as follows: firewall-cmd --zone public --add-service http --add-service https firewall-cmd --permanent --zone public --add-service http --add-service https The author has problems with the simplistic nature of firewalld . This rule allows your web services to be open to the world, but is that what you want for a monitoring server? I would say that this is usually not the case. I prefer iptables rules, because it is easy to see at a glance what you are allowing. iptables Create a script to run for adding, changing firewall rules called firewall.conf and put this in /etc vi /etc/firewall.conf Place the following in the file, substituting your network IP addresses as needed. This script allows UDP, SSH, HTTP and HTTPS from the local network in the lab, 192.168.1.0/24. It also allows ICMP type 8 (which stands for \"Echo Request\" or more commonly \"ping\") from our network gateway, 192.168.1.2: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p udp -m udp -s 192.168.1.0/24 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 443 -j ACCEPT iptables -A INPUT -p icmp -m icmp --icmp-type 8 -s 192.168.1.2 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Make the script executable: chmod +x /etc/firewall.conf Run the script: /etc/firewall.conf Assuming no errors, you should be ready to go. Enable Symbolic Link And Tab-Autocomplete For lnms Commands First, we need a symbolic link on our lnms command so that it can be executed from anywhere: ln -s /opt/librenms/lnms /usr/bin/lnms Next, we need to set it up for autocomplete: cp /opt/librenms/misc/lnms-completion.bash /etc/bash_completion.d/ Configure snmpd SNMP stands for \"Simple Network Management Protocol\" and is used in many monitoring programs for pulling data. In version 2, which we are using here, it involves a \"community string\" which is specific for your environment. You'll need to assign this \"community string\" to your network devices that you want to monitor so that snmpd (the \"d\" here stands for the daemon) will be able to find it. If your network has been in place for some time, you may already have a \"community string\" that you are using. First, copy the snmp.conf file from LibreNMS: cp /opt/librenms/snmpd.conf.example /etc/snmp/snmpd.conf Next, edit this file and change the community string from \"RANDOMSTRINGGOESHERE\" to whatever your community string is or will be. In our example, we are changing it to \"LABone\": vi /etc/snmp/snmpd.conf and change this line: com2sec readonly default RANDOMSTRINGGOESHERE to com2sec readonly default LABone Now save your changes and exit. Automating With A Cron Job Do the following: cp /opt/librenms/librenms.nonroot.cron /etc/cron.d/librenms Log Rotation LibreNMS will create a large set of logs over time. You'll need to setup log rotation for this so that it doesn't eat up too much disk space. To do this, simply do the following now: cp /opt/librenms/misc/librenms.logrotate /etc/logrotate.d/librenms Web Setup Now that we have all of the components installed and configured, our next step is to finish the installation via the web. In our lab version, we've got no hostname setup so to finish the setup, we need to go to the web server by IP address. The IP of our lab machine is 192.168.1.140, so we need to do the following in a web browser to finish the install: http://192.168.1.140/librenms Assuming all is working correctly, you should be redirected to the pre-install checks. Assuming that these are all marked as green, then we should be able to continue. There are four buttons beneath the LibreNMS logo. The first button on the left is for the pre-checks. Our next button over is for the database. You'll need the password that you set for the database user \"librenms\" earlier in the process. If you've been following along diligently, then you've got that saved in a safe place. Go ahead and click on the \"Database\" button. The \"User\" and \"Password\" should be all that is necessary to fill in here. Once you do that, click the \"Check Credentials\" button. Once you click that, if it comes back green, then you are ready to click the \"Build Database\" button. Once that is complete, the third button will be active, which is \"Create Admin User\", so go ahead and click this. You will be prompted for an admin user name. In our lab we are simply going to use \"admin\", and a password for that user. Make sure the password is secure and, again, log it somewhere safe, such as a password manager. You'll also need to fill in the email address for the administrative user. Once all of that is completed, simply click the \"Add User\" button. Once you do this, you'll be faced with a screen for \"Finish Install.\" There should only be one item left to finish the install and that is a line that asks you to \"validate your install\". Click the link. Once you've done this and everything is successful, you'll be redirected to the login page. Login with your administrative user and password. Adding Devices Again, one of our assumptions was that you are using SNMP v2. Remember that each device you add must be member of your community string. We are adding two devices as examples here. A Ubuntu workstation and a CentOS server. You will more than likely have managed switches, routers, and other devices to add. The author can tell you from past experience that adding switches and routers tends to be a whole lot easier than adding workstations and servers, which is why we are using those as our examples. Ubuntu Workstation Setup First, install snmpd on the workstation while also updating packages, just to be safe: sudo update && sudo apt-get upgrade && sudo apt-get install snmpd Next, you need to modify the snmpd.conf file: sudo vi /etc/snmpd/snmpd.conf Go ahead and find the lines that describe your workstation and change them to things that identify the workstation. These lines are shown below: sysLocation Desktop sysContact Username <user@mydomain.com> By default, when you install snmpd on Ubuntu, it only binds to the local address. It does not listen on your machine IP address. This will not allow LibreNMS to connect to it. We need to remark out this line: agentaddress 127.0.0.1,[::1] And add a new line that looks like what follows here: (In this example, the IP address of our workstation is 192.168.1.122 and the UDP port we are setting is \"161\") agentAddress udp:127.0.0.1:161,udp:192.168.1.122:161 Next, we need to specify the read only access community string. Find the below lines and remark them out. (note that we are showing them as remarked out below): #rocommunity public default -V systemonly #rocommunity6 public default -V systemonly Next, add a new line: rocommunity LABone Now save your changes and exit. Enable and start snmpd : sudo systemctl enable snmpd sudo systemctl start snmpd If you are running a firewall on your internal workstations, then you will need to modify the firewall to allow UDP traffic from the monitoring server or from the network. LibreNMS also wants to be able to \"ping\" your device, so make sure that icmp port 8 is allowed from the server. CentOS or Rocky Linux Server Setup We are assuming that you are root here or that you can sudo to become so. First, we need to install some packages: dnf install net-snmp net-snmp-utils Next, we want to create a snmpd.conf file. Rather than try to navigate through the file that is included, move this file to rename it, and create a brand new empty file: mv /etc/snmp/snmpd.conf /etc/snmp/snmpd.conf.orig and vi /etc/snmp/snmpd.conf Next copy the below into the new file: # Map 'LABone' community to the 'AllUser' # sec.name source community com2sec AllUser default LABone # Map 'ConfigUser' to 'ConfigGroup' for SNMP Version 2c # Map 'AllUser' to 'AllGroup' for SNMP Version 2c # sec.model sec.name group AllGroup v2c AllUser # Define 'SystemView', which includes everything under .1.3.6.1.2.1.1 (or .1.3.6.1.2.1.25.1) # Define 'AllView', which includes everything under .1 # incl/excl subtree view SystemView included .1.3.6.1.2.1.1 view SystemView included .1.3.6.1.2.1.25.1.1 view AllView included .1 # Give 'ConfigGroup' read access to objects in the view 'SystemView' # Give 'AllGroup' read access to objects in the view 'AllView' # context model level prefix read write notify access AllGroup \"\" any noauth exact AllView none none CentOS and Rocky use a mapping convention to direct things. The above file is commented nicely so that you can learn what is happening, but doesn't include all of the clutter of the original file. Once you've made the changes, save them and exit the file. Now we need to enable and start snmpd : systemctl enable snmpd systemctl start snmpd Firewall If you are running a server, then you are running a firewall, right? We are assuming iptables as noted above, so we need to modify our firewall configuration, (in this case, /etc/firewall.conf) and add access for UDP and ICMP traffic coming from the monitoring server. If you are running firewalld , just substitute in the appropriate rules for firewalld . Here's a rule set for our example server: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p icmp --icmp-type 8 -s 192.168.1.140 -j ACCEPT iptables -A INPUT -p udp -m udp -s 192.168.1.140 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save If you are new to this particular iptables concept, the /etc/firewall.conf is executable, and it's our way of making changes to the saved iptables rules that will be restored on boot. In the above example, we are allowing \"ping\" and UDP traffic from our monitoring server and SSH from our local network. Many other rules may be necessary for your server functions, perhaps http rules or mysql port allow rules, etc. Once you've made the changes to /etc/firewall.conf, execute it with: /etc/firewall.conf Adding The Devices In Librenms Now that our sample devices are configured to accept snmp traffic from our LibreNMS server, the next step is to add those devices in LibreNMS. We are assuming that you have the web interface for LibreNMS open, and if so, it is going to be showing you that you have no devices added and asking you to add one. So go ahead and do that. Once you click to add a device, you'll be faced with this screen: Put in the information we used for our test devices. In our case, we are using the IP for the Ubuntu workstation to start, in our example that is 192.168.1.122. The only other thing we will need to add here is the community string in the \"Community\" field, so we would type in \"LABone\" here. Now click the \"Add Device\" button. Assuming that you have done everything correctly above when adding the device, your device should be added successfully. If you run into a failure to add, review the SNMP setup for the workstation or the firewall if it exists. Next we repeat the \"Add Device\" process for our CentOS server. Getting Alerts As we said from the start, this document will only get you started with LibreNMS. There are a large number of additional configuration items, an extensive API (Application Programming Interface), an alerts system that provides a huge number of options for delivery, called \"Transports\", and much more. We are not going to create any alert rules, but instead we will be editing the built-in alert rule \"Device Down! Due to no ICMP response\" that is pre-configured out of the box, and for \"Transports\" we are going to stick with \"Mail\", which is just email. Just know that you are not limited. In order to use email for our transport, however, we need to have mail working on our server. To get this going, we are going to use this Postfix Procedure . Run through that procedure to configure postfix so that it will properly identify where the messages are coming from, but you can stop after the configuration process and come back here. Transports We need a way to send out our alerts. As noted earlier, LibreNMS supports a huge number of transports. We are going to do our alert by email, which is defined as the \"Mail\" transport. To set up the transport: Go to the dashboard Let your mouse hover over \"Alerts\" Go down to \"Alert Transports\" and click on it Click on on the \"Create alert transport\" button (Note the \"Create transport group\" button. You can use this to have alerts go to several individuals) In the \"Transport name:\" field, type in \"Alert By Email\" In the \"Transport type: field, use the drop down to select \"Mail\" Make sure the \"Default alert:\" field is set to \"On\" In the \"Email:\" field, type the email address of the administrator Organizing Devices Into Groups The best way to set up alerts is to first organize your devices into some logical order. Currently, we have a workstation and a server in devices. While we may not normally wish to organize the two together, we will for this example. Keep in mind that our example is also redundant, as there is an \"All Devices\" group that would work for this as well. To set up a device group: Go to the dashboard Let your mouse hover over \"Devices\" Go down to \"Manage Groups\" and click on it Click on the \"+ New Device Group\" button In the \"Name\" field, type \"ICMP Group\" In the description field type what ever you think will help describe the group Change the \"Type\" field from \"Dynamic\" to \"Static\" Add both devices to the \"Select Devices\" field and then just save your changes Setting Up The Alert Rules Now that we have the transport and the device group set up, let's configure the alert rule. By default, LibreNMS has several alert rules already created for you: Go to the dashboard Let your mouse hover over \"Alerts\" Go down to \"Alert Rules\" and click on it The top active rule in the display will be \"Device Down! Due to no ICMP response.\" Go over to the \"Action\" (far right column) and click on the pencil icon to edit the rule. Leave all the fields at the top as is and go down to the \"Match devices, groups and locations list:\" field and click inside the field Select \"ICMP Group\" from the list Make sure the \"All devices except in list:\" field is \"Off\" Click inside the \"Transports:\" field and select \"Mail: Alert By Email\" and save your rule. Before saving, your rule should look something like this: These two devices should now alert you by email if they are down and when they recover. Conclusions LibreNMS is a powerful monitoring tool with a full set of features in one application. We have only just scratched the surface on the capabilities. We haven't shown you some of the obvious screens. For instance, as soon as you add devices, assuming that all of the SNMP properties are set correctly, you'll start to receive bandwidth, memory utilization, and CPU utilization graphs on each device. We haven't shown you the wealth of transports available besides \"Mail\". All of that said, we have shown you enough in this document to get a good start monitoring your environment. LibreNMS takes some time to master all of the elements. You should visit the project's excellent documentation for additional information.","title":"LibreNMS Monitoring Server"},{"location":"guides/network/librenms_monitoring_server/#librenms-monitoring-server","text":"","title":"LibreNMS Monitoring Server"},{"location":"guides/network/librenms_monitoring_server/#introduction","text":"Network and systems administrators almost always need some form of monitoring. This can include graphing bandwidth usage at router end points, monitoring the up/down of services running on various servers, and much, much more. There are many monitoring options out there, but one option that is very good and has many, if not all, of the monitoring components available under one roof, is LibreNMS. This document will only get you started with LibreNMS, but we will point you to the projects excellent (and extensive) documentation to get you going further. There are lots of other options for monitoring out there that this author has used before, Nagios and Cacti being two, but LibreNMS offers what these two project offer individually, in one spot. While the installation will follow pretty closely to the official install instructions found here , we've added some explanation and even some minor changes, which make this procedure preferable to that excellent document.","title":"Introduction"},{"location":"guides/network/librenms_monitoring_server/#prerequisites-assumptions-and-conventions","text":"A server or container (yes, LibreNMS will run in a container, however if you have a lot to monitor, your best bet would be to install on its own hardware) running Rocky Linux. All commands assume a fresh install of Rocky Linux. Assumption: that you are able to execute commands as root or can sudo to do so Working knowledge of command-line tools, including editors, such as vi We are assuming the use of SNMP v2. If you want to use SNMP v3, it is supported by LibreNMS and will work. You'll just need to switch up the SNMP configuration and options on your devices to match up to v3. While we have included the SELinux procedure in this document, the container that we are using in the lab does not include it by default. For this reason, the SELinux procedure has not been lab tested. Throughout this document, the examples use the vi editor as mentioned. When the document says to save your changes and exit, this is done with SHIFT:wq! Some trouble-shooting skills, including log monitoring, web testing, and more, are required.","title":"Prerequisites, Assumptions and Conventions"},{"location":"guides/network/librenms_monitoring_server/#installing-packages","text":"These commands should be entered as the root user. Before we begin, note that this installation procedure focuses on httpd, rather than nginx. If you prefer to use the latter, head up to the Librenms Install Instructions and follow the guide there. We are assuming a fresh install, so we need to do a few things with the repositories before we can continue. First, we need to install the EPEL repository (Extra Packages for Enterprise Linux): dnf install -y epel-release Next, we need to tell the repositories to enable PHP 7.3 as the default PHP: dnf module reset php dnf module enable php:7.3 This will return a listing for httpd, nginx, and php, just answer \"y\" to the prompt to continue. Next, we need to install a bunch of packages: dnf install bash-completion cronie fping git httpd ImageMagick mariadb-server mtr net-snmp net-snmp-utils nmap php-fpm php-cli php-common php-curl php-gd php-json php-mbstring php-process php-snmp php-xml php-zip php-mysqlnd python3 python3-PyMySQL python3-redis python3-memcached python3-pip python3-systemd rrdtool unzip All of these packages represent some portion of the LibreNMS feature set.","title":"Installing Packages"},{"location":"guides/network/librenms_monitoring_server/#setting-up-the-librenms-user","text":"To do this, copy and paste (or type) the following: useradd librenms -d /opt/librenms -M -r -s \"$(which bash)\" With this command, we are setting the default directory for our new user to \"/opt/librenms\" however the \"-M\" option says \"don't create the directory.\" The reason, of course, is that we will be creating it when we install libreNMS. The \"-r\" says to make this user a system account and the \"-s\" says to set the shell (in this case, to \"bash\")","title":"Setting Up The librenms User"},{"location":"guides/network/librenms_monitoring_server/#download-librenms-and-set-permissions","text":"The download is all done through git. You may be familiar with the process as it is used for many projects these days. First, switch over to the /opt directory: cd /opt Then clone the repository: git clone https://github.com/librenms/librenms.git Next change permissions for the directory: chown -R librenms:librenms /opt/librenms chmod 771 /opt/librenms setfacl -d -m g::rwx /opt/librenms/rrd /opt/librenms/logs /opt/librenms/bootstrap/cache/ /opt/librenms/storage/ setfacl -R -m g::rwx /opt/librenms/rrd /opt/librenms/logs /opt/librenms/bootstrap/cache/ /opt/librenms/storage/ The setfacl command stands for \"set file access control lists\" and is another way of securing directories and files.","title":"Download LibreNMS and Set Permissions"},{"location":"guides/network/librenms_monitoring_server/#install-php-dependencies-as-librenms","text":"All of the above commands were executed as root or sudo , but the PHP dependencies within LibreNMS need to be installed as the librenms user. To do this, su - librenms And then enter the following: ./scripts/composer_wrapper.php install --no-dev Once the script is completed, exit back to root: exit","title":"Install PHP Dependencies As librenms"},{"location":"guides/network/librenms_monitoring_server/#failure-of-php-dependency-install-workaround","text":"LibreNMS documentation says that when you are behind a proxy server, the above procedure may fail. If so, use this procedure as a workaround. Note, too, that this workaround would have to be run as the root user, because it makes modifications to /usr/bin: wget https://getcomposer.org/composer-stable.phar mv composer-stable.phar /usr/bin/composer chmod +x /usr/bin/composer","title":"Failure Of PHP Dependency Install Workaround"},{"location":"guides/network/librenms_monitoring_server/#set-timezone","text":"We need to make sure that this is set correctly, both for the system and for PHP. You can find a list of valid timezone settings for PHP here . For instance, for the Central timezone, a common entry would be \"America/Chicago\". Let's start by editing the php.ini file: vi /etc/php.ini Find the date.timezone line and modify it. Note that it is remarked out, so remove the \";\" from the beginning of the line and add your timezone after the \"=\" sign. For our Central timezone example we will use: date.timezone = America/Chicago Save your changes and exit the php.ini file. We also need to make sure that the system timezone is correct. Again, using our Central timezone as the example, we would do this with: timedatectl set-timezone America/Chicago","title":"Set Timezone"},{"location":"guides/network/librenms_monitoring_server/#mariadb-setup","text":"Before we get into the database setup required for LibreNMS, run through the MariaDB procedure and specifically the section for \"Securing mariadb-server\", and then come back here for these specific settings. The first thing we need to do is modify the mariadb-server.cnf file: vi /etc/my.cnf.d/mariadb-server.cnf And add the following lines to the \"[Mysqld]\" section: innodb_file_per_table=1 lower_case_table_names=0 Then enable and restart the mariadb server: systemctl enable mariadb systemctl restart mariadb Now gain access to mariadb as the root user. Remember to use the password that you created when folloing the \"Securing mariadb-server\" section that you performed above: mysql -u root -p The next thing we need to do is make some specific changes for LibreNMS. With the command below, remember to change the password \"password\" to something secure and document what that is in a safe spot, such as a password manager, so that you will have it later. At the mysql prompt do: CREATE DATABASE librenms CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; CREATE USER 'librenms'@'localhost' IDENTIFIED BY 'password'; GRANT ALL PRIVILEGES ON librenms.* TO 'librenms'@'localhost'; FLUSH PRIVILEGES; Once you've done this, type \"exit\" to exit back out of mariadb.","title":"MariaDB Setup"},{"location":"guides/network/librenms_monitoring_server/#configure-php-fpm","text":"This section is basically unchanged from the official documentation. First, copy the www.conf: cp /etc/php-fpm.d/www.conf /etc/php-fpm.d/librenms.conf Next modify the librenms.conf file: vi /etc/php-fpm.d/librenms.conf Near the top, add these two lines to fix a path issue for the librenms user that will come up later: ; Set the ENV path to fix broken Centos web page issue env[PATH] = /usr/local/bin:/usr/bin:/bin Change \"[www]\" to [\"librenms]\" Change the user and group to \"librenms\": user = librenms group = librenms And finally change the \"listen\" line to reflect a unique name: listen = /run/php-fpm-librenms.sock Save your changes and exit the file. If this is the only web service that will be running on this machine, feel free to remove the old www.conf file that we copied: rm -f /etc/php-fpm.d/www.conf","title":"Configure PHP-FPM"},{"location":"guides/network/librenms_monitoring_server/#configure-apache","text":"Normally, we would use the Apache sites-enabled procedure to set up any web services, but in this case, we are just going with the default setup. Note that if you want to use that procedure, you simply need to place the configuration file in /etc/httpd/sites-available and then follow the procedure to link it to sites-enabled. The default document root, however, would not be /var/www/sub-domains/librenms/html, but instead it would be /opt/librenms/html. Again, in this case we aren't using that procedure and just going with the default, suggested setup. To do this, start by creating this file: vi /etc/httpd/conf.d/librenms.conf And placing the following in that file: <VirtualHost *:80> DocumentRoot /opt/librenms/html/ ServerName librenms.example.com AllowEncodedSlashes NoDecode <Directory \"/opt/librenms/html/\"> Require all granted AllowOverride All Options FollowSymLinks MultiViews </Directory> # Enable http authorization headers <IfModule setenvif_module> SetEnvIfNoCase ^Authorization$ \"(.+)\" HTTP_AUTHORIZATION=$1 </IfModule> <FilesMatch \".+\\.php$\"> SetHandler \"proxy:unix:/run/php-fpm-librenms.sock|fcgi://localhost\" </FilesMatch> </VirtualHost> You should also remove the old default site, welcome.conf: rm /etc/httpd/conf.d/welcome.conf Finally, we need to enable both httpd and php-fpm : systemctl enable --now httpd systemctl enable --now php-fpm","title":"Configure Apache"},{"location":"guides/network/librenms_monitoring_server/#selinux","text":"Please note that if you don't plan on using SELinux, skip this and head to the next section. This might also apply to you if you use LibreNMS on a container that does not support SELinux at the container level, or does not include it by default. To setup everything with SELinux, you'll need an additional package installed: dnf install policycoreutils-python-utils","title":"SELinux"},{"location":"guides/network/librenms_monitoring_server/#configure-librenms-contexts","text":"You'll need to set the following contexts for LibreNMS to work properly with SELinux: semanage fcontext -a -t httpd_sys_content_t '/opt/librenms/html(/.*)?' semanage fcontext -a -t httpd_sys_rw_content_t '/opt/librenms/(logs|rrd|storage)(/.*)?' restorecon -RFvv /opt/librenms setsebool -P httpd_can_sendmail=1 setsebool -P httpd_execmem 1 chcon -t httpd_sys_rw_content_t /opt/librenms/.env","title":"Configure LibreNMS Contexts"},{"location":"guides/network/librenms_monitoring_server/#allow-fping","text":"Create a file called http_fping.tt anywhere and it will be installed via a command later. The contents of this file are: module http_fping 1.0; require { type httpd_t; class capability net_raw; class rawip_socket { getopt create setopt write read }; } #============= httpd_t ============== allow httpd_t self:capability net_raw; allow httpd_t self:rawip_socket { getopt create setopt write read }; Now install the contents of this file with the following commands: checkmodule -M -m -o http_fping.mod http_fping.tt semodule_package -o http_fping.pp -m http_fping.mod semodule -i http_fping.pp If you run into problems and you suspect it might be due to an SELinux issue, run the following: audit2why < /var/log/audit/audit.log","title":"Allow fping"},{"location":"guides/network/librenms_monitoring_server/#firewall-configuration","text":"We will include the firewalld instructions from the official documentation, however we will be using iptables in the lab, so will also include those instructions. To use iptables simply follow this procedure and then use the iptables script found in this procedure, and make modifications to it for your network.","title":"Firewall Configuration"},{"location":"guides/network/librenms_monitoring_server/#firewalld","text":"The command to use for firewalld allow rules are as follows: firewall-cmd --zone public --add-service http --add-service https firewall-cmd --permanent --zone public --add-service http --add-service https The author has problems with the simplistic nature of firewalld . This rule allows your web services to be open to the world, but is that what you want for a monitoring server? I would say that this is usually not the case. I prefer iptables rules, because it is easy to see at a glance what you are allowing.","title":"firewalld"},{"location":"guides/network/librenms_monitoring_server/#iptables","text":"Create a script to run for adding, changing firewall rules called firewall.conf and put this in /etc vi /etc/firewall.conf Place the following in the file, substituting your network IP addresses as needed. This script allows UDP, SSH, HTTP and HTTPS from the local network in the lab, 192.168.1.0/24. It also allows ICMP type 8 (which stands for \"Echo Request\" or more commonly \"ping\") from our network gateway, 192.168.1.2: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p udp -m udp -s 192.168.1.0/24 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 443 -j ACCEPT iptables -A INPUT -p icmp -m icmp --icmp-type 8 -s 192.168.1.2 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Make the script executable: chmod +x /etc/firewall.conf Run the script: /etc/firewall.conf Assuming no errors, you should be ready to go.","title":"iptables"},{"location":"guides/network/librenms_monitoring_server/#enable-symbolic-link-and-tab-autocomplete-for-lnms-commands","text":"First, we need a symbolic link on our lnms command so that it can be executed from anywhere: ln -s /opt/librenms/lnms /usr/bin/lnms Next, we need to set it up for autocomplete: cp /opt/librenms/misc/lnms-completion.bash /etc/bash_completion.d/","title":"Enable Symbolic Link And Tab-Autocomplete For lnms Commands"},{"location":"guides/network/librenms_monitoring_server/#configure-snmpd","text":"SNMP stands for \"Simple Network Management Protocol\" and is used in many monitoring programs for pulling data. In version 2, which we are using here, it involves a \"community string\" which is specific for your environment. You'll need to assign this \"community string\" to your network devices that you want to monitor so that snmpd (the \"d\" here stands for the daemon) will be able to find it. If your network has been in place for some time, you may already have a \"community string\" that you are using. First, copy the snmp.conf file from LibreNMS: cp /opt/librenms/snmpd.conf.example /etc/snmp/snmpd.conf Next, edit this file and change the community string from \"RANDOMSTRINGGOESHERE\" to whatever your community string is or will be. In our example, we are changing it to \"LABone\": vi /etc/snmp/snmpd.conf and change this line: com2sec readonly default RANDOMSTRINGGOESHERE to com2sec readonly default LABone Now save your changes and exit.","title":"Configure snmpd"},{"location":"guides/network/librenms_monitoring_server/#automating-with-a-cron-job","text":"Do the following: cp /opt/librenms/librenms.nonroot.cron /etc/cron.d/librenms","title":"Automating With A Cron Job"},{"location":"guides/network/librenms_monitoring_server/#log-rotation","text":"LibreNMS will create a large set of logs over time. You'll need to setup log rotation for this so that it doesn't eat up too much disk space. To do this, simply do the following now: cp /opt/librenms/misc/librenms.logrotate /etc/logrotate.d/librenms","title":"Log Rotation"},{"location":"guides/network/librenms_monitoring_server/#web-setup","text":"Now that we have all of the components installed and configured, our next step is to finish the installation via the web. In our lab version, we've got no hostname setup so to finish the setup, we need to go to the web server by IP address. The IP of our lab machine is 192.168.1.140, so we need to do the following in a web browser to finish the install: http://192.168.1.140/librenms Assuming all is working correctly, you should be redirected to the pre-install checks. Assuming that these are all marked as green, then we should be able to continue. There are four buttons beneath the LibreNMS logo. The first button on the left is for the pre-checks. Our next button over is for the database. You'll need the password that you set for the database user \"librenms\" earlier in the process. If you've been following along diligently, then you've got that saved in a safe place. Go ahead and click on the \"Database\" button. The \"User\" and \"Password\" should be all that is necessary to fill in here. Once you do that, click the \"Check Credentials\" button. Once you click that, if it comes back green, then you are ready to click the \"Build Database\" button. Once that is complete, the third button will be active, which is \"Create Admin User\", so go ahead and click this. You will be prompted for an admin user name. In our lab we are simply going to use \"admin\", and a password for that user. Make sure the password is secure and, again, log it somewhere safe, such as a password manager. You'll also need to fill in the email address for the administrative user. Once all of that is completed, simply click the \"Add User\" button. Once you do this, you'll be faced with a screen for \"Finish Install.\" There should only be one item left to finish the install and that is a line that asks you to \"validate your install\". Click the link. Once you've done this and everything is successful, you'll be redirected to the login page. Login with your administrative user and password.","title":"Web Setup"},{"location":"guides/network/librenms_monitoring_server/#adding-devices","text":"Again, one of our assumptions was that you are using SNMP v2. Remember that each device you add must be member of your community string. We are adding two devices as examples here. A Ubuntu workstation and a CentOS server. You will more than likely have managed switches, routers, and other devices to add. The author can tell you from past experience that adding switches and routers tends to be a whole lot easier than adding workstations and servers, which is why we are using those as our examples.","title":"Adding Devices"},{"location":"guides/network/librenms_monitoring_server/#ubuntu-workstation-setup","text":"First, install snmpd on the workstation while also updating packages, just to be safe: sudo update && sudo apt-get upgrade && sudo apt-get install snmpd Next, you need to modify the snmpd.conf file: sudo vi /etc/snmpd/snmpd.conf Go ahead and find the lines that describe your workstation and change them to things that identify the workstation. These lines are shown below: sysLocation Desktop sysContact Username <user@mydomain.com> By default, when you install snmpd on Ubuntu, it only binds to the local address. It does not listen on your machine IP address. This will not allow LibreNMS to connect to it. We need to remark out this line: agentaddress 127.0.0.1,[::1] And add a new line that looks like what follows here: (In this example, the IP address of our workstation is 192.168.1.122 and the UDP port we are setting is \"161\") agentAddress udp:127.0.0.1:161,udp:192.168.1.122:161 Next, we need to specify the read only access community string. Find the below lines and remark them out. (note that we are showing them as remarked out below): #rocommunity public default -V systemonly #rocommunity6 public default -V systemonly Next, add a new line: rocommunity LABone Now save your changes and exit. Enable and start snmpd : sudo systemctl enable snmpd sudo systemctl start snmpd If you are running a firewall on your internal workstations, then you will need to modify the firewall to allow UDP traffic from the monitoring server or from the network. LibreNMS also wants to be able to \"ping\" your device, so make sure that icmp port 8 is allowed from the server.","title":"Ubuntu Workstation Setup"},{"location":"guides/network/librenms_monitoring_server/#centos-or-rocky-linux-server-setup","text":"We are assuming that you are root here or that you can sudo to become so. First, we need to install some packages: dnf install net-snmp net-snmp-utils Next, we want to create a snmpd.conf file. Rather than try to navigate through the file that is included, move this file to rename it, and create a brand new empty file: mv /etc/snmp/snmpd.conf /etc/snmp/snmpd.conf.orig and vi /etc/snmp/snmpd.conf Next copy the below into the new file: # Map 'LABone' community to the 'AllUser' # sec.name source community com2sec AllUser default LABone # Map 'ConfigUser' to 'ConfigGroup' for SNMP Version 2c # Map 'AllUser' to 'AllGroup' for SNMP Version 2c # sec.model sec.name group AllGroup v2c AllUser # Define 'SystemView', which includes everything under .1.3.6.1.2.1.1 (or .1.3.6.1.2.1.25.1) # Define 'AllView', which includes everything under .1 # incl/excl subtree view SystemView included .1.3.6.1.2.1.1 view SystemView included .1.3.6.1.2.1.25.1.1 view AllView included .1 # Give 'ConfigGroup' read access to objects in the view 'SystemView' # Give 'AllGroup' read access to objects in the view 'AllView' # context model level prefix read write notify access AllGroup \"\" any noauth exact AllView none none CentOS and Rocky use a mapping convention to direct things. The above file is commented nicely so that you can learn what is happening, but doesn't include all of the clutter of the original file. Once you've made the changes, save them and exit the file. Now we need to enable and start snmpd : systemctl enable snmpd systemctl start snmpd","title":"CentOS or Rocky Linux Server Setup"},{"location":"guides/network/librenms_monitoring_server/#firewall","text":"If you are running a server, then you are running a firewall, right? We are assuming iptables as noted above, so we need to modify our firewall configuration, (in this case, /etc/firewall.conf) and add access for UDP and ICMP traffic coming from the monitoring server. If you are running firewalld , just substitute in the appropriate rules for firewalld . Here's a rule set for our example server: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p icmp --icmp-type 8 -s 192.168.1.140 -j ACCEPT iptables -A INPUT -p udp -m udp -s 192.168.1.140 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save If you are new to this particular iptables concept, the /etc/firewall.conf is executable, and it's our way of making changes to the saved iptables rules that will be restored on boot. In the above example, we are allowing \"ping\" and UDP traffic from our monitoring server and SSH from our local network. Many other rules may be necessary for your server functions, perhaps http rules or mysql port allow rules, etc. Once you've made the changes to /etc/firewall.conf, execute it with: /etc/firewall.conf","title":"Firewall"},{"location":"guides/network/librenms_monitoring_server/#adding-the-devices-in-librenms","text":"Now that our sample devices are configured to accept snmp traffic from our LibreNMS server, the next step is to add those devices in LibreNMS. We are assuming that you have the web interface for LibreNMS open, and if so, it is going to be showing you that you have no devices added and asking you to add one. So go ahead and do that. Once you click to add a device, you'll be faced with this screen: Put in the information we used for our test devices. In our case, we are using the IP for the Ubuntu workstation to start, in our example that is 192.168.1.122. The only other thing we will need to add here is the community string in the \"Community\" field, so we would type in \"LABone\" here. Now click the \"Add Device\" button. Assuming that you have done everything correctly above when adding the device, your device should be added successfully. If you run into a failure to add, review the SNMP setup for the workstation or the firewall if it exists. Next we repeat the \"Add Device\" process for our CentOS server.","title":"Adding The Devices In Librenms"},{"location":"guides/network/librenms_monitoring_server/#getting-alerts","text":"As we said from the start, this document will only get you started with LibreNMS. There are a large number of additional configuration items, an extensive API (Application Programming Interface), an alerts system that provides a huge number of options for delivery, called \"Transports\", and much more. We are not going to create any alert rules, but instead we will be editing the built-in alert rule \"Device Down! Due to no ICMP response\" that is pre-configured out of the box, and for \"Transports\" we are going to stick with \"Mail\", which is just email. Just know that you are not limited. In order to use email for our transport, however, we need to have mail working on our server. To get this going, we are going to use this Postfix Procedure . Run through that procedure to configure postfix so that it will properly identify where the messages are coming from, but you can stop after the configuration process and come back here.","title":"Getting Alerts"},{"location":"guides/network/librenms_monitoring_server/#transports","text":"We need a way to send out our alerts. As noted earlier, LibreNMS supports a huge number of transports. We are going to do our alert by email, which is defined as the \"Mail\" transport. To set up the transport: Go to the dashboard Let your mouse hover over \"Alerts\" Go down to \"Alert Transports\" and click on it Click on on the \"Create alert transport\" button (Note the \"Create transport group\" button. You can use this to have alerts go to several individuals) In the \"Transport name:\" field, type in \"Alert By Email\" In the \"Transport type: field, use the drop down to select \"Mail\" Make sure the \"Default alert:\" field is set to \"On\" In the \"Email:\" field, type the email address of the administrator","title":"Transports"},{"location":"guides/network/librenms_monitoring_server/#organizing-devices-into-groups","text":"The best way to set up alerts is to first organize your devices into some logical order. Currently, we have a workstation and a server in devices. While we may not normally wish to organize the two together, we will for this example. Keep in mind that our example is also redundant, as there is an \"All Devices\" group that would work for this as well. To set up a device group: Go to the dashboard Let your mouse hover over \"Devices\" Go down to \"Manage Groups\" and click on it Click on the \"+ New Device Group\" button In the \"Name\" field, type \"ICMP Group\" In the description field type what ever you think will help describe the group Change the \"Type\" field from \"Dynamic\" to \"Static\" Add both devices to the \"Select Devices\" field and then just save your changes","title":"Organizing Devices Into Groups"},{"location":"guides/network/librenms_monitoring_server/#setting-up-the-alert-rules","text":"Now that we have the transport and the device group set up, let's configure the alert rule. By default, LibreNMS has several alert rules already created for you: Go to the dashboard Let your mouse hover over \"Alerts\" Go down to \"Alert Rules\" and click on it The top active rule in the display will be \"Device Down! Due to no ICMP response.\" Go over to the \"Action\" (far right column) and click on the pencil icon to edit the rule. Leave all the fields at the top as is and go down to the \"Match devices, groups and locations list:\" field and click inside the field Select \"ICMP Group\" from the list Make sure the \"All devices except in list:\" field is \"Off\" Click inside the \"Transports:\" field and select \"Mail: Alert By Email\" and save your rule. Before saving, your rule should look something like this: These two devices should now alert you by email if they are down and when they recover.","title":"Setting Up The Alert Rules"},{"location":"guides/network/librenms_monitoring_server/#conclusions","text":"LibreNMS is a powerful monitoring tool with a full set of features in one application. We have only just scratched the surface on the capabilities. We haven't shown you some of the obvious screens. For instance, as soon as you add devices, assuming that all of the SNMP properties are set correctly, you'll start to receive bandwidth, memory utilization, and CPU utilization graphs on each device. We haven't shown you the wealth of transports available besides \"Mail\". All of that said, we have shown you enough in this document to get a good start monitoring your environment. LibreNMS takes some time to master all of the elements. You should visit the project's excellent documentation for additional information.","title":"Conclusions"},{"location":"guides/package_management/","text":"Introduction This section of the documentation is dedicated to package builds. !!! caution Documents in this section are older and are probably in need of a re-write. If you use these instructions and have problems, please report the issues so that these documents can be properly modified. You can report any issues [here](https://chat.rockylinux.org/rocky-linux/channels/documentation).","title":"Introduction"},{"location":"guides/package_management/#introduction","text":"This section of the documentation is dedicated to package builds. !!! caution Documents in this section are older and are probably in need of a re-write. If you use these instructions and have problems, please report the issues so that these documents can be properly modified. You can report any issues [here](https://chat.rockylinux.org/rocky-linux/channels/documentation).","title":"Introduction"},{"location":"guides/package_management/developer_start2/","text":"Development Tutorial Download Rocky Devtools Install Rocky Devtools Download Source RPMs (rockyget) Building packages (rockybuild) Trobleshooting package builds Work in progress Rocky Devtools refers to a set of home grown scripts and utlities created by members of the Rocky Linux community to help with sourcing, creating, branding, patching and building software packages distributed with the Rocky Linux Operating system. Rocky devtools consists of rockyget , rockybuild , rockypatch , and rockyprep . At a low level Rocky Devtools is a wrapper for running some custom and tradtional programs that are used for various package management tasks. Rocky Devtools relies heavily on srpmproc , go , git , and rpmbuild . You'll need an existing modern RPM based Linux system to install and use Rocky devtools. Let's walk through a typical installation and usage scenario of the devtools. 1. Download Rocky Devtools Download the devtools zipped source from the following URL: https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip Here we use the curl command: curl -OJL https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip You should now have a zipped archive named devtools-main.zip 2. Install Rocky Devtools Locate and uncompress the devtools archive that you just downloaded. Here we'll use the unzip command line utility: unzip devtools-main.zip Change your working directory to the new devtool source directory that was just created: cd devtools-main Run make to configure and compile devtools: make Install devtools: sudo make install 3. Use Rocky Devtools (rockyget) to search for and download Source RPMs (SRPMs) Once installed, the main utility for finding and downloading SRPMs is the rockyget utility. Let's use rockyget to download the SRPM for the popular sed package: rockyget sed The first time rockyget is run, it will automatically create a directory structure that roughly mimics the repository structure of Rocky's build servers. For example the ~/rocky/rpms folder will be automaically created. For our current sed example, its sources will be stored under the following sample folder hierchy: ~rocky/rpms/sed/ \u2514\u2500\u2500 r8 \u251c\u2500\u2500 SOURCES \u2502 \u251c\u2500\u2500 sed-4.2.2-binary_copy_args.patch \u2502 \u251c\u2500\u2500 sed-4.5.tar.xz \u2502 \u251c\u2500\u2500 sedfaq.txt \u2502 \u251c\u2500\u2500 sed-fuse.patch \u2502 \u2514\u2500\u2500 sed-selinux.patch \u2514\u2500\u2500 SPECS \u2514\u2500\u2500 sed.spec TIP : Once you have the original sources, this might be a good time to look through the SPECs file ( ~rocky/rpms/sed/SPECS/specs.spec ) to look for potential debranding opportinites in the given package. Debranding might include replacing upstream artwork/logos and so on. TIP If you are looking for other Rocky packages to build and experiment with, you can browse the list of packages that are currently failing in the Rocky automated build environment here - https://kojidev.rockylinux.org/koji/builds?state=3&order=-build_id 4. Use Rocky Devtools (rockybuild) to build a new package for the Rocky OS Under the hood, rockybuild calls rpmbuild and mock utilities to build the source package in a chroot environment for the application specified on the command-line. It relies on the application sources and RPM SPEC file that was automatically downloaded via the rockyget command. Use rockybuild to build the sed utility: rockybuild sed The time needed to complete the build process/step depends on the size and complexity of the application you are trying to build. At the end of the rockybuild run, an output similar to the one here indicates that the build completed successfully. .......... + exit 0 Finish: rpmbuild sed-4.5-2.el8.src.rpm Finish: build phase for sed-4.5-2.el8.src.rpm INFO: Done(~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm) Config(baseos) 4 minutes 34 seconds INFO: Results and/or logs in: /home/centos/rocky/builds/sed/r8 ........ If all goes well you should end up with a Rocky ready SRPM file under the ~/rocky/builds/sed/r8 directory. ~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm 5. Debugging a failed package build The previous rockybuild process will generate some log files that can be used in debugging failed application builds. The results and/or logs of the build process are stored under the ~/rocky/builds/<PACKAGE NAME>/r8 . For example ~/rocky/builds/sed/r8 ~/rocky/builds/sed/r8 \u251c\u2500\u2500 build.log \u251c\u2500\u2500 hw_info.log \u251c\u2500\u2500 installed_pkgs.log \u251c\u2500\u2500 root.log \u251c\u2500\u2500 sed-4.5-2.el8_3.src.rpm \u251c\u2500\u2500 sed-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debuginfo-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debugsource-4.5-2.el8_3.x86_64.rpm \u2514\u2500\u2500 state.log The main files to search for clues for the causes any error(s) are the build.log and root.log. The build.log file should detail all build errors and the root.log file will contain information about the chroot environment setup and tear down processes. With everything else being equal, most of the build debugging/troubleshooting process can be performed with the contents of the build.log file.","title":"Development Tutorial"},{"location":"guides/package_management/developer_start2/#development-tutorial","text":"Download Rocky Devtools Install Rocky Devtools Download Source RPMs (rockyget) Building packages (rockybuild) Trobleshooting package builds Work in progress Rocky Devtools refers to a set of home grown scripts and utlities created by members of the Rocky Linux community to help with sourcing, creating, branding, patching and building software packages distributed with the Rocky Linux Operating system. Rocky devtools consists of rockyget , rockybuild , rockypatch , and rockyprep . At a low level Rocky Devtools is a wrapper for running some custom and tradtional programs that are used for various package management tasks. Rocky Devtools relies heavily on srpmproc , go , git , and rpmbuild . You'll need an existing modern RPM based Linux system to install and use Rocky devtools. Let's walk through a typical installation and usage scenario of the devtools.","title":"Development Tutorial"},{"location":"guides/package_management/developer_start2/#1-download-rocky-devtools","text":"Download the devtools zipped source from the following URL: https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip Here we use the curl command: curl -OJL https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip You should now have a zipped archive named devtools-main.zip","title":"1. Download Rocky Devtools"},{"location":"guides/package_management/developer_start2/#2-install-rocky-devtools","text":"Locate and uncompress the devtools archive that you just downloaded. Here we'll use the unzip command line utility: unzip devtools-main.zip Change your working directory to the new devtool source directory that was just created: cd devtools-main Run make to configure and compile devtools: make Install devtools: sudo make install","title":"2. Install Rocky Devtools"},{"location":"guides/package_management/developer_start2/#3-use-rocky-devtools-rockyget-to-search-for-and-download-source-rpms-srpms","text":"Once installed, the main utility for finding and downloading SRPMs is the rockyget utility. Let's use rockyget to download the SRPM for the popular sed package: rockyget sed The first time rockyget is run, it will automatically create a directory structure that roughly mimics the repository structure of Rocky's build servers. For example the ~/rocky/rpms folder will be automaically created. For our current sed example, its sources will be stored under the following sample folder hierchy: ~rocky/rpms/sed/ \u2514\u2500\u2500 r8 \u251c\u2500\u2500 SOURCES \u2502 \u251c\u2500\u2500 sed-4.2.2-binary_copy_args.patch \u2502 \u251c\u2500\u2500 sed-4.5.tar.xz \u2502 \u251c\u2500\u2500 sedfaq.txt \u2502 \u251c\u2500\u2500 sed-fuse.patch \u2502 \u2514\u2500\u2500 sed-selinux.patch \u2514\u2500\u2500 SPECS \u2514\u2500\u2500 sed.spec","title":"3. Use Rocky Devtools (rockyget) to search for and download Source RPMs (SRPMs)"},{"location":"guides/package_management/developer_start2/#tip","text":"Once you have the original sources, this might be a good time to look through the SPECs file ( ~rocky/rpms/sed/SPECS/specs.spec ) to look for potential debranding opportinites in the given package. Debranding might include replacing upstream artwork/logos and so on.","title":"TIP :"},{"location":"guides/package_management/developer_start2/#tip_1","text":"If you are looking for other Rocky packages to build and experiment with, you can browse the list of packages that are currently failing in the Rocky automated build environment here - https://kojidev.rockylinux.org/koji/builds?state=3&order=-build_id","title":"TIP"},{"location":"guides/package_management/developer_start2/#4-use-rocky-devtools-rockybuild-to-build-a-new-package-for-the-rocky-os","text":"Under the hood, rockybuild calls rpmbuild and mock utilities to build the source package in a chroot environment for the application specified on the command-line. It relies on the application sources and RPM SPEC file that was automatically downloaded via the rockyget command. Use rockybuild to build the sed utility: rockybuild sed The time needed to complete the build process/step depends on the size and complexity of the application you are trying to build. At the end of the rockybuild run, an output similar to the one here indicates that the build completed successfully. .......... + exit 0 Finish: rpmbuild sed-4.5-2.el8.src.rpm Finish: build phase for sed-4.5-2.el8.src.rpm INFO: Done(~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm) Config(baseos) 4 minutes 34 seconds INFO: Results and/or logs in: /home/centos/rocky/builds/sed/r8 ........ If all goes well you should end up with a Rocky ready SRPM file under the ~/rocky/builds/sed/r8 directory. ~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm","title":"4. Use Rocky Devtools (rockybuild) to build a new package for the Rocky OS"},{"location":"guides/package_management/developer_start2/#5-debugging-a-failed-package-build","text":"The previous rockybuild process will generate some log files that can be used in debugging failed application builds. The results and/or logs of the build process are stored under the ~/rocky/builds/<PACKAGE NAME>/r8 . For example ~/rocky/builds/sed/r8 ~/rocky/builds/sed/r8 \u251c\u2500\u2500 build.log \u251c\u2500\u2500 hw_info.log \u251c\u2500\u2500 installed_pkgs.log \u251c\u2500\u2500 root.log \u251c\u2500\u2500 sed-4.5-2.el8_3.src.rpm \u251c\u2500\u2500 sed-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debuginfo-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debugsource-4.5-2.el8_3.x86_64.rpm \u2514\u2500\u2500 state.log The main files to search for clues for the causes any error(s) are the build.log and root.log. The build.log file should detail all build errors and the root.log file will contain information about the chroot environment setup and tear down processes. With everything else being equal, most of the build debugging/troubleshooting process can be performed with the contents of the build.log file.","title":"5. Debugging a failed package build"},{"location":"guides/package_management/package_build_troubleshooting/","text":"First get Familiar with the Mock build tool: Once you get through that, the biggest and most relevant technical/intro page for our package debugging effort is this: https://wiki.rockylinux.org/en/team/development/Mock_Build_Howto We are using the \u201cmock\u201d program to perform our builds, just like the real Rocky infrastructure will. You should install it and get very used to it. Please use this guide to get started, and explain a bit about what we hope to achieve and why we have to build all these packages in a specific order. Please read those carefully, and maybe dip your toe in the water by feeding your mock an SRPM or 2 and compiling some things. Mock is really great, as it\u2019s an easy-to-call program that constructs an entire system inside a chroot to perform the build, then cleans it up afterwards. If you\u2019d like a reference for Mock config files to look at or play with, there are some published here (that correspond with the \u201cBuild Passes\u201d being done to test package builds): https://rocky.lowend.ninja/RockyDevel/mock_configs/ Once you\u2019re familiar with Mock (and especially digging through its output logs), we have a list of failing packages that we need to investigate and come up with explanations and/or fixes for. Intro - What needs to be done The area we need help the most right now, and the easiest way to contribute, is to help troubleshoot failing package builds. We\u2019re rebuilding CentOS 8.3 as \u201cpractice\u201d, so we can figure out any issues that crop up with our official Rocky build ahead of time. We are documenting any errors we find in the packages and how to fix them (to make it build). This documentation will help our release engineering team when it comes time to do official builds. Helping with the debug effort: Once you are familiar with Mock, and especially with debugging its output, you can begin looking at failing packages. Some of this information is also on the Mock HowTo page linked above. Find a failing package on the newest build pass failures page (currently Build Pass 10: https://wiki.rockylinux.org/en/team/development/Build_Order/Build_Pass_10_Failure) Make sure the package hasn\u2019t already been looked at and/or fixed: https://wiki.rockylinux.org/en/team/development/Package_Error_Tracking Let other debuggers know what you\u2019re working on! We don\u2019t want to duplicate effort. Hop on chat.rockylinux.org (#dev/packaging channel) and let us know! Set your mock program up with the most recent configs that we are using (linked above). You can use it to attempt the build in the same way as we do (with external dependencies, extra repos, etc.) Investigate the error(s): You can use your own mock, as well as the log files from when the build failed, located here: https://rocky.lowend.ninja/RockyDevel/MOCK_RAW/ Figure out what\u2019s going on, and how to fix it. It may take the form of special mock settings, or a patch added to the program + specfile. Report your findings to the #Dev/Packaging channel, and someone will record them on the Wiki Package_Error_Tracking page linked above. The idea is to shrink the Build Failures, and grow the Package_Error_Tracking page. If necessary, we will commit build fixes to our patch repo for the different packages located here: https://git.rockylinux.org/staging/patch.","title":"Package Build & Troubleshooting"},{"location":"guides/package_management/package_build_troubleshooting/#first-get-familiar-with-the-mock-build-tool","text":"Once you get through that, the biggest and most relevant technical/intro page for our package debugging effort is this: https://wiki.rockylinux.org/en/team/development/Mock_Build_Howto We are using the \u201cmock\u201d program to perform our builds, just like the real Rocky infrastructure will. You should install it and get very used to it. Please use this guide to get started, and explain a bit about what we hope to achieve and why we have to build all these packages in a specific order. Please read those carefully, and maybe dip your toe in the water by feeding your mock an SRPM or 2 and compiling some things. Mock is really great, as it\u2019s an easy-to-call program that constructs an entire system inside a chroot to perform the build, then cleans it up afterwards. If you\u2019d like a reference for Mock config files to look at or play with, there are some published here (that correspond with the \u201cBuild Passes\u201d being done to test package builds): https://rocky.lowend.ninja/RockyDevel/mock_configs/ Once you\u2019re familiar with Mock (and especially digging through its output logs), we have a list of failing packages that we need to investigate and come up with explanations and/or fixes for.","title":"First get Familiar with the Mock build tool:"},{"location":"guides/package_management/package_build_troubleshooting/#intro-what-needs-to-be-done","text":"The area we need help the most right now, and the easiest way to contribute, is to help troubleshoot failing package builds. We\u2019re rebuilding CentOS 8.3 as \u201cpractice\u201d, so we can figure out any issues that crop up with our official Rocky build ahead of time. We are documenting any errors we find in the packages and how to fix them (to make it build). This documentation will help our release engineering team when it comes time to do official builds.","title":"Intro - What needs to be done"},{"location":"guides/package_management/package_build_troubleshooting/#helping-with-the-debug-effort","text":"Once you are familiar with Mock, and especially with debugging its output, you can begin looking at failing packages. Some of this information is also on the Mock HowTo page linked above. Find a failing package on the newest build pass failures page (currently Build Pass 10: https://wiki.rockylinux.org/en/team/development/Build_Order/Build_Pass_10_Failure) Make sure the package hasn\u2019t already been looked at and/or fixed: https://wiki.rockylinux.org/en/team/development/Package_Error_Tracking Let other debuggers know what you\u2019re working on! We don\u2019t want to duplicate effort. Hop on chat.rockylinux.org (#dev/packaging channel) and let us know! Set your mock program up with the most recent configs that we are using (linked above). You can use it to attempt the build in the same way as we do (with external dependencies, extra repos, etc.) Investigate the error(s): You can use your own mock, as well as the log files from when the build failed, located here: https://rocky.lowend.ninja/RockyDevel/MOCK_RAW/ Figure out what\u2019s going on, and how to fix it. It may take the form of special mock settings, or a patch added to the program + specfile. Report your findings to the #Dev/Packaging channel, and someone will record them on the Wiki Package_Error_Tracking page linked above. The idea is to shrink the Build Failures, and grow the Package_Error_Tracking page. If necessary, we will commit build fixes to our patch repo for the different packages located here: https://git.rockylinux.org/staging/patch.","title":"Helping with the debug effort:"},{"location":"guides/package_management/package_debranding/","text":"Rocky package debranding How-To This explains how to debrand a package for the Rocky Linux distribution. General Instructions First, identify the files in the package that need to be changed. They could be text files, image files, or others. You can identify the file(s) by digging into git.centos.org/rpms/PACKAGE/ Develop replacements for these files, but with Rocky branding placed instead. Diff/patch files may be needed as well for certain types of text, depends on the content being replaced. Replacement files go under https://git.rockylinux.org/patch/PACKAGE/ROCKY/_supporting/ Config file (specifying how to apply the patches) goes in https://git.rockylinux.org/patch/PACKAGE/ROCKY/CFG/*.cfg Note: Use spaces, not tabs. When srpmproc goes to import the package to Rocky, it will see the work done in https://git.rockylinux.org/patch/PACKAGE , and apply the stored debranding patches by reading the config file(s) under ROCKY/CFG/*.cfg from https://wiki.rockylinux.org/en/team/development/debranding/how-to","title":"Package Debranding"},{"location":"guides/package_management/package_debranding/#rocky-package-debranding-how-to","text":"This explains how to debrand a package for the Rocky Linux distribution. General Instructions First, identify the files in the package that need to be changed. They could be text files, image files, or others. You can identify the file(s) by digging into git.centos.org/rpms/PACKAGE/ Develop replacements for these files, but with Rocky branding placed instead. Diff/patch files may be needed as well for certain types of text, depends on the content being replaced. Replacement files go under https://git.rockylinux.org/patch/PACKAGE/ROCKY/_supporting/ Config file (specifying how to apply the patches) goes in https://git.rockylinux.org/patch/PACKAGE/ROCKY/CFG/*.cfg Note: Use spaces, not tabs. When srpmproc goes to import the package to Rocky, it will see the work done in https://git.rockylinux.org/patch/PACKAGE , and apply the stored debranding patches by reading the config file(s) under ROCKY/CFG/*.cfg from https://wiki.rockylinux.org/en/team/development/debranding/how-to","title":"Rocky package debranding How-To"},{"location":"guides/package_management/package_debranding.sv/","text":"Detta f\u00f6rklarar hur du \u00e4ndrar varum\u00e4rke p\u00e5 ett paket f\u00f6r Rocky Linux-distributionen. Generella instruktioner F\u00f6rst, identifiera filerna i paketet som beh\u00f6ver \u00e4ndras. Dessa kan vara textfiler, bildfiler, eller annat. Du kan identifiera dessa filer/filer genom att kolla i git.centos.org/rpms/PACKAGE/ Utveckla ers\u00e4ttningar f\u00f6r dessa filer, men med Rocky varum\u00e4rken p\u00e5 plats ist\u00e4llet. Diff/patch filer kan ocks\u00e5 beh\u00f6vas f\u00f6r vissa typer av text, beroende p\u00e5 inneh\u00e5llet som ers\u00e4tts. Ers\u00e4ttningsfiler ska places p\u00e5 https://git.rockylinux.org/patch/PACKAGE/ROCKY/_supporting/ Konfigurationsfiler (som speciferar hur du applicerar patches) ska placeras p\u00e5 https://git.rockylinux.org/patch/PACKAGE/ROCKY/CFG/*.cfg Notera: Anv\u00e4nd mellanslag, inte tabbar. N\u00e4r srpmproc b\u00f6rja importera paketet till Rocky, s\u00e5 kommer det att se arbetet gjort i https://git.rockylinux.org/patch/PACKAGE , och applicera dom lagrade patcharna f\u00f6r att ta bort varum\u00e4rken genom att l\u00e4sa konfigurationsfiler under ROCKY/CFG/*.cfg fr\u00e5n https://wiki.rockylinux.org/en/team/development/debranding/how-to","title":"Rocky paket Hur man tar bort varum\u00e4rke"},{"location":"guides/package_management/package_dev_start/","text":"Packaging and developer starter guide Rocky Devtools refers to a set of home grown scripts and utlities created by members of the Rocky Linux community to help with sourcing, creating, branding, patching and building software packages distributed with the Rocky Linux Operating system. Rocky devtools consists of rockyget , rockybuild , rockypatch , and rockyprep . At a low level Rocky Devtools is a wrapper for running some custom and tradtional programs that are used for various package management tasks. Rocky Devtools relies heavily on srpmproc , go , git , and rpmbuild . You'll need an existing modern RPM based Linux system to install and use Rocky devtools. Let's walk through a typical installation and usage scenario of the devtools. Dependencies Several packages are required on the system before you can begin to use the devtools. These commands have been tested on Rocky Linux but should work on CentOS 8 / RHEL 8 too dnf install git make golang 1. Download Rocky Devtools Download the devtools zipped source from the following URL: https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip Here we use the curl command: curl -OJL https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip You should now have a zipped archive named devtools-main.zip 2. Install Rocky Devtools Locate and uncompress the devtools archive that you just downloaded. Here we'll use the unzip command line utility: unzip devtools-main.zip Change your working directory to the new devtool source directory that was just created: cd devtools-main Run make to configure and compile devtools: make Install devtools: sudo make install 3. Use Rocky Devtools (rockyget) to search for and download Source RPMs (SRPMs) Once installed, the main utility for finding and downloading SRPMs is the rockyget utility. Let's use rockyget to download the SRPM for the popular sed package: rockyget sed The first time rockyget is run, it will automatically create a directory structure that roughly mimics the repository structure of Rocky's build servers. For example the ~/rocky/rpms folder will be automaically created. For our current sed example, its sources will be stored under the following sample folder hierchy: ~rocky/rpms/sed/ \u2514\u2500\u2500 r8 \u251c\u2500\u2500 SOURCES \u2502 \u251c\u2500\u2500 sed-4.2.2-binary_copy_args.patch \u2502 \u251c\u2500\u2500 sed-4.5.tar.xz \u2502 \u251c\u2500\u2500 sedfaq.txt \u2502 \u251c\u2500\u2500 sed-fuse.patch \u2502 \u2514\u2500\u2500 sed-selinux.patch \u2514\u2500\u2500 SPECS \u2514\u2500\u2500 sed.spec TIP : Once you have the original sources, this might be a good time to look through the SPECs file ( ~rocky/rpms/sed/SPECS/specs.spec ) to look for potential debranding opportinites in the given package. Debranding might include replacing upstream artwork/logos and so on. TIP If you are looking for other Rocky packages to build and experiment with, you can browse the list of packages that are currently failing in the Rocky automated build environment here - https://kojidev.rockylinux.org/koji/builds?state=3&order=-build_id 4. Use Rocky Devtools (rockybuild) to build a new package for the Rocky OS Under the hood, rockybuild calls rpmbuild and mock utilities to build the source package in a chroot environment for the application specified on the command-line. It relies on the application sources and RPM SPEC file that was automatically downloaded via the rockyget command. Use rockybuild to build the sed utility: rockybuild sed The time needed to complete the build process/step depends on the size and complexity of the application you are trying to build. At the end of the rockybuild run, an output similar to the one here indicates that the build completed successfully. .......... + exit 0 Finish: rpmbuild sed-4.5-2.el8.src.rpm Finish: build phase for sed-4.5-2.el8.src.rpm INFO: Done(~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm) Config(baseos) 4 minutes 34 seconds INFO: Results and/or logs in: /home/centos/rocky/builds/sed/r8 ........ If all goes well you should end up with a Rocky ready SRPM file under the ~/rocky/builds/sed/r8 directory. ~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm 5. Debugging a failed package build The previous rockybuild process will generate some log files that can be used in debugging failed application builds. The results and/or logs of the build process are stored under the ~/rocky/builds/<PACKAGE NAME>/r8 . For example ~/rocky/builds/sed/r8 ~/rocky/builds/sed/r8 \u251c\u2500\u2500 build.log \u251c\u2500\u2500 hw_info.log \u251c\u2500\u2500 installed_pkgs.log \u251c\u2500\u2500 root.log \u251c\u2500\u2500 sed-4.5-2.el8_3.src.rpm \u251c\u2500\u2500 sed-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debuginfo-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debugsource-4.5-2.el8_3.x86_64.rpm \u2514\u2500\u2500 state.log The main files to search for clues for the causes any error(s) are the build.log and root.log. The build.log file should detail all build errors and the root.log file will contain information about the chroot environment setup and tear down processes. With everything else being equal, most of the build debugging/troubleshooting process can be performed with the contents of the build.log file.","title":"Packaging And Developer Guide"},{"location":"guides/package_management/package_dev_start/#packaging-and-developer-starter-guide","text":"Rocky Devtools refers to a set of home grown scripts and utlities created by members of the Rocky Linux community to help with sourcing, creating, branding, patching and building software packages distributed with the Rocky Linux Operating system. Rocky devtools consists of rockyget , rockybuild , rockypatch , and rockyprep . At a low level Rocky Devtools is a wrapper for running some custom and tradtional programs that are used for various package management tasks. Rocky Devtools relies heavily on srpmproc , go , git , and rpmbuild . You'll need an existing modern RPM based Linux system to install and use Rocky devtools. Let's walk through a typical installation and usage scenario of the devtools.","title":"Packaging and developer starter guide"},{"location":"guides/package_management/package_dev_start/#dependencies","text":"Several packages are required on the system before you can begin to use the devtools. These commands have been tested on Rocky Linux but should work on CentOS 8 / RHEL 8 too dnf install git make golang","title":"Dependencies"},{"location":"guides/package_management/package_dev_start/#1-download-rocky-devtools","text":"Download the devtools zipped source from the following URL: https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip Here we use the curl command: curl -OJL https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip You should now have a zipped archive named devtools-main.zip","title":"1. Download Rocky Devtools"},{"location":"guides/package_management/package_dev_start/#2-install-rocky-devtools","text":"Locate and uncompress the devtools archive that you just downloaded. Here we'll use the unzip command line utility: unzip devtools-main.zip Change your working directory to the new devtool source directory that was just created: cd devtools-main Run make to configure and compile devtools: make Install devtools: sudo make install","title":"2. Install Rocky Devtools"},{"location":"guides/package_management/package_dev_start/#3-use-rocky-devtools-rockyget-to-search-for-and-download-source-rpms-srpms","text":"Once installed, the main utility for finding and downloading SRPMs is the rockyget utility. Let's use rockyget to download the SRPM for the popular sed package: rockyget sed The first time rockyget is run, it will automatically create a directory structure that roughly mimics the repository structure of Rocky's build servers. For example the ~/rocky/rpms folder will be automaically created. For our current sed example, its sources will be stored under the following sample folder hierchy: ~rocky/rpms/sed/ \u2514\u2500\u2500 r8 \u251c\u2500\u2500 SOURCES \u2502 \u251c\u2500\u2500 sed-4.2.2-binary_copy_args.patch \u2502 \u251c\u2500\u2500 sed-4.5.tar.xz \u2502 \u251c\u2500\u2500 sedfaq.txt \u2502 \u251c\u2500\u2500 sed-fuse.patch \u2502 \u2514\u2500\u2500 sed-selinux.patch \u2514\u2500\u2500 SPECS \u2514\u2500\u2500 sed.spec","title":"3. Use Rocky Devtools (rockyget) to search for and download Source RPMs (SRPMs)"},{"location":"guides/package_management/package_dev_start/#tip","text":"Once you have the original sources, this might be a good time to look through the SPECs file ( ~rocky/rpms/sed/SPECS/specs.spec ) to look for potential debranding opportinites in the given package. Debranding might include replacing upstream artwork/logos and so on.","title":"TIP :"},{"location":"guides/package_management/package_dev_start/#tip_1","text":"If you are looking for other Rocky packages to build and experiment with, you can browse the list of packages that are currently failing in the Rocky automated build environment here - https://kojidev.rockylinux.org/koji/builds?state=3&order=-build_id","title":"TIP"},{"location":"guides/package_management/package_dev_start/#4-use-rocky-devtools-rockybuild-to-build-a-new-package-for-the-rocky-os","text":"Under the hood, rockybuild calls rpmbuild and mock utilities to build the source package in a chroot environment for the application specified on the command-line. It relies on the application sources and RPM SPEC file that was automatically downloaded via the rockyget command. Use rockybuild to build the sed utility: rockybuild sed The time needed to complete the build process/step depends on the size and complexity of the application you are trying to build. At the end of the rockybuild run, an output similar to the one here indicates that the build completed successfully. .......... + exit 0 Finish: rpmbuild sed-4.5-2.el8.src.rpm Finish: build phase for sed-4.5-2.el8.src.rpm INFO: Done(~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm) Config(baseos) 4 minutes 34 seconds INFO: Results and/or logs in: /home/centos/rocky/builds/sed/r8 ........ If all goes well you should end up with a Rocky ready SRPM file under the ~/rocky/builds/sed/r8 directory. ~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm","title":"4. Use Rocky Devtools (rockybuild) to build a new package for the Rocky OS"},{"location":"guides/package_management/package_dev_start/#5-debugging-a-failed-package-build","text":"The previous rockybuild process will generate some log files that can be used in debugging failed application builds. The results and/or logs of the build process are stored under the ~/rocky/builds/<PACKAGE NAME>/r8 . For example ~/rocky/builds/sed/r8 ~/rocky/builds/sed/r8 \u251c\u2500\u2500 build.log \u251c\u2500\u2500 hw_info.log \u251c\u2500\u2500 installed_pkgs.log \u251c\u2500\u2500 root.log \u251c\u2500\u2500 sed-4.5-2.el8_3.src.rpm \u251c\u2500\u2500 sed-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debuginfo-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debugsource-4.5-2.el8_3.x86_64.rpm \u2514\u2500\u2500 state.log The main files to search for clues for the causes any error(s) are the build.log and root.log. The build.log file should detail all build errors and the root.log file will contain information about the chroot environment setup and tear down processes. With everything else being equal, most of the build debugging/troubleshooting process can be performed with the contents of the build.log file.","title":"5. Debugging a failed package build"},{"location":"guides/package_management/package_signing/","text":"Package signing and testing' RPMs produced by us should be cryptographically signed with a Rocky Linux key, which guarantees to users that the package was indeed built by the Rocky Linux project. The package will also need to be put through some testing - preferably automated. The nature of the testing is yet to be determined, but we\u2019ll want to do some sanity checks at the bare minimum before unleashing it on the world. (Is this package installable? Did we accidentally miss any files? Does it cause dnf/yum dependency conflicts? etc.)","title":"Package Signing & Testing"},{"location":"guides/package_management/package_signing/#package-signing-and-testing","text":"RPMs produced by us should be cryptographically signed with a Rocky Linux key, which guarantees to users that the package was indeed built by the Rocky Linux project. The package will also need to be put through some testing - preferably automated. The nature of the testing is yet to be determined, but we\u2019ll want to do some sanity checks at the bare minimum before unleashing it on the world. (Is this package installable? Did we accidentally miss any files? Does it cause dnf/yum dependency conflicts? etc.)","title":"Package signing and testing'"},{"location":"guides/package_management/package_signing.sv/","text":"RPMs som produceras av oss ska vara kryptografiskt signerade med en Rocky Linux nyckel, vilket garanterar f\u00f6r anv\u00e4ndarna att paketet verkligen \u00e4r byggt av Rocky Linux-projektet. Paketet m\u00e5ste ocks\u00e5 g\u00e5 igenom n\u00e5gon sorts testning - helst automatiserad. Testningens karakt\u00e4r \u00e4r \u00e4nnu inte fastst\u00e4lld, men vi vill g\u00f6ra n\u00e5gra minst n\u00e5gra snabba h\u00e4lsokontroller innan vi sl\u00e4pper paket ut till v\u00e4rlden. (\u00c4r detta pake installerbart? Missade vi n\u00e5gra filer av misstag? Orsakar det konflikter mellan dnf/yum-beroende? t.ex.)","title":"Paketsignering och testning"},{"location":"guides/proxies/haproxy_apache_lxd/","text":"HAProxy Load Balancing Apache using LXD Containers Introduction HAProxy stands for \"High Availability Proxy.\" This proxy can sit in front of any TCP application (such as web servers), but it is often used to act as a load-balancer between multiple instances of a website. There might be a number of reasons for doing this. If you have a website that is being hit hard \u2014 adding another instance of that same website and placing HAProxy in front of both \u2014 allows you to distribute traffic between instances. Another reason might be to be able to update content on a website without any down time. HAProxy can also help mitigate DOS and DDOS attacks. This guide is going to explore using HAProxy using two website instances, and load-balancing with round robin rotation, on the same LXD host. This might be a perfectly fine solution for ensuring that updates can be performed without downtime. If your problem is website performance, however, you may need to distribute your multiple sites across actual bare metal or between multiple LXD hosts. It is certainly possible to do all of this on bare metal without using LXD at all, however LXD offers great flexibility and performance, plus it is great to use for lab testing. Prerequisites and Assumptions Complete comfort at the command line on a Linux machine Experience with a command line editor (we are using vim here) Experience with crontab Knowledge of LXD. For more information, you may want to consult the LXD Server document. It is perfectly fine to install LXD on a laptop or workstation as well without doing the full-blown server install. This document is being written with a lab machine that is running LXD, but is not set up as a full server as the document linked above uses. Some knowledge on installing, configuring, and using web servers. We will assume that LXD is already installed and ready to create containers. Installing Containers On your LXD host for this guide, we will need three containers. Obviously, there could be more web server containers if you wish. We will use web1 and web2 for our website containers and proxyha for our HAProxy container. To install these on your LXD host do: lxc launch images:rockylinux/8 web1 lxc launch images:rockylinux/8 web2 lxc launch images:rockylinux/8 proxyha Running an lxc list should return something like this: +---------+---------+----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +---------+---------+----------------------+------+-----------+-----------+ | proxyha | RUNNING | 10.181.87.137 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ | web1 | RUNNING | 10.181.87.207 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ | web2 | RUNNING | 10.181.87.34 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ Creating and Using the macvlan Profile The containers are currently running on the default bridge interface with bridge assigned DHCP addresses. We are going to want to use DHCP addresses from our local LAN, so the first thing we need to do is to create and assign the macvlan profile. Start by creating the profile: lxc profile create macvlan Make sure that your editor is set to your preferred editor, in this case vim : export EDITOR=/usr/bin/vim Next we need to modify the macvlan profile. But before we do, we need to know what interface the host is using for our LAN so run ip addr and look for the interface with the LAN IP assignment: 2: eno1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether a8:5e:45:52:f8:b6 brd ff:ff:ff:ff:ff:ff inet 192.168.1.141/24 brd 192.168.1.255 scope global dynamic noprefixroute eno1 !!! Note In this case, the interface we are looking for is \"eno1\" but this could be completely different on your system. Use **your** interface information! Now that we know the LAN interface, we can modify our macvlan profile. To do this, at the command line type: lxc profile edit macvlan We need to make our profile look something like this. We've excluded the comments at the top of the file, but if you are new to LXD, take a look at those: config: {} description: \"\" devices: eth0: name: eth0 nictype: macvlan parent: eno1 type: nic name: macvlan What happened when we created the macvlan profile is that the default profile was copied. The default profile cannot be changed. Now that we have the macvlan profile, we need to apply it to our three containers: lxc profile assign web1 default,macvlan lxc profile assign web2 default,macvlan lxc profile assign proxyha default,macvlan Unfortunately, the default behavior of macvlan as implemented in the kernel, is inexplicably broken within an LXD container (see this document ). This has been the case with the upstream provider since version 8 was released. To get around these issues, we will need to run dhclient on boot in each of the containers. Doing this is pretty simple when using DHCP. Just follow this for each container: lxc exec web1 bash which will put you at the command line of the web1 container crontab -e which will edit root's crontab on the container type i to get into insert mode. add a line: @reboot /usr/sbin/dhclient hit the ESC key to exit out of insert mode. save your changes with SHIFT: wq type exit to exit container Repeat steps for web2 and proxyha . Once these steps are completed, restart the containers: lxc restart web1 lxc restart web2 lxc restart proxyha and when you do an lxc list again, you should see that the DHCP addresses are now assigned from your LAN: +---------+---------+----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +---------+---------+----------------------+------+-----------+-----------+ | proxyha | RUNNING | 192.168.1.149 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ | web1 | RUNNING | 192.168.1.150 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ | web2 | RUNNING | 192.168.1.101 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ Installing Apache and Modifying the Welcome Screen Now that our environment is set, we need to install Apache ( httpd ) on each web container. This can done without physically accessing them: lxc exec web1 dnf install httpd lxc exec web2 dnf install httpd While it is understood that you will need a whole lot more than Apache for any modern web server, this is enough to run some tests. Next, we need to enable httpd , start it, and then modify the default welcome screen, so we know which server we are hitting when we attempt to access via proxy. Enable and start httpd : lxc exec web1 systemctl enable httpd lxc exec web1 systemctl start httpd lxc exec web2 systemctl enable httpd lxc exec web2 systemctl start httpd Now that we have httpd enabled and started, let's modify the welcome screen. This is the screen that comes up when there is no website configured, essentially a default page that loads. In Rocky Linux, this page is located here /usr/share/httpd/noindex/index.html . To modify that file, again, there's no need for direct access to the container. Simply do the following: lxc exec web1 vi /usr/share/httpd/noindex/index.html and then do a search for the <h1> tag, which should show this: <h1>HTTP Server <strong>Test Page</strong></h1> Simply change that line to read: <h1>SITE1 HTTP Server <strong>Test Page</strong></h1> Now repeat the process for web2. Going to these machines by IP in a browser should now return the correct welcome page for each. There's more to do on the web servers, but let's leave them and go on to the proxy server next. Installing HAProxy on proxyha and LXD Proxy Configuration It is just as easy to install HAProxy on the proxy container as well. Again, no need to access that container directly: lxc exec proxyha dnf install haproxy The next thing we want to do is configure haproxy to listen on port 80 and port 443 for the web services. This is done with the configure sub-command of lxc : lxc config device add proxyha http proxy listen=tcp:0.0.0.0:80 connect=tcp:127.0.0.1:80 lxc config device add proxyha https proxy listen=tcp:0.0.0.0:443 connect=tcp:127.0.0.1:443 For our testing, we are only going to use port 80, or HTTP traffic, but this shows you how you would configure the container to listen on the default web ports for both HTTP and HTTPS. Using this command also ensures that restarting the proxyha container will maintain those listening ports. The HAProxy Configuration We've already installed HAProxy on the container, but we have done nothing with the configuration. Before we do anything, we need to do something to resolve our hosts. Normally we would be using fully-qualified domain names, but in this lab environment, we are just using IPs. To get some names associated with the machines, we are going to add some host file records to the proxyha container. lxc exec proxyha vi /etc/hosts Add the following records to the bottom of the file: 192.168.1.150 site1.testdomain.com site1 192.168.1.101 site2.testdomain.com site2 Which should allow the proxyha container to resolve those names. Once that is complete, let's edit the haproxy.cfg file. There is so much in the original file that we are not going to be using, that we are simply going to make a backup of it first by moving it to a different name: lxc exec proxyha mv /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.orig Now let's create a new configuration file: lxc exec proxyha vi /etc/haproxy/haproxy.cfg Note that we have commented out all of the HTTPS protocol lines for now. In a production environment, you'd want to use a wildcard certificate that would cover your web servers and enable HTTPS: global log /dev/log local0 log /dev/log local1 notice chroot /var/lib/haproxy stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners stats timeout 30s user haproxy group haproxy daemon # For now, all https is remarked out # #ssl-default-bind-options no-sslv3 no-tlsv10 no-tlsv11 no-tls-tickets #ssl-default-bind-ciphers EECDH+AESGCM:EDH+AESGCM #tune.ssl.default-dh-param 2048 defaults log global mode http option httplog option dontlognull option forwardfor option http-server-close timeout connect 5000 timeout client 50000 timeout server 50000 errorfile 400 /etc/haproxy/errors/400.http errorfile 403 /etc/haproxy/errors/403.http errorfile 408 /etc/haproxy/errors/408.http errorfile 500 /etc/haproxy/errors/500.http errorfile 502 /etc/haproxy/errors/502.http errorfile 503 /etc/haproxy/errors/503.http errorfile 504 /etc/haproxy/errors/504.http # For now, all https is remarked out # frontend www-https # bind *:443 ssl crt /etc/letsencrypt/live/example.com/example.com.pem # reqadd X-Forwarded-Proto:\\ https # acl host_web1 hdr(host) -i site1.testdomain.com # acl host_web2 hdr(host) -i site2.testdomain.com # use_backend subdomain1 if host_web1 # use_backend subdomain2 if host_web2 frontend http_frontend bind *:80 acl web_host1 hdr(host) -i site1.testdomain.com acl web_host2 hdr(host) -i site2.testdomain.com use_backend subdomain1 if web_host1 use_backend subdomain2 if web_host2 backend subdomain1 # balance leastconn balance roundrobin http-request set-header X-Client-IP %[src] # redirect scheme https if !{ ssl_fc } server site1 site1.testdomain.com:80 check server site2 web2.testdomain.com:80 check backend subdomain2 # balance leastconn balance roundrobin http-request set-header X-Client-IP %[src] # redirect scheme https if !{ ssl_fc } server site2 site2.testdomain.com:80 check server site1 site1.testdomain.com:80 check A little explanation of what's going on above. You should see this in your testing, when you get to the testing section of this guide (below): Both site1 and site2 are defined in the \"acl\" section. Then both site1 and site2 are included in each other's \"roundrobin\" for their respective back ends. What happens when you go to site1.testdomain.com in the test, the URL does not change, but the page inside will switch each time you access the page from the site1 to the site2 test pages. Same goes for site2.testdomain.com. This is done to show you the switch is occurring, but in reality, your website content will look exactly the same regardless of which server you are hitting. Keep in mind that we are showing how you might want to distribute traffic between multiple hosts. You can also use \"leastcon\" in the balance line, and instead of switching based on the previous hit, it will load the site with the least number of connections. The Error Files Some versions of HAProxy come with a standard set of web error files, however the version that comes from Rocky Linux (and the upstream vendor), does not have these files. You probably do want to create them, as they may help you troubleshoot any problems. These files go in the directory /etc/haproxy/errors which does not exist. The first thing we need to do is create that directory: lxc exec proxyha mkdir /etc/haproxy/errors Then we need to create each of these files in that directory. Note that you can do this with each filename from your LXD host with the command lxc exec proxyha vi /etc/haproxy/errors/filename.http , where \"filename.http\" references one of the below file names. In a production environment, your company may have more specific errors that they would like to use: File name 400.http : HTTP/1.0 400 Bad request Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>400 Bad request</h1> Your browser sent an invalid request. </body></html> File name 403.http : HTTP/1.0 403 Forbidden Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>403 Forbidden</h1> Request forbidden by administrative rules. </body></html> Filename 408.http : HTTP/1.0 408 Request Time-out Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>408 Request Time-out</h1> Your browser didn't send a complete request in time. </body></html> Filename 500.http : HTTP/1.0 500 Internal Server Error Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>500 Internal Server Error</h1> An internal server error occurred. </body></html> Filename 502.http : HTTP/1.0 502 Bad Gateway Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>502 Bad Gateway</h1> The server returned an invalid or incomplete response. </body></html> Filename 503.http : HTTP/1.0 503 Service Unavailable Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>503 Service Unavailable</h1> No server is available to handle this request. </body></html> Filename 504.http : HTTP/1.0 504 Gateway Time-out Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>504 Gateway Time-out</h1> The server didn't respond in time. </body></html> Running The Proxy We need to create a \"run\" directory for haproxy before we start the service: lxc exec proxyha mkdir /run/haproxy Next, we need to enable the service and start it: lxc exec proxyha systemctl enable haproxy lxc exec proxyha systemctl start haproxy If you get any errors, research the reason by using: lxc exec proxyha systemctl status haproxy If everything starts and runs without issue, we are ready to move on to testing. Testing The Proxy As with the hosts ( /etc/hosts ) setup that we used so that our proxyha container can resolve the web servers, and since in our lab environment we don't have a local DNS server running, we need to set the IP values on our local machine for both the site1 and site2 websites, to correspond to our haproxy container. To do this, we need to modify our /etc/hosts file on our local machine. Consider this method of domain resolution a \"poor man's DNS.\" sudo vi /etc/hosts Then just add these two lines: 192.168.1.149 site1.testdomain.com site1 192.168.1.149 site2.testdomain.com site2 If you ping either site1 or site2 on your local machine now, you should get a response from proxyha : PING site1.testdomain.com (192.168.1.149) 56(84) bytes of data. 64 bytes from site1.testdomain.com (192.168.1.149): icmp_seq=1 ttl=64 time=0.427 ms 64 bytes from site1.testdomain.com (192.168.1.149): icmp_seq=2 ttl=64 time=0.430 ms Now open your web browser and type site1.testdomain.com (or site2.testdomain.com) as the URL in the address bar. You should get a response back from one of the two test pages and if you load the page again, you should get the next server's test page. Note that the URL does not change, but the returned page will change alternately between servers. Logging Even though our configuration file is set up correctly for logging, we need two things: First, we need a directory in /var/lib/haproxy/ called \"dev\": lxc exec proxyha mkdir /var/lib/haproxy/dev Next, we need to create a system process for rsyslogd to grab instances from the socket ( /var/lib/haproxy/dev/log in this case) and store those in /var/log/haproxy.log : lxc exec proxyha vi /etc/rsyslog.d/99-haproxy.conf Add the following contents to that file: $AddUnixListenSocket /var/lib/haproxy/dev/log # Send HAProxy messages to a dedicated logfile :programname, startswith, \"haproxy\" { /var/log/haproxy.log stop } Save the file and exit, then restart rsyslog : lxc exec proxyha systemctl restart rsyslog And to populate that log file with something right away, restart haproxy again: lxc exec proxyha systemctl restart haproxy To take a look at the log file created: lxc exec proxyha more /var/log/haproxy.log Which should show you something like this: Sep 25 23:18:02 proxyha haproxy[4602]: Proxy http_frontend started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy http_frontend started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy subdomain1 started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy subdomain1 started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy subdomain2 started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy subdomain2 started. Conclusions HAProxy is a powerful proxy engine that can be used for many things. It is a high-performance, open-source load balancer and reverse proxy for TCP and HTTP applications. We have shown in this document how to use load balancing of two web server instances. It can also be used for other applications, including databases. It works within LXD containers, as well as on bare metal and standalone servers. There are plenty of uses not covered in this document. Check out the official manual for HAProxy here.","title":"HAProxy-Apache-LXD"},{"location":"guides/proxies/haproxy_apache_lxd/#haproxy-load-balancing-apache-using-lxd-containers","text":"","title":"HAProxy Load Balancing Apache using LXD Containers"},{"location":"guides/proxies/haproxy_apache_lxd/#introduction","text":"HAProxy stands for \"High Availability Proxy.\" This proxy can sit in front of any TCP application (such as web servers), but it is often used to act as a load-balancer between multiple instances of a website. There might be a number of reasons for doing this. If you have a website that is being hit hard \u2014 adding another instance of that same website and placing HAProxy in front of both \u2014 allows you to distribute traffic between instances. Another reason might be to be able to update content on a website without any down time. HAProxy can also help mitigate DOS and DDOS attacks. This guide is going to explore using HAProxy using two website instances, and load-balancing with round robin rotation, on the same LXD host. This might be a perfectly fine solution for ensuring that updates can be performed without downtime. If your problem is website performance, however, you may need to distribute your multiple sites across actual bare metal or between multiple LXD hosts. It is certainly possible to do all of this on bare metal without using LXD at all, however LXD offers great flexibility and performance, plus it is great to use for lab testing.","title":"Introduction"},{"location":"guides/proxies/haproxy_apache_lxd/#prerequisites-and-assumptions","text":"Complete comfort at the command line on a Linux machine Experience with a command line editor (we are using vim here) Experience with crontab Knowledge of LXD. For more information, you may want to consult the LXD Server document. It is perfectly fine to install LXD on a laptop or workstation as well without doing the full-blown server install. This document is being written with a lab machine that is running LXD, but is not set up as a full server as the document linked above uses. Some knowledge on installing, configuring, and using web servers. We will assume that LXD is already installed and ready to create containers.","title":"Prerequisites and Assumptions"},{"location":"guides/proxies/haproxy_apache_lxd/#installing-containers","text":"On your LXD host for this guide, we will need three containers. Obviously, there could be more web server containers if you wish. We will use web1 and web2 for our website containers and proxyha for our HAProxy container. To install these on your LXD host do: lxc launch images:rockylinux/8 web1 lxc launch images:rockylinux/8 web2 lxc launch images:rockylinux/8 proxyha Running an lxc list should return something like this: +---------+---------+----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +---------+---------+----------------------+------+-----------+-----------+ | proxyha | RUNNING | 10.181.87.137 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ | web1 | RUNNING | 10.181.87.207 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ | web2 | RUNNING | 10.181.87.34 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+","title":"Installing Containers"},{"location":"guides/proxies/haproxy_apache_lxd/#creating-and-using-the-macvlan-profile","text":"The containers are currently running on the default bridge interface with bridge assigned DHCP addresses. We are going to want to use DHCP addresses from our local LAN, so the first thing we need to do is to create and assign the macvlan profile. Start by creating the profile: lxc profile create macvlan Make sure that your editor is set to your preferred editor, in this case vim : export EDITOR=/usr/bin/vim Next we need to modify the macvlan profile. But before we do, we need to know what interface the host is using for our LAN so run ip addr and look for the interface with the LAN IP assignment: 2: eno1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether a8:5e:45:52:f8:b6 brd ff:ff:ff:ff:ff:ff inet 192.168.1.141/24 brd 192.168.1.255 scope global dynamic noprefixroute eno1 !!! Note In this case, the interface we are looking for is \"eno1\" but this could be completely different on your system. Use **your** interface information! Now that we know the LAN interface, we can modify our macvlan profile. To do this, at the command line type: lxc profile edit macvlan We need to make our profile look something like this. We've excluded the comments at the top of the file, but if you are new to LXD, take a look at those: config: {} description: \"\" devices: eth0: name: eth0 nictype: macvlan parent: eno1 type: nic name: macvlan What happened when we created the macvlan profile is that the default profile was copied. The default profile cannot be changed. Now that we have the macvlan profile, we need to apply it to our three containers: lxc profile assign web1 default,macvlan lxc profile assign web2 default,macvlan lxc profile assign proxyha default,macvlan Unfortunately, the default behavior of macvlan as implemented in the kernel, is inexplicably broken within an LXD container (see this document ). This has been the case with the upstream provider since version 8 was released. To get around these issues, we will need to run dhclient on boot in each of the containers. Doing this is pretty simple when using DHCP. Just follow this for each container: lxc exec web1 bash which will put you at the command line of the web1 container crontab -e which will edit root's crontab on the container type i to get into insert mode. add a line: @reboot /usr/sbin/dhclient hit the ESC key to exit out of insert mode. save your changes with SHIFT: wq type exit to exit container Repeat steps for web2 and proxyha . Once these steps are completed, restart the containers: lxc restart web1 lxc restart web2 lxc restart proxyha and when you do an lxc list again, you should see that the DHCP addresses are now assigned from your LAN: +---------+---------+----------------------+------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +---------+---------+----------------------+------+-----------+-----------+ | proxyha | RUNNING | 192.168.1.149 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ | web1 | RUNNING | 192.168.1.150 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+ | web2 | RUNNING | 192.168.1.101 (eth0) | | CONTAINER | 0 | +---------+---------+----------------------+------+-----------+-----------+","title":"Creating and Using the macvlan Profile"},{"location":"guides/proxies/haproxy_apache_lxd/#installing-apache-and-modifying-the-welcome-screen","text":"Now that our environment is set, we need to install Apache ( httpd ) on each web container. This can done without physically accessing them: lxc exec web1 dnf install httpd lxc exec web2 dnf install httpd While it is understood that you will need a whole lot more than Apache for any modern web server, this is enough to run some tests. Next, we need to enable httpd , start it, and then modify the default welcome screen, so we know which server we are hitting when we attempt to access via proxy. Enable and start httpd : lxc exec web1 systemctl enable httpd lxc exec web1 systemctl start httpd lxc exec web2 systemctl enable httpd lxc exec web2 systemctl start httpd Now that we have httpd enabled and started, let's modify the welcome screen. This is the screen that comes up when there is no website configured, essentially a default page that loads. In Rocky Linux, this page is located here /usr/share/httpd/noindex/index.html . To modify that file, again, there's no need for direct access to the container. Simply do the following: lxc exec web1 vi /usr/share/httpd/noindex/index.html and then do a search for the <h1> tag, which should show this: <h1>HTTP Server <strong>Test Page</strong></h1> Simply change that line to read: <h1>SITE1 HTTP Server <strong>Test Page</strong></h1> Now repeat the process for web2. Going to these machines by IP in a browser should now return the correct welcome page for each. There's more to do on the web servers, but let's leave them and go on to the proxy server next.","title":"Installing Apache and Modifying the Welcome Screen"},{"location":"guides/proxies/haproxy_apache_lxd/#installing-haproxy-on-proxyha-and-lxd-proxy-configuration","text":"It is just as easy to install HAProxy on the proxy container as well. Again, no need to access that container directly: lxc exec proxyha dnf install haproxy The next thing we want to do is configure haproxy to listen on port 80 and port 443 for the web services. This is done with the configure sub-command of lxc : lxc config device add proxyha http proxy listen=tcp:0.0.0.0:80 connect=tcp:127.0.0.1:80 lxc config device add proxyha https proxy listen=tcp:0.0.0.0:443 connect=tcp:127.0.0.1:443 For our testing, we are only going to use port 80, or HTTP traffic, but this shows you how you would configure the container to listen on the default web ports for both HTTP and HTTPS. Using this command also ensures that restarting the proxyha container will maintain those listening ports.","title":"Installing HAProxy on proxyha and LXD Proxy Configuration"},{"location":"guides/proxies/haproxy_apache_lxd/#the-haproxy-configuration","text":"We've already installed HAProxy on the container, but we have done nothing with the configuration. Before we do anything, we need to do something to resolve our hosts. Normally we would be using fully-qualified domain names, but in this lab environment, we are just using IPs. To get some names associated with the machines, we are going to add some host file records to the proxyha container. lxc exec proxyha vi /etc/hosts Add the following records to the bottom of the file: 192.168.1.150 site1.testdomain.com site1 192.168.1.101 site2.testdomain.com site2 Which should allow the proxyha container to resolve those names. Once that is complete, let's edit the haproxy.cfg file. There is so much in the original file that we are not going to be using, that we are simply going to make a backup of it first by moving it to a different name: lxc exec proxyha mv /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.orig Now let's create a new configuration file: lxc exec proxyha vi /etc/haproxy/haproxy.cfg Note that we have commented out all of the HTTPS protocol lines for now. In a production environment, you'd want to use a wildcard certificate that would cover your web servers and enable HTTPS: global log /dev/log local0 log /dev/log local1 notice chroot /var/lib/haproxy stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners stats timeout 30s user haproxy group haproxy daemon # For now, all https is remarked out # #ssl-default-bind-options no-sslv3 no-tlsv10 no-tlsv11 no-tls-tickets #ssl-default-bind-ciphers EECDH+AESGCM:EDH+AESGCM #tune.ssl.default-dh-param 2048 defaults log global mode http option httplog option dontlognull option forwardfor option http-server-close timeout connect 5000 timeout client 50000 timeout server 50000 errorfile 400 /etc/haproxy/errors/400.http errorfile 403 /etc/haproxy/errors/403.http errorfile 408 /etc/haproxy/errors/408.http errorfile 500 /etc/haproxy/errors/500.http errorfile 502 /etc/haproxy/errors/502.http errorfile 503 /etc/haproxy/errors/503.http errorfile 504 /etc/haproxy/errors/504.http # For now, all https is remarked out # frontend www-https # bind *:443 ssl crt /etc/letsencrypt/live/example.com/example.com.pem # reqadd X-Forwarded-Proto:\\ https # acl host_web1 hdr(host) -i site1.testdomain.com # acl host_web2 hdr(host) -i site2.testdomain.com # use_backend subdomain1 if host_web1 # use_backend subdomain2 if host_web2 frontend http_frontend bind *:80 acl web_host1 hdr(host) -i site1.testdomain.com acl web_host2 hdr(host) -i site2.testdomain.com use_backend subdomain1 if web_host1 use_backend subdomain2 if web_host2 backend subdomain1 # balance leastconn balance roundrobin http-request set-header X-Client-IP %[src] # redirect scheme https if !{ ssl_fc } server site1 site1.testdomain.com:80 check server site2 web2.testdomain.com:80 check backend subdomain2 # balance leastconn balance roundrobin http-request set-header X-Client-IP %[src] # redirect scheme https if !{ ssl_fc } server site2 site2.testdomain.com:80 check server site1 site1.testdomain.com:80 check A little explanation of what's going on above. You should see this in your testing, when you get to the testing section of this guide (below): Both site1 and site2 are defined in the \"acl\" section. Then both site1 and site2 are included in each other's \"roundrobin\" for their respective back ends. What happens when you go to site1.testdomain.com in the test, the URL does not change, but the page inside will switch each time you access the page from the site1 to the site2 test pages. Same goes for site2.testdomain.com. This is done to show you the switch is occurring, but in reality, your website content will look exactly the same regardless of which server you are hitting. Keep in mind that we are showing how you might want to distribute traffic between multiple hosts. You can also use \"leastcon\" in the balance line, and instead of switching based on the previous hit, it will load the site with the least number of connections.","title":"The HAProxy Configuration"},{"location":"guides/proxies/haproxy_apache_lxd/#the-error-files","text":"Some versions of HAProxy come with a standard set of web error files, however the version that comes from Rocky Linux (and the upstream vendor), does not have these files. You probably do want to create them, as they may help you troubleshoot any problems. These files go in the directory /etc/haproxy/errors which does not exist. The first thing we need to do is create that directory: lxc exec proxyha mkdir /etc/haproxy/errors Then we need to create each of these files in that directory. Note that you can do this with each filename from your LXD host with the command lxc exec proxyha vi /etc/haproxy/errors/filename.http , where \"filename.http\" references one of the below file names. In a production environment, your company may have more specific errors that they would like to use: File name 400.http : HTTP/1.0 400 Bad request Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>400 Bad request</h1> Your browser sent an invalid request. </body></html> File name 403.http : HTTP/1.0 403 Forbidden Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>403 Forbidden</h1> Request forbidden by administrative rules. </body></html> Filename 408.http : HTTP/1.0 408 Request Time-out Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>408 Request Time-out</h1> Your browser didn't send a complete request in time. </body></html> Filename 500.http : HTTP/1.0 500 Internal Server Error Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>500 Internal Server Error</h1> An internal server error occurred. </body></html> Filename 502.http : HTTP/1.0 502 Bad Gateway Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>502 Bad Gateway</h1> The server returned an invalid or incomplete response. </body></html> Filename 503.http : HTTP/1.0 503 Service Unavailable Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>503 Service Unavailable</h1> No server is available to handle this request. </body></html> Filename 504.http : HTTP/1.0 504 Gateway Time-out Cache-Control: no-cache Connection: close Content-Type: text/html <html><body><h1>504 Gateway Time-out</h1> The server didn't respond in time. </body></html>","title":"The Error Files"},{"location":"guides/proxies/haproxy_apache_lxd/#running-the-proxy","text":"We need to create a \"run\" directory for haproxy before we start the service: lxc exec proxyha mkdir /run/haproxy Next, we need to enable the service and start it: lxc exec proxyha systemctl enable haproxy lxc exec proxyha systemctl start haproxy If you get any errors, research the reason by using: lxc exec proxyha systemctl status haproxy If everything starts and runs without issue, we are ready to move on to testing.","title":"Running The Proxy"},{"location":"guides/proxies/haproxy_apache_lxd/#testing-the-proxy","text":"As with the hosts ( /etc/hosts ) setup that we used so that our proxyha container can resolve the web servers, and since in our lab environment we don't have a local DNS server running, we need to set the IP values on our local machine for both the site1 and site2 websites, to correspond to our haproxy container. To do this, we need to modify our /etc/hosts file on our local machine. Consider this method of domain resolution a \"poor man's DNS.\" sudo vi /etc/hosts Then just add these two lines: 192.168.1.149 site1.testdomain.com site1 192.168.1.149 site2.testdomain.com site2 If you ping either site1 or site2 on your local machine now, you should get a response from proxyha : PING site1.testdomain.com (192.168.1.149) 56(84) bytes of data. 64 bytes from site1.testdomain.com (192.168.1.149): icmp_seq=1 ttl=64 time=0.427 ms 64 bytes from site1.testdomain.com (192.168.1.149): icmp_seq=2 ttl=64 time=0.430 ms Now open your web browser and type site1.testdomain.com (or site2.testdomain.com) as the URL in the address bar. You should get a response back from one of the two test pages and if you load the page again, you should get the next server's test page. Note that the URL does not change, but the returned page will change alternately between servers.","title":"Testing The Proxy"},{"location":"guides/proxies/haproxy_apache_lxd/#logging","text":"Even though our configuration file is set up correctly for logging, we need two things: First, we need a directory in /var/lib/haproxy/ called \"dev\": lxc exec proxyha mkdir /var/lib/haproxy/dev Next, we need to create a system process for rsyslogd to grab instances from the socket ( /var/lib/haproxy/dev/log in this case) and store those in /var/log/haproxy.log : lxc exec proxyha vi /etc/rsyslog.d/99-haproxy.conf Add the following contents to that file: $AddUnixListenSocket /var/lib/haproxy/dev/log # Send HAProxy messages to a dedicated logfile :programname, startswith, \"haproxy\" { /var/log/haproxy.log stop } Save the file and exit, then restart rsyslog : lxc exec proxyha systemctl restart rsyslog And to populate that log file with something right away, restart haproxy again: lxc exec proxyha systemctl restart haproxy To take a look at the log file created: lxc exec proxyha more /var/log/haproxy.log Which should show you something like this: Sep 25 23:18:02 proxyha haproxy[4602]: Proxy http_frontend started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy http_frontend started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy subdomain1 started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy subdomain1 started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy subdomain2 started. Sep 25 23:18:02 proxyha haproxy[4602]: Proxy subdomain2 started.","title":"Logging"},{"location":"guides/proxies/haproxy_apache_lxd/#conclusions","text":"HAProxy is a powerful proxy engine that can be used for many things. It is a high-performance, open-source load balancer and reverse proxy for TCP and HTTP applications. We have shown in this document how to use load balancing of two web server instances. It can also be used for other applications, including databases. It works within LXD containers, as well as on bare metal and standalone servers. There are plenty of uses not covered in this document. Check out the official manual for HAProxy here.","title":"Conclusions"},{"location":"guides/proxies/pound/","tags":["proxy","proxies"],"text":"Pound Proxy Server Introduction Pound is a web server agnostic reverse proxy and load balancer that is very easy to setup and manage. It does not use a web service itself, but does listen on the web service ports (http, https). Now, there are a lot of proxy server options, some referenced in these documentation pages. There is a document on using HAProxy here and there have been references in other documents to using Nginx for a reverse proxy. Load balancing services are quite useful for a busy web server environment. Many proxy servers, including the previously mentioned HAProxy, can be used for many service types. In the case of Pound, it can only be used for web services, but it's good at what it does. Prerequisites and Assumptions The following are minimum requirements for using this procedure: A desire to load balance between a few websites, or a desire to learn a new tool do do the same. The ability to execute commands as the root user or use sudo to get there. Familiarity with a command-line editor. We are using vi or vim here, but feel free to substitute in your favorite editor. Comfort with changing the listen ports on a few types of web servers. We are assuming that both the Nginx and the Apache servers are already installed. We are assuming that you are using Rocky Linux servers or containers for everything here. While we make all kinds of statements regarding https below, this guide only deals with the http service. To properly do https , you'll need to configure your pound server with a real certificate from a real certificate authority. !!! hint If you don't have either of these servers installed, you can do so on a container environment (LXD or Docker) or on bare metal, and get them up and running. For this procedure, you merely need to install them with their respective packages, and enable and start the services. We won't be modifying them significantly in any way. ``` dnf -y install nginx && dnf enable --now nginx ``` or ``` dnf -y install httpd && dnf enable --now httpd ``` Conventions For this procedure, we are going to be using two web servers (known as back end servers), one running Nginx (192.168.1.111) and one running Apache (192.168.1.108). Our Pound server (192.168.1.103) will be considered the gateway. We will be switching our listen ports on both of the back end servers to 8080 for the Nginx server and 8081 for the Apache server. Everything will be detailed below as we go, so no need to worry about these for the moment. !!! note Remember to change the associated IPs to whatever they are in your own environment and substitute them where applicable throughout this procedure. Installing the Pound Server To install Pound, we need to first install the EPEL (Extra Packages for Enterprise Linux) and run updates in case there is something new with EPEL: dnf -y install epel-release && dnf -y update Then just install Pound. (Yes, that's a capital \"P\"): dnf -y install Pound Configuring Pound Now that the packages are installed we need to configure Pound. We will be using vi to update this, but if you prefer nano or something else, go ahead and substitute that in: vi /etc/pound.cfg The file is set up with default information in it, which makes it easy to see most of the default components of Pound: User \"pound\" Group \"pound\" Control \"/var/lib/pound/pound.cfg\" ListenHTTP Address 0.0.0.0 Port 80 End ListenHTTPS Address 0.0.0.0 Port 443 Cert \"/etc/pki/tls/certs/pound.pem\" End Service BackEnd Address 127.0.0.1 Port 8000 End BackEnd Address 127.0.0.1 Port 8001 End End Taking a Closer Look The \"User\" and \"Group\" was taken care of when we did the install The \"Control\" file does not appear to be used anywhere. The \"ListenHTTP\" section represents the service http (Port 80) and the \"Address\" that the proxy will listen on. We will change this to the actual IP of our Pound server. The \"ListenHTTPS\" section represents the service https (Port 443) and the \"Address\" that the proxy will listen on. As with the above, we will change this to the IP to that of the Pound server. The \"Cert\" option is the self-signed certificate provided by the Pound install process. You would want to replace this in a production environment with a real certificate using either one of these procedures: Generating SSL Keys or SSL Keys with Let's Encrypt . The \"Service\" section is where the \"BackEnd\" servers are configured along with their listening ports. You can have as many \"BackEnd\" servers as you need. Changing The Configuration change the IP Address under both listen options to our Pound server IP, 192.168.1.103 change the IP Addresses and ports under the \"BackEnd\" sections to match our configuration found in \"Conventions\" above (IPs and Ports) When you are all done modifying the configuration you should have a changed file that looks something like this: User \"pound\" Group \"pound\" Control \"/var/lib/pound/pound.cfg\" ListenHTTP Address 192.168.1.103 Port 80 End ListenHTTPS Address 192.168.1.103 Port 443 Cert \"/etc/pki/tls/certs/pound.pem\" End Service BackEnd Address 192.168.1.111 Port 8080 End BackEnd Address 192.168.1.108 Port 8081 End End Configuring Nginx to Listen on 8080 Since we have set the listen port for Nginx in our Pound configuration to 8080, we need to also make that change on our running Nginx server. We do this by modifying the nginx.conf : vi /etc/nginx/nginx.conf You just want to change the \"listen\" line to the new port number: listen 8080 default_server; Save your changes and then restart the nginx service: systemctl restart nginx Configuring Apache to listen on 8081 Since we have set the listen port for Apache in our Pound configuration to 8081, we need to also make that change on our running Apache server. We do this by modifying the httpd.conf : vi /etc/httpd/conf/httpd.conf You want to change the \"Listen\" line to the new port number: Listen 8081 Save your changes and restart the httpd service: systemctl restart httpd Test and Turn Up Once you have your web services up and running and listening on the right ports on each of our servers, the next step is to turn up the pound service on the Pound server: systemctl enable --now pound !!! attention Using Nginx and Apache, as we are doing here for demonstration, will mean that the Nginx server will almost always respond first. For this reason, to test effectively, you will need to assign a low priority to the Nginx server so that you will be able to see both screens. This speaks volumes about the speed of Nginx over Apache. To change the priority for the Nginx server, you just need to add a priority (1-9, with 9 being the lowest priority) in the \"BackEnd\" section for the Nginx server like this: ``` BackEnd Address 192.168.1.111 Port 8080 Priority 9 End ``` When you open your proxy server ip in a web browser you should be faced with one of these two screens: Or Using Emergency One thing that you may need to do when using a load balancer such as Pound, is to take the productions servers off-line for maintenance or to have a fall-back \"BackEnd\" for a complete outage. This is done with the \"Emergency\" declaration in the pound.conf file. You can only have one \"Emergency\" declaration per service. In our case, this would appear at the end of the \"Service\" section in our configuration file: ... Service BackEnd Address 192.168.1.117 Port 8080 Priority 9 End BackEnd Address 192.168.1.108 Port 8081 End Emergency Address 192.168.1.104 Port 8000 End End This server might only display a message that says, \"Down For Maintenance\". Security Considerations Something that most documents dealing with load balancing proxy servers will not deal with are the security issues. For instance, if this is a public facing web server, you will need to have the http and https services open to the world on the load balancing proxy. But what about the \"BackEnd\" servers? Those should only need to be accessed by their ports from the Pound server itself, but since the Pound server is redirecting to 8080 or 8081 on the BackEnd servers, and since the BackEnd servers have http listening on those subsequent ports, you can just use the service names for the firewall commands on those BackEnd servers. In this section we will deal with those concerns, and the firewalld commands needed to lock everything down. !!! warning We are assuming that you have direct access to the servers in question and are not remote to them. If you are remote, take extreme caution when removing services from a `firewalld` zone! You could lock yourself out of your server by accident. Firewall - Pound Server For the Pound server, as noted above, we want to allow http and https from the world. You will need to consider whether ssh needs to be allowed from the world or not. If you are local to the server, this is probably NOT the case. We are assuming that the server here is available via your local network and that you have direct access to it, so we will be locking down ssh to our LAN IPs. To accomplish the above, we will use the built-in firewall for Rocky Linux, firewalld and the firewall-cmd command structure. For simplicity sake, we will also use two of the built-in zones, \"public\" and \"trusted\". Let's start by adding our source IPs to the \"trusted\" zone. This is our LAN here (in our example: 192.168.1.0/24): firewall-cmd --zone=trusted --add-source=192.168.1.0/24 --permanent Then, let's add the ssh service to the zone: firewall-cmd --zone=trusted --add-service=ssh --permanent Once all of this is completed, reload the firewall with: firewall-cmd --reload And then list out the zone so that you can see everything with firewall-cmd --zone=trusted --list-all which should give you something like this: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Next we need to make changes to the \"public\" zone, which by default has the ssh service enabled. This needs to be carefully removed (again, we are assuming that you are NOT remote to the server here!) with the following: firewall-cmd --zone=public --remove-service=ssh --permanent We also need to add http and https services: firewall-cmd --zone=public --add-service=http --add-service=https --permanent Then we need to reload the firewall before you can see the changes: firewall-cmd --reload And then list out the public zone with firewall-cmd --zone=public --list-all which should show you something like this: public target: default icmp-block-inversion: no interfaces: sources: services: cockpit dhcpv6-client http https ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Within our lab environment, those are the only changes we need to make to our pound server load balancer. Firewall - Back End Servers For the \"BackEnd\" servers, we do not need to allow access from the world for anything and definitely not for our listen ports that the load balancer will be using. We will need to allow ssh from the LAN IPs, and http and https from our pound load balancer. That's pretty much it. Again, we are going to add the ssh service to our \"trusted\" zone, with the essentially the same commands we used for our pound server. Then we are going to add a zone called \"balance\" that we will use for the remaining http and https , and set the source IPs to that of the load balancer. Are you having fun yet? To be quick, let's use all of those commands that we used for the \"trusted\" zone in a single set of commands: firewall-cmd --zone=trusted --add-source=192.168.1.0/24 --permanent firewall-cmd --zone=trusted --add-service=ssh --permanent firewall-cmd --reload firewall-cmd --zone=trusted --list-all After, the \"trusted\" zone should look like this: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Again, test your ssh rule from an IP on the LAN, and then remove the ssh service from the \"public\" zone. Remember our warning from above, and do this only if you have local access to the server! firewall-cmd --zone=public --remove-service=ssh --permanent firewall-cmd --reload firewall-cmd --zone=public --list-all The public zone should now look like this: public target: default icmp-block-inversion: no interfaces: sources: services: cockpit dhcpv6-client ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Now let's add that new zone to deal with http and https . Remember that the source IP here needs to only be our load balancer (in our example: 192.168.1.103): !!! note A new zone must be added with the `--permanent` option and cannot be used until the firewall is reloaded. Also, don't forget to `--set-target=ACCEPT` for this zone! firewall-cmd --new-zone=balance --permanent firewall-cmd --reload firewall-cmd --zone=balance --set-target=ACCEPT firewall-cmd --zone=balance --add-source=192.168.1.103 --permanent firewall-cmd --zone=balance --add-service=http --add-service=https --permanent firewall-cmd --reload firewall-cmd --zone=balance --list-all The result: balance (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.103 services: http https ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Now repeat those steps on the other web server back end. Once you have your firewall rules added to everything, test your pound server again from your workstation browser. Other Information There are a LOT of options that can be included in your pound.conf file, including error message directives, logging options, time out values, etc. You can find more on what is available by looking here. Conveniently, Pound automatically figures out if one of the \"BackEnd\" servers is off-line and disables it so that web services can continue without delay. It also automatically sees them again when they are back on-line. Conclusion Pound offers another option for those who do not want to use HAProxy or Nginx as for load balancing. Pound as a load balancing server is very easy to install, set up and use. As noted here, Pound can also be used as a reverse proxy, and there are a lot of proxy and load balancing options available. And you should always remember to keep security in mind when setting up any service, including a load-balancing proxy server.","title":"Pound"},{"location":"guides/proxies/pound/#pound-proxy-server","text":"","title":"Pound Proxy Server"},{"location":"guides/proxies/pound/#introduction","text":"Pound is a web server agnostic reverse proxy and load balancer that is very easy to setup and manage. It does not use a web service itself, but does listen on the web service ports (http, https). Now, there are a lot of proxy server options, some referenced in these documentation pages. There is a document on using HAProxy here and there have been references in other documents to using Nginx for a reverse proxy. Load balancing services are quite useful for a busy web server environment. Many proxy servers, including the previously mentioned HAProxy, can be used for many service types. In the case of Pound, it can only be used for web services, but it's good at what it does.","title":"Introduction"},{"location":"guides/proxies/pound/#prerequisites-and-assumptions","text":"The following are minimum requirements for using this procedure: A desire to load balance between a few websites, or a desire to learn a new tool do do the same. The ability to execute commands as the root user or use sudo to get there. Familiarity with a command-line editor. We are using vi or vim here, but feel free to substitute in your favorite editor. Comfort with changing the listen ports on a few types of web servers. We are assuming that both the Nginx and the Apache servers are already installed. We are assuming that you are using Rocky Linux servers or containers for everything here. While we make all kinds of statements regarding https below, this guide only deals with the http service. To properly do https , you'll need to configure your pound server with a real certificate from a real certificate authority. !!! hint If you don't have either of these servers installed, you can do so on a container environment (LXD or Docker) or on bare metal, and get them up and running. For this procedure, you merely need to install them with their respective packages, and enable and start the services. We won't be modifying them significantly in any way. ``` dnf -y install nginx && dnf enable --now nginx ``` or ``` dnf -y install httpd && dnf enable --now httpd ```","title":"Prerequisites and Assumptions"},{"location":"guides/proxies/pound/#conventions","text":"For this procedure, we are going to be using two web servers (known as back end servers), one running Nginx (192.168.1.111) and one running Apache (192.168.1.108). Our Pound server (192.168.1.103) will be considered the gateway. We will be switching our listen ports on both of the back end servers to 8080 for the Nginx server and 8081 for the Apache server. Everything will be detailed below as we go, so no need to worry about these for the moment. !!! note Remember to change the associated IPs to whatever they are in your own environment and substitute them where applicable throughout this procedure.","title":"Conventions"},{"location":"guides/proxies/pound/#installing-the-pound-server","text":"To install Pound, we need to first install the EPEL (Extra Packages for Enterprise Linux) and run updates in case there is something new with EPEL: dnf -y install epel-release && dnf -y update Then just install Pound. (Yes, that's a capital \"P\"): dnf -y install Pound","title":"Installing the Pound Server"},{"location":"guides/proxies/pound/#configuring-pound","text":"Now that the packages are installed we need to configure Pound. We will be using vi to update this, but if you prefer nano or something else, go ahead and substitute that in: vi /etc/pound.cfg The file is set up with default information in it, which makes it easy to see most of the default components of Pound: User \"pound\" Group \"pound\" Control \"/var/lib/pound/pound.cfg\" ListenHTTP Address 0.0.0.0 Port 80 End ListenHTTPS Address 0.0.0.0 Port 443 Cert \"/etc/pki/tls/certs/pound.pem\" End Service BackEnd Address 127.0.0.1 Port 8000 End BackEnd Address 127.0.0.1 Port 8001 End End","title":"Configuring Pound"},{"location":"guides/proxies/pound/#taking-a-closer-look","text":"The \"User\" and \"Group\" was taken care of when we did the install The \"Control\" file does not appear to be used anywhere. The \"ListenHTTP\" section represents the service http (Port 80) and the \"Address\" that the proxy will listen on. We will change this to the actual IP of our Pound server. The \"ListenHTTPS\" section represents the service https (Port 443) and the \"Address\" that the proxy will listen on. As with the above, we will change this to the IP to that of the Pound server. The \"Cert\" option is the self-signed certificate provided by the Pound install process. You would want to replace this in a production environment with a real certificate using either one of these procedures: Generating SSL Keys or SSL Keys with Let's Encrypt . The \"Service\" section is where the \"BackEnd\" servers are configured along with their listening ports. You can have as many \"BackEnd\" servers as you need.","title":"Taking a Closer Look"},{"location":"guides/proxies/pound/#changing-the-configuration","text":"change the IP Address under both listen options to our Pound server IP, 192.168.1.103 change the IP Addresses and ports under the \"BackEnd\" sections to match our configuration found in \"Conventions\" above (IPs and Ports) When you are all done modifying the configuration you should have a changed file that looks something like this: User \"pound\" Group \"pound\" Control \"/var/lib/pound/pound.cfg\" ListenHTTP Address 192.168.1.103 Port 80 End ListenHTTPS Address 192.168.1.103 Port 443 Cert \"/etc/pki/tls/certs/pound.pem\" End Service BackEnd Address 192.168.1.111 Port 8080 End BackEnd Address 192.168.1.108 Port 8081 End End","title":"Changing The Configuration"},{"location":"guides/proxies/pound/#configuring-nginx-to-listen-on-8080","text":"Since we have set the listen port for Nginx in our Pound configuration to 8080, we need to also make that change on our running Nginx server. We do this by modifying the nginx.conf : vi /etc/nginx/nginx.conf You just want to change the \"listen\" line to the new port number: listen 8080 default_server; Save your changes and then restart the nginx service: systemctl restart nginx","title":"Configuring Nginx to Listen on 8080"},{"location":"guides/proxies/pound/#configuring-apache-to-listen-on-8081","text":"Since we have set the listen port for Apache in our Pound configuration to 8081, we need to also make that change on our running Apache server. We do this by modifying the httpd.conf : vi /etc/httpd/conf/httpd.conf You want to change the \"Listen\" line to the new port number: Listen 8081 Save your changes and restart the httpd service: systemctl restart httpd","title":"Configuring Apache to listen on 8081"},{"location":"guides/proxies/pound/#test-and-turn-up","text":"Once you have your web services up and running and listening on the right ports on each of our servers, the next step is to turn up the pound service on the Pound server: systemctl enable --now pound !!! attention Using Nginx and Apache, as we are doing here for demonstration, will mean that the Nginx server will almost always respond first. For this reason, to test effectively, you will need to assign a low priority to the Nginx server so that you will be able to see both screens. This speaks volumes about the speed of Nginx over Apache. To change the priority for the Nginx server, you just need to add a priority (1-9, with 9 being the lowest priority) in the \"BackEnd\" section for the Nginx server like this: ``` BackEnd Address 192.168.1.111 Port 8080 Priority 9 End ``` When you open your proxy server ip in a web browser you should be faced with one of these two screens: Or","title":"Test and Turn Up"},{"location":"guides/proxies/pound/#using-emergency","text":"One thing that you may need to do when using a load balancer such as Pound, is to take the productions servers off-line for maintenance or to have a fall-back \"BackEnd\" for a complete outage. This is done with the \"Emergency\" declaration in the pound.conf file. You can only have one \"Emergency\" declaration per service. In our case, this would appear at the end of the \"Service\" section in our configuration file: ... Service BackEnd Address 192.168.1.117 Port 8080 Priority 9 End BackEnd Address 192.168.1.108 Port 8081 End Emergency Address 192.168.1.104 Port 8000 End End This server might only display a message that says, \"Down For Maintenance\".","title":"Using Emergency"},{"location":"guides/proxies/pound/#security-considerations","text":"Something that most documents dealing with load balancing proxy servers will not deal with are the security issues. For instance, if this is a public facing web server, you will need to have the http and https services open to the world on the load balancing proxy. But what about the \"BackEnd\" servers? Those should only need to be accessed by their ports from the Pound server itself, but since the Pound server is redirecting to 8080 or 8081 on the BackEnd servers, and since the BackEnd servers have http listening on those subsequent ports, you can just use the service names for the firewall commands on those BackEnd servers. In this section we will deal with those concerns, and the firewalld commands needed to lock everything down. !!! warning We are assuming that you have direct access to the servers in question and are not remote to them. If you are remote, take extreme caution when removing services from a `firewalld` zone! You could lock yourself out of your server by accident.","title":"Security Considerations"},{"location":"guides/proxies/pound/#firewall-pound-server","text":"For the Pound server, as noted above, we want to allow http and https from the world. You will need to consider whether ssh needs to be allowed from the world or not. If you are local to the server, this is probably NOT the case. We are assuming that the server here is available via your local network and that you have direct access to it, so we will be locking down ssh to our LAN IPs. To accomplish the above, we will use the built-in firewall for Rocky Linux, firewalld and the firewall-cmd command structure. For simplicity sake, we will also use two of the built-in zones, \"public\" and \"trusted\". Let's start by adding our source IPs to the \"trusted\" zone. This is our LAN here (in our example: 192.168.1.0/24): firewall-cmd --zone=trusted --add-source=192.168.1.0/24 --permanent Then, let's add the ssh service to the zone: firewall-cmd --zone=trusted --add-service=ssh --permanent Once all of this is completed, reload the firewall with: firewall-cmd --reload And then list out the zone so that you can see everything with firewall-cmd --zone=trusted --list-all which should give you something like this: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Next we need to make changes to the \"public\" zone, which by default has the ssh service enabled. This needs to be carefully removed (again, we are assuming that you are NOT remote to the server here!) with the following: firewall-cmd --zone=public --remove-service=ssh --permanent We also need to add http and https services: firewall-cmd --zone=public --add-service=http --add-service=https --permanent Then we need to reload the firewall before you can see the changes: firewall-cmd --reload And then list out the public zone with firewall-cmd --zone=public --list-all which should show you something like this: public target: default icmp-block-inversion: no interfaces: sources: services: cockpit dhcpv6-client http https ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Within our lab environment, those are the only changes we need to make to our pound server load balancer.","title":"Firewall - Pound Server"},{"location":"guides/proxies/pound/#firewall-back-end-servers","text":"For the \"BackEnd\" servers, we do not need to allow access from the world for anything and definitely not for our listen ports that the load balancer will be using. We will need to allow ssh from the LAN IPs, and http and https from our pound load balancer. That's pretty much it. Again, we are going to add the ssh service to our \"trusted\" zone, with the essentially the same commands we used for our pound server. Then we are going to add a zone called \"balance\" that we will use for the remaining http and https , and set the source IPs to that of the load balancer. Are you having fun yet? To be quick, let's use all of those commands that we used for the \"trusted\" zone in a single set of commands: firewall-cmd --zone=trusted --add-source=192.168.1.0/24 --permanent firewall-cmd --zone=trusted --add-service=ssh --permanent firewall-cmd --reload firewall-cmd --zone=trusted --list-all After, the \"trusted\" zone should look like this: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Again, test your ssh rule from an IP on the LAN, and then remove the ssh service from the \"public\" zone. Remember our warning from above, and do this only if you have local access to the server! firewall-cmd --zone=public --remove-service=ssh --permanent firewall-cmd --reload firewall-cmd --zone=public --list-all The public zone should now look like this: public target: default icmp-block-inversion: no interfaces: sources: services: cockpit dhcpv6-client ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Now let's add that new zone to deal with http and https . Remember that the source IP here needs to only be our load balancer (in our example: 192.168.1.103): !!! note A new zone must be added with the `--permanent` option and cannot be used until the firewall is reloaded. Also, don't forget to `--set-target=ACCEPT` for this zone! firewall-cmd --new-zone=balance --permanent firewall-cmd --reload firewall-cmd --zone=balance --set-target=ACCEPT firewall-cmd --zone=balance --add-source=192.168.1.103 --permanent firewall-cmd --zone=balance --add-service=http --add-service=https --permanent firewall-cmd --reload firewall-cmd --zone=balance --list-all The result: balance (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.103 services: http https ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Now repeat those steps on the other web server back end. Once you have your firewall rules added to everything, test your pound server again from your workstation browser.","title":"Firewall - Back End Servers"},{"location":"guides/proxies/pound/#other-information","text":"There are a LOT of options that can be included in your pound.conf file, including error message directives, logging options, time out values, etc. You can find more on what is available by looking here. Conveniently, Pound automatically figures out if one of the \"BackEnd\" servers is off-line and disables it so that web services can continue without delay. It also automatically sees them again when they are back on-line.","title":"Other Information"},{"location":"guides/proxies/pound/#conclusion","text":"Pound offers another option for those who do not want to use HAProxy or Nginx as for load balancing. Pound as a load balancing server is very easy to install, set up and use. As noted here, Pound can also be used as a reverse proxy, and there are a lot of proxy and load balancing options available. And you should always remember to keep security in mind when setting up any service, including a load-balancing proxy server.","title":"Conclusion"},{"location":"guides/security/dnf_automatic/","tags":["security","dnf","automation","updates"],"text":"Patching servers with dnf-automatic Managing the installation of security updates is an important matter for the system administrator. The process of providing software updates is a well-trodden path that ultimately causes few problems. For these reasons, it is reasonable to automate the download and application of updates daily and automatically on Rocky servers. The security of your information system will be strengthened. dnf-automatic is an additional tool that will allow you to achieve this. !!! hint \"If you are worried...\" Years ago, applying updates automatically like this would have been a recipe for disaster. There were many times where an update applied might cause issues. That still happens rarely, when an update of a package removes a deprecated feature that is being used on the server, but for the most part, this simply isn't an issue these days. That said though, if you still feel uncomfortable letting `dnf-automatic` handle the updates, consider using it to download and/or notify you that updates are available. That way your server doesn't remain unpatched for long. These features are `dnf-automatic-notifyonly` and `dnf-automatic-download` For more on these features, take a look at the [official documentation](https://dnf.readthedocs.io/en/latest/automatic.html). Installation You can install dnf-automatic from the rocky repositories: sudo dnf install dnf-automatic Configuration By default, the update process will start at 6am, with a random extra time delta to avoid all your machines updating at the same time. To change this behavior, you must override the timer configuration associated with the application service: sudo systemctl edit dnf-automatic.timer [Unit] Description=dnf-automatic timer # See comment in dnf-makecache.service ConditionPathExists=!/run/ostree-booted Wants=network-online.target [Timer] OnCalendar=*-*-* 6:00 RandomizedDelaySec=10m Persistent=true [Install] WantedBy=timers.target This configuration reduces the start-up delay between 6:00 and 6:10 am. (A server that would be shut down at this time would be automatically patched after its restart.) Then activate the timer associated to the service (not the service itself): $ sudo systemctl enable --now dnf-automatic.timer What about CentOS 7 servers? !!! tip Yes, this is Rocky Linux documentation, but if you are a system or network administrator, you may have some CentOS 7 machines still in play. We get that, and that is why we are including this section. The process under CentOS 7 is similar but uses: yum-cron . $ sudo yum install yum-cron The configuration of the service is done this time in the file /etc/yum/yum-cron.conf . Set configuration as needed: [commands] # What kind of update to use: # default = yum upgrade # security = yum --security upgrade # security-severity:Critical = yum --sec-severity=Critical upgrade # minimal = yum --bugfix update-minimal # minimal-security = yum --security update-minimal # minimal-security-severity:Critical = --sec-severity=Critical update-minimal update_cmd = default # Whether a message should be emitted when updates are available, # were downloaded, or applied. update_messages = yes # Whether updates should be downloaded when they are available. download_updates = yes # Whether updates should be applied when they are available. Note # that download_updates must also be yes for the update to be applied. apply_updates = yes # Maximum amout of time to randomly sleep, in minutes. The program # will sleep for a random amount of time between 0 and random_sleep # minutes before running. This is useful for e.g. staggering the # times that multiple systems will access update servers. If # random_sleep is 0 or negative, the program will run immediately. # 6*60 = 360 random_sleep = 30 The comments in the configuration file speak for themselves. You can now enable the service and start it: $ sudo systemctl enable --now yum-cron Conclusion The automatic update of packages is easily activated and considerably increases the security of your information system.","title":"Patching with dnf-automatic"},{"location":"guides/security/dnf_automatic/#patching-servers-with-dnf-automatic","text":"Managing the installation of security updates is an important matter for the system administrator. The process of providing software updates is a well-trodden path that ultimately causes few problems. For these reasons, it is reasonable to automate the download and application of updates daily and automatically on Rocky servers. The security of your information system will be strengthened. dnf-automatic is an additional tool that will allow you to achieve this. !!! hint \"If you are worried...\" Years ago, applying updates automatically like this would have been a recipe for disaster. There were many times where an update applied might cause issues. That still happens rarely, when an update of a package removes a deprecated feature that is being used on the server, but for the most part, this simply isn't an issue these days. That said though, if you still feel uncomfortable letting `dnf-automatic` handle the updates, consider using it to download and/or notify you that updates are available. That way your server doesn't remain unpatched for long. These features are `dnf-automatic-notifyonly` and `dnf-automatic-download` For more on these features, take a look at the [official documentation](https://dnf.readthedocs.io/en/latest/automatic.html).","title":"Patching servers with dnf-automatic"},{"location":"guides/security/dnf_automatic/#installation","text":"You can install dnf-automatic from the rocky repositories: sudo dnf install dnf-automatic","title":"Installation"},{"location":"guides/security/dnf_automatic/#configuration","text":"By default, the update process will start at 6am, with a random extra time delta to avoid all your machines updating at the same time. To change this behavior, you must override the timer configuration associated with the application service: sudo systemctl edit dnf-automatic.timer [Unit] Description=dnf-automatic timer # See comment in dnf-makecache.service ConditionPathExists=!/run/ostree-booted Wants=network-online.target [Timer] OnCalendar=*-*-* 6:00 RandomizedDelaySec=10m Persistent=true [Install] WantedBy=timers.target This configuration reduces the start-up delay between 6:00 and 6:10 am. (A server that would be shut down at this time would be automatically patched after its restart.) Then activate the timer associated to the service (not the service itself): $ sudo systemctl enable --now dnf-automatic.timer","title":"Configuration"},{"location":"guides/security/dnf_automatic/#what-about-centos-7-servers","text":"!!! tip Yes, this is Rocky Linux documentation, but if you are a system or network administrator, you may have some CentOS 7 machines still in play. We get that, and that is why we are including this section. The process under CentOS 7 is similar but uses: yum-cron . $ sudo yum install yum-cron The configuration of the service is done this time in the file /etc/yum/yum-cron.conf . Set configuration as needed: [commands] # What kind of update to use: # default = yum upgrade # security = yum --security upgrade # security-severity:Critical = yum --sec-severity=Critical upgrade # minimal = yum --bugfix update-minimal # minimal-security = yum --security update-minimal # minimal-security-severity:Critical = --sec-severity=Critical update-minimal update_cmd = default # Whether a message should be emitted when updates are available, # were downloaded, or applied. update_messages = yes # Whether updates should be downloaded when they are available. download_updates = yes # Whether updates should be applied when they are available. Note # that download_updates must also be yes for the update to be applied. apply_updates = yes # Maximum amout of time to randomly sleep, in minutes. The program # will sleep for a random amount of time between 0 and random_sleep # minutes before running. This is useful for e.g. staggering the # times that multiple systems will access update servers. If # random_sleep is 0 or negative, the program will run immediately. # 6*60 = 360 random_sleep = 30 The comments in the configuration file speak for themselves. You can now enable the service and start it: $ sudo systemctl enable --now yum-cron","title":"What about CentOS 7 servers?"},{"location":"guides/security/dnf_automatic/#conclusion","text":"The automatic update of packages is easily activated and considerably increases the security of your information system.","title":"Conclusion"},{"location":"guides/security/enabling_iptables_firewall/","tags":["security","iptables","deprecated"],"text":"Enabling iptables Firewall Prerequisites A burning, unquenchable desire to disable the default firewalld application, and enable iptables . !!! warning \"This Process Is Deprecated\" As of Rocky Linux 9.0, `iptables` and all of the utilities associated with it, are deprecated. This means that future releases of the OS will be removing `iptables`. For that reason, it is highly recommended that you not use this process. If you are familiar with iptables, we recommend using [`iptables` Guide To `firewalld`](firewalld.md). If you are new to firewall concepts, then we recommend [`firewalld` For Beginners](firewalld-beginners.md). Introduction firewalld is now the default firewall on Rocky Linux. firewalld was nothing more than a dynamic application of iptables using xml files that loaded changes without flushing the rules in CentOS 7/RHEL 7. With CentOS 8/RHEL 8/Rocky 8, firewalld is now a wrapper around nftables . It is still possible, however, to install and use straight iptables if that is your preference. To install and run straight iptables without firewalld you can do so by following this guide. What this guide will not tell you is how to write rules for iptables . It is assumed that if you want to get rid of firewalld , you must already know how to write rules for iptables . Disabling firewalld You can't really run the old iptables utilities alongside firewalld . They're just not compatible. The best way to get around this is to disable firewalld entirely (no need to unistall it unless you want to), and reinstall the iptables utilities. Disabling firewalld can be done using these commands: Stop firewalld : systemctl stop firewalld Disable firewalld so it won't start on boot: systemctl disable firewalld Mask the service so that it can't be found: systemctl mask firewalld Installing And Enabling iptables Services Next we need to install the old iptables services and utilities. This is done with the following: dnf install iptables-services iptables-utils This will install everything that is needed to run a straight iptables rule set. Now we need to enable the iptables service to make sure that it starts on boot: systemctl enable iptables Conclusion You can return to using straight iptables if you prefer it over firewalld . You can return to using the default firewalld by simply reversing these changes.","title":"Enabling `iptables` Firewall"},{"location":"guides/security/enabling_iptables_firewall/#enabling-iptables-firewall","text":"","title":"Enabling iptables Firewall"},{"location":"guides/security/enabling_iptables_firewall/#prerequisites","text":"A burning, unquenchable desire to disable the default firewalld application, and enable iptables . !!! warning \"This Process Is Deprecated\" As of Rocky Linux 9.0, `iptables` and all of the utilities associated with it, are deprecated. This means that future releases of the OS will be removing `iptables`. For that reason, it is highly recommended that you not use this process. If you are familiar with iptables, we recommend using [`iptables` Guide To `firewalld`](firewalld.md). If you are new to firewall concepts, then we recommend [`firewalld` For Beginners](firewalld-beginners.md).","title":"Prerequisites"},{"location":"guides/security/enabling_iptables_firewall/#introduction","text":"firewalld is now the default firewall on Rocky Linux. firewalld was nothing more than a dynamic application of iptables using xml files that loaded changes without flushing the rules in CentOS 7/RHEL 7. With CentOS 8/RHEL 8/Rocky 8, firewalld is now a wrapper around nftables . It is still possible, however, to install and use straight iptables if that is your preference. To install and run straight iptables without firewalld you can do so by following this guide. What this guide will not tell you is how to write rules for iptables . It is assumed that if you want to get rid of firewalld , you must already know how to write rules for iptables .","title":"Introduction"},{"location":"guides/security/enabling_iptables_firewall/#disabling-firewalld","text":"You can't really run the old iptables utilities alongside firewalld . They're just not compatible. The best way to get around this is to disable firewalld entirely (no need to unistall it unless you want to), and reinstall the iptables utilities. Disabling firewalld can be done using these commands: Stop firewalld : systemctl stop firewalld Disable firewalld so it won't start on boot: systemctl disable firewalld Mask the service so that it can't be found: systemctl mask firewalld","title":"Disabling firewalld"},{"location":"guides/security/enabling_iptables_firewall/#installing-and-enabling-iptables-services","text":"Next we need to install the old iptables services and utilities. This is done with the following: dnf install iptables-services iptables-utils This will install everything that is needed to run a straight iptables rule set. Now we need to enable the iptables service to make sure that it starts on boot: systemctl enable iptables","title":"Installing And Enabling iptables Services"},{"location":"guides/security/enabling_iptables_firewall/#conclusion","text":"You can return to using straight iptables if you prefer it over firewalld . You can return to using the default firewalld by simply reversing these changes.","title":"Conclusion"},{"location":"guides/security/enabling_iptables_firewall.sv/","text":"Aktivera iptables Brandv\u00e4gg Prerequisites En br\u00e4nnande, osl\u00e4cklig lust att inaktivera den standard firewalld applikationen, och aktivera iptables ist\u00e4llet. Introduktion firewalld \u00e4r nu standard brandv\u00e4ggen p\u00e5 Rocky Linux. firewalld \u00e4r inget annat \u00e4n en dynamisk applikation baserad p\u00e5 iptables som anv\u00e4nder xml filer, och den laddar \u00e4ndringar utan att spola reglerna. Men om du vill, anv\u00e4nda enkel iptables d\u00e5 det \u00e4r n\u00e5got som du kanske \u00e4r mer van med. Om det \u00e4r s\u00e5, \u00e4r det fortfarande m\u00f6jligt att anv\u00e4nda iptables utan firewalld genom att f\u00f6lja denna guide. Denna guide kommer dock inte ber\u00e4tta f\u00f6r dig \u00e4r hur man skriver regler f\u00f6r iptables . Det antas att om du vill bli av med firewalld , att du redan vet hur man skriver regler f\u00f6r iptables . Inaktivera firewalld Du kan inte riktigt k\u00f6ra det gamla iptables verktygen samtidigt som firewalld . De \u00e4r bara inte kompatibla. B\u00e4sta s\u00e4ttet att komma runt detta \u00e4r att inaktivera firewalld helt (du beh\u00f6ver inte avinstallera det om du inte vill), och installera om iptables verktygen. Inaktivera firewalld kan g\u00f6ras med dessa kommandon: Stoppa firewalld : systemctl stop firewalld Inaktivera firewalld s\u00e5 det inte kommer starta vid uppstart av datorn: systemctl disable firewalld Maskera tj\u00e4nsten s\u00e5 att den inte kan hittas: systemctl mask firewalld Installera och aktivera iptables tj\u00e4nst D\u00e4refter m\u00e5ste vi installera den gamla iptables tj\u00e4nsten och verktyg. Detta g\u00f6rs med f\u00f6ljande: dnf install iptables-services iptables-utils Detta kommer installera allting som beh\u00f6vs f\u00f6r att k\u00f6ra ett rakt iptables regelverk. Nu m\u00e5ste vi aktivera iptables tj\u00e4nsten f\u00f6r att se till att den startar direkt vid uppstart: systemctl enable iptables Slutsats YDu kan \u00e5terg\u00e5 till att anv\u00e4nda rakt av anv\u00e4nda iptables om du trivs med det b\u00e4ttre ist\u00e4llet f\u00f6r firewalld . Du kan \u00e5terg\u00e5 till att anv\u00e4nda standard firewalld genom att helt enkelt backa dessa f\u00f6r\u00e4ndringar.","title":"Aktivera iptables Brandv\u00e4gg"},{"location":"guides/security/enabling_iptables_firewall.sv/#aktivera-iptables-brandvagg","text":"","title":"Aktivera iptables Brandv\u00e4gg"},{"location":"guides/security/enabling_iptables_firewall.sv/#prerequisites","text":"En br\u00e4nnande, osl\u00e4cklig lust att inaktivera den standard firewalld applikationen, och aktivera iptables ist\u00e4llet.","title":"Prerequisites"},{"location":"guides/security/enabling_iptables_firewall.sv/#introduktion","text":"firewalld \u00e4r nu standard brandv\u00e4ggen p\u00e5 Rocky Linux. firewalld \u00e4r inget annat \u00e4n en dynamisk applikation baserad p\u00e5 iptables som anv\u00e4nder xml filer, och den laddar \u00e4ndringar utan att spola reglerna. Men om du vill, anv\u00e4nda enkel iptables d\u00e5 det \u00e4r n\u00e5got som du kanske \u00e4r mer van med. Om det \u00e4r s\u00e5, \u00e4r det fortfarande m\u00f6jligt att anv\u00e4nda iptables utan firewalld genom att f\u00f6lja denna guide. Denna guide kommer dock inte ber\u00e4tta f\u00f6r dig \u00e4r hur man skriver regler f\u00f6r iptables . Det antas att om du vill bli av med firewalld , att du redan vet hur man skriver regler f\u00f6r iptables .","title":"Introduktion"},{"location":"guides/security/enabling_iptables_firewall.sv/#inaktivera-firewalld","text":"Du kan inte riktigt k\u00f6ra det gamla iptables verktygen samtidigt som firewalld . De \u00e4r bara inte kompatibla. B\u00e4sta s\u00e4ttet att komma runt detta \u00e4r att inaktivera firewalld helt (du beh\u00f6ver inte avinstallera det om du inte vill), och installera om iptables verktygen. Inaktivera firewalld kan g\u00f6ras med dessa kommandon: Stoppa firewalld : systemctl stop firewalld Inaktivera firewalld s\u00e5 det inte kommer starta vid uppstart av datorn: systemctl disable firewalld Maskera tj\u00e4nsten s\u00e5 att den inte kan hittas: systemctl mask firewalld","title":"Inaktivera firewalld"},{"location":"guides/security/enabling_iptables_firewall.sv/#installera-och-aktivera-iptables-tjanst","text":"D\u00e4refter m\u00e5ste vi installera den gamla iptables tj\u00e4nsten och verktyg. Detta g\u00f6rs med f\u00f6ljande: dnf install iptables-services iptables-utils Detta kommer installera allting som beh\u00f6vs f\u00f6r att k\u00f6ra ett rakt iptables regelverk. Nu m\u00e5ste vi aktivera iptables tj\u00e4nsten f\u00f6r att se till att den startar direkt vid uppstart: systemctl enable iptables","title":"Installera och aktivera iptables tj\u00e4nst"},{"location":"guides/security/enabling_iptables_firewall.sv/#slutsats","text":"YDu kan \u00e5terg\u00e5 till att anv\u00e4nda rakt av anv\u00e4nda iptables om du trivs med det b\u00e4ttre ist\u00e4llet f\u00f6r firewalld . Du kan \u00e5terg\u00e5 till att anv\u00e4nda standard firewalld genom att helt enkelt backa dessa f\u00f6r\u00e4ndringar.","title":"Slutsats"},{"location":"guides/security/firewalld-beginners.fr/","text":"pare-feu pour les d\u00e9butants Introduction Il y a longtemps, j'\u00e9tais un petit utilisateur d'ordinateur d\u00e9butant qui a entendu dire qu'avoir un pare-feu \u00e9tait suppos\u00e9 \u00eatre super bon. Il me permettait de d\u00e9cider ce qui est entr\u00e9, et ce qui est sorti de mon ordinateur, non ? Mais il semblait surtout emp\u00eacher mes jeux vid\u00e9o d'acc\u00e9der \u00e0 Internet ; j'\u00e9tais pas un campeur heureux. Bien s\u00fbr, si vous \u00eates l\u00e0, vous avez probablement une meilleure id\u00e9e de ce qu'est un pare-feu et de ce qu'il fait que je ne l'ai fait. Mais si votre exp\u00e9rience de pare-feu revient \u00e0 dire \u00e0 Windows Defender que oui, pour l'amour de tout ce qui est saint, votre nouvelle application est autoris\u00e9e \u00e0 utiliser Internet, ne vous inqui\u00e9tez pas. Cela dit \"pour les d\u00e9butants\" vers le haut, je vous ai. En d'autres termes, mes coll\u00e8gues devraient savoir qu'il y aura beaucoup d'explications \u00e0 apporter. Alors, parlons de ce que nous sommes ici. firewalld est l'application de pare-feu par d\u00e9faut empaquet\u00e9e avec Rocky Linux, et elle est con\u00e7ue pour \u00eatre assez simple \u00e0 utiliser. Vous devez juste en savoir un peu sur le fonctionnement des pare-feu, et ne pas avoir peur d'utiliser la ligne de commande. Ici tu apprendras : Les bases m\u00eames de la fa\u00e7on dont pare-feu fonctionne Comment utiliser pare-feu pour restreindre ou autoriser les connexions entrantes et sortantes Comment autoriser uniquement les personnes de certaines adresses IP ou lieux \u00e0 se connecter \u00e0 distance \u00e0 votre machine Comment g\u00e9rer certaines fonctionnalit\u00e9s sp\u00e9cifiques \u00e0 pare-feu comme les Zones. Ceci est non pr\u00e9vu pour \u00eatre un guide complet ou exhaustif. Une note sur l'utilisation de la ligne de commande pour g\u00e9rer votre pare-feu Eh bien... il y a options de configuration du pare-feu graphique. Sur le bureau, il y a firewall-config qui peut \u00eatre install\u00e9 \u00e0 partir des d\u00e9p\u00f4ts, et sur les serveurs, vous pouvez installer Cockpit pour vous aider \u00e0 g\u00e9rer les pare-feu et toute une s\u00e9rie d'autres choses. Cependant, je vais vous enseigner la fa\u00e7on de faire des choses en ligne de commande dans ce tutoriel pour deux raisons :** Si vous utilisez un serveur, vous utiliserez la ligne de commande pour la plupart de ces choses. De nombreux tutoriels et guides pour le serveur Rocky donneront des instructions en ligne de commande pour la gestion du pare-feu, et il est pr\u00e9f\u00e9rable que vous compreniez ces instructions, plut\u00f4t que de simplement copier et coller ce que vous voyez. Comprendre comment les commandes coupe-feu fonctionnent peut vous aider \u00e0 mieux comprendre comment fonctionne le logiciel de pare-feu. Vous pouvez prendre les m\u00eames principes que vous apprenez ici, et avez une meilleure id\u00e9e de ce que vous faites si vous d\u00e9cidez d'utiliser une interface graphique dans le futur. Pr\u00e9requis et hypoth\u00e8ses Vous aurez besoin de : Une machine Rocky Linux de toute sorte, locale ou distante, physique ou virtuelle Acc\u00e8s au terminal et volont\u00e9 de l'utiliser Vous avez besoin d'un acc\u00e8s root, ou au moins de la possibilit\u00e9 d'utiliser sudo sur votre compte utilisateur. Pour des raisons de simplicit\u00e9, je suppose que toutes les commandes sont ex\u00e9cut\u00e9es en tant que root. Une compr\u00e9hension de base de SSH ne ferait pas de mal \u00e0 la gestion de machines distantes. Utilisation de base Commandes de service syst\u00e8me le pare-feu est ex\u00e9cut\u00e9 en tant que service sur votre machine. Il d\u00e9marre quand la machine le fait, ou il devrait. Si, pour une raison quelconque, le pare-feu n'est pas d\u00e9j\u00e0 activ\u00e9 sur votre machine, vous pouvez le faire avec une simple commande : systemctl active --now firewalld Le drapeau --now d\u00e9marre le service d\u00e8s qu'il est activ\u00e9, et vous sautez l'\u00e9tape systemctl d\u00e9marre pare-feu . Comme pour tous les services sur Rocky Linux, vous pouvez v\u00e9rifier si le pare-feu fonctionne avec : \u00e9tat du pare-feu syst\u00e8me Pour l'arr\u00eater enti\u00e8rement: arr\u00eater le pare-feu syst\u00e8me Et pour donner au service un red\u00e9marrage dur : systemctl red\u00e9marre le pare-feu Commandes de configuration et de gestion de pare-feu de base le pare-feu est configur\u00e9 avec la commande firewall-cmd . Vous pouvez, par exemple, v\u00e9rifier l'\u00e9tat du pare-feu avec : firewall-cmd --state Apr\u00e8s chaque changement permanent de votre pare-feu, vous devrez le recharger pour voir les changements. Vous pouvez donner aux configurations du pare-feu un \"red\u00e9marrage doux\" avec: firewall-cmd --reload !!! Note Si vous rechargez vos configurations qui n'ont pas \u00e9t\u00e9 rendues permanentes, elles dispara\u00eetront sur vous. Vous pouvez voir toutes vos configurations et param\u00e8tres en m\u00eame temps avec: firewall-cmd --list-all Cette commande affichera quelque chose qui ressemble \u00e0 ceci : public (actif) target : default icmp-block-inversion: no interfaces: enp9s0 sources: services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Enregistrement de vos modifications !!! Avertissement \"Attention : s\u00e9rieusement, lisez ceci suivant.\" Par d\u00e9faut, toutes les modifications apport\u00e9es \u00e0 la configuration de `firewalld` sont temporaires. Si vous red\u00e9marrez tout le service `firewalld`, ou red\u00e9marrez votre machine, aucun de vos changements au pare-feu ne sera sauvegard\u00e9 \u00e0 moins que vous ne fassiez une des deux choses tr\u00e8s sp\u00e9cifiques. Il est pr\u00e9f\u00e9rable de tester tous vos changements un par un, rechargeant la configuration de votre pare-feu au fur et \u00e0 mesure. Ainsi, si vous vous enfermez accidentellement de quoi que ce soit, vous pouvez red\u00e9marrer le service (ou la machine), tous ces changements disparaissent comme mentionn\u00e9 ci-dessus. Mais une fois que vous avez une configuration fonctionnelle, vous pouvez enregistrer vos modifications de fa\u00e7on permanente avec: firewall-cmd --runtime-to-permanent Cependant, si vous \u00eates absolument s\u00fbr de ce que vous faites, et si vous voulez juste ajouter la r\u00e8gle et aller de l'avant avec votre vie, vous pouvez ajouter le drapeau --permanent \u00e0 n'importe quelle commande de configuration : firewall-cmd --permanent [le reste de votre commande] Gestion des Zones Avant toute chose, je dois expliquer les zones. Les zones sont une fonctionnalit\u00e9 qui vous permet essentiellement de d\u00e9finir diff\u00e9rents ensembles de r\u00e8gles pour diff\u00e9rentes situations. Les zones sont une grande partie du pare-feu donc il est payant de comprendre comment elles fonctionnent. Si votre machine a plusieurs fa\u00e7ons de se connecter \u00e0 diff\u00e9rents r\u00e9seaux (par ex. Ethernet et WiFi), vous pouvez d\u00e9cider qu'une connexion est plus fiable que l'autre. Vous pouvez configurer votre connexion Ethernet dans la zone \u00ab fiable \u00bb si elle est uniquement connect\u00e9e \u00e0 un r\u00e9seau local que vous avez construit, et mettre le WiFi (qui pourrait \u00eatre connect\u00e9 \u00e0 l'internet) dans la zone \"public\" avec des restrictions plus strictes. !!! Note Une zone peut *seulement* \u00eatre dans un \u00e9tat actif si elle a l'une de ces deux conditions : 1. La zone est assign\u00e9e \u00e0 une interface r\u00e9seau 2. La zone est affect\u00e9e aux adresses IP sources ou aux plages de r\u00e9seau. (En savoir plus sur cela ci-dessous) Les zones par d\u00e9faut incluent ce qui suit (j'ai pris cette explication du guide de DigitalOcean au pare-feu , que vous devriez \u00e9galement lire): drop : Le niveau de confiance le plus bas. Toutes les connexions entrantes sont abandonn\u00e9es sans r\u00e9ponse et seules les connexions sortantes sont possibles. bloc : Similaire \u00e0 ce qui pr\u00e9c\u00e8de, mais au lieu de simplement supprimer les connexions, les requ\u00eates entrantes sont rejet\u00e9es avec un message icmp-host-interdit ou icmp6-adm-prohib\u00e9. public : Repr\u00e9sente des r\u00e9seaux publics non fiables. Vous ne faites pas confiance aux autres ordinateurs, mais vous pouvez autoriser certaines connexions entrantes au cas par cas. externe: R\u00e9seaux externes dans l'\u00e9ventualit\u00e9 o\u00f9 vous utilisez le pare-feu comme passerelle. Il est configur\u00e9 pour le masquage NAT afin que votre r\u00e9seau interne reste priv\u00e9 mais accessible. interne : L'autre c\u00f4t\u00e9 de la zone externe, utilis\u00e9 pour la partie interne d'une passerelle. Les ordinateurs sont assez fiables et certains services suppl\u00e9mentaires sont disponibles. dmz : Utilis\u00e9 pour les ordinateurs situ\u00e9s dans une DMZ (ordinateurs isol\u00e9s qui n'auront pas acc\u00e8s au reste de votre r\u00e9seau). Seules certaines connexions entrantes sont autoris\u00e9es. travail : Utilis\u00e9 pour les machines de travail. Faites confiance \u00e0 la plupart des ordinateurs du r\u00e9seau. Quelques services suppl\u00e9mentaires pourraient \u00eatre autoris\u00e9s. maison : Un environnement domestique. Cela implique g\u00e9n\u00e9ralement que vous faites confiance \u00e0 la plupart des autres ordinateurs et que quelques autres services seront accept\u00e9s. confiance : Faites confiance \u00e0 toutes les machines du r\u00e9seau. Le plus ouvert des options disponibles et devrait \u00eatre utilis\u00e9 avec mod\u00e9ration. Ok, donc certaines de ces explications sont compliqu\u00e9es, mais honn\u00eatement? Le d\u00e9butant moyen peut se passer avec la compr\u00e9hension \"fiable\", \"maison\", et \"public\", et quand utiliser lequel. Commandes de gestion de zone Pour voir votre zone par d\u00e9faut, ex\u00e9cutez : pare-feu-cmd --get-default-zone Pour voir quelles zones sont actives et faire des choses, ex\u00e9cutez : firewall-cmd --get-active-zones !!! Note : \u00ab Note : certaines choses peuvent avoir \u00e9t\u00e9 faites pour vous.\u00bb Si vous utilisez Rocky Linux sur un VPS, il est probable qu'une configuration de base ait \u00e9t\u00e9 mise en place pour vous. Plus pr\u00e9cis\u00e9ment, vous devriez pouvoir acc\u00e9der au serveur via SSH, et l'interface r\u00e9seau aura d\u00e9j\u00e0 \u00e9t\u00e9 ajout\u00e9e \u00e0 la zone \"publique\". Pour changer la zone par d\u00e9faut : firewall-cmd --set-default-zone [your-zone] Pour ajouter une interface r\u00e9seau \u00e0 une zone : firewall-cmd --zone=[your-zone] --add-interface=[your-network-device] Pour changer la zone d'une interface r\u00e9seau : firewall-cmd --zone=[your-zone] --change-interface=[your-network-device] Pour supprimer compl\u00e8tement une interface d'une zone : firewall-cmd --zone=[your-zone] --remove-interface=[your-network-device] Pour cr\u00e9er votre propre nouvelle zone avec un ensemble de r\u00e8gles enti\u00e8rement personnalis\u00e9, et pour v\u00e9rifier qu'elle a \u00e9t\u00e9 correctement ajout\u00e9e : firewall-cmd --new-zone=[your-new-zone] pare-feu-cmd --get-zones Gestion des ports Pour les ports non initi\u00e9s, les ports (dans ce contexte) ne sont que des terminaux virtuels o\u00f9 les ordinateurs se connectent les uns aux autres afin qu'ils puissent envoyer des informations de retour et de suite. Pensez \u00e0 ces ports physiques Ethernet ou USB sur votre ordinateur, mais invisible, et vous pouvez avoir jusqu'\u00e0 65,535 d'entre eux vont tous en m\u00eame temps. Je ne le ferais pas, mais vous le pouvez. Chaque port est d\u00e9fini par un num\u00e9ro, et certains ports sont r\u00e9serv\u00e9s \u00e0 des services sp\u00e9cifiques et \u00e0 des types d'informations. Si vous avez d\u00e9j\u00e0 travaill\u00e9 avec des serveurs web pour construire un site Web, par exemple, vous \u00eates peut-\u00eatre familier avec le port 80 et le port 443. Ces ports permettent la transmission des donn\u00e9es des pages Web. Plus pr\u00e9cis\u00e9ment, le port 80 permet le transfert de donn\u00e9es via le protocole de transfert Hypertext (HTTP), et le port 443 est r\u00e9serv\u00e9 aux donn\u00e9es Hypertext Transfer Protocol Secure (HTTPS). * Le port 22 est r\u00e9serv\u00e9 au protocole Secure Shell (SSH) qui vous permet de vous connecter et de g\u00e9rer d'autres machines via la ligne de commande (voir notre court guide sur le suject). tout nouveau serveur distant peut seulement autoriser les connexions sur le port 22 pour SSH, et rien d'autre. D'autres exemples incluent FTP (ports 20 et 21), SSH (port 22), et bien d'autres. Vous pouvez \u00e9galement d\u00e9finir des ports personnalis\u00e9s \u00e0 utiliser par les nouvelles applications que vous pouvez installer, qui n'ont pas d\u00e9j\u00e0 de num\u00e9ro standard. !!! Note : \"Note: Vous ne devriez pas utiliser de ports pour tout.\" Pour des choses comme SSH, HTTP/S, FTP, et plus encore, il est recommand\u00e9 de les ajouter \u00e0 votre zone de pare-feu en tant que *services* et non en tant que num\u00e9ros de port. Je vais vous montrer comment cela fonctionne ci-dessous. Cela dit, vous devez toujours savoir comment ouvrir les ports manuellement. * Pour les d\u00e9butants absolus, HTTPS est essentiellement (plus ou moins) la m\u00eame chose que HTTP, mais chiffr\u00e9. Commandes de gestion du port Pour cette section, je vais utiliser --zone=public ... et le port 9001 comme exemple al\u00e9atoire, car il est plus de 9 000. Pour voir tous les ports ouverts : firewall-cmd --list-ports Pour ajouter un port \u00e0 votre zone de pare-feu (donc l'ouvrir pour l'utilisation), lancez simplement cette commande : firewall-cmd --zone=public --add-port=9001/tcp !!! Note \u00c0 propos de cet bit `/tcp` : Ce bit `/tcp` \u00e0 la fin indique au pare-feu que les connexions entreront par le protocole de contr\u00f4le de transfert, qui est ce que vous utiliserez pour la plupart des choses li\u00e9es au serveur et \u00e0 la maison. Les alternatives comme UDP sont pour le d\u00e9bogage, ou d'autres types de choses tr\u00e8s sp\u00e9cifiques qui, franchement, ne sont pas dans la port\u00e9e de ce guide. Reportez-vous \u00e0 la documentation de n'importe quelle application ou service pour lequel vous souhaitez ouvrir un port. Pour supprimer un port, renversez simplement la commande avec un seul mot : firewall-cmd --zone=public --remove-port=9001/tcp Gestion des services Les services, comme vous pouvez l'imaginer, sont des programmes normalis\u00e9s qui s'ex\u00e9cutent sur votre ordinateur. firewalld est configur\u00e9 pour qu'il puisse juste ouvrir la voie \u00e0 la plupart des services communs chaque fois que vous en avez besoin. C'est la meilleure fa\u00e7on d'ouvrir les ports \u00e0 ces services communs, et bien plus encore: HTTP et HTTPS : pour les serveurs web FTP: Pour d\u00e9placer des fichiers (anciennement fa\u00e7onn\u00e9) SSH : Pour contr\u00f4ler les machines distantes et d\u00e9placer les fichiers \u00e0 badigeonner la nouvelle fa\u00e7on Samba: Pour partager des fichiers avec des machines Windows !!! Warning **Ne supprimez jamais le service SSH du pare-feu d'un serveur distant !** Rappelez-vous, SSH est ce que vous utilisez pour vous connecter \u00e0 votre serveur. Sauf si vous avez un autre moyen d'acc\u00e9der au serveur physique, ou son shell (c'est \u00e0 dire via. un panneau de contr\u00f4le fourni par l'h\u00f4te), la suppression du service SSH vous bloquera d\u00e9finitivement. Vous devrez soit contacter le support pour r\u00e9cup\u00e9rer votre acc\u00e8s, soit r\u00e9installer compl\u00e8tement le syst\u00e8me d'exploitation. Commandes de gestion du service Pour voir une liste de tous les services disponibles que vous pourriez \u00e9ventuellement ajouter \u00e0 votre pare-feu, ex\u00e9cutez : firewall-cmd --get-services Pour voir quels services vous avez actuellement actifs sur votre pare-feu, utilisez : firewall-cmd --list-services Pour ouvrir un service dans votre pare-feu (par exemple HTTP dans la zone publique), utilisez : firewall-cmd --zone=public --add-service=http Pour supprimer/fermer un service sur votre pare-feu, changez simplement un mot \u00e0 nouveau: firewall-cmd --zone=public --remove-service=http !!! Note \"Note: Vous pouvez ajouter vos propres services\" Et personnalisez aussi le coup de foudre de ceux-ci. Cependant, c'est un sujet qui devient complexe. Familiarisez-vous d'abord avec `firewalld` et allez de l\u00e0. Restreindre l'acc\u00e8s Disons que vous avez un serveur, et que vous ne voulez pas le rendre public. si vous voulez d\u00e9finir juste qui est autoris\u00e9 \u00e0 y acc\u00e9der via SSH, ou voir quelques pages web priv\u00e9es, vous pouvez le faire. Il y a quelques m\u00e9thodes pour y parvenir. Premi\u00e8rement, pour un serveur plus verrouill\u00e9, vous pouvez choisir une des zones les plus restrictives, assigner votre p\u00e9riph\u00e9rique r\u00e9seau \u00e0 elle, ajouter le service SSH comme indiqu\u00e9 ci-dessus, puis ajouter votre propre adresse IP publique comme suit: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0 [< insert your IP here] Vous pouvez en faire une plage d'adresses IP en ajoutant un nombre plus \u00e9lev\u00e9 \u00e0 la fin comme suit: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0/24 [< insert your IP here] Encore une fois, il suffit de changer --add-source \u00e0 --remove-source pour inverser le processus. Cependant, si vous g\u00e9rez un serveur distant avec un site web qui doit \u00eatre public, et vous ne voulez toujours ouvrir SSH que pour une adresse IP ou une petite gamme d'entre eux, vous avez quelques options. Dans ces deux exemples, la seule interface r\u00e9seau est affect\u00e9e \u00e0 la zone publique. Tout d'abord, vous pouvez utiliser une \"r\u00e8gle riche\" dans votre zone publique, et cela ressemblerait \u00e0 ceci: # firewall-cmd --permanent --zone=public --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept' Une fois que la r\u00e8gle riche est en place, ne faites pas que les r\u00e8gles soient permanentes. Tout d'abord, retirez le service SSH de la configuration de la zone publique et testez votre connexion pour vous assurer que vous pouvez toujours acc\u00e9der au serveur via SSH. Votre configuration devrait maintenant ressembler \u00e0 ceci: your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: rule family=\"ipv4\" source address=\"192. 68.1.0/24\" service name=\"ssh\" accepter Deuxi\u00e8mement, vous pouvez utiliser deux zones diff\u00e9rentes \u00e0 la fois. Si vous avez votre interface li\u00e9e \u00e0 la zone publique, vous pouvez activer une seconde zone (la zone \"confi\u00e9e\" par exemple) en y ajoutant une IP source ou une plage IP comme indiqu\u00e9 ci-dessus. Ensuite, ajoutez le service SSH \u00e0 la zone de confiance et retirez-le de la zone publique. Lorsque vous avez termin\u00e9, la sortie devrait ressembler \u00e0 ceci : your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: your@server ~# firewall-cmd --list-all --zone=trusted trusted (active) target: default icmp-block-inversion: no interfaces: sources: 192. 68.0.0/24 services : ssh ports : protocoles : en avant : no masquerade: no ports en avant : ports sources: blocs icmp: r\u00e8gles riches: Si vous \u00eates bloqu\u00e9, red\u00e9marrez le serveur (la plupart des panneaux de contr\u00f4le VPS ont une option pour cela) et r\u00e9essayez. !!! Warning Ces techniques ne fonctionnent que si vous avez une adresse IP statique. Si vous \u00eates bloqu\u00e9 avec un fournisseur de service Internet qui change votre adresse IP chaque fois que votre modem red\u00e9marre, n'utilisez pas ces r\u00e8gles (au moins pas pour SSH) jusqu'\u00e0 ce que vous ayez un correctif pour cela. Vous vous fermerez hors de votre serveur Soit mettre \u00e0 niveau votre plan/fournisseur Internet, ou obtenez un VPN qui vous fournit une adresse IP d\u00e9di\u00e9e, et *jamais* jamais* de la perdre. En attendant, [installer et configurer fail2ban](https://wiki.crowncloud.net/?How_to_Install_Fail2Ban_on_RockyLinux_8), qui peut aider \u00e0 r\u00e9duire les attaques par force brute. \u00c9videmment, sur un r\u00e9seau local que vous contr\u00f4lez (et o\u00f9 vous pouvez d\u00e9finir l'adresse IP de chaque machine manuellement), vous pouvez utiliser toutes ces r\u00e8gles autant que vous le souhaitez. Notes Finales C'est loin d'\u00eatre un guide exhaustif, et vous pouvez en apprendre beaucoup plus avec la documentation officielle `` coupe-feu . Il y a \u00e9galement des guides pratiques sp\u00e9cifiques \u00e0 des applications sur Internet qui vous montreront comment configurer votre pare-feu pour ces applications sp\u00e9cifiques. Pour vous les fans de iptables (si vous avez r\u00e9ussi jusqu'ici... , nous avons un guide d\u00e9taillant certaines des diff\u00e9rences dans le fonctionnement de firewalld et iptables . Ce guide pourrait vous aider \u00e0 comprendre si vous voulez rester avec pare-feu ou retourner \u00e0 The Old Ways (TM) . Il y a quelque chose \u00e0 dire pour The Old Ways (TM) , dans ce cas. Conclusion Et c'est coupe-feu en aussi peu de mots que je pourrais le g\u00e9rer tout en expliquant tous les bases. Prenez-le lent, exp\u00e9rimentez prudemment et ne rendez aucune r\u00e8gle permanente tant que vous ne savez pas qu'elle fonctionne. Et, vous savez, amusez-vous bien. Une fois que vous avez les bases en bas, mettre en place un pare-feu d\u00e9cent et r\u00e9alisable peut prendre 5-10 minutes.","title":"pare-feu pour les d\u00e9butants"},{"location":"guides/security/firewalld-beginners.fr/#pare-feu-pour-les-debutants","text":"","title":"pare-feu pour les d\u00e9butants"},{"location":"guides/security/firewalld-beginners.fr/#introduction","text":"Il y a longtemps, j'\u00e9tais un petit utilisateur d'ordinateur d\u00e9butant qui a entendu dire qu'avoir un pare-feu \u00e9tait suppos\u00e9 \u00eatre super bon. Il me permettait de d\u00e9cider ce qui est entr\u00e9, et ce qui est sorti de mon ordinateur, non ? Mais il semblait surtout emp\u00eacher mes jeux vid\u00e9o d'acc\u00e9der \u00e0 Internet ; j'\u00e9tais pas un campeur heureux. Bien s\u00fbr, si vous \u00eates l\u00e0, vous avez probablement une meilleure id\u00e9e de ce qu'est un pare-feu et de ce qu'il fait que je ne l'ai fait. Mais si votre exp\u00e9rience de pare-feu revient \u00e0 dire \u00e0 Windows Defender que oui, pour l'amour de tout ce qui est saint, votre nouvelle application est autoris\u00e9e \u00e0 utiliser Internet, ne vous inqui\u00e9tez pas. Cela dit \"pour les d\u00e9butants\" vers le haut, je vous ai. En d'autres termes, mes coll\u00e8gues devraient savoir qu'il y aura beaucoup d'explications \u00e0 apporter. Alors, parlons de ce que nous sommes ici. firewalld est l'application de pare-feu par d\u00e9faut empaquet\u00e9e avec Rocky Linux, et elle est con\u00e7ue pour \u00eatre assez simple \u00e0 utiliser. Vous devez juste en savoir un peu sur le fonctionnement des pare-feu, et ne pas avoir peur d'utiliser la ligne de commande. Ici tu apprendras : Les bases m\u00eames de la fa\u00e7on dont pare-feu fonctionne Comment utiliser pare-feu pour restreindre ou autoriser les connexions entrantes et sortantes Comment autoriser uniquement les personnes de certaines adresses IP ou lieux \u00e0 se connecter \u00e0 distance \u00e0 votre machine Comment g\u00e9rer certaines fonctionnalit\u00e9s sp\u00e9cifiques \u00e0 pare-feu comme les Zones. Ceci est non pr\u00e9vu pour \u00eatre un guide complet ou exhaustif.","title":"Introduction"},{"location":"guides/security/firewalld-beginners.fr/#une-note-sur-lutilisation-de-la-ligne-de-commande-pour-gerer-votre-pare-feu","text":"Eh bien... il y a options de configuration du pare-feu graphique. Sur le bureau, il y a firewall-config qui peut \u00eatre install\u00e9 \u00e0 partir des d\u00e9p\u00f4ts, et sur les serveurs, vous pouvez installer Cockpit pour vous aider \u00e0 g\u00e9rer les pare-feu et toute une s\u00e9rie d'autres choses. Cependant, je vais vous enseigner la fa\u00e7on de faire des choses en ligne de commande dans ce tutoriel pour deux raisons :** Si vous utilisez un serveur, vous utiliserez la ligne de commande pour la plupart de ces choses. De nombreux tutoriels et guides pour le serveur Rocky donneront des instructions en ligne de commande pour la gestion du pare-feu, et il est pr\u00e9f\u00e9rable que vous compreniez ces instructions, plut\u00f4t que de simplement copier et coller ce que vous voyez. Comprendre comment les commandes coupe-feu fonctionnent peut vous aider \u00e0 mieux comprendre comment fonctionne le logiciel de pare-feu. Vous pouvez prendre les m\u00eames principes que vous apprenez ici, et avez une meilleure id\u00e9e de ce que vous faites si vous d\u00e9cidez d'utiliser une interface graphique dans le futur.","title":"Une note sur l'utilisation de la ligne de commande pour g\u00e9rer votre pare-feu"},{"location":"guides/security/firewalld-beginners.fr/#prerequis-et-hypotheses","text":"Vous aurez besoin de : Une machine Rocky Linux de toute sorte, locale ou distante, physique ou virtuelle Acc\u00e8s au terminal et volont\u00e9 de l'utiliser Vous avez besoin d'un acc\u00e8s root, ou au moins de la possibilit\u00e9 d'utiliser sudo sur votre compte utilisateur. Pour des raisons de simplicit\u00e9, je suppose que toutes les commandes sont ex\u00e9cut\u00e9es en tant que root. Une compr\u00e9hension de base de SSH ne ferait pas de mal \u00e0 la gestion de machines distantes.","title":"Pr\u00e9requis et hypoth\u00e8ses"},{"location":"guides/security/firewalld-beginners.fr/#utilisation-de-base","text":"","title":"Utilisation de base"},{"location":"guides/security/firewalld-beginners.fr/#commandes-de-service-systeme","text":"le pare-feu est ex\u00e9cut\u00e9 en tant que service sur votre machine. Il d\u00e9marre quand la machine le fait, ou il devrait. Si, pour une raison quelconque, le pare-feu n'est pas d\u00e9j\u00e0 activ\u00e9 sur votre machine, vous pouvez le faire avec une simple commande : systemctl active --now firewalld Le drapeau --now d\u00e9marre le service d\u00e8s qu'il est activ\u00e9, et vous sautez l'\u00e9tape systemctl d\u00e9marre pare-feu . Comme pour tous les services sur Rocky Linux, vous pouvez v\u00e9rifier si le pare-feu fonctionne avec : \u00e9tat du pare-feu syst\u00e8me Pour l'arr\u00eater enti\u00e8rement: arr\u00eater le pare-feu syst\u00e8me Et pour donner au service un red\u00e9marrage dur : systemctl red\u00e9marre le pare-feu","title":"Commandes de service syst\u00e8me"},{"location":"guides/security/firewalld-beginners.fr/#commandes-de-configuration-et-de-gestion-de-pare-feu-de-base","text":"le pare-feu est configur\u00e9 avec la commande firewall-cmd . Vous pouvez, par exemple, v\u00e9rifier l'\u00e9tat du pare-feu avec : firewall-cmd --state Apr\u00e8s chaque changement permanent de votre pare-feu, vous devrez le recharger pour voir les changements. Vous pouvez donner aux configurations du pare-feu un \"red\u00e9marrage doux\" avec: firewall-cmd --reload !!! Note Si vous rechargez vos configurations qui n'ont pas \u00e9t\u00e9 rendues permanentes, elles dispara\u00eetront sur vous. Vous pouvez voir toutes vos configurations et param\u00e8tres en m\u00eame temps avec: firewall-cmd --list-all Cette commande affichera quelque chose qui ressemble \u00e0 ceci : public (actif) target : default icmp-block-inversion: no interfaces: enp9s0 sources: services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules:","title":"Commandes de configuration et de gestion de pare-feu de base"},{"location":"guides/security/firewalld-beginners.fr/#enregistrement-de-vos-modifications","text":"!!! Avertissement \"Attention : s\u00e9rieusement, lisez ceci suivant.\" Par d\u00e9faut, toutes les modifications apport\u00e9es \u00e0 la configuration de `firewalld` sont temporaires. Si vous red\u00e9marrez tout le service `firewalld`, ou red\u00e9marrez votre machine, aucun de vos changements au pare-feu ne sera sauvegard\u00e9 \u00e0 moins que vous ne fassiez une des deux choses tr\u00e8s sp\u00e9cifiques. Il est pr\u00e9f\u00e9rable de tester tous vos changements un par un, rechargeant la configuration de votre pare-feu au fur et \u00e0 mesure. Ainsi, si vous vous enfermez accidentellement de quoi que ce soit, vous pouvez red\u00e9marrer le service (ou la machine), tous ces changements disparaissent comme mentionn\u00e9 ci-dessus. Mais une fois que vous avez une configuration fonctionnelle, vous pouvez enregistrer vos modifications de fa\u00e7on permanente avec: firewall-cmd --runtime-to-permanent Cependant, si vous \u00eates absolument s\u00fbr de ce que vous faites, et si vous voulez juste ajouter la r\u00e8gle et aller de l'avant avec votre vie, vous pouvez ajouter le drapeau --permanent \u00e0 n'importe quelle commande de configuration : firewall-cmd --permanent [le reste de votre commande]","title":"Enregistrement de vos modifications"},{"location":"guides/security/firewalld-beginners.fr/#gestion-des-zones","text":"Avant toute chose, je dois expliquer les zones. Les zones sont une fonctionnalit\u00e9 qui vous permet essentiellement de d\u00e9finir diff\u00e9rents ensembles de r\u00e8gles pour diff\u00e9rentes situations. Les zones sont une grande partie du pare-feu donc il est payant de comprendre comment elles fonctionnent. Si votre machine a plusieurs fa\u00e7ons de se connecter \u00e0 diff\u00e9rents r\u00e9seaux (par ex. Ethernet et WiFi), vous pouvez d\u00e9cider qu'une connexion est plus fiable que l'autre. Vous pouvez configurer votre connexion Ethernet dans la zone \u00ab fiable \u00bb si elle est uniquement connect\u00e9e \u00e0 un r\u00e9seau local que vous avez construit, et mettre le WiFi (qui pourrait \u00eatre connect\u00e9 \u00e0 l'internet) dans la zone \"public\" avec des restrictions plus strictes. !!! Note Une zone peut *seulement* \u00eatre dans un \u00e9tat actif si elle a l'une de ces deux conditions : 1. La zone est assign\u00e9e \u00e0 une interface r\u00e9seau 2. La zone est affect\u00e9e aux adresses IP sources ou aux plages de r\u00e9seau. (En savoir plus sur cela ci-dessous) Les zones par d\u00e9faut incluent ce qui suit (j'ai pris cette explication du guide de DigitalOcean au pare-feu , que vous devriez \u00e9galement lire): drop : Le niveau de confiance le plus bas. Toutes les connexions entrantes sont abandonn\u00e9es sans r\u00e9ponse et seules les connexions sortantes sont possibles. bloc : Similaire \u00e0 ce qui pr\u00e9c\u00e8de, mais au lieu de simplement supprimer les connexions, les requ\u00eates entrantes sont rejet\u00e9es avec un message icmp-host-interdit ou icmp6-adm-prohib\u00e9. public : Repr\u00e9sente des r\u00e9seaux publics non fiables. Vous ne faites pas confiance aux autres ordinateurs, mais vous pouvez autoriser certaines connexions entrantes au cas par cas. externe: R\u00e9seaux externes dans l'\u00e9ventualit\u00e9 o\u00f9 vous utilisez le pare-feu comme passerelle. Il est configur\u00e9 pour le masquage NAT afin que votre r\u00e9seau interne reste priv\u00e9 mais accessible. interne : L'autre c\u00f4t\u00e9 de la zone externe, utilis\u00e9 pour la partie interne d'une passerelle. Les ordinateurs sont assez fiables et certains services suppl\u00e9mentaires sont disponibles. dmz : Utilis\u00e9 pour les ordinateurs situ\u00e9s dans une DMZ (ordinateurs isol\u00e9s qui n'auront pas acc\u00e8s au reste de votre r\u00e9seau). Seules certaines connexions entrantes sont autoris\u00e9es. travail : Utilis\u00e9 pour les machines de travail. Faites confiance \u00e0 la plupart des ordinateurs du r\u00e9seau. Quelques services suppl\u00e9mentaires pourraient \u00eatre autoris\u00e9s. maison : Un environnement domestique. Cela implique g\u00e9n\u00e9ralement que vous faites confiance \u00e0 la plupart des autres ordinateurs et que quelques autres services seront accept\u00e9s. confiance : Faites confiance \u00e0 toutes les machines du r\u00e9seau. Le plus ouvert des options disponibles et devrait \u00eatre utilis\u00e9 avec mod\u00e9ration. Ok, donc certaines de ces explications sont compliqu\u00e9es, mais honn\u00eatement? Le d\u00e9butant moyen peut se passer avec la compr\u00e9hension \"fiable\", \"maison\", et \"public\", et quand utiliser lequel.","title":"Gestion des Zones"},{"location":"guides/security/firewalld-beginners.fr/#commandes-de-gestion-de-zone","text":"Pour voir votre zone par d\u00e9faut, ex\u00e9cutez : pare-feu-cmd --get-default-zone Pour voir quelles zones sont actives et faire des choses, ex\u00e9cutez : firewall-cmd --get-active-zones !!! Note : \u00ab Note : certaines choses peuvent avoir \u00e9t\u00e9 faites pour vous.\u00bb Si vous utilisez Rocky Linux sur un VPS, il est probable qu'une configuration de base ait \u00e9t\u00e9 mise en place pour vous. Plus pr\u00e9cis\u00e9ment, vous devriez pouvoir acc\u00e9der au serveur via SSH, et l'interface r\u00e9seau aura d\u00e9j\u00e0 \u00e9t\u00e9 ajout\u00e9e \u00e0 la zone \"publique\". Pour changer la zone par d\u00e9faut : firewall-cmd --set-default-zone [your-zone] Pour ajouter une interface r\u00e9seau \u00e0 une zone : firewall-cmd --zone=[your-zone] --add-interface=[your-network-device] Pour changer la zone d'une interface r\u00e9seau : firewall-cmd --zone=[your-zone] --change-interface=[your-network-device] Pour supprimer compl\u00e8tement une interface d'une zone : firewall-cmd --zone=[your-zone] --remove-interface=[your-network-device] Pour cr\u00e9er votre propre nouvelle zone avec un ensemble de r\u00e8gles enti\u00e8rement personnalis\u00e9, et pour v\u00e9rifier qu'elle a \u00e9t\u00e9 correctement ajout\u00e9e : firewall-cmd --new-zone=[your-new-zone] pare-feu-cmd --get-zones","title":"Commandes de gestion de zone"},{"location":"guides/security/firewalld-beginners.fr/#gestion-des-ports","text":"Pour les ports non initi\u00e9s, les ports (dans ce contexte) ne sont que des terminaux virtuels o\u00f9 les ordinateurs se connectent les uns aux autres afin qu'ils puissent envoyer des informations de retour et de suite. Pensez \u00e0 ces ports physiques Ethernet ou USB sur votre ordinateur, mais invisible, et vous pouvez avoir jusqu'\u00e0 65,535 d'entre eux vont tous en m\u00eame temps. Je ne le ferais pas, mais vous le pouvez. Chaque port est d\u00e9fini par un num\u00e9ro, et certains ports sont r\u00e9serv\u00e9s \u00e0 des services sp\u00e9cifiques et \u00e0 des types d'informations. Si vous avez d\u00e9j\u00e0 travaill\u00e9 avec des serveurs web pour construire un site Web, par exemple, vous \u00eates peut-\u00eatre familier avec le port 80 et le port 443. Ces ports permettent la transmission des donn\u00e9es des pages Web. Plus pr\u00e9cis\u00e9ment, le port 80 permet le transfert de donn\u00e9es via le protocole de transfert Hypertext (HTTP), et le port 443 est r\u00e9serv\u00e9 aux donn\u00e9es Hypertext Transfer Protocol Secure (HTTPS). * Le port 22 est r\u00e9serv\u00e9 au protocole Secure Shell (SSH) qui vous permet de vous connecter et de g\u00e9rer d'autres machines via la ligne de commande (voir notre court guide sur le suject). tout nouveau serveur distant peut seulement autoriser les connexions sur le port 22 pour SSH, et rien d'autre. D'autres exemples incluent FTP (ports 20 et 21), SSH (port 22), et bien d'autres. Vous pouvez \u00e9galement d\u00e9finir des ports personnalis\u00e9s \u00e0 utiliser par les nouvelles applications que vous pouvez installer, qui n'ont pas d\u00e9j\u00e0 de num\u00e9ro standard. !!! Note : \"Note: Vous ne devriez pas utiliser de ports pour tout.\" Pour des choses comme SSH, HTTP/S, FTP, et plus encore, il est recommand\u00e9 de les ajouter \u00e0 votre zone de pare-feu en tant que *services* et non en tant que num\u00e9ros de port. Je vais vous montrer comment cela fonctionne ci-dessous. Cela dit, vous devez toujours savoir comment ouvrir les ports manuellement. * Pour les d\u00e9butants absolus, HTTPS est essentiellement (plus ou moins) la m\u00eame chose que HTTP, mais chiffr\u00e9.","title":"Gestion des ports"},{"location":"guides/security/firewalld-beginners.fr/#commandes-de-gestion-du-port","text":"Pour cette section, je vais utiliser --zone=public ... et le port 9001 comme exemple al\u00e9atoire, car il est plus de 9 000. Pour voir tous les ports ouverts : firewall-cmd --list-ports Pour ajouter un port \u00e0 votre zone de pare-feu (donc l'ouvrir pour l'utilisation), lancez simplement cette commande : firewall-cmd --zone=public --add-port=9001/tcp !!! Note \u00c0 propos de cet bit `/tcp` : Ce bit `/tcp` \u00e0 la fin indique au pare-feu que les connexions entreront par le protocole de contr\u00f4le de transfert, qui est ce que vous utiliserez pour la plupart des choses li\u00e9es au serveur et \u00e0 la maison. Les alternatives comme UDP sont pour le d\u00e9bogage, ou d'autres types de choses tr\u00e8s sp\u00e9cifiques qui, franchement, ne sont pas dans la port\u00e9e de ce guide. Reportez-vous \u00e0 la documentation de n'importe quelle application ou service pour lequel vous souhaitez ouvrir un port. Pour supprimer un port, renversez simplement la commande avec un seul mot : firewall-cmd --zone=public --remove-port=9001/tcp","title":"Commandes de gestion du port"},{"location":"guides/security/firewalld-beginners.fr/#gestion-des-services","text":"Les services, comme vous pouvez l'imaginer, sont des programmes normalis\u00e9s qui s'ex\u00e9cutent sur votre ordinateur. firewalld est configur\u00e9 pour qu'il puisse juste ouvrir la voie \u00e0 la plupart des services communs chaque fois que vous en avez besoin. C'est la meilleure fa\u00e7on d'ouvrir les ports \u00e0 ces services communs, et bien plus encore: HTTP et HTTPS : pour les serveurs web FTP: Pour d\u00e9placer des fichiers (anciennement fa\u00e7onn\u00e9) SSH : Pour contr\u00f4ler les machines distantes et d\u00e9placer les fichiers \u00e0 badigeonner la nouvelle fa\u00e7on Samba: Pour partager des fichiers avec des machines Windows !!! Warning **Ne supprimez jamais le service SSH du pare-feu d'un serveur distant !** Rappelez-vous, SSH est ce que vous utilisez pour vous connecter \u00e0 votre serveur. Sauf si vous avez un autre moyen d'acc\u00e9der au serveur physique, ou son shell (c'est \u00e0 dire via. un panneau de contr\u00f4le fourni par l'h\u00f4te), la suppression du service SSH vous bloquera d\u00e9finitivement. Vous devrez soit contacter le support pour r\u00e9cup\u00e9rer votre acc\u00e8s, soit r\u00e9installer compl\u00e8tement le syst\u00e8me d'exploitation.","title":"Gestion des services"},{"location":"guides/security/firewalld-beginners.fr/#commandes-de-gestion-du-service","text":"Pour voir une liste de tous les services disponibles que vous pourriez \u00e9ventuellement ajouter \u00e0 votre pare-feu, ex\u00e9cutez : firewall-cmd --get-services Pour voir quels services vous avez actuellement actifs sur votre pare-feu, utilisez : firewall-cmd --list-services Pour ouvrir un service dans votre pare-feu (par exemple HTTP dans la zone publique), utilisez : firewall-cmd --zone=public --add-service=http Pour supprimer/fermer un service sur votre pare-feu, changez simplement un mot \u00e0 nouveau: firewall-cmd --zone=public --remove-service=http !!! Note \"Note: Vous pouvez ajouter vos propres services\" Et personnalisez aussi le coup de foudre de ceux-ci. Cependant, c'est un sujet qui devient complexe. Familiarisez-vous d'abord avec `firewalld` et allez de l\u00e0.","title":"Commandes de gestion du service"},{"location":"guides/security/firewalld-beginners.fr/#restreindre-lacces","text":"Disons que vous avez un serveur, et que vous ne voulez pas le rendre public. si vous voulez d\u00e9finir juste qui est autoris\u00e9 \u00e0 y acc\u00e9der via SSH, ou voir quelques pages web priv\u00e9es, vous pouvez le faire. Il y a quelques m\u00e9thodes pour y parvenir. Premi\u00e8rement, pour un serveur plus verrouill\u00e9, vous pouvez choisir une des zones les plus restrictives, assigner votre p\u00e9riph\u00e9rique r\u00e9seau \u00e0 elle, ajouter le service SSH comme indiqu\u00e9 ci-dessus, puis ajouter votre propre adresse IP publique comme suit: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0 [< insert your IP here] Vous pouvez en faire une plage d'adresses IP en ajoutant un nombre plus \u00e9lev\u00e9 \u00e0 la fin comme suit: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0/24 [< insert your IP here] Encore une fois, il suffit de changer --add-source \u00e0 --remove-source pour inverser le processus. Cependant, si vous g\u00e9rez un serveur distant avec un site web qui doit \u00eatre public, et vous ne voulez toujours ouvrir SSH que pour une adresse IP ou une petite gamme d'entre eux, vous avez quelques options. Dans ces deux exemples, la seule interface r\u00e9seau est affect\u00e9e \u00e0 la zone publique. Tout d'abord, vous pouvez utiliser une \"r\u00e8gle riche\" dans votre zone publique, et cela ressemblerait \u00e0 ceci: # firewall-cmd --permanent --zone=public --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept' Une fois que la r\u00e8gle riche est en place, ne faites pas que les r\u00e8gles soient permanentes. Tout d'abord, retirez le service SSH de la configuration de la zone publique et testez votre connexion pour vous assurer que vous pouvez toujours acc\u00e9der au serveur via SSH. Votre configuration devrait maintenant ressembler \u00e0 ceci: your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: rule family=\"ipv4\" source address=\"192. 68.1.0/24\" service name=\"ssh\" accepter Deuxi\u00e8mement, vous pouvez utiliser deux zones diff\u00e9rentes \u00e0 la fois. Si vous avez votre interface li\u00e9e \u00e0 la zone publique, vous pouvez activer une seconde zone (la zone \"confi\u00e9e\" par exemple) en y ajoutant une IP source ou une plage IP comme indiqu\u00e9 ci-dessus. Ensuite, ajoutez le service SSH \u00e0 la zone de confiance et retirez-le de la zone publique. Lorsque vous avez termin\u00e9, la sortie devrait ressembler \u00e0 ceci : your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: your@server ~# firewall-cmd --list-all --zone=trusted trusted (active) target: default icmp-block-inversion: no interfaces: sources: 192. 68.0.0/24 services : ssh ports : protocoles : en avant : no masquerade: no ports en avant : ports sources: blocs icmp: r\u00e8gles riches: Si vous \u00eates bloqu\u00e9, red\u00e9marrez le serveur (la plupart des panneaux de contr\u00f4le VPS ont une option pour cela) et r\u00e9essayez. !!! Warning Ces techniques ne fonctionnent que si vous avez une adresse IP statique. Si vous \u00eates bloqu\u00e9 avec un fournisseur de service Internet qui change votre adresse IP chaque fois que votre modem red\u00e9marre, n'utilisez pas ces r\u00e8gles (au moins pas pour SSH) jusqu'\u00e0 ce que vous ayez un correctif pour cela. Vous vous fermerez hors de votre serveur Soit mettre \u00e0 niveau votre plan/fournisseur Internet, ou obtenez un VPN qui vous fournit une adresse IP d\u00e9di\u00e9e, et *jamais* jamais* de la perdre. En attendant, [installer et configurer fail2ban](https://wiki.crowncloud.net/?How_to_Install_Fail2Ban_on_RockyLinux_8), qui peut aider \u00e0 r\u00e9duire les attaques par force brute. \u00c9videmment, sur un r\u00e9seau local que vous contr\u00f4lez (et o\u00f9 vous pouvez d\u00e9finir l'adresse IP de chaque machine manuellement), vous pouvez utiliser toutes ces r\u00e8gles autant que vous le souhaitez.","title":"Restreindre l'acc\u00e8s"},{"location":"guides/security/firewalld-beginners.fr/#notes-finales","text":"C'est loin d'\u00eatre un guide exhaustif, et vous pouvez en apprendre beaucoup plus avec la documentation officielle `` coupe-feu . Il y a \u00e9galement des guides pratiques sp\u00e9cifiques \u00e0 des applications sur Internet qui vous montreront comment configurer votre pare-feu pour ces applications sp\u00e9cifiques. Pour vous les fans de iptables (si vous avez r\u00e9ussi jusqu'ici... , nous avons un guide d\u00e9taillant certaines des diff\u00e9rences dans le fonctionnement de firewalld et iptables . Ce guide pourrait vous aider \u00e0 comprendre si vous voulez rester avec pare-feu ou retourner \u00e0 The Old Ways (TM) . Il y a quelque chose \u00e0 dire pour The Old Ways (TM) , dans ce cas.","title":"Notes Finales"},{"location":"guides/security/firewalld-beginners.fr/#conclusion","text":"Et c'est coupe-feu en aussi peu de mots que je pourrais le g\u00e9rer tout en expliquant tous les bases. Prenez-le lent, exp\u00e9rimentez prudemment et ne rendez aucune r\u00e8gle permanente tant que vous ne savez pas qu'elle fonctionne. Et, vous savez, amusez-vous bien. Une fois que vous avez les bases en bas, mettre en place un pare-feu d\u00e9cent et r\u00e9alisable peut prendre 5-10 minutes.","title":"Conclusion"},{"location":"guides/security/firewalld-beginners/","text":"firewalld for Beginners Introduction A long time ago, I was a little newbie computer user who heard that having a firewall was supposed to be super good. It would let me decide what got in, and what got out of my computer, right? But it mostly seemed to stop my video games from accessing the internet; I was not a happy camper. Of course, if you're here, you probably have a better idea what a firewall is and what it does than I did. But if your firewall experience amounts to telling Windows Defender that yes, for the love of all that is holy, your new app is allowed to use the internet, don't worry. It says \"for Beginners\" up top; I've got you. In other words, my fellow nerds should be aware that there will be a lot of explanations incoming. So let's talk about what we're here for. firewalld is the default firewall app packaged with Rocky Linux, and it's designed to be pretty simple to use. You just need to know a little bit about how firewalls work, and not be afraid to use the command line. Here you'll learn: The very basics of how firewalld works How to use firewalld to restrict or allow incoming and outgoing connections How to allow only people from certain IP addresses or places to log into your machine remotely How to manage some firewalld -specific features like Zones. This is not intended to be a complete or exhaustive guide. A note on using the command line for managing your firewall Well... there are graphical firewall configuration options. On the desktop, there's firewall-config which can be installed from the repos, and on servers you can install Cockpit to help you manage firewalls and a whole bunch of other stuff. However, I'll be teaching you the command-line way to do things in this tutorial for a couple of reasons: If you're running a server, you'll be using the command line for most of this stuff anyway. Lots of tutorials and guides for Rocky server will give command line instructions for firewall management, and it's best that you understand those instructions, rather than just copying and pasting whatever you see. Understanding how the firewalld commands work might help you better grasp how the firewall software works. You can take the same principles you learn here, and have a better idea what you're doing if you do decide to use a graphical interface in the future. Prerequisites and Assumptions You'll need: A Rocky Linux machine of any kind, local or remote, physical or virtual Access to the terminal, and a willingness to use it You need root access, or at least the ability to use sudo on your user account. For simplicity's sake, I'm assuming all commands are being run as root. A basic understanding of SSH wouldn't hurt for managing remote machines. Basic Usage System service commands firewalld is run as a service on your machine. It starts when the machine does, or it should. If for some reason firewalld is not already enabled on your machine, you can do that with a simple command: systemctl enable --now firewalld The --now flag starts the service as soon as its enabled, and let's you skip the systemctl start firewalld step. As with all services on Rocky Linux, you can check if the firewall is running with: systemctl status firewalld To stop it altogether: systemctl stop firewalld And to give the service a hard restart: systemctl restart firewalld Basic firewalld configuration and management commands firewalld is configured with the firewall-cmd command. You can, for example, check the status of firewalld with: firewall-cmd --state After every permanent change to your firewall, you'll need to reload it to see the changes. You can give the firewall configurations a \"soft restart\" with: firewall-cmd --reload !!! Note If you reload your configurations that haven't been made permanent, they'll disappear on you. You can see all of your configurations and settings at once with: firewall-cmd --list-all That command will output something that looks like this: public (active) target: default icmp-block-inversion: no interfaces: enp9s0 sources: services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Saving your changes !!! Warning \"Warning: Seriously, read this next bit.\" By default, all changes to `firewalld`'s configuration are temporary. If you restart the whole `firewalld` service, or restart your machine, none of your changes to the firewall will be saved unless you do one of two very specific things. It's best practice to test all of your changes one by one, reloading your firewall config as you go. That way, if you accidentally lock yourself out of anything, you can restart the service (or the machine), all of those changes disappear as mentioned above. But once you have a working configuration, you can save your changes permanently with: firewall-cmd --runtime-to-permanent However, if you're absolutely sure about what you're doing, and just want to add the rule and move on with your life, you can add the --permanent flag to any configuration command: firewall-cmd --permanent [the rest of your command] Managing Zones Before anything else, I need to explain zones. Zones are a feature that basically allow you to define different sets of rules for different situations. Zones are a huge part of firewalld so it pays to understand how they work. If your machine has multiple ways to connect to different networks (eg. Ethernet and WiFi), you can decide that one connection is more trusted than the other. You might set your Ethernet connection to the \"trusted\" zone if it's only connected to a local network that you built, and put the WiFi (which might be connected to the internet) in the \"public\" zone with more stringent restrictions. !!! Note A zone can *only* be in an active state if it has one of these two conditions: 1. The zone is assigned to a network interface 2. The zone is assigned source IPs or network ranges. (More on that below) Default zones include the following (I've taken this explanation from DigitalOcean's guide to firewalld , which you should also read): drop: The lowest level of trust. All incoming connections are dropped without reply and only outgoing connections are possible. block: Similar to the above, but instead of simply dropping connections, incoming requests are rejected with an icmp-host-prohibited or icmp6-adm-prohibited message. public: Represents public, untrusted networks. You don\u2019t trust other computers but may allow selected incoming connections on a case-by-case basis. external: External networks in the event that you are using the firewall as your gateway. It is configured for NAT masquerading so that your internal network remains private but reachable. internal: The other side of the external zone, used for the internal portion of a gateway. The computers are fairly trustworthy and some additional services are available. dmz: Used for computers located in a DMZ (isolated computers that will not have access to the rest of your network). Only certain incoming connections are allowed. work: Used for work machines. Trust most of the computers in the network. A few more services might be allowed. home: A home environment. It generally implies that you trust most of the other computers and that a few more services will be accepted. trusted: Trust all of the machines in the network. The most open of the available options and should be used sparingly. Okay, so some of those explanations get complicated, but Honestly? The average beginner can get by with understanding \"trusted\", \"home\", and \"public\", and when to use which. Zone management commands To see your default zone, run: firewall-cmd --get-default-zone To see which zones are active and doing things, run: firewall-cmd --get-active-zones !!! Note \"Note: Some of this might have been done for you.\" If you're running Rocky Linux on a VPS, it's probable that a basic configuration has been set up for you. Specifically, you should be able to access the server via SSH, and the network interface will already have been added to the \"public\" zone. To change the default zone: firewall-cmd --set-default-zone [your-zone] To add a network interface to a zone: firewall-cmd --zone=[your-zone] --add-interface=[your-network-device] To change the zone of a network interface: firewall-cmd --zone=[your-zone] --change-interface=[your-network-device] To remove an interface from a zone completely: firewall-cmd --zone=[your-zone] --remove-interface=[your-network-device] To make your own brand new zone with a completely custom set of rules, and to check that it was added properly: firewall-cmd --new-zone=[your-new-zone] firewall-cmd --get-zones Managing Ports For the uninitiated, ports (in this context) are just virtual endpoints where computers connect to each other so they can send information back and forth. Think of them like physical Ethernet or USB ports on your computer, but invisible, and you can have up to 65,535 of them all going at once. I wouldn't, but you can. Every port is defined by a number, and some ports are reserved for specific services, and kinds of information. If you've ever worked with web servers to build a website, for example, you may be familiar with port 80, and port 443. Those ports allow for the transmission of web page data. Specifically, port 80 allows for transferring data via the Hypertext Transfer Protocol (HTTP), and port 443 is reserved for Hypertext Transfer Protocol Secure (HTTPS) data. * Port 22 is reserved for the Secure Shell protocol (SSH) which lets you log into and manage other machines via the command line (see our short guide on the suject).A brand new remote server might only allow connections over port 22 for SSH, and nothing else. Other examples include FTP (ports 20 and 21), SSH (port 22), and so many more. You can also set custom ports to be used by new apps you might install, that don't already have a standard number. !!! Note \"Note: You shouldn't use ports for everything.\" For things like SSH, HTTP/S, FTP, and more, it's actually recommended to add them to your firewall zone as *services*, and not as port numbers. I'll show you how that works below. That said, you still need to know how to open ports manually. * For absolute beginners, HTTPS is basically (more or less) the same as HTTP, but encrypted. Port management commands For this section, I'll be using --zone=public ... and port 9001 as a random example, because it's over 9,000. To see all open ports: firewall-cmd --list-ports To add a port to your firewall zone (thus opening it for use), just run this command: firewall-cmd --zone=public --add-port=9001/tcp !!! Note About that `/tcp` bit: That `/tcp` bit at the end tells the firewall that connections will be coming in over the Transfer Control Protocol, which is what you'll be using for most server-and-home-related stuff. Alternatives like UDP are for debugging, or other very specific kinds of stuff that frankly aren't in the scope of this guide. Refer to the documentation of whatever app or service you specifically want to open up a port for. To remove a port, just reverse the command with a single word change: firewall-cmd --zone=public --remove-port=9001/tcp Managing Services Services, as you might imagine, are fairly standardized programs that run on your computer. firewalld is set up so that it can just open the way for most common services whenever you need to do that. This is the preferred way to open up the ports for these common services, and a whole lot more: HTTP and HTTPS: for web servers FTP: For moving files back and forth (the old fashioned way) SSH: For controlling remote machines and moving files back and forth the new way Samba: For sharing files with Windows machines !!! Warning **Never remove the SSH service from a remote server's firewall!** Remember, SSH is what you use to log in to your server. Unless you have another way to access the physical server, or its shell (ie via. a control panel provided by the host), removing the SSH service will lock you out permanently. You'll either need to contact support to get your access back, or reinstall the OS entirely. Service management commands To see a list of all available service services that you could potentially add to your firewall, run: firewall-cmd --get-services To see what services you currently have active on your firewall, use: firewall-cmd --list-services To open up a service in your firewall (eg. HTTP in the public zone), use: firewall-cmd --zone=public --add-service=http To remove/close a service on your firewall, just change one word again: firewall-cmd --zone=public --remove-service=http !!! Note \"Note: You can add your own services\" And customize the heck out of them, too. However, that's a topic that gets kind of complex. Get familiar with `firewalld` first, and go from there. Restricting Access Let's say you have a server, and you just don't want to make it public. if you want to define just who is allowed to access it via SSH, or view some private web pages/apps, you can do that. There are a couple of methods to accomplish this. First, for a more locked-down server, you can pick one of the more restrictive zones, assign your network device to it, add the SSH service to it as shown above, and then whitelist your own public IP address like so: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0 [< insert your IP here] You can make it a range of IP addresses by adding a higher number at the end like so: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0/24 [< insert your IP here] Again, just change --add-source to --remove-source in order to reverse the process. However, if you're managing a remote server with a website on it that needs to be public, and still only want to open up SSH for one IP address or a small range of them, you have a couple of options. In both of these examples, the sole network interface is assigned to the public zone. First, you can use a \"rich rule\" to your public zone, and it would look something like this: # firewall-cmd --permanent --zone=public --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept' Once the rich rule is in place, don't make the rules permanent yet. First, remove the SSH service from the public zone configuration, and test your connection to make sure you can still access the server via SSH. Your configuration should now look like this: your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept Secondly, you can use two different zones at a time. If you have your interface bound to the public zone, you can activate a second zone (the \"trusted\" zone for example) by adding a source IP or IP range to it as shown above. Then, add the SSH service to the trusted zone, and remove it from the public zone. When you're done, the output should look a bit like this: your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: your@server ~# firewall-cmd --list-all --zone=trusted trusted (active) target: default icmp-block-inversion: no interfaces: sources: 192.168.0.0/24 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: If you get locked out, restart the server (most VPS control panels have an option for this) and try again. !!! Warning These techniques only work if you have a static IP address. If you're stuck with an internet service provider that changes your IP address every time your modem reboots, don't use these rules (at least not for SSH) until you have a fix for that. You'll lock yourself out of your server Either upgrade your internet plan/provider, or get a VPN that provides you with a dedicated IP, and *never, ever* lose it. In the meantime, [install and configure fail2ban](https://wiki.crowncloud.net/?How_to_Install_Fail2Ban_on_RockyLinux_8), which can help cut down on brute force attacks. Obviously, on a local network that you control (and where you can set every machine's IP address manually), you can use all of these rules as much as you like. Final Notes This is far from an exhaustive guide, and you can learn a whole lot more with the official firewalld documentation . There are also handy app-specific guides all over the internet that will show you how to set up your firewall for for those specific apps. For you fans of iptables (if you've gotten this far...), we have a guide detailing some of the differences in how firewalld and iptables work. That guide might help you figure out if you want to stay with firewalld or go back to The Old Ways (TM) . There is something to be said for The Old Ways (TM) , in this case. Conclusion And that is firewalld in as few words as I could manage while still explaining all the basics. Take it slow, experiment carefully, and don't make any rules permanent until you're sure they work. And, you know, have fun. Once you have the basics down, actually setting up a decent, workable firewall can take 5-10 minutes.","title":"firewalld for Beginners"},{"location":"guides/security/firewalld-beginners/#firewalld-for-beginners","text":"","title":"firewalld for Beginners"},{"location":"guides/security/firewalld-beginners/#introduction","text":"A long time ago, I was a little newbie computer user who heard that having a firewall was supposed to be super good. It would let me decide what got in, and what got out of my computer, right? But it mostly seemed to stop my video games from accessing the internet; I was not a happy camper. Of course, if you're here, you probably have a better idea what a firewall is and what it does than I did. But if your firewall experience amounts to telling Windows Defender that yes, for the love of all that is holy, your new app is allowed to use the internet, don't worry. It says \"for Beginners\" up top; I've got you. In other words, my fellow nerds should be aware that there will be a lot of explanations incoming. So let's talk about what we're here for. firewalld is the default firewall app packaged with Rocky Linux, and it's designed to be pretty simple to use. You just need to know a little bit about how firewalls work, and not be afraid to use the command line. Here you'll learn: The very basics of how firewalld works How to use firewalld to restrict or allow incoming and outgoing connections How to allow only people from certain IP addresses or places to log into your machine remotely How to manage some firewalld -specific features like Zones. This is not intended to be a complete or exhaustive guide.","title":"Introduction"},{"location":"guides/security/firewalld-beginners/#a-note-on-using-the-command-line-for-managing-your-firewall","text":"Well... there are graphical firewall configuration options. On the desktop, there's firewall-config which can be installed from the repos, and on servers you can install Cockpit to help you manage firewalls and a whole bunch of other stuff. However, I'll be teaching you the command-line way to do things in this tutorial for a couple of reasons: If you're running a server, you'll be using the command line for most of this stuff anyway. Lots of tutorials and guides for Rocky server will give command line instructions for firewall management, and it's best that you understand those instructions, rather than just copying and pasting whatever you see. Understanding how the firewalld commands work might help you better grasp how the firewall software works. You can take the same principles you learn here, and have a better idea what you're doing if you do decide to use a graphical interface in the future.","title":"A note on using the command line for managing your firewall"},{"location":"guides/security/firewalld-beginners/#prerequisites-and-assumptions","text":"You'll need: A Rocky Linux machine of any kind, local or remote, physical or virtual Access to the terminal, and a willingness to use it You need root access, or at least the ability to use sudo on your user account. For simplicity's sake, I'm assuming all commands are being run as root. A basic understanding of SSH wouldn't hurt for managing remote machines.","title":"Prerequisites and Assumptions"},{"location":"guides/security/firewalld-beginners/#basic-usage","text":"","title":"Basic Usage"},{"location":"guides/security/firewalld-beginners/#system-service-commands","text":"firewalld is run as a service on your machine. It starts when the machine does, or it should. If for some reason firewalld is not already enabled on your machine, you can do that with a simple command: systemctl enable --now firewalld The --now flag starts the service as soon as its enabled, and let's you skip the systemctl start firewalld step. As with all services on Rocky Linux, you can check if the firewall is running with: systemctl status firewalld To stop it altogether: systemctl stop firewalld And to give the service a hard restart: systemctl restart firewalld","title":"System service commands"},{"location":"guides/security/firewalld-beginners/#basic-firewalld-configuration-and-management-commands","text":"firewalld is configured with the firewall-cmd command. You can, for example, check the status of firewalld with: firewall-cmd --state After every permanent change to your firewall, you'll need to reload it to see the changes. You can give the firewall configurations a \"soft restart\" with: firewall-cmd --reload !!! Note If you reload your configurations that haven't been made permanent, they'll disappear on you. You can see all of your configurations and settings at once with: firewall-cmd --list-all That command will output something that looks like this: public (active) target: default icmp-block-inversion: no interfaces: enp9s0 sources: services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules:","title":"Basic firewalld configuration and management commands"},{"location":"guides/security/firewalld-beginners/#saving-your-changes","text":"!!! Warning \"Warning: Seriously, read this next bit.\" By default, all changes to `firewalld`'s configuration are temporary. If you restart the whole `firewalld` service, or restart your machine, none of your changes to the firewall will be saved unless you do one of two very specific things. It's best practice to test all of your changes one by one, reloading your firewall config as you go. That way, if you accidentally lock yourself out of anything, you can restart the service (or the machine), all of those changes disappear as mentioned above. But once you have a working configuration, you can save your changes permanently with: firewall-cmd --runtime-to-permanent However, if you're absolutely sure about what you're doing, and just want to add the rule and move on with your life, you can add the --permanent flag to any configuration command: firewall-cmd --permanent [the rest of your command]","title":"Saving your changes"},{"location":"guides/security/firewalld-beginners/#managing-zones","text":"Before anything else, I need to explain zones. Zones are a feature that basically allow you to define different sets of rules for different situations. Zones are a huge part of firewalld so it pays to understand how they work. If your machine has multiple ways to connect to different networks (eg. Ethernet and WiFi), you can decide that one connection is more trusted than the other. You might set your Ethernet connection to the \"trusted\" zone if it's only connected to a local network that you built, and put the WiFi (which might be connected to the internet) in the \"public\" zone with more stringent restrictions. !!! Note A zone can *only* be in an active state if it has one of these two conditions: 1. The zone is assigned to a network interface 2. The zone is assigned source IPs or network ranges. (More on that below) Default zones include the following (I've taken this explanation from DigitalOcean's guide to firewalld , which you should also read): drop: The lowest level of trust. All incoming connections are dropped without reply and only outgoing connections are possible. block: Similar to the above, but instead of simply dropping connections, incoming requests are rejected with an icmp-host-prohibited or icmp6-adm-prohibited message. public: Represents public, untrusted networks. You don\u2019t trust other computers but may allow selected incoming connections on a case-by-case basis. external: External networks in the event that you are using the firewall as your gateway. It is configured for NAT masquerading so that your internal network remains private but reachable. internal: The other side of the external zone, used for the internal portion of a gateway. The computers are fairly trustworthy and some additional services are available. dmz: Used for computers located in a DMZ (isolated computers that will not have access to the rest of your network). Only certain incoming connections are allowed. work: Used for work machines. Trust most of the computers in the network. A few more services might be allowed. home: A home environment. It generally implies that you trust most of the other computers and that a few more services will be accepted. trusted: Trust all of the machines in the network. The most open of the available options and should be used sparingly. Okay, so some of those explanations get complicated, but Honestly? The average beginner can get by with understanding \"trusted\", \"home\", and \"public\", and when to use which.","title":"Managing Zones"},{"location":"guides/security/firewalld-beginners/#zone-management-commands","text":"To see your default zone, run: firewall-cmd --get-default-zone To see which zones are active and doing things, run: firewall-cmd --get-active-zones !!! Note \"Note: Some of this might have been done for you.\" If you're running Rocky Linux on a VPS, it's probable that a basic configuration has been set up for you. Specifically, you should be able to access the server via SSH, and the network interface will already have been added to the \"public\" zone. To change the default zone: firewall-cmd --set-default-zone [your-zone] To add a network interface to a zone: firewall-cmd --zone=[your-zone] --add-interface=[your-network-device] To change the zone of a network interface: firewall-cmd --zone=[your-zone] --change-interface=[your-network-device] To remove an interface from a zone completely: firewall-cmd --zone=[your-zone] --remove-interface=[your-network-device] To make your own brand new zone with a completely custom set of rules, and to check that it was added properly: firewall-cmd --new-zone=[your-new-zone] firewall-cmd --get-zones","title":"Zone management commands"},{"location":"guides/security/firewalld-beginners/#managing-ports","text":"For the uninitiated, ports (in this context) are just virtual endpoints where computers connect to each other so they can send information back and forth. Think of them like physical Ethernet or USB ports on your computer, but invisible, and you can have up to 65,535 of them all going at once. I wouldn't, but you can. Every port is defined by a number, and some ports are reserved for specific services, and kinds of information. If you've ever worked with web servers to build a website, for example, you may be familiar with port 80, and port 443. Those ports allow for the transmission of web page data. Specifically, port 80 allows for transferring data via the Hypertext Transfer Protocol (HTTP), and port 443 is reserved for Hypertext Transfer Protocol Secure (HTTPS) data. * Port 22 is reserved for the Secure Shell protocol (SSH) which lets you log into and manage other machines via the command line (see our short guide on the suject).A brand new remote server might only allow connections over port 22 for SSH, and nothing else. Other examples include FTP (ports 20 and 21), SSH (port 22), and so many more. You can also set custom ports to be used by new apps you might install, that don't already have a standard number. !!! Note \"Note: You shouldn't use ports for everything.\" For things like SSH, HTTP/S, FTP, and more, it's actually recommended to add them to your firewall zone as *services*, and not as port numbers. I'll show you how that works below. That said, you still need to know how to open ports manually. * For absolute beginners, HTTPS is basically (more or less) the same as HTTP, but encrypted.","title":"Managing Ports"},{"location":"guides/security/firewalld-beginners/#port-management-commands","text":"For this section, I'll be using --zone=public ... and port 9001 as a random example, because it's over 9,000. To see all open ports: firewall-cmd --list-ports To add a port to your firewall zone (thus opening it for use), just run this command: firewall-cmd --zone=public --add-port=9001/tcp !!! Note About that `/tcp` bit: That `/tcp` bit at the end tells the firewall that connections will be coming in over the Transfer Control Protocol, which is what you'll be using for most server-and-home-related stuff. Alternatives like UDP are for debugging, or other very specific kinds of stuff that frankly aren't in the scope of this guide. Refer to the documentation of whatever app or service you specifically want to open up a port for. To remove a port, just reverse the command with a single word change: firewall-cmd --zone=public --remove-port=9001/tcp","title":"Port management commands"},{"location":"guides/security/firewalld-beginners/#managing-services","text":"Services, as you might imagine, are fairly standardized programs that run on your computer. firewalld is set up so that it can just open the way for most common services whenever you need to do that. This is the preferred way to open up the ports for these common services, and a whole lot more: HTTP and HTTPS: for web servers FTP: For moving files back and forth (the old fashioned way) SSH: For controlling remote machines and moving files back and forth the new way Samba: For sharing files with Windows machines !!! Warning **Never remove the SSH service from a remote server's firewall!** Remember, SSH is what you use to log in to your server. Unless you have another way to access the physical server, or its shell (ie via. a control panel provided by the host), removing the SSH service will lock you out permanently. You'll either need to contact support to get your access back, or reinstall the OS entirely.","title":"Managing Services"},{"location":"guides/security/firewalld-beginners/#service-management-commands","text":"To see a list of all available service services that you could potentially add to your firewall, run: firewall-cmd --get-services To see what services you currently have active on your firewall, use: firewall-cmd --list-services To open up a service in your firewall (eg. HTTP in the public zone), use: firewall-cmd --zone=public --add-service=http To remove/close a service on your firewall, just change one word again: firewall-cmd --zone=public --remove-service=http !!! Note \"Note: You can add your own services\" And customize the heck out of them, too. However, that's a topic that gets kind of complex. Get familiar with `firewalld` first, and go from there.","title":"Service management commands"},{"location":"guides/security/firewalld-beginners/#restricting-access","text":"Let's say you have a server, and you just don't want to make it public. if you want to define just who is allowed to access it via SSH, or view some private web pages/apps, you can do that. There are a couple of methods to accomplish this. First, for a more locked-down server, you can pick one of the more restrictive zones, assign your network device to it, add the SSH service to it as shown above, and then whitelist your own public IP address like so: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0 [< insert your IP here] You can make it a range of IP addresses by adding a higher number at the end like so: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0/24 [< insert your IP here] Again, just change --add-source to --remove-source in order to reverse the process. However, if you're managing a remote server with a website on it that needs to be public, and still only want to open up SSH for one IP address or a small range of them, you have a couple of options. In both of these examples, the sole network interface is assigned to the public zone. First, you can use a \"rich rule\" to your public zone, and it would look something like this: # firewall-cmd --permanent --zone=public --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept' Once the rich rule is in place, don't make the rules permanent yet. First, remove the SSH service from the public zone configuration, and test your connection to make sure you can still access the server via SSH. Your configuration should now look like this: your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept Secondly, you can use two different zones at a time. If you have your interface bound to the public zone, you can activate a second zone (the \"trusted\" zone for example) by adding a source IP or IP range to it as shown above. Then, add the SSH service to the trusted zone, and remove it from the public zone. When you're done, the output should look a bit like this: your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: your@server ~# firewall-cmd --list-all --zone=trusted trusted (active) target: default icmp-block-inversion: no interfaces: sources: 192.168.0.0/24 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: If you get locked out, restart the server (most VPS control panels have an option for this) and try again. !!! Warning These techniques only work if you have a static IP address. If you're stuck with an internet service provider that changes your IP address every time your modem reboots, don't use these rules (at least not for SSH) until you have a fix for that. You'll lock yourself out of your server Either upgrade your internet plan/provider, or get a VPN that provides you with a dedicated IP, and *never, ever* lose it. In the meantime, [install and configure fail2ban](https://wiki.crowncloud.net/?How_to_Install_Fail2Ban_on_RockyLinux_8), which can help cut down on brute force attacks. Obviously, on a local network that you control (and where you can set every machine's IP address manually), you can use all of these rules as much as you like.","title":"Restricting Access"},{"location":"guides/security/firewalld-beginners/#final-notes","text":"This is far from an exhaustive guide, and you can learn a whole lot more with the official firewalld documentation . There are also handy app-specific guides all over the internet that will show you how to set up your firewall for for those specific apps. For you fans of iptables (if you've gotten this far...), we have a guide detailing some of the differences in how firewalld and iptables work. That guide might help you figure out if you want to stay with firewalld or go back to The Old Ways (TM) . There is something to be said for The Old Ways (TM) , in this case.","title":"Final Notes"},{"location":"guides/security/firewalld-beginners/#conclusion","text":"And that is firewalld in as few words as I could manage while still explaining all the basics. Take it slow, experiment carefully, and don't make any rules permanent until you're sure they work. And, you know, have fun. Once you have the basics down, actually setting up a decent, workable firewall can take 5-10 minutes.","title":"Conclusion"},{"location":"guides/security/firewalld-beginners.sv/","text":"brandv\u00e4gg f\u00f6r nyb\u00f6rjare Introduktion F\u00f6r l\u00e4nge sedan var jag lite nyb\u00f6rjare datoranv\u00e4ndare som h\u00f6rde att ha en brandv\u00e4gg var t\u00e4nkt att vara super bra. Det skulle l\u00e5ta mig best\u00e4mma vad som kom in, och vad fick ut av min dator, eller hur? Men det verkade mest att stoppa mina videospel fr\u00e5n att komma \u00e5t internet; Jag var inte en lycklig camper. Naturligtvis, om du \u00e4r h\u00e4r, har du f\u00f6rmodligen en b\u00e4ttre uppfattning om vad en brandv\u00e4gg \u00e4r och vad den g\u00f6r \u00e4n jag gjorde. Men om din brandv\u00e4gg erfarenhet inneb\u00e4r att tala om f\u00f6r Windows Defender att ja, f\u00f6r k\u00e4rleken till allt som \u00e4r heligt, din nya app \u00e4r till\u00e5ten att anv\u00e4nda internet, oroa dig inte. Det st\u00e5r \"f\u00f6r nyb\u00f6rjare\" upp p\u00e5 toppen, jag har dig. Med andra ord b\u00f6r mina n\u00f6rdar vara medvetna om att det kommer att finnas en hel del f\u00f6rklaringar till inkomst. S\u00e5 l\u00e5t oss tala om vad vi \u00e4r h\u00e4r f\u00f6r. brandv\u00e4gg \u00e4r standard-brandv\u00e4ggsappen paketerad med Rocky Linux, och den \u00e4r utformad f\u00f6r att vara ganska enkel att anv\u00e4nda. Du beh\u00f6ver bara veta lite om hur brandv\u00e4ggar fungerar, och inte vara r\u00e4dd f\u00f6r att anv\u00e4nda kommandoraden. H\u00e4r f\u00e5r du l\u00e4ra dig: Sj\u00e4lva grunderna i hur brandv\u00e4gg fungerar Hur du anv\u00e4nder brandv\u00e4gg f\u00f6r att begr\u00e4nsa eller till\u00e5ta inkommande och utg\u00e5ende anslutningar Hur man till\u00e5ter endast personer fr\u00e5n vissa IP-adresser eller platser att logga in p\u00e5 din maskin p\u00e5 distans Hur man hanterar n\u00e5gra brandv\u00e4gg -specifika funktioner som Zoner. Detta \u00e4r inte avsett att vara en komplett eller utt\u00f6mmande guide. En anteckning om att anv\u00e4nda kommandoraden f\u00f6r att hantera din brandv\u00e4gg V\u00e4l... det finns grafiska brandv\u00e4ggskonfigurationsalternativ. P\u00e5 skrivbordet finns brandv\u00e4gg-config som kan installeras fr\u00e5n repos, och p\u00e5 servrar kan du installera Cockpit f\u00f6r att hj\u00e4lpa dig att hantera brandv\u00e4ggar och ett helt g\u00e4ng andra saker. Jag kommer dock att l\u00e4ra dig kommandoradss\u00e4ttet att g\u00f6ra saker i den h\u00e4r handledningen av ett par sk\u00e4l: Om du k\u00f6r en server, kommer du att anv\u00e4nda kommandoraden f\u00f6r de flesta av dessa saker \u00e4nd\u00e5. Massor av \u00f6vningar och guider f\u00f6r Rocky server kommer att ge kommandoraden instruktioner f\u00f6r brandv\u00e4ggshantering, och det \u00e4r b\u00e4st att du f\u00f6rst\u00e5r dessa instruktioner, snarare \u00e4n att bara kopiera och klistra in vad du \u00e4n ser. Att f\u00f6rst\u00e5 hur brandv\u00e4gg kommandon fungerar kan hj\u00e4lpa dig att b\u00e4ttre f\u00f6rst\u00e5 hur brandv\u00e4ggsprogrammet fungerar. Du kan ta samma principer som du l\u00e4r dig h\u00e4r, och har en b\u00e4ttre uppfattning om vad du g\u00f6r om du v\u00e4ljer att anv\u00e4nda ett grafiskt gr\u00e4nssnitt i framtiden. F\u00f6ruts\u00e4ttningar och antaganden Du beh\u00f6ver. En Rocky Linux-maskin av alla slag, lokal eller fj\u00e4rrstyrd, fysisk eller virtuell Tillg\u00e5ng till terminalen, och en vilja att anv\u00e4nda den Du beh\u00f6ver root-\u00e5tkomst, eller \u00e5tminstone m\u00f6jligheten att anv\u00e4nda sudo p\u00e5 ditt anv\u00e4ndarkonto. F\u00f6r enkelhetens skull antar jag att alla kommandon k\u00f6rs som rot. En grundl\u00e4ggande f\u00f6rst\u00e5else f\u00f6r SSH skulle inte skada f\u00f6r hantering av fj\u00e4rrmaskiner. Grundl\u00e4ggande anv\u00e4ndning Systemtj\u00e4nstkommandon brandv\u00e4gg k\u00f6rs som en tj\u00e4nst p\u00e5 din maskin. Det b\u00f6rjar n\u00e4r maskinen g\u00f6r det, eller det borde. Om brandv\u00e4gg av n\u00e5gon anledning inte redan \u00e4r aktiverat p\u00e5 din maskin, kan du g\u00f6ra det med ett enkelt kommando: systemctl aktivera --nu brandv\u00e4gg Flaggan --now startar tj\u00e4nsten s\u00e5 snart den \u00e4r aktiverad, och l\u00e5t dig hoppa \u00f6ver systemctl starta brandv\u00e4ggen steget. Som med alla tj\u00e4nster p\u00e5 Rocky Linux kan du kontrollera om brandv\u00e4ggen k\u00f6rs med: brandv\u00e4gg systemctl status Att stoppa det helt och h\u00e5llet: systemctl stoppa brandv\u00e4gg Och f\u00f6r att ge tj\u00e4nsten en h\u00e5rd omstart: systemctl starta om brandv\u00e4gg Grundl\u00e4ggande brandv\u00e4gg konfigurations- och hanteringskommandon brandv\u00e4gg \u00e4r konfigurerad med brandv\u00e4gg-cmd kommandot. Du kan till exempel kontrollera statusen f\u00f6r brandv\u00e4gg med: brandv\u00e4gg-cmd --stat Efter varje permanent \u00e4ndring av din brandv\u00e4gg, m\u00e5ste du ladda om den f\u00f6r att se \u00e4ndringarna. Du kan ge brandv\u00e4ggskonfigurationerna en \"mjuk omstart\" med: brandv\u00e4gg-cmd --ladda om !!! Anteckning Om du laddar om dina konfigurationer som inte har blivit permanenta, f\u00f6rsvinner de p\u00e5 dig. Du kan se alla dina konfigurationer och inst\u00e4llningar samtidigt med: brandv\u00e4gg-cmd --list-all Det kommandot kommer att skriva ut n\u00e5got som ser ut s\u00e5 h\u00e4r: offentliga (aktiva) m\u00e5l: standard icmp-block-inversion: inga gr\u00e4nssnitt: enp9s0 k\u00e4llor: tj\u00e4nster: ssh portar: protokoll: fram\u00e5t: nej maskerad: nej fram\u00e5t-portar: k\u00e4ll-portar: icmp-blocks: rika regler: Sparar dina \u00e4ndringar !!! Varning \"Varning: Allvarligt, l\u00e4s n\u00e4sta bit.\" Som standard \u00e4r alla \u00e4ndringar i `firewalld`s konfiguration tillf\u00e4lliga. Om du startar om hela `firewalld`-tj\u00e4nsten eller startar om din maskin, Ingen av dina \u00e4ndringar i brandv\u00e4ggen kommer att sparas om du inte g\u00f6r en av tv\u00e5 mycket specifika saker. Det \u00e4r b\u00e4st att testa alla dina \u00e4ndringar en efter en, ladda om din brandv\u00e4gg konfiguration n\u00e4r du g\u00e5r. P\u00e5 det s\u00e4ttet, om du av misstag l\u00e5sa dig sj\u00e4lv ur n\u00e5got, Du kan starta om tj\u00e4nsten (eller maskinen), alla dessa \u00e4ndringar f\u00f6rsvinner som n\u00e4mnts ovan. Men n\u00e4r du har en fungerande konfiguration, kan du spara dina \u00e4ndringar permanent med: brandv\u00e4gg-cmd --runtime-to-permanent Men om du \u00e4r helt s\u00e4ker p\u00e5 vad du g\u00f6r, och bara vill l\u00e4gga till regeln och g\u00e5 vidare med ditt liv, du kan l\u00e4gga till flaggan --permanent till valfritt konfigurationskommando: brandv\u00e4gg-cmd - permanent [resten av ditt kommando] Hantera zoner Innan n\u00e5got annat m\u00e5ste jag f\u00f6rklara zoner. Zoner \u00e4r en funktion som i grunden g\u00f6r att du kan definiera olika upps\u00e4ttningar av regler f\u00f6r olika situationer. Zoner \u00e4r en stor del av brandv\u00e4gg s\u00e5 det l\u00f6nar sig att f\u00f6rst\u00e5 hur de fungerar. Om din maskin har flera s\u00e4tt att ansluta till olika n\u00e4tverk (t.ex. Ethernet och WiFi) kan du best\u00e4mma att en anslutning \u00e4r mer betrodd \u00e4n den andra. Du kan st\u00e4lla in din Ethernet-anslutning till den \"betrodda\" zonen om den bara \u00e4r ansluten till ett lokalt n\u00e4tverk som du byggt, och s\u00e4tta WiFi (som kan vara ansluten till internet) i den \"offentliga\" zonen med str\u00e4ngare begr\u00e4nsningar. !!! Anteckning En zon kan *endast* vara i ett aktivt tillst\u00e5nd om den har n\u00e5got av dessa tv\u00e5 f\u00f6ruts\u00e4ttningar: 1. Zonen \u00e4r tilldelad till ett n\u00e4tverksgr\u00e4nssnitt 2. Zonen \u00e4r tilldelad k\u00e4lla IP-adresser eller n\u00e4tverksintervall. (Mer om detta nedan) Standardzoner inkluderar f\u00f6ljande (jag har tagit denna f\u00f6rklaring fr\u00e5n DigitalOceans guide till brandv\u00e4gg , som du ocks\u00e5 b\u00f6r l\u00e4sa): droppe: Den l\u00e4gsta niv\u00e5n av tillit. Alla inkommande anslutningar sl\u00e4pps utan svar och endast utg\u00e5ende anslutningar \u00e4r m\u00f6jliga. block: Liknar ovan, men ist\u00e4llet f\u00f6r att helt enkelt sl\u00e4ppa anslutningar, avvisas inkommande f\u00f6rfr\u00e5gningar med ett icmp-host-f\u00f6rbjudet eller icmp6-adm-f\u00f6rbjudet meddelande. public: Representerar offentliga, op\u00e5litliga n\u00e4tverk. Du litar inte p\u00e5 andra datorer men kan till\u00e5ta valda inkommande anslutningar fr\u00e5n fall till fall. externt: Externa n\u00e4tverk i h\u00e4ndelse av att du anv\u00e4nder brandv\u00e4ggen som port. Det \u00e4r konfigurerat f\u00f6r NAT maskering s\u00e5 att ditt interna n\u00e4tverk f\u00f6rblir privat men kan n\u00e5s. internt: Den andra sidan av den yttre zonen, som anv\u00e4nds f\u00f6r den inre delen av en gateway. Datorerna \u00e4r ganska p\u00e5litliga och vissa ytterligare tj\u00e4nster finns tillg\u00e4ngliga. dmz: Anv\u00e4nds f\u00f6r datorer som ligger i en DMZ (isolerade datorer som inte har tillg\u00e5ng till resten av ditt n\u00e4tverk). Endast vissa inkommande anslutningar \u00e4r till\u00e5tna. arbete: Anv\u00e4nds f\u00f6r arbetsmaskiner. Lita p\u00e5 de flesta datorer i n\u00e4tverket. N\u00e5gra fler tj\u00e4nster kan till\u00e5tas. hem: En hemmilj\u00f6. Det inneb\u00e4r i allm\u00e4nhet att du litar p\u00e5 de flesta andra datorer och att n\u00e5gra fler tj\u00e4nster kommer att accepteras. litade p\u00e5: Lita p\u00e5 alla maskiner i n\u00e4tverket. Den mest \u00f6ppna av de tillg\u00e4ngliga alternativen och b\u00f6r anv\u00e4ndas sparsamt. Okej, s\u00e5 n\u00e5gra av dessa f\u00f6rklaringar blir komplicerade, men \u00e4rligt? Den genomsnittliga nyb\u00f6rjaren kan f\u00e5 med att f\u00f6rst\u00e5 \"betrodd\", \"hem\", och \"offentlig\", och n\u00e4r man ska anv\u00e4nda vilken. Zonhanteringskommandon K\u00f6r f\u00f6r att se din standardzon: brandv\u00e4gg-cmd --get-default-zone F\u00f6r att se vilka zoner som \u00e4r aktiva och g\u00f6ra saker, k\u00f6ra: brandv\u00e4gg-cmd --get-active-zoner !!! Notera att en del av detta kan ha gjorts f\u00f6r dig.\" Om du k\u00f6r Rocky Linux p\u00e5 en VPS, \u00e4r det troligt att en grundl\u00e4ggande konfiguration har konfigurerats f\u00f6r dig. Specifikt b\u00f6r du kunna komma \u00e5t servern via SSH, och n\u00e4tverksgr\u00e4nssnittet kommer redan att ha lagts till den \"offentliga\" zonen. F\u00f6r att \u00e4ndra standardzonen: brandv\u00e4gg-cmd --set-default-zone [your-zone] L\u00e4gga till ett n\u00e4tverksgr\u00e4nssnitt i en zon: firewall-cmd --zone=[your-zone] --add-interface=[your-network-device] \u00c4ndra zonen i ett n\u00e4tverksgr\u00e4nssnitt: brandv\u00e4gg-cmd --zone=[your-zone] --change-interface=[your-network-device] Ta bort ett gr\u00e4nssnitt fr\u00e5n en zon helt: firewall-cmd --zone=[your-zone] --remove-interface=[your-network-device] F\u00f6r att g\u00f6ra din egen helt nya zon med en helt egen upps\u00e4ttning regler, och f\u00f6r att kontrollera att den har lagts till ordentligt: brandv\u00e4gg-cmd --new-zone=[your-new-zone] brandv\u00e4gg-cmd --get-zones Hantera portar F\u00f6r de oinitierade \u00e4r portarna (i detta sammanhang) bara virtuella \u00e4ndpunkter d\u00e4r datorer ansluter till varandra s\u00e5 att de kan skicka information fram och tillbaka. T\u00e4nk p\u00e5 dem som fysiska Ethernet eller USB-portar p\u00e5 din dator, men osynliga, och du kan ha upp till 65.535 av dem alla p\u00e5 en g\u00e5ng. Det skulle jag inte, men ni kan. Varje port definieras av ett nummer, och vissa hamnar \u00e4r reserverade f\u00f6r specifika tj\u00e4nster och typer av information. Om du n\u00e5gonsin har arbetat med webbservrar f\u00f6r att bygga en webbplats, till exempel, kan du vara bekant med port 80 och port 443. Dessa portar m\u00f6jligg\u00f6r \u00f6verf\u00f6ring av webbsidedata. Specifikt, port 80 till\u00e5ter \u00f6verf\u00f6ring av data via Hypertext Transfer Protocol (HTTP), och port 443 \u00e4r reserverad f\u00f6r Hypertext Transfer Protocol Secure (HTTPS) data. * Port 22 \u00e4r reserverad f\u00f6r Secure Shell Protocol (SSH) som l\u00e5ter dig logga in och hantera andra maskiner via kommandoraden (se v\u00e5r korta guide p\u00e5 suject). helt ny fj\u00e4rrserver kan bara till\u00e5ta anslutningar \u00f6ver port 22 f\u00f6r SSH, och inget annat. Andra exempel \u00e4r FTP (portar 20 och 21), SSH (port 22), och s\u00e5 m\u00e5nga fler. Du kan ocks\u00e5 st\u00e4lla in anpassade portar som ska anv\u00e4ndas av nya appar som du kan installera, som inte redan har ett standardnummer. !!! Notera \"Obs: Du b\u00f6r inte anv\u00e4nda portar f\u00f6r allt.\" F\u00f6r saker som SSH, HTTP/S, FTP och mer, \u00e4r det faktiskt rekommenderat att l\u00e4gga till dem i din brandv\u00e4ggszon som *tj\u00e4nster*, och inte som portnummer. Jag ska visa dig hur det fungerar nedan. Som sagt, du beh\u00f6ver fortfarande veta hur man \u00f6ppnar portar manuellt. * F\u00f6r absolut nyb\u00f6rjare \u00e4r HTTPS i princip (mer eller mindre) samma som HTTP, men krypterad. Porthanteringskommandon F\u00f6r det h\u00e4r avsnittet anv\u00e4nder jag --zone=public ... och portar 9001 som ett slumpm\u00e4ssigt exempel, eftersom det \u00e4r \u00f6ver 9000. F\u00f6r att se alla \u00f6ppna portar: brandv\u00e4gg-cmd --list-portar F\u00f6r att l\u00e4gga till en port till din brandv\u00e4ggszon (\u00f6ppna den f\u00f6r anv\u00e4ndning), k\u00f6r du bara detta kommando: brandv\u00e4gg-cmd --zone=public --add-port=9001/tcp !!! Anteckning Om den `/tcp`-biten: Den d\u00e4r `/tcp`-biten i slutet talar om f\u00f6r brandv\u00e4ggen att anslutningar kommer in \u00f6ver \u00f6verf\u00f6ringskontrollprotokollet, vilket \u00e4r vad du kommer att anv\u00e4nda f\u00f6r de flesta server-och-hem-relaterade grejer. Alternativ som UDP \u00e4r f\u00f6r fels\u00f6kning, eller andra mycket specifika typer av saker som uppriktigt sagt inte omfattas av den h\u00e4r guiden. Se dokumentationen f\u00f6r vilken app eller tj\u00e4nst du vill \u00f6ppna en port f\u00f6r. F\u00f6r att ta bort en port, v\u00e4nd bara kommandot med en enda ord\u00e4ndring: brandv\u00e4gg-cmd --zone=offentlig --remove-port=9001/tcp Hantera tj\u00e4nster Tj\u00e4nster, som ni kanske tror, \u00e4r ganska standardiserade program som k\u00f6rs p\u00e5 din dator. brandv\u00e4gg \u00e4r satt upp s\u00e5 att det bara kan \u00f6ppna v\u00e4gen f\u00f6r de vanligaste tj\u00e4nsterna n\u00e4r du beh\u00f6ver g\u00f6ra det. Detta \u00e4r det b\u00e4sta s\u00e4ttet att \u00f6ppna hamnarna f\u00f6r dessa gemensamma tj\u00e4nster, och en hel del mer: HTTP och HTTPS: f\u00f6r webbservrar FTP: F\u00f6r att flytta filer fram och tillbaka (gammaldags s\u00e4tt) SSH: F\u00f6r att styra fj\u00e4rrmaskiner och flytta filer bacck och fram\u00e5t det nya s\u00e4ttet Samba: F\u00f6r att dela filer med Windows-maskiner !!! Varning **Ta aldrig bort SSH-tj\u00e4nsten fr\u00e5n en fj\u00e4rrservers brandv\u00e4gg!** Kom ih\u00e5g att SSH \u00e4r vad du anv\u00e4nder f\u00f6r att logga in p\u00e5 din server. Om du inte har ett annat s\u00e4tt att komma \u00e5t den fysiska servern, eller dess skal (dvs via. en kontrollpanel som tillhandah\u00e5lls av v\u00e4rden), ta bort SSH-tj\u00e4nsten kommer att l\u00e5sa dig permanent. Du beh\u00f6ver antingen kontakta supporten f\u00f6r att f\u00e5 tillbaka din \u00e5tkomst eller installera om operativsystemet helt och h\u00e5llet. Service Management-kommandon F\u00f6r att se en lista \u00f6ver alla tj\u00e4nster som du kan l\u00e4gga till i din brandv\u00e4gg, k\u00f6ra: brandv\u00e4gg-cmd --get-services F\u00f6r att se vilka tj\u00e4nster du f\u00f6r n\u00e4rvarande har aktiv p\u00e5 din brandv\u00e4gg, anv\u00e4nd: brandv\u00e4gg-cmd --list-services F\u00f6r att \u00f6ppna en tj\u00e4nst i din brandv\u00e4gg (t.ex. HTTP i den offentliga zonen), anv\u00e4nd: firewall-cmd --zone=public --add-service=http F\u00f6r att ta bort/st\u00e4nga en tj\u00e4nst p\u00e5 din brandv\u00e4gg, \u00e4ndra bara ett ord igen: brandv\u00e4gg-cmd --zone=public --remove-service=http !!! Notera att du kan l\u00e4gga till dina egna tj\u00e4nster\" Och anpassa heck ur dem ocks\u00e5. Det \u00e4r dock ett \u00e4mne som blir lite komplext. Bekanta dig f\u00f6rst med `brandv\u00e4gg` och g\u00e5 d\u00e4rifr\u00e5n. Begr\u00e4nsa \u00e5tkomst L\u00e5t oss s\u00e4ga att du har en server, och du vill bara inte g\u00f6ra det offentligt. om du vill definiera bara vem som f\u00e5r komma \u00e5t det via SSH, eller visa n\u00e5gra privata webbsidor/appar, kan du g\u00f6ra det. Det finns ett par metoder f\u00f6r att \u00e5stadkomma detta. F\u00f6r det f\u00f6rsta, f\u00f6r en mer l\u00e5st server, kan du v\u00e4lja en av de mer restriktiva zonerna, tilldela din n\u00e4tverksenhet till det, l\u00e4gg till SSH-tj\u00e4nsten till den som visas ovan, och sedan vitlista din egen publika IP-adress s\u00e5h\u00e4r: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0 [< s\u00e4tt in din IP h\u00e4r] Du kan g\u00f6ra det en rad IP-adresser genom att l\u00e4gga till ett h\u00f6gre antal i slutet som s\u00e5: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0/24 [< s\u00e4tt in din IP h\u00e4r] \u00c5terigen, \u00e4ndra bara --add-source till --remove-source f\u00f6r att \u00e4ndra processen. Men om du hanterar en fj\u00e4rrserver med en webbplats p\u00e5 den som m\u00e5ste vara offentlig, och \u00e4nd\u00e5 bara vill \u00f6ppna upp SSH f\u00f6r en IP-adress eller ett litet utbud av dem, har du ett par alternativ. I b\u00e5da dessa exempel \u00e4r det enda n\u00e4tverksgr\u00e4nssnittet tilldelat den offentliga zonen. F\u00f6rst kan du anv\u00e4nda en \"rik regel\" till din offentliga zon, och det skulle se ut ungef\u00e4r s\u00e5 h\u00e4r: # firewall-cmd --permanent --zone=public --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept\" N\u00e4r v\u00e4l den rika regeln \u00e4r p\u00e5 plats, g\u00f6r inte reglerna permanenta \u00e4nnu. Ta f\u00f6rst bort SSH-tj\u00e4nsten fr\u00e5n konfigurationen f\u00f6r offentlig zon och testa din anslutning f\u00f6r att se till att du fortfarande kan komma \u00e5t servern via SSH. Din konfiguration ska nu se ut s\u00e5 h\u00e4r: your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protokoll: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules rule family=\"ipv4\" source address=\"192. 68.1.0/24\" servicenamn = \"ssh\" acceptera F\u00f6r det andra kan man anv\u00e4nda tv\u00e5 olika zoner \u00e5t g\u00e5ngen. Om du har ditt gr\u00e4nssnitt bundet till den offentliga zonen, du kan aktivera en andra zon (den \"betrodda\" zonen till exempel) genom att l\u00e4gga till en k\u00e4lla IP eller IP-intervall till den som visas ovan. L\u00e4gg sedan till SSH-tj\u00e4nsten till den betrodda zonen, och ta bort den fr\u00e5n den offentliga zonen. N\u00e4r du \u00e4r klar b\u00f6r utdata se ut lite s\u00e5 h\u00e4r: ditt@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 k\u00e4llor: tj\u00e4nster: cockpit dhcpv6-client portar: 80/tcp 443/tcp protokoll: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rika regler: din@server ~# firewall-cmd --list-all --zone=trusted trusted (active) target: default icmp-block-inversion: no interfaces: k\u00e4llor: 192. 68.0.0/24 tj\u00e4nster: ssh portar: protokoll: fram\u00e5t: nej maskerad: nej fram\u00e5triktade portar: k\u00e4llportar: icmp-block: rika regler: Om du blir utl\u00e5st, starta om servern (de flesta VPS kontrollpaneler har ett alternativ f\u00f6r detta) och f\u00f6rs\u00f6k igen. !!! Varning Dessa tekniker fungerar bara om du har en statisk IP-adress. Om du har fastnat med en internetleverant\u00f6r som \u00e4ndrar din IP-adress varje g\u00e5ng ditt modem startar om, Anv\u00e4nd inte dessa regler (\u00e5tminstone inte f\u00f6r SSH) f\u00f6rr\u00e4n du har en r\u00e4ttelse f\u00f6r det. Du kommer att l\u00e5sa dig sj\u00e4lv fr\u00e5n din server Antingen uppgradera din internetplan/leverant\u00f6r, eller f\u00e5 en VPN som ger dig en dedikerad IP-adress, och *aldrig, n\u00e5gonsin* f\u00f6rlorar den. Under tiden, [installera och konfigurera fail2ban](https://wiki.crowncloud.net/?How_to_Install_Fail2Ban_on_RockyLinux_8), som kan hj\u00e4lpa till att sk\u00e4ra ner p\u00e5 brute force-attacker. Uppenbarligen p\u00e5 ett lokalt n\u00e4tverk som du styr (och d\u00e4r du kan st\u00e4lla in alla maskiners IP-adress manuellt), du kan anv\u00e4nda alla dessa regler s\u00e5 mycket du vill. Slutgiltiga anteckningar Detta \u00e4r l\u00e5ngt ifr\u00e5n en utt\u00f6mmande guide, och du kan l\u00e4ra dig en hel del mer med officiella brandv\u00e4gg dokumentation . Det finns ocks\u00e5 praktiska app-specifika guider \u00f6ver hela internet som visar dig hur du st\u00e4ller in din brandv\u00e4gg f\u00f6r de specifika apparna. F\u00f6r dig fans av iptables (om du har kommit s\u00e5 h\u00e4r l\u00e5ngt... , vi har en guide som beskriver n\u00e5gra av skillnaderna i hur brandv\u00e4gg och iptables fungerar. Den guiden kan hj\u00e4lpa dig att r\u00e4kna ut om du vill stanna med brandv\u00e4gg eller g\u00e5 tillbaka till De gamla v\u00e4garna (TM) . Det finns n\u00e5got att s\u00e4ga till The Old Ways (TM) , i detta fall. Slutsats Och det \u00e4r brandv\u00e4gg med s\u00e5 f\u00e5 ord som jag kunde hantera samtidigt som jag fortfarande f\u00f6rklarar alla grunder. Ta det l\u00e5ngsamt, experimentera noggrant, och g\u00f6r inga regler permanenta f\u00f6rr\u00e4n du \u00e4r s\u00e4ker p\u00e5 att de fungerar. Och du vet, ha kul. N\u00e4r du har grunderna ner, faktiskt inr\u00e4tta en anst\u00e4ndig, kan fungerande brandv\u00e4gg ta 5-10 minuter.","title":"brandv\u00e4gg f\u00f6r nyb\u00f6rjare"},{"location":"guides/security/firewalld-beginners.sv/#brandvagg-for-nyborjare","text":"","title":"brandv\u00e4gg f\u00f6r nyb\u00f6rjare"},{"location":"guides/security/firewalld-beginners.sv/#introduktion","text":"F\u00f6r l\u00e4nge sedan var jag lite nyb\u00f6rjare datoranv\u00e4ndare som h\u00f6rde att ha en brandv\u00e4gg var t\u00e4nkt att vara super bra. Det skulle l\u00e5ta mig best\u00e4mma vad som kom in, och vad fick ut av min dator, eller hur? Men det verkade mest att stoppa mina videospel fr\u00e5n att komma \u00e5t internet; Jag var inte en lycklig camper. Naturligtvis, om du \u00e4r h\u00e4r, har du f\u00f6rmodligen en b\u00e4ttre uppfattning om vad en brandv\u00e4gg \u00e4r och vad den g\u00f6r \u00e4n jag gjorde. Men om din brandv\u00e4gg erfarenhet inneb\u00e4r att tala om f\u00f6r Windows Defender att ja, f\u00f6r k\u00e4rleken till allt som \u00e4r heligt, din nya app \u00e4r till\u00e5ten att anv\u00e4nda internet, oroa dig inte. Det st\u00e5r \"f\u00f6r nyb\u00f6rjare\" upp p\u00e5 toppen, jag har dig. Med andra ord b\u00f6r mina n\u00f6rdar vara medvetna om att det kommer att finnas en hel del f\u00f6rklaringar till inkomst. S\u00e5 l\u00e5t oss tala om vad vi \u00e4r h\u00e4r f\u00f6r. brandv\u00e4gg \u00e4r standard-brandv\u00e4ggsappen paketerad med Rocky Linux, och den \u00e4r utformad f\u00f6r att vara ganska enkel att anv\u00e4nda. Du beh\u00f6ver bara veta lite om hur brandv\u00e4ggar fungerar, och inte vara r\u00e4dd f\u00f6r att anv\u00e4nda kommandoraden. H\u00e4r f\u00e5r du l\u00e4ra dig: Sj\u00e4lva grunderna i hur brandv\u00e4gg fungerar Hur du anv\u00e4nder brandv\u00e4gg f\u00f6r att begr\u00e4nsa eller till\u00e5ta inkommande och utg\u00e5ende anslutningar Hur man till\u00e5ter endast personer fr\u00e5n vissa IP-adresser eller platser att logga in p\u00e5 din maskin p\u00e5 distans Hur man hanterar n\u00e5gra brandv\u00e4gg -specifika funktioner som Zoner. Detta \u00e4r inte avsett att vara en komplett eller utt\u00f6mmande guide.","title":"Introduktion"},{"location":"guides/security/firewalld-beginners.sv/#en-anteckning-om-att-anvanda-kommandoraden-for-att-hantera-din-brandvagg","text":"V\u00e4l... det finns grafiska brandv\u00e4ggskonfigurationsalternativ. P\u00e5 skrivbordet finns brandv\u00e4gg-config som kan installeras fr\u00e5n repos, och p\u00e5 servrar kan du installera Cockpit f\u00f6r att hj\u00e4lpa dig att hantera brandv\u00e4ggar och ett helt g\u00e4ng andra saker. Jag kommer dock att l\u00e4ra dig kommandoradss\u00e4ttet att g\u00f6ra saker i den h\u00e4r handledningen av ett par sk\u00e4l: Om du k\u00f6r en server, kommer du att anv\u00e4nda kommandoraden f\u00f6r de flesta av dessa saker \u00e4nd\u00e5. Massor av \u00f6vningar och guider f\u00f6r Rocky server kommer att ge kommandoraden instruktioner f\u00f6r brandv\u00e4ggshantering, och det \u00e4r b\u00e4st att du f\u00f6rst\u00e5r dessa instruktioner, snarare \u00e4n att bara kopiera och klistra in vad du \u00e4n ser. Att f\u00f6rst\u00e5 hur brandv\u00e4gg kommandon fungerar kan hj\u00e4lpa dig att b\u00e4ttre f\u00f6rst\u00e5 hur brandv\u00e4ggsprogrammet fungerar. Du kan ta samma principer som du l\u00e4r dig h\u00e4r, och har en b\u00e4ttre uppfattning om vad du g\u00f6r om du v\u00e4ljer att anv\u00e4nda ett grafiskt gr\u00e4nssnitt i framtiden.","title":"En anteckning om att anv\u00e4nda kommandoraden f\u00f6r att hantera din brandv\u00e4gg"},{"location":"guides/security/firewalld-beginners.sv/#forutsattningar-och-antaganden","text":"Du beh\u00f6ver. En Rocky Linux-maskin av alla slag, lokal eller fj\u00e4rrstyrd, fysisk eller virtuell Tillg\u00e5ng till terminalen, och en vilja att anv\u00e4nda den Du beh\u00f6ver root-\u00e5tkomst, eller \u00e5tminstone m\u00f6jligheten att anv\u00e4nda sudo p\u00e5 ditt anv\u00e4ndarkonto. F\u00f6r enkelhetens skull antar jag att alla kommandon k\u00f6rs som rot. En grundl\u00e4ggande f\u00f6rst\u00e5else f\u00f6r SSH skulle inte skada f\u00f6r hantering av fj\u00e4rrmaskiner.","title":"F\u00f6ruts\u00e4ttningar och antaganden"},{"location":"guides/security/firewalld-beginners.sv/#grundlaggande-anvandning","text":"","title":"Grundl\u00e4ggande anv\u00e4ndning"},{"location":"guides/security/firewalld-beginners.sv/#systemtjanstkommandon","text":"brandv\u00e4gg k\u00f6rs som en tj\u00e4nst p\u00e5 din maskin. Det b\u00f6rjar n\u00e4r maskinen g\u00f6r det, eller det borde. Om brandv\u00e4gg av n\u00e5gon anledning inte redan \u00e4r aktiverat p\u00e5 din maskin, kan du g\u00f6ra det med ett enkelt kommando: systemctl aktivera --nu brandv\u00e4gg Flaggan --now startar tj\u00e4nsten s\u00e5 snart den \u00e4r aktiverad, och l\u00e5t dig hoppa \u00f6ver systemctl starta brandv\u00e4ggen steget. Som med alla tj\u00e4nster p\u00e5 Rocky Linux kan du kontrollera om brandv\u00e4ggen k\u00f6rs med: brandv\u00e4gg systemctl status Att stoppa det helt och h\u00e5llet: systemctl stoppa brandv\u00e4gg Och f\u00f6r att ge tj\u00e4nsten en h\u00e5rd omstart: systemctl starta om brandv\u00e4gg","title":"Systemtj\u00e4nstkommandon"},{"location":"guides/security/firewalld-beginners.sv/#grundlaggande-brandvagg-konfigurations-och-hanteringskommandon","text":"brandv\u00e4gg \u00e4r konfigurerad med brandv\u00e4gg-cmd kommandot. Du kan till exempel kontrollera statusen f\u00f6r brandv\u00e4gg med: brandv\u00e4gg-cmd --stat Efter varje permanent \u00e4ndring av din brandv\u00e4gg, m\u00e5ste du ladda om den f\u00f6r att se \u00e4ndringarna. Du kan ge brandv\u00e4ggskonfigurationerna en \"mjuk omstart\" med: brandv\u00e4gg-cmd --ladda om !!! Anteckning Om du laddar om dina konfigurationer som inte har blivit permanenta, f\u00f6rsvinner de p\u00e5 dig. Du kan se alla dina konfigurationer och inst\u00e4llningar samtidigt med: brandv\u00e4gg-cmd --list-all Det kommandot kommer att skriva ut n\u00e5got som ser ut s\u00e5 h\u00e4r: offentliga (aktiva) m\u00e5l: standard icmp-block-inversion: inga gr\u00e4nssnitt: enp9s0 k\u00e4llor: tj\u00e4nster: ssh portar: protokoll: fram\u00e5t: nej maskerad: nej fram\u00e5t-portar: k\u00e4ll-portar: icmp-blocks: rika regler:","title":"Grundl\u00e4ggande brandv\u00e4gg konfigurations- och hanteringskommandon"},{"location":"guides/security/firewalld-beginners.sv/#sparar-dina-andringar","text":"!!! Varning \"Varning: Allvarligt, l\u00e4s n\u00e4sta bit.\" Som standard \u00e4r alla \u00e4ndringar i `firewalld`s konfiguration tillf\u00e4lliga. Om du startar om hela `firewalld`-tj\u00e4nsten eller startar om din maskin, Ingen av dina \u00e4ndringar i brandv\u00e4ggen kommer att sparas om du inte g\u00f6r en av tv\u00e5 mycket specifika saker. Det \u00e4r b\u00e4st att testa alla dina \u00e4ndringar en efter en, ladda om din brandv\u00e4gg konfiguration n\u00e4r du g\u00e5r. P\u00e5 det s\u00e4ttet, om du av misstag l\u00e5sa dig sj\u00e4lv ur n\u00e5got, Du kan starta om tj\u00e4nsten (eller maskinen), alla dessa \u00e4ndringar f\u00f6rsvinner som n\u00e4mnts ovan. Men n\u00e4r du har en fungerande konfiguration, kan du spara dina \u00e4ndringar permanent med: brandv\u00e4gg-cmd --runtime-to-permanent Men om du \u00e4r helt s\u00e4ker p\u00e5 vad du g\u00f6r, och bara vill l\u00e4gga till regeln och g\u00e5 vidare med ditt liv, du kan l\u00e4gga till flaggan --permanent till valfritt konfigurationskommando: brandv\u00e4gg-cmd - permanent [resten av ditt kommando]","title":"Sparar dina \u00e4ndringar"},{"location":"guides/security/firewalld-beginners.sv/#hantera-zoner","text":"Innan n\u00e5got annat m\u00e5ste jag f\u00f6rklara zoner. Zoner \u00e4r en funktion som i grunden g\u00f6r att du kan definiera olika upps\u00e4ttningar av regler f\u00f6r olika situationer. Zoner \u00e4r en stor del av brandv\u00e4gg s\u00e5 det l\u00f6nar sig att f\u00f6rst\u00e5 hur de fungerar. Om din maskin har flera s\u00e4tt att ansluta till olika n\u00e4tverk (t.ex. Ethernet och WiFi) kan du best\u00e4mma att en anslutning \u00e4r mer betrodd \u00e4n den andra. Du kan st\u00e4lla in din Ethernet-anslutning till den \"betrodda\" zonen om den bara \u00e4r ansluten till ett lokalt n\u00e4tverk som du byggt, och s\u00e4tta WiFi (som kan vara ansluten till internet) i den \"offentliga\" zonen med str\u00e4ngare begr\u00e4nsningar. !!! Anteckning En zon kan *endast* vara i ett aktivt tillst\u00e5nd om den har n\u00e5got av dessa tv\u00e5 f\u00f6ruts\u00e4ttningar: 1. Zonen \u00e4r tilldelad till ett n\u00e4tverksgr\u00e4nssnitt 2. Zonen \u00e4r tilldelad k\u00e4lla IP-adresser eller n\u00e4tverksintervall. (Mer om detta nedan) Standardzoner inkluderar f\u00f6ljande (jag har tagit denna f\u00f6rklaring fr\u00e5n DigitalOceans guide till brandv\u00e4gg , som du ocks\u00e5 b\u00f6r l\u00e4sa): droppe: Den l\u00e4gsta niv\u00e5n av tillit. Alla inkommande anslutningar sl\u00e4pps utan svar och endast utg\u00e5ende anslutningar \u00e4r m\u00f6jliga. block: Liknar ovan, men ist\u00e4llet f\u00f6r att helt enkelt sl\u00e4ppa anslutningar, avvisas inkommande f\u00f6rfr\u00e5gningar med ett icmp-host-f\u00f6rbjudet eller icmp6-adm-f\u00f6rbjudet meddelande. public: Representerar offentliga, op\u00e5litliga n\u00e4tverk. Du litar inte p\u00e5 andra datorer men kan till\u00e5ta valda inkommande anslutningar fr\u00e5n fall till fall. externt: Externa n\u00e4tverk i h\u00e4ndelse av att du anv\u00e4nder brandv\u00e4ggen som port. Det \u00e4r konfigurerat f\u00f6r NAT maskering s\u00e5 att ditt interna n\u00e4tverk f\u00f6rblir privat men kan n\u00e5s. internt: Den andra sidan av den yttre zonen, som anv\u00e4nds f\u00f6r den inre delen av en gateway. Datorerna \u00e4r ganska p\u00e5litliga och vissa ytterligare tj\u00e4nster finns tillg\u00e4ngliga. dmz: Anv\u00e4nds f\u00f6r datorer som ligger i en DMZ (isolerade datorer som inte har tillg\u00e5ng till resten av ditt n\u00e4tverk). Endast vissa inkommande anslutningar \u00e4r till\u00e5tna. arbete: Anv\u00e4nds f\u00f6r arbetsmaskiner. Lita p\u00e5 de flesta datorer i n\u00e4tverket. N\u00e5gra fler tj\u00e4nster kan till\u00e5tas. hem: En hemmilj\u00f6. Det inneb\u00e4r i allm\u00e4nhet att du litar p\u00e5 de flesta andra datorer och att n\u00e5gra fler tj\u00e4nster kommer att accepteras. litade p\u00e5: Lita p\u00e5 alla maskiner i n\u00e4tverket. Den mest \u00f6ppna av de tillg\u00e4ngliga alternativen och b\u00f6r anv\u00e4ndas sparsamt. Okej, s\u00e5 n\u00e5gra av dessa f\u00f6rklaringar blir komplicerade, men \u00e4rligt? Den genomsnittliga nyb\u00f6rjaren kan f\u00e5 med att f\u00f6rst\u00e5 \"betrodd\", \"hem\", och \"offentlig\", och n\u00e4r man ska anv\u00e4nda vilken.","title":"Hantera zoner"},{"location":"guides/security/firewalld-beginners.sv/#zonhanteringskommandon","text":"K\u00f6r f\u00f6r att se din standardzon: brandv\u00e4gg-cmd --get-default-zone F\u00f6r att se vilka zoner som \u00e4r aktiva och g\u00f6ra saker, k\u00f6ra: brandv\u00e4gg-cmd --get-active-zoner !!! Notera att en del av detta kan ha gjorts f\u00f6r dig.\" Om du k\u00f6r Rocky Linux p\u00e5 en VPS, \u00e4r det troligt att en grundl\u00e4ggande konfiguration har konfigurerats f\u00f6r dig. Specifikt b\u00f6r du kunna komma \u00e5t servern via SSH, och n\u00e4tverksgr\u00e4nssnittet kommer redan att ha lagts till den \"offentliga\" zonen. F\u00f6r att \u00e4ndra standardzonen: brandv\u00e4gg-cmd --set-default-zone [your-zone] L\u00e4gga till ett n\u00e4tverksgr\u00e4nssnitt i en zon: firewall-cmd --zone=[your-zone] --add-interface=[your-network-device] \u00c4ndra zonen i ett n\u00e4tverksgr\u00e4nssnitt: brandv\u00e4gg-cmd --zone=[your-zone] --change-interface=[your-network-device] Ta bort ett gr\u00e4nssnitt fr\u00e5n en zon helt: firewall-cmd --zone=[your-zone] --remove-interface=[your-network-device] F\u00f6r att g\u00f6ra din egen helt nya zon med en helt egen upps\u00e4ttning regler, och f\u00f6r att kontrollera att den har lagts till ordentligt: brandv\u00e4gg-cmd --new-zone=[your-new-zone] brandv\u00e4gg-cmd --get-zones","title":"Zonhanteringskommandon"},{"location":"guides/security/firewalld-beginners.sv/#hantera-portar","text":"F\u00f6r de oinitierade \u00e4r portarna (i detta sammanhang) bara virtuella \u00e4ndpunkter d\u00e4r datorer ansluter till varandra s\u00e5 att de kan skicka information fram och tillbaka. T\u00e4nk p\u00e5 dem som fysiska Ethernet eller USB-portar p\u00e5 din dator, men osynliga, och du kan ha upp till 65.535 av dem alla p\u00e5 en g\u00e5ng. Det skulle jag inte, men ni kan. Varje port definieras av ett nummer, och vissa hamnar \u00e4r reserverade f\u00f6r specifika tj\u00e4nster och typer av information. Om du n\u00e5gonsin har arbetat med webbservrar f\u00f6r att bygga en webbplats, till exempel, kan du vara bekant med port 80 och port 443. Dessa portar m\u00f6jligg\u00f6r \u00f6verf\u00f6ring av webbsidedata. Specifikt, port 80 till\u00e5ter \u00f6verf\u00f6ring av data via Hypertext Transfer Protocol (HTTP), och port 443 \u00e4r reserverad f\u00f6r Hypertext Transfer Protocol Secure (HTTPS) data. * Port 22 \u00e4r reserverad f\u00f6r Secure Shell Protocol (SSH) som l\u00e5ter dig logga in och hantera andra maskiner via kommandoraden (se v\u00e5r korta guide p\u00e5 suject). helt ny fj\u00e4rrserver kan bara till\u00e5ta anslutningar \u00f6ver port 22 f\u00f6r SSH, och inget annat. Andra exempel \u00e4r FTP (portar 20 och 21), SSH (port 22), och s\u00e5 m\u00e5nga fler. Du kan ocks\u00e5 st\u00e4lla in anpassade portar som ska anv\u00e4ndas av nya appar som du kan installera, som inte redan har ett standardnummer. !!! Notera \"Obs: Du b\u00f6r inte anv\u00e4nda portar f\u00f6r allt.\" F\u00f6r saker som SSH, HTTP/S, FTP och mer, \u00e4r det faktiskt rekommenderat att l\u00e4gga till dem i din brandv\u00e4ggszon som *tj\u00e4nster*, och inte som portnummer. Jag ska visa dig hur det fungerar nedan. Som sagt, du beh\u00f6ver fortfarande veta hur man \u00f6ppnar portar manuellt. * F\u00f6r absolut nyb\u00f6rjare \u00e4r HTTPS i princip (mer eller mindre) samma som HTTP, men krypterad.","title":"Hantera portar"},{"location":"guides/security/firewalld-beginners.sv/#porthanteringskommandon","text":"F\u00f6r det h\u00e4r avsnittet anv\u00e4nder jag --zone=public ... och portar 9001 som ett slumpm\u00e4ssigt exempel, eftersom det \u00e4r \u00f6ver 9000. F\u00f6r att se alla \u00f6ppna portar: brandv\u00e4gg-cmd --list-portar F\u00f6r att l\u00e4gga till en port till din brandv\u00e4ggszon (\u00f6ppna den f\u00f6r anv\u00e4ndning), k\u00f6r du bara detta kommando: brandv\u00e4gg-cmd --zone=public --add-port=9001/tcp !!! Anteckning Om den `/tcp`-biten: Den d\u00e4r `/tcp`-biten i slutet talar om f\u00f6r brandv\u00e4ggen att anslutningar kommer in \u00f6ver \u00f6verf\u00f6ringskontrollprotokollet, vilket \u00e4r vad du kommer att anv\u00e4nda f\u00f6r de flesta server-och-hem-relaterade grejer. Alternativ som UDP \u00e4r f\u00f6r fels\u00f6kning, eller andra mycket specifika typer av saker som uppriktigt sagt inte omfattas av den h\u00e4r guiden. Se dokumentationen f\u00f6r vilken app eller tj\u00e4nst du vill \u00f6ppna en port f\u00f6r. F\u00f6r att ta bort en port, v\u00e4nd bara kommandot med en enda ord\u00e4ndring: brandv\u00e4gg-cmd --zone=offentlig --remove-port=9001/tcp","title":"Porthanteringskommandon"},{"location":"guides/security/firewalld-beginners.sv/#hantera-tjanster","text":"Tj\u00e4nster, som ni kanske tror, \u00e4r ganska standardiserade program som k\u00f6rs p\u00e5 din dator. brandv\u00e4gg \u00e4r satt upp s\u00e5 att det bara kan \u00f6ppna v\u00e4gen f\u00f6r de vanligaste tj\u00e4nsterna n\u00e4r du beh\u00f6ver g\u00f6ra det. Detta \u00e4r det b\u00e4sta s\u00e4ttet att \u00f6ppna hamnarna f\u00f6r dessa gemensamma tj\u00e4nster, och en hel del mer: HTTP och HTTPS: f\u00f6r webbservrar FTP: F\u00f6r att flytta filer fram och tillbaka (gammaldags s\u00e4tt) SSH: F\u00f6r att styra fj\u00e4rrmaskiner och flytta filer bacck och fram\u00e5t det nya s\u00e4ttet Samba: F\u00f6r att dela filer med Windows-maskiner !!! Varning **Ta aldrig bort SSH-tj\u00e4nsten fr\u00e5n en fj\u00e4rrservers brandv\u00e4gg!** Kom ih\u00e5g att SSH \u00e4r vad du anv\u00e4nder f\u00f6r att logga in p\u00e5 din server. Om du inte har ett annat s\u00e4tt att komma \u00e5t den fysiska servern, eller dess skal (dvs via. en kontrollpanel som tillhandah\u00e5lls av v\u00e4rden), ta bort SSH-tj\u00e4nsten kommer att l\u00e5sa dig permanent. Du beh\u00f6ver antingen kontakta supporten f\u00f6r att f\u00e5 tillbaka din \u00e5tkomst eller installera om operativsystemet helt och h\u00e5llet.","title":"Hantera tj\u00e4nster"},{"location":"guides/security/firewalld-beginners.sv/#service-management-kommandon","text":"F\u00f6r att se en lista \u00f6ver alla tj\u00e4nster som du kan l\u00e4gga till i din brandv\u00e4gg, k\u00f6ra: brandv\u00e4gg-cmd --get-services F\u00f6r att se vilka tj\u00e4nster du f\u00f6r n\u00e4rvarande har aktiv p\u00e5 din brandv\u00e4gg, anv\u00e4nd: brandv\u00e4gg-cmd --list-services F\u00f6r att \u00f6ppna en tj\u00e4nst i din brandv\u00e4gg (t.ex. HTTP i den offentliga zonen), anv\u00e4nd: firewall-cmd --zone=public --add-service=http F\u00f6r att ta bort/st\u00e4nga en tj\u00e4nst p\u00e5 din brandv\u00e4gg, \u00e4ndra bara ett ord igen: brandv\u00e4gg-cmd --zone=public --remove-service=http !!! Notera att du kan l\u00e4gga till dina egna tj\u00e4nster\" Och anpassa heck ur dem ocks\u00e5. Det \u00e4r dock ett \u00e4mne som blir lite komplext. Bekanta dig f\u00f6rst med `brandv\u00e4gg` och g\u00e5 d\u00e4rifr\u00e5n.","title":"Service Management-kommandon"},{"location":"guides/security/firewalld-beginners.sv/#begransa-atkomst","text":"L\u00e5t oss s\u00e4ga att du har en server, och du vill bara inte g\u00f6ra det offentligt. om du vill definiera bara vem som f\u00e5r komma \u00e5t det via SSH, eller visa n\u00e5gra privata webbsidor/appar, kan du g\u00f6ra det. Det finns ett par metoder f\u00f6r att \u00e5stadkomma detta. F\u00f6r det f\u00f6rsta, f\u00f6r en mer l\u00e5st server, kan du v\u00e4lja en av de mer restriktiva zonerna, tilldela din n\u00e4tverksenhet till det, l\u00e4gg till SSH-tj\u00e4nsten till den som visas ovan, och sedan vitlista din egen publika IP-adress s\u00e5h\u00e4r: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0 [< s\u00e4tt in din IP h\u00e4r] Du kan g\u00f6ra det en rad IP-adresser genom att l\u00e4gga till ett h\u00f6gre antal i slutet som s\u00e5: firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0/24 [< s\u00e4tt in din IP h\u00e4r] \u00c5terigen, \u00e4ndra bara --add-source till --remove-source f\u00f6r att \u00e4ndra processen. Men om du hanterar en fj\u00e4rrserver med en webbplats p\u00e5 den som m\u00e5ste vara offentlig, och \u00e4nd\u00e5 bara vill \u00f6ppna upp SSH f\u00f6r en IP-adress eller ett litet utbud av dem, har du ett par alternativ. I b\u00e5da dessa exempel \u00e4r det enda n\u00e4tverksgr\u00e4nssnittet tilldelat den offentliga zonen. F\u00f6rst kan du anv\u00e4nda en \"rik regel\" till din offentliga zon, och det skulle se ut ungef\u00e4r s\u00e5 h\u00e4r: # firewall-cmd --permanent --zone=public --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept\" N\u00e4r v\u00e4l den rika regeln \u00e4r p\u00e5 plats, g\u00f6r inte reglerna permanenta \u00e4nnu. Ta f\u00f6rst bort SSH-tj\u00e4nsten fr\u00e5n konfigurationen f\u00f6r offentlig zon och testa din anslutning f\u00f6r att se till att du fortfarande kan komma \u00e5t servern via SSH. Din konfiguration ska nu se ut s\u00e5 h\u00e4r: your@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 sources: services: cockpit dhcpv6-client ports: 80/tcp 443/tcp protokoll: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules rule family=\"ipv4\" source address=\"192. 68.1.0/24\" servicenamn = \"ssh\" acceptera F\u00f6r det andra kan man anv\u00e4nda tv\u00e5 olika zoner \u00e5t g\u00e5ngen. Om du har ditt gr\u00e4nssnitt bundet till den offentliga zonen, du kan aktivera en andra zon (den \"betrodda\" zonen till exempel) genom att l\u00e4gga till en k\u00e4lla IP eller IP-intervall till den som visas ovan. L\u00e4gg sedan till SSH-tj\u00e4nsten till den betrodda zonen, och ta bort den fr\u00e5n den offentliga zonen. N\u00e4r du \u00e4r klar b\u00f6r utdata se ut lite s\u00e5 h\u00e4r: ditt@server ~# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: wlp3s0 k\u00e4llor: tj\u00e4nster: cockpit dhcpv6-client portar: 80/tcp 443/tcp protokoll: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rika regler: din@server ~# firewall-cmd --list-all --zone=trusted trusted (active) target: default icmp-block-inversion: no interfaces: k\u00e4llor: 192. 68.0.0/24 tj\u00e4nster: ssh portar: protokoll: fram\u00e5t: nej maskerad: nej fram\u00e5triktade portar: k\u00e4llportar: icmp-block: rika regler: Om du blir utl\u00e5st, starta om servern (de flesta VPS kontrollpaneler har ett alternativ f\u00f6r detta) och f\u00f6rs\u00f6k igen. !!! Varning Dessa tekniker fungerar bara om du har en statisk IP-adress. Om du har fastnat med en internetleverant\u00f6r som \u00e4ndrar din IP-adress varje g\u00e5ng ditt modem startar om, Anv\u00e4nd inte dessa regler (\u00e5tminstone inte f\u00f6r SSH) f\u00f6rr\u00e4n du har en r\u00e4ttelse f\u00f6r det. Du kommer att l\u00e5sa dig sj\u00e4lv fr\u00e5n din server Antingen uppgradera din internetplan/leverant\u00f6r, eller f\u00e5 en VPN som ger dig en dedikerad IP-adress, och *aldrig, n\u00e5gonsin* f\u00f6rlorar den. Under tiden, [installera och konfigurera fail2ban](https://wiki.crowncloud.net/?How_to_Install_Fail2Ban_on_RockyLinux_8), som kan hj\u00e4lpa till att sk\u00e4ra ner p\u00e5 brute force-attacker. Uppenbarligen p\u00e5 ett lokalt n\u00e4tverk som du styr (och d\u00e4r du kan st\u00e4lla in alla maskiners IP-adress manuellt), du kan anv\u00e4nda alla dessa regler s\u00e5 mycket du vill.","title":"Begr\u00e4nsa \u00e5tkomst"},{"location":"guides/security/firewalld-beginners.sv/#slutgiltiga-anteckningar","text":"Detta \u00e4r l\u00e5ngt ifr\u00e5n en utt\u00f6mmande guide, och du kan l\u00e4ra dig en hel del mer med officiella brandv\u00e4gg dokumentation . Det finns ocks\u00e5 praktiska app-specifika guider \u00f6ver hela internet som visar dig hur du st\u00e4ller in din brandv\u00e4gg f\u00f6r de specifika apparna. F\u00f6r dig fans av iptables (om du har kommit s\u00e5 h\u00e4r l\u00e5ngt... , vi har en guide som beskriver n\u00e5gra av skillnaderna i hur brandv\u00e4gg och iptables fungerar. Den guiden kan hj\u00e4lpa dig att r\u00e4kna ut om du vill stanna med brandv\u00e4gg eller g\u00e5 tillbaka till De gamla v\u00e4garna (TM) . Det finns n\u00e5got att s\u00e4ga till The Old Ways (TM) , i detta fall.","title":"Slutgiltiga anteckningar"},{"location":"guides/security/firewalld-beginners.sv/#slutsats","text":"Och det \u00e4r brandv\u00e4gg med s\u00e5 f\u00e5 ord som jag kunde hantera samtidigt som jag fortfarande f\u00f6rklarar alla grunder. Ta det l\u00e5ngsamt, experimentera noggrant, och g\u00f6r inga regler permanenta f\u00f6rr\u00e4n du \u00e4r s\u00e4ker p\u00e5 att de fungerar. Och du vet, ha kul. N\u00e4r du har grunderna ner, faktiskt inr\u00e4tta en anst\u00e4ndig, kan fungerande brandv\u00e4gg ta 5-10 minuter.","title":"Slutsats"},{"location":"guides/security/firewalld/","tags":["security","firewalld"],"text":"iptables Guide To firewalld - Introduction Ever since firewalld came out as the default firewall (I believe this was with CentOS 7, even though it was introduced in 2011), I've made it my mission in life to return to iptables at all costs. There were two reasons for this. First, the documentation that was available at the time used simplistic rules that did not properly show how the server was being secured down to the IP level . Second, and probably the primary reason: I had a long history with iptables going back many years, and it was frankly easier to just continue using iptables . Every server I deployed, whether it was public facing or internal, used an iptables firewall rule set. It was easy to simply adjust a default set of rules for the server we were dealing with and deploy. In order to do this on CentOS 7, CentOS 8, and now Rocky Linux 8, I needed to use this procedure . So why am I writing this document? First, to address the limitations of most firewalld references and, second, to force myself to find ways to use firewalld to mimic those more granular firewall rules. And, of course, to help beginners get a handle on Rocky Linux's default firewall. From the manual page: \" firewalld provides a dynamically managed firewall with support for network/firewall zones to define the trust level of network connections or interfaces. It has support for IPv4, IPv6 firewall settings and for Ethernet bridges and has a separation of runtime and permanent configuration options. It also supports an interface for services or applications to add firewall rules directly.\" Fun fact: firewalld is actually a front end to the netfilter and nftables Kernel sub-systems in Rocky Linux. This guide focuses on applying rules from an iptables firewall to a firewalld firewall. If you are really at the beginning of your firewall journey, this document might help you more. Consider reading through both documents to get the most out of firewalld . Prerequisites and Assumptions Throughout this document, we assume that you are either the root user or have used sudo to become so A passing knowledge of firewall rules, particularly iptables or at minimum, a desire to learn something about firewalld You feel comfortable entering commands at the command line. All of the examples here deal with IPv4 IPs. Zones To really get your head around firewalld , you need to understand the use of zones. Zones are where the granularity of the firewall rule sets are applied. firewalld has several built in zones: zone example use drop drop incoming connections without reply - only outgoing packets are allowed block incoming connections are rejected with an icmp-host-prohibited message for IPv4 and icmp6-adm-prohibited for IPv6 public all incoming connections are allowed external for use on external networks with masquerading enabled dmz for computers on your demilitarized zone that are publicly-accessible with limited access to your internal network work for computers in work areas (nope, I don't get this one either) home for use in home areas (nope, I don't get this one either) internal for your internal network device access trusted all network connections are accepted !!! Note `firewall-cmd` is the command line program for managing the `firewalld` daemon. To list existing zones on your system, type: firewall-cmd --get-zones !!! Warning Remember to check the status of your firewall, if the `firewalld-cmd` returns you an error, with either: the command firewall-cmd: ``` $ firewall-cmd --state running ``` the systemctl command: ``` $ systemctl status firewalld ``` To be honest, I mostly hate the names of these zones. drop, block, public, and trusted are perfectly clear, but some aren't good enough for perfect granular security. Let's take this iptables rule section as an example: iptables -A INPUT -p tcp -m tcp -s 192.168.1.122 --dport 22 -j ACCEPT Here we have a single IP address being allowed for SSH (port 22) into the server. If we decide to use the built-in zones, we could use \"trusted\" for this. First, we would add the IP to the zone and second, we would apply the rule to the zone: firewall-cmd --zone=trusted --add-source=192.168.1.122 --permanent firewall-cmd --zone trusted --add-service=ssh --permanent But what if on this server we also have an intranet that is accessible to only the IP blocks that our organization is assigned? Would we use the \"internal\" zone now to apply to that rule? Frankly, I'd prefer to create a zone that deals with the admin users' IPs (those allowed to secure-shell into the server). Truth be told, I'd prefer to add all of my own zones, but that might be ridiculous to do. Adding Zones To add a zone, we need to use the firewall-cmd with the --new-zone parameter. We are going to add \"admin\" (for administrative) as a zone: firewall-cmd --new-zone=admin --permanent !!! Note We have used the --permanent flag a great deal throughout. For testing, it is recommended to add the rule without the `--permanent` flag, test it, and if it works as expected, then use the `firewall-cmd --runtime-to-permanent` to move the rule live prior to running `firewall-cmd --reload`. If the risk is low (in other words, you won't lock yourself out), you can add the `--permanent` flag as I've done here. Before this zone can actually be used, we need to reload the firewall: firewall-cmd --reload !!! hint A note about custom zones: If you need to add a zone that will be a trusted zone, but will only contain a particular source IP or interface and no protocols or services, and the \"trusted\" zone doesn't work for you, probably because you've already used it for something else, etc. You can add a custom zone to do this, but you must change the target of the zone from \"default\" to \"ACCEPT\" (REJECT or DROP can also be used, depending on your goals). Here's an example using a bridge interface (lxdbr0 in this case) on an LXD machine. First, we add the zone and reload so that we can use it: ``` firewall-cmd --new-zone=bridge --permanent firewall-cmd --reload ``` Next, we change the target of the zone from \"default\" to \"ACCEPT\" (**note that the \"--permanent\" option is required for changing a target**) then assign the interface, and reload: ``` firewall-cmd --zone=bridge --set-target=ACCEPT --permanent firewall-cmd --zone=bridge --add-interface=lxdbr0 --permanent firewall-cmd --reload ``` This tells the firewall that you: 1. are changing the target of the zone to ACCEPT 2. are adding the bridge interface \"lxdbr0\" to the zone 3. reloading the firewall All of which says that you are accepting all traffic from the bridge interface. Listing Zones Before we go any further, we need to take a look at the process of listing zones. Rather than a tabular output provided by iptables -L , you get a single column of output with headers. Listing a zone is done with the command firewall-cmd --zone=[zone_name] --list-all . Here's what this looks like when we list out the newly created \"admin\" zone: firewall-cmd --zone=admin --list-all admin target: default icmp-block-inversion: no interfaces: sources: services: ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: You can list out the active zones on your system by using this command: firewall-cmd --get-active-zones !!! Note \"Important: Active Zones\" A zone can *only* be in an active state if it has one of these two conditions: 1. The zone is assigned to a network interface 2. The zone is assigned source IPs or network ranges. Removing an IP and Service from a Zone If you actually followed the earlier instruction adding the IP to the \"trusted\" zone, we need to now remove it from that zone. Remember our note about using the --permanent flag? This is a good place to avoid using it while doing proper testing before taking this rule live: firewall-cmd --zone=trusted --remove-source=192.168.1.122 We also want to remove the service ssh from the zone: firewall-cmd --zone=trusted --remove-service ssh Then test. You want to make sure that you have a way in via ssh from another zone before doing the final two steps. (See Warning below!). If you've made no other changes, then the \"public\" zone will still have ssh allowed, as it is there by default. Once you are satisfied, move the runtime rules to permanent: firewall-cmd --runtime-to-permanent and reload: firewall-cmd --reload !!! Warning If you're working on a remote server or VPS, hold off on that last instruction! *NEVER remove the `ssh` service from a remote server* unless you have another way to access the shell (see below). If you lock yourself out of `ssh` access via the firewall, you'll need to (in the worst-case scenarios) go fix your server in person, contact support, or possibly reinstall the OS from your control panel (depending on whether the server is physical or virtual). Using A New Zone - Adding Administrative IPs Now just repeat our original steps using the \"admin\" zone: firewall-cmd --zone=admin --add-source=192.168.1.122 firewall-cmd --zone admin --add-service=ssh Now list the zone to make sure that the zone looks correct and has the service properly added: firewall-cmd --zone=admin --list-all Test your rule to make sure it works. To test: SSH as root from your source IP (above it is 192.168.1.122) ( the root user is used here because we are going to run commands on the host that require it ) Once connected, run tail /var/log/secure and you should get output that looks similar to this: Feb 14 22:02:34 serverhostname sshd[9805]: Accepted password for root from 192.168.1.122 port 42854 ssh2 Feb 14 22:02:34 serverhostname sshd[9805]: pam_unix(sshd:session): session opened for user root by (uid=0) This shows that the source IP for our SSH connection was indeed the same IP that we just added to the \"admin\" zone. So we should be safe to move this rule permanent: firewall-cmd --runtime-to-permanent When you've finished adding rules, don't forget to reload: firewall-cmd --reload There are obviously other services that might need to be added to the \"admin\" zone, but ssh is the most logical for now. !!! Warning By default the \"public\" zone has the `ssh` service enabled; this can be a security liability. Once you have your administrative zone created, assigned to `ssh`, and tested, you can remove the service from the public zone. If you have more than one administrative IP that you need to add (quite likely), then just add it to the sources for the zone. In this case, we are adding an IP to the \"admin\" zone: firewall-cmd --zone=admin --add-source=192.168.1.151 --permanent !!! Note Keep in mind that if you are working on a remote server or VPS, and have an internet connection that doesn't always use the same IP, you may want to open your `ssh` service to a range of IP addresses used by your internet service provider or geographical region. This, again, is so you don't get locked out by your own firewall. Many ISPs charge extra for dedicated IP addresses, if they're offered at all, so it's a real concern. The examples here assume that you are using IPs on your own private network to access a server that is also local. ICMP Rules Let's look at another line in our iptables firewall that we want to emulate in firewalld - Our ICMP rule: iptables -A INPUT -p icmp -m icmp --icmp-type 8 -s 192.168.1.136 -j ACCEPT For the newbies among us, ICMP is a data transfer protocol designed for error reporting. Basically, it tells you when there's been any sort of problem connecting to a machine. In reality, we would probably leave ICMP open to all of our local IPs (in this case 192.168.1.0/24). Keep in mind, though, that our \"public\" and \"admin\" zones will have ICMP on by default, so the first thing to do to limit ICMP to that one network address is to block these requests on \"public\" and \"admin\" . Again, this is for demonstration purposes. You would definitely want your administrative users to have ICMP to your servers, and they probably still will, because they are members of the LAN network IP. To turn off ICMP on the \"public\" zone, we would: firewall-cmd --zone=public --add-icmp-block={echo-request,echo-reply} --permanent And then do the same thing on our \"trusted\" zone: firewall-cmd --zone=trusted --add-icmp-block={echo-request,echo-reply} --permanent We've introduced something new here: The curly braces \"{}\" allow us to specify more than one parameter. As always, after making changes like this, we need to reload: firewall-cmd --reload Testing by using ping from a disallowed IP will give you: ping 192.168.1.104 PING 192.168.1.104 (192.168.1.104) 56(84) bytes of data. From 192.168.1.104 icmp_seq=1 Packet filtered From 192.168.1.104 icmp_seq=2 Packet filtered From 192.168.1.104 icmp_seq=3 Packet filtered Web Server Ports Here's the iptables script for publicly allowing http and https , the protocols you'd need to serve web pages: iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT And here's the firewalld equivalent that you have probably seen many times before: firewall-cmd --zone=public --add-service=http --add-service=https --permanent OK, that is all fine, but what if you are running for example, a Nextcloud service on http/https and you only wanted your trusted network to have access to it? It's not unusual! This sort of thing happens all the time, and just publicly allowing traffic, without considering who actually needs access, is a huge security hole. We can't actually use the \"trusted\" zone information that we've used above. That was for testing. We have to assume that we have at minimum our LAN IP block added to \"trusted\". That would look like this: firewall-cmd --zone=trusted --add-source=192.168.1.0/24 --permanent Then we need to add the services to the zone: firewall-cmd --zone=trusted --add-service=http --add-service=https --permanent If you had added those services to the \"public\" zone as well, you'd need to remove them: firewall-cmd --zone=public --remove-service=http --remove-service=https --permanent Now reload: firewall-cmd --reload FTP Ports Let's return to our iptables script. We have the following rules dealing with FTP: iptables -A INPUT -p tcp -m tcp --dport 20-21 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 7000-7500 -j ACCEPT This portion of the script deals with the standard FTP ports (20 and 21) as well as opening some additional passive ports. This sort of a rule set is often needed by such ftp servers as VSFTPD . Generally, this sort of rule would be on a publicly facing web server, and is there for allowing ftp connections from your customers. There is no ftp-data service (port 20) with firewalld . The ports 7000 through 7500 listed here are for passive FTP connections, and again, there's no direct way to do this in firewalld . You could switch to SFTP, which would simplify the port allow rules here, and is likely the recommended way these days. What we are trying to demonstrate here, however, is the conversion of a set of iptables rules to firewalld . To get around all of these issues, we can do the following. First, add the ftp service to the zone that is also hosting the web services. This is probably going to be \"public\" in this example: firewall-cmd --zone=public --add-service=ftp --permanent Then let's add the ftp-data port: firewall-cmd --zone=public --add-port=20/tcp --permanent Next let's add the passive connection ports: firewall-cmd --zone=public --add-port=7000-7500/tcp --permanent And then, you guessed it, reload: firewall-cmd --reload Database Ports If you are dealing with a web server, you are almost certainly dealing with a database. The access to that database should be handled with the same care that you apply to other services. If access is not needed from the world, apply your rule to something other than \"public\". The other consideration is, do you need to offer access at all? Again, this probably depends on your environment. Where I was previously employed, we ran a hosted web server for our customers. Many had Wordpress sites, and none of them really needed or requested access to any front-end for MariaDB . If a customer needed more access, we created an LXD container for their web server, set up the firewall the way the customer wanted it, and left them responsible for what happened on the server. Still, if your server is public, you may need to offer access to phpmyadmin or some other front-end to MariaDB . In this case, you need to concern yourself with the password requirements for the database and set the database user to something other than defaults. For me, password length is the primary consideration when creating passwords . Obviously, password security is a discussion for another document dealing with just that, so we will assume that you've a good password policy for your database access and the iptables line in your firewall dealing with the database looks like this: iptables -A INPUT -p tcp -m tcp --dport=3600 -j ACCEPT In this case, we simply add the service to the \"public\" zone for a firewalld conversion: firewall-cmd --zone=public --add-service=mysql --permanent Postgresql Considerations Postgresql uses it's own service port. Here's an IP tables rule example: iptables -A INPUT -p tcp -m tcp --dport 5432 -s 192.168.1.0/24 -j ACCEPT While it is less common on publicly facing web servers, it might be more common as an internal resource. The same security considerations apply. If you have a server on your trusted network (192.168.1.0/24 in our example), you might not want or need to give access to everyone on that network. Postgresql has an access list available to take care of the more granular access rights. Our firewalld rule would look something like this: firewall-cmd --zone=trusted --add-services=postgresql DNS Ports Having a private or public DNS server also means taking precautions in the rules you write to protect those services. If you have a private DNS server, with iptables rules that looked like this (note that most DNS services are UDP, rather than TCP, but not always): iptables -A INPUT -p udp -m udp -s 192.168.1.0/24 --dport 53 -j ACCEPT then allowing only your \"trusted\" zone would be correct. We've already setup our \"trusted\" zone's sources, so all you would need to do would be to add the service to the zone: firewall-cmd --zone=trusted --add-service=dns With a public facing DNS server, you would just need to add the same service to the \"public\" zone: firewall-cmd --zone=public --add-service=dns More on Listing Rules !!! Note You *can* list all of the rules if you like, by listing the nftables rules. It's ugly, and I don't recommend it, but if you really must, you can do a `nft list ruleset`. One thing that we haven't done much of yet is to list the rules. This is something that you can do by zone. Here are examples with the zones we have used. Please note that you can list the zone before you move a rule permanent too, which is a good idea. firewall-cmd --list-all --zone=trusted Here we can see what we have applied above: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: dns ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: echo-reply echo-request rich rules: This can be applied to any zone. For instance, here is the \"public\" zone so far: firewall-cmd --list-all --zone=public public target: default icmp-block-inversion: no interfaces: sources: services: cockpit dhcpv6-client ftp http https ports: 20/tcp 7000-7500/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: echo-reply echo-request rich rules: Note that we have removed \"ssh\" access from services and blocked icmp echo-reply and echo-request. In our \"admin\" zone so far, it looks like this: firewall-cmd --list-all --zone=admin admin (active) target: default icmp-block-inversion: no interfaces: sources: 192.168.1.122 192.168.1.151 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: Establised Related Rules Although I can find no document that specifically states this, it appears that firewalld handles the following iptables rule internally by default (if you know that this is incorrect, please correct this!): iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT Interfaces By default, firewalld will listen on all available interfaces. On a bare-metal server with multiple interfaces facing multiple networks, it will be necessary for you to assign an interface to a zone based on the network it faces. In our examples, we've not added any interfaces, because we are working with an LXD container for lab testing. We only have one interface to work with. Let's say that your \"public\" zone needs to be configured to use Ethernet port enp3s0 as this port has the public IP on it, and let's say that your \"trusted\" and \"admin\" zones are on the LAN interface, which might be enp3s1. To assign these zones to the appropriate interface, we would use the following commands: firewall-cmd --zone=public --change-interface=enp3s0 --permanent firewall-cmd --zone=trusted --change-interface=enp3s1 --permanent firewall-cmd --zone=admin --change-interface=enp3s1 --permanent firewall-cmd --reload Common firewall-cmd Commands We've used some commands already. Here are a few more common commands and what they do: Command Result firewall-cmd --list-all-zones similar to firewall-cmd --list-all --zone=[zone] except it lists all of the zones and their contents. firewall-cmd --get-default-zone shows the default zone, which is \"public\" unless it has been changed. firewall-cmd --list-services --zone=[zone] shows all of the services enabled for the zone. firewall-cmd --list-ports --zone=[zone] shows all ports open on the zone. firewall-cmd --get-active-zones shows the zones that are active on the system, their active interfaces, services, and ports. firewall-cmd --get-services shows all available services possible for use. firewall-cmd --runtime-to-permanent if you have entered many rules without the --permanent option, do this before reloading. There are a great many firewall-cmd options not covered here, but this gives you the most used commands. Conclusion Since firewalld is the recommended and included firewall with Rocky Linux, it is a good idea to get your head around how it works. Simplistic rules, included in documentation for applying services using firewalld often do not take into account what the server is being used for, and offer no options other than publicly allowing the service. This is a drawback that comes with security holes that just don't need to be there. When you see these instructions, think about what your server is being used for and whether or not the service in question needs to be open to the world. If not, consider using more granularity in your rules as described above. While the author still isn't 100% commfortable with switching over to firewalld , it is highly probable that I'll use firewalld in future documentation. The process of writing this document and lab-testing the results have been very helpful to me. Hopefully, they will be helpful to someone else as well. This is not meant to be an exhaustive guide to firewalld , but rather a starting point.","title":"firewalld from iptables"},{"location":"guides/security/firewalld/#iptables-guide-to-firewalld-introduction","text":"Ever since firewalld came out as the default firewall (I believe this was with CentOS 7, even though it was introduced in 2011), I've made it my mission in life to return to iptables at all costs. There were two reasons for this. First, the documentation that was available at the time used simplistic rules that did not properly show how the server was being secured down to the IP level . Second, and probably the primary reason: I had a long history with iptables going back many years, and it was frankly easier to just continue using iptables . Every server I deployed, whether it was public facing or internal, used an iptables firewall rule set. It was easy to simply adjust a default set of rules for the server we were dealing with and deploy. In order to do this on CentOS 7, CentOS 8, and now Rocky Linux 8, I needed to use this procedure . So why am I writing this document? First, to address the limitations of most firewalld references and, second, to force myself to find ways to use firewalld to mimic those more granular firewall rules. And, of course, to help beginners get a handle on Rocky Linux's default firewall. From the manual page: \" firewalld provides a dynamically managed firewall with support for network/firewall zones to define the trust level of network connections or interfaces. It has support for IPv4, IPv6 firewall settings and for Ethernet bridges and has a separation of runtime and permanent configuration options. It also supports an interface for services or applications to add firewall rules directly.\" Fun fact: firewalld is actually a front end to the netfilter and nftables Kernel sub-systems in Rocky Linux. This guide focuses on applying rules from an iptables firewall to a firewalld firewall. If you are really at the beginning of your firewall journey, this document might help you more. Consider reading through both documents to get the most out of firewalld .","title":"iptables Guide To firewalld - Introduction"},{"location":"guides/security/firewalld/#prerequisites-and-assumptions","text":"Throughout this document, we assume that you are either the root user or have used sudo to become so A passing knowledge of firewall rules, particularly iptables or at minimum, a desire to learn something about firewalld You feel comfortable entering commands at the command line. All of the examples here deal with IPv4 IPs.","title":"Prerequisites and Assumptions"},{"location":"guides/security/firewalld/#zones","text":"To really get your head around firewalld , you need to understand the use of zones. Zones are where the granularity of the firewall rule sets are applied. firewalld has several built in zones: zone example use drop drop incoming connections without reply - only outgoing packets are allowed block incoming connections are rejected with an icmp-host-prohibited message for IPv4 and icmp6-adm-prohibited for IPv6 public all incoming connections are allowed external for use on external networks with masquerading enabled dmz for computers on your demilitarized zone that are publicly-accessible with limited access to your internal network work for computers in work areas (nope, I don't get this one either) home for use in home areas (nope, I don't get this one either) internal for your internal network device access trusted all network connections are accepted !!! Note `firewall-cmd` is the command line program for managing the `firewalld` daemon. To list existing zones on your system, type: firewall-cmd --get-zones !!! Warning Remember to check the status of your firewall, if the `firewalld-cmd` returns you an error, with either: the command firewall-cmd: ``` $ firewall-cmd --state running ``` the systemctl command: ``` $ systemctl status firewalld ``` To be honest, I mostly hate the names of these zones. drop, block, public, and trusted are perfectly clear, but some aren't good enough for perfect granular security. Let's take this iptables rule section as an example: iptables -A INPUT -p tcp -m tcp -s 192.168.1.122 --dport 22 -j ACCEPT Here we have a single IP address being allowed for SSH (port 22) into the server. If we decide to use the built-in zones, we could use \"trusted\" for this. First, we would add the IP to the zone and second, we would apply the rule to the zone: firewall-cmd --zone=trusted --add-source=192.168.1.122 --permanent firewall-cmd --zone trusted --add-service=ssh --permanent But what if on this server we also have an intranet that is accessible to only the IP blocks that our organization is assigned? Would we use the \"internal\" zone now to apply to that rule? Frankly, I'd prefer to create a zone that deals with the admin users' IPs (those allowed to secure-shell into the server). Truth be told, I'd prefer to add all of my own zones, but that might be ridiculous to do.","title":"Zones"},{"location":"guides/security/firewalld/#adding-zones","text":"To add a zone, we need to use the firewall-cmd with the --new-zone parameter. We are going to add \"admin\" (for administrative) as a zone: firewall-cmd --new-zone=admin --permanent !!! Note We have used the --permanent flag a great deal throughout. For testing, it is recommended to add the rule without the `--permanent` flag, test it, and if it works as expected, then use the `firewall-cmd --runtime-to-permanent` to move the rule live prior to running `firewall-cmd --reload`. If the risk is low (in other words, you won't lock yourself out), you can add the `--permanent` flag as I've done here. Before this zone can actually be used, we need to reload the firewall: firewall-cmd --reload !!! hint A note about custom zones: If you need to add a zone that will be a trusted zone, but will only contain a particular source IP or interface and no protocols or services, and the \"trusted\" zone doesn't work for you, probably because you've already used it for something else, etc. You can add a custom zone to do this, but you must change the target of the zone from \"default\" to \"ACCEPT\" (REJECT or DROP can also be used, depending on your goals). Here's an example using a bridge interface (lxdbr0 in this case) on an LXD machine. First, we add the zone and reload so that we can use it: ``` firewall-cmd --new-zone=bridge --permanent firewall-cmd --reload ``` Next, we change the target of the zone from \"default\" to \"ACCEPT\" (**note that the \"--permanent\" option is required for changing a target**) then assign the interface, and reload: ``` firewall-cmd --zone=bridge --set-target=ACCEPT --permanent firewall-cmd --zone=bridge --add-interface=lxdbr0 --permanent firewall-cmd --reload ``` This tells the firewall that you: 1. are changing the target of the zone to ACCEPT 2. are adding the bridge interface \"lxdbr0\" to the zone 3. reloading the firewall All of which says that you are accepting all traffic from the bridge interface.","title":"Adding Zones"},{"location":"guides/security/firewalld/#listing-zones","text":"Before we go any further, we need to take a look at the process of listing zones. Rather than a tabular output provided by iptables -L , you get a single column of output with headers. Listing a zone is done with the command firewall-cmd --zone=[zone_name] --list-all . Here's what this looks like when we list out the newly created \"admin\" zone: firewall-cmd --zone=admin --list-all admin target: default icmp-block-inversion: no interfaces: sources: services: ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: You can list out the active zones on your system by using this command: firewall-cmd --get-active-zones !!! Note \"Important: Active Zones\" A zone can *only* be in an active state if it has one of these two conditions: 1. The zone is assigned to a network interface 2. The zone is assigned source IPs or network ranges.","title":"Listing Zones"},{"location":"guides/security/firewalld/#removing-an-ip-and-service-from-a-zone","text":"If you actually followed the earlier instruction adding the IP to the \"trusted\" zone, we need to now remove it from that zone. Remember our note about using the --permanent flag? This is a good place to avoid using it while doing proper testing before taking this rule live: firewall-cmd --zone=trusted --remove-source=192.168.1.122 We also want to remove the service ssh from the zone: firewall-cmd --zone=trusted --remove-service ssh Then test. You want to make sure that you have a way in via ssh from another zone before doing the final two steps. (See Warning below!). If you've made no other changes, then the \"public\" zone will still have ssh allowed, as it is there by default. Once you are satisfied, move the runtime rules to permanent: firewall-cmd --runtime-to-permanent and reload: firewall-cmd --reload !!! Warning If you're working on a remote server or VPS, hold off on that last instruction! *NEVER remove the `ssh` service from a remote server* unless you have another way to access the shell (see below). If you lock yourself out of `ssh` access via the firewall, you'll need to (in the worst-case scenarios) go fix your server in person, contact support, or possibly reinstall the OS from your control panel (depending on whether the server is physical or virtual).","title":"Removing an IP and Service from a Zone"},{"location":"guides/security/firewalld/#using-a-new-zone-adding-administrative-ips","text":"Now just repeat our original steps using the \"admin\" zone: firewall-cmd --zone=admin --add-source=192.168.1.122 firewall-cmd --zone admin --add-service=ssh Now list the zone to make sure that the zone looks correct and has the service properly added: firewall-cmd --zone=admin --list-all Test your rule to make sure it works. To test: SSH as root from your source IP (above it is 192.168.1.122) ( the root user is used here because we are going to run commands on the host that require it ) Once connected, run tail /var/log/secure and you should get output that looks similar to this: Feb 14 22:02:34 serverhostname sshd[9805]: Accepted password for root from 192.168.1.122 port 42854 ssh2 Feb 14 22:02:34 serverhostname sshd[9805]: pam_unix(sshd:session): session opened for user root by (uid=0) This shows that the source IP for our SSH connection was indeed the same IP that we just added to the \"admin\" zone. So we should be safe to move this rule permanent: firewall-cmd --runtime-to-permanent When you've finished adding rules, don't forget to reload: firewall-cmd --reload There are obviously other services that might need to be added to the \"admin\" zone, but ssh is the most logical for now. !!! Warning By default the \"public\" zone has the `ssh` service enabled; this can be a security liability. Once you have your administrative zone created, assigned to `ssh`, and tested, you can remove the service from the public zone. If you have more than one administrative IP that you need to add (quite likely), then just add it to the sources for the zone. In this case, we are adding an IP to the \"admin\" zone: firewall-cmd --zone=admin --add-source=192.168.1.151 --permanent !!! Note Keep in mind that if you are working on a remote server or VPS, and have an internet connection that doesn't always use the same IP, you may want to open your `ssh` service to a range of IP addresses used by your internet service provider or geographical region. This, again, is so you don't get locked out by your own firewall. Many ISPs charge extra for dedicated IP addresses, if they're offered at all, so it's a real concern. The examples here assume that you are using IPs on your own private network to access a server that is also local.","title":"Using A New Zone - Adding Administrative IPs"},{"location":"guides/security/firewalld/#icmp-rules","text":"Let's look at another line in our iptables firewall that we want to emulate in firewalld - Our ICMP rule: iptables -A INPUT -p icmp -m icmp --icmp-type 8 -s 192.168.1.136 -j ACCEPT For the newbies among us, ICMP is a data transfer protocol designed for error reporting. Basically, it tells you when there's been any sort of problem connecting to a machine. In reality, we would probably leave ICMP open to all of our local IPs (in this case 192.168.1.0/24). Keep in mind, though, that our \"public\" and \"admin\" zones will have ICMP on by default, so the first thing to do to limit ICMP to that one network address is to block these requests on \"public\" and \"admin\" . Again, this is for demonstration purposes. You would definitely want your administrative users to have ICMP to your servers, and they probably still will, because they are members of the LAN network IP. To turn off ICMP on the \"public\" zone, we would: firewall-cmd --zone=public --add-icmp-block={echo-request,echo-reply} --permanent And then do the same thing on our \"trusted\" zone: firewall-cmd --zone=trusted --add-icmp-block={echo-request,echo-reply} --permanent We've introduced something new here: The curly braces \"{}\" allow us to specify more than one parameter. As always, after making changes like this, we need to reload: firewall-cmd --reload Testing by using ping from a disallowed IP will give you: ping 192.168.1.104 PING 192.168.1.104 (192.168.1.104) 56(84) bytes of data. From 192.168.1.104 icmp_seq=1 Packet filtered From 192.168.1.104 icmp_seq=2 Packet filtered From 192.168.1.104 icmp_seq=3 Packet filtered","title":"ICMP Rules"},{"location":"guides/security/firewalld/#web-server-ports","text":"Here's the iptables script for publicly allowing http and https , the protocols you'd need to serve web pages: iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT And here's the firewalld equivalent that you have probably seen many times before: firewall-cmd --zone=public --add-service=http --add-service=https --permanent OK, that is all fine, but what if you are running for example, a Nextcloud service on http/https and you only wanted your trusted network to have access to it? It's not unusual! This sort of thing happens all the time, and just publicly allowing traffic, without considering who actually needs access, is a huge security hole. We can't actually use the \"trusted\" zone information that we've used above. That was for testing. We have to assume that we have at minimum our LAN IP block added to \"trusted\". That would look like this: firewall-cmd --zone=trusted --add-source=192.168.1.0/24 --permanent Then we need to add the services to the zone: firewall-cmd --zone=trusted --add-service=http --add-service=https --permanent If you had added those services to the \"public\" zone as well, you'd need to remove them: firewall-cmd --zone=public --remove-service=http --remove-service=https --permanent Now reload: firewall-cmd --reload","title":"Web Server Ports"},{"location":"guides/security/firewalld/#ftp-ports","text":"Let's return to our iptables script. We have the following rules dealing with FTP: iptables -A INPUT -p tcp -m tcp --dport 20-21 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 7000-7500 -j ACCEPT This portion of the script deals with the standard FTP ports (20 and 21) as well as opening some additional passive ports. This sort of a rule set is often needed by such ftp servers as VSFTPD . Generally, this sort of rule would be on a publicly facing web server, and is there for allowing ftp connections from your customers. There is no ftp-data service (port 20) with firewalld . The ports 7000 through 7500 listed here are for passive FTP connections, and again, there's no direct way to do this in firewalld . You could switch to SFTP, which would simplify the port allow rules here, and is likely the recommended way these days. What we are trying to demonstrate here, however, is the conversion of a set of iptables rules to firewalld . To get around all of these issues, we can do the following. First, add the ftp service to the zone that is also hosting the web services. This is probably going to be \"public\" in this example: firewall-cmd --zone=public --add-service=ftp --permanent Then let's add the ftp-data port: firewall-cmd --zone=public --add-port=20/tcp --permanent Next let's add the passive connection ports: firewall-cmd --zone=public --add-port=7000-7500/tcp --permanent And then, you guessed it, reload: firewall-cmd --reload","title":"FTP Ports"},{"location":"guides/security/firewalld/#database-ports","text":"If you are dealing with a web server, you are almost certainly dealing with a database. The access to that database should be handled with the same care that you apply to other services. If access is not needed from the world, apply your rule to something other than \"public\". The other consideration is, do you need to offer access at all? Again, this probably depends on your environment. Where I was previously employed, we ran a hosted web server for our customers. Many had Wordpress sites, and none of them really needed or requested access to any front-end for MariaDB . If a customer needed more access, we created an LXD container for their web server, set up the firewall the way the customer wanted it, and left them responsible for what happened on the server. Still, if your server is public, you may need to offer access to phpmyadmin or some other front-end to MariaDB . In this case, you need to concern yourself with the password requirements for the database and set the database user to something other than defaults. For me, password length is the primary consideration when creating passwords . Obviously, password security is a discussion for another document dealing with just that, so we will assume that you've a good password policy for your database access and the iptables line in your firewall dealing with the database looks like this: iptables -A INPUT -p tcp -m tcp --dport=3600 -j ACCEPT In this case, we simply add the service to the \"public\" zone for a firewalld conversion: firewall-cmd --zone=public --add-service=mysql --permanent","title":"Database Ports"},{"location":"guides/security/firewalld/#postgresql-considerations","text":"Postgresql uses it's own service port. Here's an IP tables rule example: iptables -A INPUT -p tcp -m tcp --dport 5432 -s 192.168.1.0/24 -j ACCEPT While it is less common on publicly facing web servers, it might be more common as an internal resource. The same security considerations apply. If you have a server on your trusted network (192.168.1.0/24 in our example), you might not want or need to give access to everyone on that network. Postgresql has an access list available to take care of the more granular access rights. Our firewalld rule would look something like this: firewall-cmd --zone=trusted --add-services=postgresql","title":"Postgresql Considerations"},{"location":"guides/security/firewalld/#dns-ports","text":"Having a private or public DNS server also means taking precautions in the rules you write to protect those services. If you have a private DNS server, with iptables rules that looked like this (note that most DNS services are UDP, rather than TCP, but not always): iptables -A INPUT -p udp -m udp -s 192.168.1.0/24 --dport 53 -j ACCEPT then allowing only your \"trusted\" zone would be correct. We've already setup our \"trusted\" zone's sources, so all you would need to do would be to add the service to the zone: firewall-cmd --zone=trusted --add-service=dns With a public facing DNS server, you would just need to add the same service to the \"public\" zone: firewall-cmd --zone=public --add-service=dns","title":"DNS Ports"},{"location":"guides/security/firewalld/#more-on-listing-rules","text":"!!! Note You *can* list all of the rules if you like, by listing the nftables rules. It's ugly, and I don't recommend it, but if you really must, you can do a `nft list ruleset`. One thing that we haven't done much of yet is to list the rules. This is something that you can do by zone. Here are examples with the zones we have used. Please note that you can list the zone before you move a rule permanent too, which is a good idea. firewall-cmd --list-all --zone=trusted Here we can see what we have applied above: trusted (active) target: ACCEPT icmp-block-inversion: no interfaces: sources: 192.168.1.0/24 services: dns ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: echo-reply echo-request rich rules: This can be applied to any zone. For instance, here is the \"public\" zone so far: firewall-cmd --list-all --zone=public public target: default icmp-block-inversion: no interfaces: sources: services: cockpit dhcpv6-client ftp http https ports: 20/tcp 7000-7500/tcp protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: echo-reply echo-request rich rules: Note that we have removed \"ssh\" access from services and blocked icmp echo-reply and echo-request. In our \"admin\" zone so far, it looks like this: firewall-cmd --list-all --zone=admin admin (active) target: default icmp-block-inversion: no interfaces: sources: 192.168.1.122 192.168.1.151 services: ssh ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules:","title":"More on Listing Rules"},{"location":"guides/security/firewalld/#establised-related-rules","text":"Although I can find no document that specifically states this, it appears that firewalld handles the following iptables rule internally by default (if you know that this is incorrect, please correct this!): iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT","title":"Establised Related Rules"},{"location":"guides/security/firewalld/#interfaces","text":"By default, firewalld will listen on all available interfaces. On a bare-metal server with multiple interfaces facing multiple networks, it will be necessary for you to assign an interface to a zone based on the network it faces. In our examples, we've not added any interfaces, because we are working with an LXD container for lab testing. We only have one interface to work with. Let's say that your \"public\" zone needs to be configured to use Ethernet port enp3s0 as this port has the public IP on it, and let's say that your \"trusted\" and \"admin\" zones are on the LAN interface, which might be enp3s1. To assign these zones to the appropriate interface, we would use the following commands: firewall-cmd --zone=public --change-interface=enp3s0 --permanent firewall-cmd --zone=trusted --change-interface=enp3s1 --permanent firewall-cmd --zone=admin --change-interface=enp3s1 --permanent firewall-cmd --reload","title":"Interfaces"},{"location":"guides/security/firewalld/#common-firewall-cmd-commands","text":"We've used some commands already. Here are a few more common commands and what they do: Command Result firewall-cmd --list-all-zones similar to firewall-cmd --list-all --zone=[zone] except it lists all of the zones and their contents. firewall-cmd --get-default-zone shows the default zone, which is \"public\" unless it has been changed. firewall-cmd --list-services --zone=[zone] shows all of the services enabled for the zone. firewall-cmd --list-ports --zone=[zone] shows all ports open on the zone. firewall-cmd --get-active-zones shows the zones that are active on the system, their active interfaces, services, and ports. firewall-cmd --get-services shows all available services possible for use. firewall-cmd --runtime-to-permanent if you have entered many rules without the --permanent option, do this before reloading. There are a great many firewall-cmd options not covered here, but this gives you the most used commands.","title":"Common firewall-cmd Commands"},{"location":"guides/security/firewalld/#conclusion","text":"Since firewalld is the recommended and included firewall with Rocky Linux, it is a good idea to get your head around how it works. Simplistic rules, included in documentation for applying services using firewalld often do not take into account what the server is being used for, and offer no options other than publicly allowing the service. This is a drawback that comes with security holes that just don't need to be there. When you see these instructions, think about what your server is being used for and whether or not the service in question needs to be open to the world. If not, consider using more granularity in your rules as described above. While the author still isn't 100% commfortable with switching over to firewalld , it is highly probable that I'll use firewalld in future documentation. The process of writing this document and lab-testing the results have been very helpful to me. Hopefully, they will be helpful to someone else as well. This is not meant to be an exhaustive guide to firewalld , but rather a starting point.","title":"Conclusion"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/","tags":["security","ssl","certbot"],"text":"Generating SSL Keys - Let's Encrypt Prerequisites & Assumptions Comfort with the command line Familiarity with securing web sites with SSL certificates is a plus Knowledge of command line text editors (this example uses vi ) An already running web server open to the world on port 80 (http) Familiarity with ssh (secure shell) and the ability to access your server with ssh All commands assume that you are either the root user or that you have used sudo to gain root access. Introduction One of the most popular ways to secure a web site, currently, is using Let's Encrypt SSL certificates, which are also free. These are actual certificates, not self-signed or snake oil, etc., so they are great for a low-budget security solution. This document will walk you through the process of installing and using Let's Encrypt certificates on a Rocky Linux web server. Installation To do the next steps, use ssh to log into your server. If your server's fully qualified DNS name was www.myhost.com, then you would use: ssh -l root www.myhost.com Or, if you must access your server as an unprivileged user first. Use your username: ssh -l username www.myhost.com And then: sudo -s You will need your sudo user's credentials in this case to gain access to the system as root. Let's Encrypt uses a package called certbot which needs to be installed via the EPEL repositories. Add those first: dnf install epel-release Then, just install the appropriate packages, depending on whether you're using Apache or Nginx as your web server. For Apache that's: dnf install certbot python3-certbot-apache For Nginx, just change out one... partial word? dnf install certbot python3-certbot-nginx You can always install both server modules if necessary, of course. !!! Note An earlier version of this guide required the snap package version of certbot, as it was found to be necessary at the time. The RPM versions have been re-tested recently, and are working now. Getting The Let's Encrypt Certificate for the Apache Server There are two ways to retrieve your Let's Encrypt certificate, either using the command to modify the http configuration file for you, or to just retrieve the certificate. If you are using the procedure for a multi-site setup suggested for one or more sites in the procedure Apache Web Server Multi-Site Setup , then you will only want to retrieve your certificate. We are assuming that you are using this procedure so we will only retrieve the certificate. If you are running a standalone web server using the default configuration, you can retrieve the certificate and modify the configuration file in one step using: certbot --apache That's really the easiest way to get things done. However, sometimes you want to take a more manual approach, and just want to grab the certificate. To retrieve the certificate only, use this command: certbot certonly --apache Both commands will generate a set of prompts that you will need to answer. The first is to give an email address for important information: Saving debug log to /var/log/letsencrypt/letsencrypt.log Plugins selected: Authenticator apache, Installer apache Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): yourusername@youremaildomain.com The next asks you to read and accept the terms of the subscriber agreement. Once you have read the agreement answer 'Y' to continue: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Please read the Terms of Service at https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You must agree in order to register with the ACME server. Do you agree? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - (Y)es/(N)o: The next is a request to share your email with the Electronic Frontier Foundation. Answer 'Y' or 'N' as is your preference: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Would you be willing, once your first certificate is successfully issued, to share your email address with the Electronic Frontier Foundation, a founding partner of the Let's Encrypt project and the non-profit organization that develops Certbot? We'd like to send you email about our work encrypting the web, EFF news, campaigns, and ways to support digital freedom. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - (Y)es/(N)o: The next prompt asks you which domain you want the certificate for. It should display a domain in the listing based on your running web server. If so, enter the number next to the domain that you are getting the certificate for. In this case there is only one option ('1'): Which names would you like to activate HTTPS for? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1: yourdomain.com - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Select the appropriate numbers separated by commas and/or spaces, or leave input blank to select all options shown (Enter 'c' to cancel): If all goes well, you should receive the following message: Requesting a certificate for yourdomain.com Performing the following challenges: http-01 challenge for yourdomain.com Waiting for verification... Cleaning up challenges Subscribe to the EFF mailing list (email: yourusername@youremaildomain.com). IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/yourdomain.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/yourdomain.com/privkey.pem Your certificate will expire on 2021-07-01. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run \"certbot renew\" - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le The Site Configuration - https Applying the configuration file to our site is slightly different than if we were using a purchased SSL certificate from another provider (and if we didn't let certbot do it automatically). The certificate and chain file are included in a single PEM (Privacy Enhanced Mail) file. This is a common format for all certificate files now, so even though it has \"Mail\" in the reference, it is just a type of certificate file. To illustrate the configuration file, we will show it in it's entirety and then describe what is happening: <VirtualHost *:80> ServerName www.yourdomain.com ServerAdmin username@rockylinux.org Redirect / https://www.yourdomain.com/ </VirtualHost> <Virtual Host *:443> ServerName www.yourdomain.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.yourdomain.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.yourdomain.www/cgi-bin/ CustomLog \"/var/log/httpd/com.yourdomain.www-access_log\" combined ErrorLog \"/var/log/httpd/com.yourdomain.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /etc/letsencrypt/live/yourdomain.com/fullchain.pem SSLCertificateKeyFile /etc/letsencrypt/live/yourdomain.com/privkey.pem SSLCertificateChainFile /etc/letsencrypt/live/yourdomain.com/fullchain.pem <Directory /var/www/sub-domains/com.yourdomain.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Here's what's happening above. You may want to review the Apache Web Server Multi-Site Setup to see the differences in the application of an SSL purchased from another provider and the Let's Encrypt certificate: Even though port 80 (standard http) is listening, we are redirecting all traffic to port 443 (https) SSLEngine on - simply says to use SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - says to use all available protocols, except those that have been found to have vulnerabilities. You should research periodically which protocols are currently acceptable for use. SSLHonorCipherOrder on - this deals with the next line regarding the cipher suites, and says to deal with them in the order that they are given. This is another area where you should review the cipher suites that you want to include periodically SSLCertificateFile - this is the PEM file, that contains the site certificate AND the intermediate certificate. We still need the 'SSLCertificateChainFile' line in our configuration, but it will simply specify the same PEM file again. SSLCertificateKeyFile - the PEM file for the private key, generated with the certbot request. SSLCertificateChainFile - the certificate from your certificate provider, often called the intermediate certificate, in this case exactly like the 'SSLCertificateFile' location above. Once you have made all of your changes, simply restart httpd and if it starts test your site to make sure you now have a valid certificate file showing. If so, you are ready to move on to the next step: automation. Using Certbot With Nginx A quick note: using certbot with Nginx is pretty much the same as with Apache. Here's the short, short version of the guide: Run this command to get started: certbot --nginx You'll be asked a couple of questions as shown above, including your email address, and which site you want to get a certificate for. Assuming you have at least one site configured (with a domain name pointing at the server), you'll see a list like this: 1. yourwebsite.com 2. subdomain.yourwebsite.com If you have more than one site, just press the number that corresponds to the site you want a certificate for. The rest of the text you'll see is awful similar to what's above. The results will be a bit different, of course. If you have a dead-simple Nginx config file that looks like this: server { server_name yourwebsite.com; listen 80; listen [::]:80; location / { root /usr/share/nginx/html; index index.html index.htm; } } After certbot gets through with it, it'll look like a bit this: server { server_name yourwebsite.com; listen 443 ssl; # managed by Certbot listen [::]:443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/yourwebsite.com/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/yourwebsite.com/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot location / { root /usr/share/nginx/html; index index.html index.htm; } } server { if ($host = yourwebsite.com) { return 301 https://$host$request_uri; } # managed by Certbot listen 80; listen [::]:80; server_name yourwebsite.com; return 404; # managed by Certbot } Depending on a couple of things (for example, if you're using Nginx as a reverse proxy), you may need to dive into the new config file to fix up a few things that certbot won't handle perfectly on its own. Or write your own config file the hard way. Automating Let's Encrypt Certificate Renewal The beauty of installing certbot is that the Let's Encrypt certificate will be automatically renewed. There is no need to create a process to do this. We do need to test the renewal with: certbot renew --dry-run When you run this command, you'll get a nice output showing the renewal process: Saving debug log to /var/log/letsencrypt/letsencrypt.log - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Processing /etc/letsencrypt/renewal/yourdomain.com.conf - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Cert not due for renewal, but simulating renewal for dry run Plugins selected: Authenticator apache, Installer apache Account registered. Simulating renewal of an existing certificate for yourdomain.com Performing the following challenges: http-01 challenge for yourdomain.com Waiting for verification... Cleaning up challenges - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - new certificate deployed with reload of apache server; fullchain is /etc/letsencrypt/live/yourdomain.com/fullchain.pem - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Congratulations, all simulated renewals succeeded: /etc/letsencrypt/live/yourdomain.com/fullchain.pem (success) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - The certbot documentation tells you in their step number 8, that the automatic renewal process could be in a couple of different spots, depending on your system. For a Rocky Linux install, you are going to find the process by using: systemctl list-timers Which gives you a list of processes, one of which will be for certbot : Sat 2021-04-03 07:12:00 UTC 14h left n/a n/a snap.certbot.renew.timer snap.certbot.renew.service Conclusions Let's Encrypt SSL certificates are yet another option for securing your web site with an SSL. Once installed, the system provides automatic renewal of certificates and will encrypt traffic to your web site. It should be noted that Let's Encrypt certificates are used for standard DV (Domain Validation) certificates. They cannot be used for OV (Organization Validation) or EV (Extended Validation) certificates.","title":"Generating SSL Keys - Let's Encrypt"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#generating-ssl-keys-lets-encrypt","text":"","title":"Generating SSL Keys - Let's Encrypt"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#prerequisites-assumptions","text":"Comfort with the command line Familiarity with securing web sites with SSL certificates is a plus Knowledge of command line text editors (this example uses vi ) An already running web server open to the world on port 80 (http) Familiarity with ssh (secure shell) and the ability to access your server with ssh All commands assume that you are either the root user or that you have used sudo to gain root access.","title":"Prerequisites &amp; Assumptions"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#introduction","text":"One of the most popular ways to secure a web site, currently, is using Let's Encrypt SSL certificates, which are also free. These are actual certificates, not self-signed or snake oil, etc., so they are great for a low-budget security solution. This document will walk you through the process of installing and using Let's Encrypt certificates on a Rocky Linux web server.","title":"Introduction"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#installation","text":"To do the next steps, use ssh to log into your server. If your server's fully qualified DNS name was www.myhost.com, then you would use: ssh -l root www.myhost.com Or, if you must access your server as an unprivileged user first. Use your username: ssh -l username www.myhost.com And then: sudo -s You will need your sudo user's credentials in this case to gain access to the system as root. Let's Encrypt uses a package called certbot which needs to be installed via the EPEL repositories. Add those first: dnf install epel-release Then, just install the appropriate packages, depending on whether you're using Apache or Nginx as your web server. For Apache that's: dnf install certbot python3-certbot-apache For Nginx, just change out one... partial word? dnf install certbot python3-certbot-nginx You can always install both server modules if necessary, of course. !!! Note An earlier version of this guide required the snap package version of certbot, as it was found to be necessary at the time. The RPM versions have been re-tested recently, and are working now.","title":"Installation"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#getting-the-lets-encrypt-certificate-for-the-apache-server","text":"There are two ways to retrieve your Let's Encrypt certificate, either using the command to modify the http configuration file for you, or to just retrieve the certificate. If you are using the procedure for a multi-site setup suggested for one or more sites in the procedure Apache Web Server Multi-Site Setup , then you will only want to retrieve your certificate. We are assuming that you are using this procedure so we will only retrieve the certificate. If you are running a standalone web server using the default configuration, you can retrieve the certificate and modify the configuration file in one step using: certbot --apache That's really the easiest way to get things done. However, sometimes you want to take a more manual approach, and just want to grab the certificate. To retrieve the certificate only, use this command: certbot certonly --apache Both commands will generate a set of prompts that you will need to answer. The first is to give an email address for important information: Saving debug log to /var/log/letsencrypt/letsencrypt.log Plugins selected: Authenticator apache, Installer apache Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): yourusername@youremaildomain.com The next asks you to read and accept the terms of the subscriber agreement. Once you have read the agreement answer 'Y' to continue: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Please read the Terms of Service at https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You must agree in order to register with the ACME server. Do you agree? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - (Y)es/(N)o: The next is a request to share your email with the Electronic Frontier Foundation. Answer 'Y' or 'N' as is your preference: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Would you be willing, once your first certificate is successfully issued, to share your email address with the Electronic Frontier Foundation, a founding partner of the Let's Encrypt project and the non-profit organization that develops Certbot? We'd like to send you email about our work encrypting the web, EFF news, campaigns, and ways to support digital freedom. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - (Y)es/(N)o: The next prompt asks you which domain you want the certificate for. It should display a domain in the listing based on your running web server. If so, enter the number next to the domain that you are getting the certificate for. In this case there is only one option ('1'): Which names would you like to activate HTTPS for? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1: yourdomain.com - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Select the appropriate numbers separated by commas and/or spaces, or leave input blank to select all options shown (Enter 'c' to cancel): If all goes well, you should receive the following message: Requesting a certificate for yourdomain.com Performing the following challenges: http-01 challenge for yourdomain.com Waiting for verification... Cleaning up challenges Subscribe to the EFF mailing list (email: yourusername@youremaildomain.com). IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/yourdomain.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/yourdomain.com/privkey.pem Your certificate will expire on 2021-07-01. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run \"certbot renew\" - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le","title":"Getting The Let's Encrypt Certificate for the Apache Server"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#the-site-configuration-https","text":"Applying the configuration file to our site is slightly different than if we were using a purchased SSL certificate from another provider (and if we didn't let certbot do it automatically). The certificate and chain file are included in a single PEM (Privacy Enhanced Mail) file. This is a common format for all certificate files now, so even though it has \"Mail\" in the reference, it is just a type of certificate file. To illustrate the configuration file, we will show it in it's entirety and then describe what is happening: <VirtualHost *:80> ServerName www.yourdomain.com ServerAdmin username@rockylinux.org Redirect / https://www.yourdomain.com/ </VirtualHost> <Virtual Host *:443> ServerName www.yourdomain.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.yourdomain.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.yourdomain.www/cgi-bin/ CustomLog \"/var/log/httpd/com.yourdomain.www-access_log\" combined ErrorLog \"/var/log/httpd/com.yourdomain.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /etc/letsencrypt/live/yourdomain.com/fullchain.pem SSLCertificateKeyFile /etc/letsencrypt/live/yourdomain.com/privkey.pem SSLCertificateChainFile /etc/letsencrypt/live/yourdomain.com/fullchain.pem <Directory /var/www/sub-domains/com.yourdomain.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Here's what's happening above. You may want to review the Apache Web Server Multi-Site Setup to see the differences in the application of an SSL purchased from another provider and the Let's Encrypt certificate: Even though port 80 (standard http) is listening, we are redirecting all traffic to port 443 (https) SSLEngine on - simply says to use SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - says to use all available protocols, except those that have been found to have vulnerabilities. You should research periodically which protocols are currently acceptable for use. SSLHonorCipherOrder on - this deals with the next line regarding the cipher suites, and says to deal with them in the order that they are given. This is another area where you should review the cipher suites that you want to include periodically SSLCertificateFile - this is the PEM file, that contains the site certificate AND the intermediate certificate. We still need the 'SSLCertificateChainFile' line in our configuration, but it will simply specify the same PEM file again. SSLCertificateKeyFile - the PEM file for the private key, generated with the certbot request. SSLCertificateChainFile - the certificate from your certificate provider, often called the intermediate certificate, in this case exactly like the 'SSLCertificateFile' location above. Once you have made all of your changes, simply restart httpd and if it starts test your site to make sure you now have a valid certificate file showing. If so, you are ready to move on to the next step: automation.","title":"The Site Configuration - https"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#using-certbot-with-nginx","text":"A quick note: using certbot with Nginx is pretty much the same as with Apache. Here's the short, short version of the guide: Run this command to get started: certbot --nginx You'll be asked a couple of questions as shown above, including your email address, and which site you want to get a certificate for. Assuming you have at least one site configured (with a domain name pointing at the server), you'll see a list like this: 1. yourwebsite.com 2. subdomain.yourwebsite.com If you have more than one site, just press the number that corresponds to the site you want a certificate for. The rest of the text you'll see is awful similar to what's above. The results will be a bit different, of course. If you have a dead-simple Nginx config file that looks like this: server { server_name yourwebsite.com; listen 80; listen [::]:80; location / { root /usr/share/nginx/html; index index.html index.htm; } } After certbot gets through with it, it'll look like a bit this: server { server_name yourwebsite.com; listen 443 ssl; # managed by Certbot listen [::]:443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/yourwebsite.com/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/yourwebsite.com/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot location / { root /usr/share/nginx/html; index index.html index.htm; } } server { if ($host = yourwebsite.com) { return 301 https://$host$request_uri; } # managed by Certbot listen 80; listen [::]:80; server_name yourwebsite.com; return 404; # managed by Certbot } Depending on a couple of things (for example, if you're using Nginx as a reverse proxy), you may need to dive into the new config file to fix up a few things that certbot won't handle perfectly on its own. Or write your own config file the hard way.","title":"Using Certbot With Nginx"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#automating-lets-encrypt-certificate-renewal","text":"The beauty of installing certbot is that the Let's Encrypt certificate will be automatically renewed. There is no need to create a process to do this. We do need to test the renewal with: certbot renew --dry-run When you run this command, you'll get a nice output showing the renewal process: Saving debug log to /var/log/letsencrypt/letsencrypt.log - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Processing /etc/letsencrypt/renewal/yourdomain.com.conf - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Cert not due for renewal, but simulating renewal for dry run Plugins selected: Authenticator apache, Installer apache Account registered. Simulating renewal of an existing certificate for yourdomain.com Performing the following challenges: http-01 challenge for yourdomain.com Waiting for verification... Cleaning up challenges - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - new certificate deployed with reload of apache server; fullchain is /etc/letsencrypt/live/yourdomain.com/fullchain.pem - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Congratulations, all simulated renewals succeeded: /etc/letsencrypt/live/yourdomain.com/fullchain.pem (success) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - The certbot documentation tells you in their step number 8, that the automatic renewal process could be in a couple of different spots, depending on your system. For a Rocky Linux install, you are going to find the process by using: systemctl list-timers Which gives you a list of processes, one of which will be for certbot : Sat 2021-04-03 07:12:00 UTC 14h left n/a n/a snap.certbot.renew.timer snap.certbot.renew.service","title":"Automating Let's Encrypt Certificate Renewal"},{"location":"guides/security/generating_ssl_keys_lets_encrypt/#conclusions","text":"Let's Encrypt SSL certificates are yet another option for securing your web site with an SSL. Once installed, the system provides automatic renewal of certificates and will encrypt traffic to your web site. It should be noted that Let's Encrypt certificates are used for standard DV (Domain Validation) certificates. They cannot be used for OV (Organization Validation) or EV (Extended Validation) certificates.","title":"Conclusions"},{"location":"guides/security/learning_selinux/","text":"SELinux security With the arrival of kernel version 2.6, a new security system was introduced to provide a security mechanism to support access control security policies. This system is called SELinux ( S ecurity E nhanced Linux ) and was created by the NSA ( N ational S ecurity A dministration) to implement a robust M andatory A ccess C ontrol ( MAC ) architecture in the Linux kernel subsystems. If, throughout your career, you have either disabled or ignored SELinux, this document will be a good introduction to this system. SELinux works to limit privileges or remove the risks associated with compromising a program or daemon. Before starting, you should know that SELinux is mainly intended for RHEL distributions, although it is possible to implement it on other distributions like Debian (but good luck!). The distributions of the Debian family generally integrate the AppArmor system, which works differently from SELinux. Generalities SELinux (Security Enhanced Linux) is a Mandatory Access Control system. Before the appearance of MAC systems, standard access management security was based on DAC ( D iscretionary A ccess C ontrol) systems. An application, or a daemon, operated with UID or SUID ( S et O wner U ser I d) rights, which made it possible to evaluate permissions (on files, sockets, and other processes...) according to this user. This operation does not sufficiently limit the rights of a program that is corrupted, potentially allowing it to access the subsystems of the operating system. A MAC system reinforces the separation of confidentiality and integrity information in the system to achieve a containment system. The containment system is independent of the traditional rights system and there is no notion of a superuser. With each system call, the kernel queries SELinux to see if it allows the action to be performed. SELinux uses a set of rules (policies) for this. A set of two standard rule sets ( targeted and strict ) is provided and each application usually provides its own rules. The SELinux context The operation of SELinux is totally different from traditional Unix rights. The SELinux security context is defined by the trio identity + role + domain . The identity of a user depends directly on his Linux account. An identity is assigned one or more roles, but to each role corresponds to one domain, and only one. It is according to the domain of the security context (and thus the role) that the rights of a user on a resource are evaluated. The terms \"domain\" and \"type\" are similar. Typically \"domain\" is used when referring to a process, while \"type\" refers to an object. The naming convention is: user_u:role_r:type_t . The security context is assigned to a user at the time of his connection, according to his roles. The security context of a file is defined by the chcon ( ch ange con text) command, which we will see later in this document. Consider the following pieces of the SELinux puzzle: The subjects The objects The policies The mode When a subject (an application for example) tries to access an object (a file for example), the SELinux part of the Linux kernel queries its policy database. Depending on the mode of operation, SELinux authorizes access to the object in case of success, otherwise it records the failure in the file /var/log/messages . The SELinux context of standard processes The rights of a process depend on its security context. By default, the security context of the process is defined by the context of the user (identity + role + domain) who launches it. A domain being a specific type (in the SELinux sense) linked to a process and inherited (normally) from the user who launched it, its rights are expressed in terms of authorization or refusal on types linked to objects: A process whose context has security domain D can access objects of type T . The SELinux context of important processes Most important programs are assigned a dedicated domain. Each executable is tagged with a dedicated type (here sshd_exec_t ) which automatically switches the associated process to the sshd_t context (instead of user_t ). This mechanism is essential since it restricts the rights of a process as much as possible. Management The semanage command is used to manage SELinux rules. semanage [object_type] [options] Example: $ semanage boolean -l Options Observations -a Adds an object -d Delete an object -m Modify an object -l List the objects The semanage command may not be installed by default under Rocky Linux. Without knowing the package that provides this command, you should search for its name with the command: dnf provides */semanage then install it: sudo dnf install policycoreutils-python-utils Administering Boolean objects Booleans allow the containment of processes. semanage boolean [options] To list the available Booleans: semanage boolean \u2013l SELinux boolean State Default Description \u2026 httpd_can_sendmail (off , off) Allow httpd to send mail \u2026 !!! Note As you can see, there is a `default` state (eg. at startup) and a running state. The setsebool command is used to change the state of a boolean object: setsebool [-PV] boolean on|off Example: sudo setsebool -P httpd_can_sendmail on Options Observations -P Changes the default value at startup (otherwise only until reboot) -V Deletes an object !!! Warning Don't forget the `-P` option to keep the state after the next startup. Administering Port objects The semanage command is used to manage objects of type port: semanage port [options] Example: allow port 81 for httpd domain processes sudo semanage port -a -t http_port_t -p tcp 81 Operating modes SELinux has three operating modes: Enforcing Default mode for Rocky Linux. Access will be restricted according to the rules in force. Permissive Rules are polled, access errors are logged, but access will not be blocked. Disabled Nothing will be restricted, nothing will be logged. By default, most operating systems are configured with SELinux in Enforcing mode. The getenforce command returns the current operating mode getenforce Example: $ getenforce Enforcing The sestatus command returns information about SELinux sestatus Example: $ sestatus SELinux status: enabled SELinuxfs mount: /sys/fs/selinux SELinux root directory: /etc/selinux Loaded policy name: targeted Current mode: enforcing Mode from config file: enforcing ... Max kernel policy version: 33 The setenforce command changes the current operating mode: setenforce 0|1 Switch SELinux to permissive mode: sudo setenforce 0 The /etc/sysconfig/selinux file The /etc/sysconfig/selinux file allows you to change the operating mode of SELinux. !!! Warning Disabling SELinux is done at your own risk! It is better to learn how SELinux works than to disable it systematically! Edit the file /etc/sysconfig/selinux SELINUX=disabled !!! Note `/etc/sysconfig/selinux` is a symlink to `/etc/selinux/config` Reboot the system: sudo reboot !!! Warning Beware of the SELinux mode change! In permissive or disabled mode, newly created files will not have any labels. To reactivate SELinux, you will have to reposition the labels on your entire system. Labeling the entire system: sudo touch /.autorelabel sudo reboot The Policy Type SELinux provides two standard types of rules: Targeted : only network daemons are protected ( dhcpd , httpd , named , nscd , ntpd , portmap , snmpd , squid and syslogd ) Strict : all daemons are protected Context The display of security contexts is done with the -Z option. It is associated with many commands: Examples: id -Z # the user's context ls -Z # those of the current files ps -eZ # those of the processes netstat \u2013Z # for network connections lsof -Z # for open files The matchpathcon command returns the context of a directory. matchpathcon directory Example: sudo matchpathcon /root /root system_u:object_r:admin_home_t:s0 sudo matchpathcon / / system_u:object_r:root_t:s0 The chcon command modifies a security context: chcon [-vR] [-u USER] [\u2013r ROLE] [-t TYPE] file Example: sudo chcon -vR -t httpd_sys_content_t /data/websites/ Options Observations -v Switch into verbose mode -R Apply recursion -u , -r , -t Applies to a user, role or type The restorecon command restores the default security context (the one provided by the rules): restorecon [-vR] directory Example: sudo restorecon -vR /home/ Options Observations -v Switch into verbose mode -R Apply recursion To make a context change survive to a restorecon , you have to modify the default file contexts with the semanage fcontext command: semanage fcontext -a options file !!! Note If you are performing a context switch for a folder that is not standard for the system, creating the rule and then applying the context is a good practice as in the example below! Example: $ sudo semanage fcontext -a -t httpd_sys_content_t \"/data/websites(/.*)?\" $ sudo restorecon -vR /data/websites/ audit2why command The audit2why command indicates the cause of a SELinux rejection: audit2why [-vw] Example to get the cause of the last rejection by SELinux: sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 | audit2why Options Observations -v Switch into verbose mode -w Translates the cause of a rejection by SELinux and proposes a solution to remedy it (default option) Going further with SELinux The audit2allow command creates a module to allow a SELinux action (when no module exists) from a line in an \"audit\" file: audit2allow [-mM] Example: sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 | audit2allow -M mylocalmodule Options Observations -m Just create the module ( *.te ) -M Create the module, compile and package it ( *.pp ) Example of configuration After the execution of a command, the system gives you back the command prompt but the expected result is not visible: no error message on the screen. Step 1 : Read the log file knowing that the message we are interested in is of type AVC (SELinux), refused (denied) and the most recent one (therefore the last one). sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 The message is correctly isolated but is of no help to us. Step 2 : Read the isolated message with the audit2why command to get a more explicit message that may contain the solution to our problem (typically a boolean to be set). sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 | audit2why There are two cases: either we can place a context or fill in a boolean, or we must go to step 3 to create our own context. Step 3 : Create your own module. $ sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 | audit2allow -M mylocalmodule Generating type enforcement: mylocalmodule.te Compiling policy: checkmodule -M -m -o mylocalmodule.mod mylocalmodule.te Building package: semodule_package -o mylocalmodule.pp -m mylocalmodule.mod $ sudo semodule -i mylocalmodule.pp","title":"SELinux Security"},{"location":"guides/security/learning_selinux/#selinux-security","text":"With the arrival of kernel version 2.6, a new security system was introduced to provide a security mechanism to support access control security policies. This system is called SELinux ( S ecurity E nhanced Linux ) and was created by the NSA ( N ational S ecurity A dministration) to implement a robust M andatory A ccess C ontrol ( MAC ) architecture in the Linux kernel subsystems. If, throughout your career, you have either disabled or ignored SELinux, this document will be a good introduction to this system. SELinux works to limit privileges or remove the risks associated with compromising a program or daemon. Before starting, you should know that SELinux is mainly intended for RHEL distributions, although it is possible to implement it on other distributions like Debian (but good luck!). The distributions of the Debian family generally integrate the AppArmor system, which works differently from SELinux.","title":"SELinux security"},{"location":"guides/security/learning_selinux/#generalities","text":"SELinux (Security Enhanced Linux) is a Mandatory Access Control system. Before the appearance of MAC systems, standard access management security was based on DAC ( D iscretionary A ccess C ontrol) systems. An application, or a daemon, operated with UID or SUID ( S et O wner U ser I d) rights, which made it possible to evaluate permissions (on files, sockets, and other processes...) according to this user. This operation does not sufficiently limit the rights of a program that is corrupted, potentially allowing it to access the subsystems of the operating system. A MAC system reinforces the separation of confidentiality and integrity information in the system to achieve a containment system. The containment system is independent of the traditional rights system and there is no notion of a superuser. With each system call, the kernel queries SELinux to see if it allows the action to be performed. SELinux uses a set of rules (policies) for this. A set of two standard rule sets ( targeted and strict ) is provided and each application usually provides its own rules.","title":"Generalities"},{"location":"guides/security/learning_selinux/#the-selinux-context","text":"The operation of SELinux is totally different from traditional Unix rights. The SELinux security context is defined by the trio identity + role + domain . The identity of a user depends directly on his Linux account. An identity is assigned one or more roles, but to each role corresponds to one domain, and only one. It is according to the domain of the security context (and thus the role) that the rights of a user on a resource are evaluated. The terms \"domain\" and \"type\" are similar. Typically \"domain\" is used when referring to a process, while \"type\" refers to an object. The naming convention is: user_u:role_r:type_t . The security context is assigned to a user at the time of his connection, according to his roles. The security context of a file is defined by the chcon ( ch ange con text) command, which we will see later in this document. Consider the following pieces of the SELinux puzzle: The subjects The objects The policies The mode When a subject (an application for example) tries to access an object (a file for example), the SELinux part of the Linux kernel queries its policy database. Depending on the mode of operation, SELinux authorizes access to the object in case of success, otherwise it records the failure in the file /var/log/messages .","title":"The SELinux context"},{"location":"guides/security/learning_selinux/#the-selinux-context-of-standard-processes","text":"The rights of a process depend on its security context. By default, the security context of the process is defined by the context of the user (identity + role + domain) who launches it. A domain being a specific type (in the SELinux sense) linked to a process and inherited (normally) from the user who launched it, its rights are expressed in terms of authorization or refusal on types linked to objects: A process whose context has security domain D can access objects of type T .","title":"The SELinux context of standard processes"},{"location":"guides/security/learning_selinux/#the-selinux-context-of-important-processes","text":"Most important programs are assigned a dedicated domain. Each executable is tagged with a dedicated type (here sshd_exec_t ) which automatically switches the associated process to the sshd_t context (instead of user_t ). This mechanism is essential since it restricts the rights of a process as much as possible.","title":"The SELinux context of important processes"},{"location":"guides/security/learning_selinux/#management","text":"The semanage command is used to manage SELinux rules. semanage [object_type] [options] Example: $ semanage boolean -l Options Observations -a Adds an object -d Delete an object -m Modify an object -l List the objects The semanage command may not be installed by default under Rocky Linux. Without knowing the package that provides this command, you should search for its name with the command: dnf provides */semanage then install it: sudo dnf install policycoreutils-python-utils","title":"Management"},{"location":"guides/security/learning_selinux/#administering-boolean-objects","text":"Booleans allow the containment of processes. semanage boolean [options] To list the available Booleans: semanage boolean \u2013l SELinux boolean State Default Description \u2026 httpd_can_sendmail (off , off) Allow httpd to send mail \u2026 !!! Note As you can see, there is a `default` state (eg. at startup) and a running state. The setsebool command is used to change the state of a boolean object: setsebool [-PV] boolean on|off Example: sudo setsebool -P httpd_can_sendmail on Options Observations -P Changes the default value at startup (otherwise only until reboot) -V Deletes an object !!! Warning Don't forget the `-P` option to keep the state after the next startup.","title":"Administering Boolean objects"},{"location":"guides/security/learning_selinux/#administering-port-objects","text":"The semanage command is used to manage objects of type port: semanage port [options] Example: allow port 81 for httpd domain processes sudo semanage port -a -t http_port_t -p tcp 81","title":"Administering Port objects"},{"location":"guides/security/learning_selinux/#operating-modes","text":"SELinux has three operating modes: Enforcing Default mode for Rocky Linux. Access will be restricted according to the rules in force. Permissive Rules are polled, access errors are logged, but access will not be blocked. Disabled Nothing will be restricted, nothing will be logged. By default, most operating systems are configured with SELinux in Enforcing mode. The getenforce command returns the current operating mode getenforce Example: $ getenforce Enforcing The sestatus command returns information about SELinux sestatus Example: $ sestatus SELinux status: enabled SELinuxfs mount: /sys/fs/selinux SELinux root directory: /etc/selinux Loaded policy name: targeted Current mode: enforcing Mode from config file: enforcing ... Max kernel policy version: 33 The setenforce command changes the current operating mode: setenforce 0|1 Switch SELinux to permissive mode: sudo setenforce 0","title":"Operating modes"},{"location":"guides/security/learning_selinux/#the-etcsysconfigselinux-file","text":"The /etc/sysconfig/selinux file allows you to change the operating mode of SELinux. !!! Warning Disabling SELinux is done at your own risk! It is better to learn how SELinux works than to disable it systematically! Edit the file /etc/sysconfig/selinux SELINUX=disabled !!! Note `/etc/sysconfig/selinux` is a symlink to `/etc/selinux/config` Reboot the system: sudo reboot !!! Warning Beware of the SELinux mode change! In permissive or disabled mode, newly created files will not have any labels. To reactivate SELinux, you will have to reposition the labels on your entire system. Labeling the entire system: sudo touch /.autorelabel sudo reboot","title":"The /etc/sysconfig/selinux file"},{"location":"guides/security/learning_selinux/#the-policy-type","text":"SELinux provides two standard types of rules: Targeted : only network daemons are protected ( dhcpd , httpd , named , nscd , ntpd , portmap , snmpd , squid and syslogd ) Strict : all daemons are protected","title":"The Policy Type"},{"location":"guides/security/learning_selinux/#context","text":"The display of security contexts is done with the -Z option. It is associated with many commands: Examples: id -Z # the user's context ls -Z # those of the current files ps -eZ # those of the processes netstat \u2013Z # for network connections lsof -Z # for open files The matchpathcon command returns the context of a directory. matchpathcon directory Example: sudo matchpathcon /root /root system_u:object_r:admin_home_t:s0 sudo matchpathcon / / system_u:object_r:root_t:s0 The chcon command modifies a security context: chcon [-vR] [-u USER] [\u2013r ROLE] [-t TYPE] file Example: sudo chcon -vR -t httpd_sys_content_t /data/websites/ Options Observations -v Switch into verbose mode -R Apply recursion -u , -r , -t Applies to a user, role or type The restorecon command restores the default security context (the one provided by the rules): restorecon [-vR] directory Example: sudo restorecon -vR /home/ Options Observations -v Switch into verbose mode -R Apply recursion To make a context change survive to a restorecon , you have to modify the default file contexts with the semanage fcontext command: semanage fcontext -a options file !!! Note If you are performing a context switch for a folder that is not standard for the system, creating the rule and then applying the context is a good practice as in the example below! Example: $ sudo semanage fcontext -a -t httpd_sys_content_t \"/data/websites(/.*)?\" $ sudo restorecon -vR /data/websites/","title":"Context"},{"location":"guides/security/learning_selinux/#audit2why-command","text":"The audit2why command indicates the cause of a SELinux rejection: audit2why [-vw] Example to get the cause of the last rejection by SELinux: sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 | audit2why Options Observations -v Switch into verbose mode -w Translates the cause of a rejection by SELinux and proposes a solution to remedy it (default option)","title":"audit2why command"},{"location":"guides/security/learning_selinux/#going-further-with-selinux","text":"The audit2allow command creates a module to allow a SELinux action (when no module exists) from a line in an \"audit\" file: audit2allow [-mM] Example: sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 | audit2allow -M mylocalmodule Options Observations -m Just create the module ( *.te ) -M Create the module, compile and package it ( *.pp )","title":"Going further with SELinux"},{"location":"guides/security/learning_selinux/#example-of-configuration","text":"After the execution of a command, the system gives you back the command prompt but the expected result is not visible: no error message on the screen. Step 1 : Read the log file knowing that the message we are interested in is of type AVC (SELinux), refused (denied) and the most recent one (therefore the last one). sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 The message is correctly isolated but is of no help to us. Step 2 : Read the isolated message with the audit2why command to get a more explicit message that may contain the solution to our problem (typically a boolean to be set). sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 | audit2why There are two cases: either we can place a context or fill in a boolean, or we must go to step 3 to create our own context. Step 3 : Create your own module. $ sudo cat /var/log/audit/audit.log | grep AVC | grep denied | tail -1 | audit2allow -M mylocalmodule Generating type enforcement: mylocalmodule.te Compiling policy: checkmodule -M -m -o mylocalmodule.mod mylocalmodule.te Building package: semodule_package -o mylocalmodule.pp -m mylocalmodule.mod $ sudo semodule -i mylocalmodule.pp","title":"Example of configuration"},{"location":"guides/security/ssh_public_private_keys/","tags":["security","ssh","keygen"],"text":"SSH Public and Private Key Prerequisites A certain amount of comfort operating from the command line Rocky Linux servers and/or workstations with openssh installed Okay technically, this process should work on any Linux system with openssh installed Optional: familiarity with Linux file and directory permissions Introduction SSH is a protocol used to access one machine from another, usually via the command line. With SSH, you can run commands on remote computers and servers, send files, and generally manage everything you do from one place. When you are working with multiple Rocky Linux servers in multiple locations, or if you are just trying to save some time accessing these servers, you'll want to use an SSH public and private key pair. Key pairs basically make logging into remote machines and running commands easier. This document will guide you through the process of creating the keys and setting up your servers for easy access with those keys. Process For Generating Keys The following commands are all executed from the command line on your Rocky Linux workstation: ssh-keygen -t rsa Which will display the following: Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Hit Enter to accept the default location. Next the system will show: Enter passphrase (empty for no passphrase): So just hit Enter here. Finally, it will ask for you to re-enter the passphrase: Enter same passphrase again: So hit Enter a final time. You now should have an RSA type public and private key pair in your .ssh directory: ls -a .ssh/ . .. id_rsa id_rsa.pub Now we need to send the public key (id_rsa.pub) to every machine that we are going to be accessing... but before we do that, we need to make sure that we can SSH into the servers that we will be sending the key to. For our example, we are going to be using just three servers. You can either access them via SSH by a DNS name or IP address, but for our example we are going to be using the DNS name. Our example servers are web, mail, and portal. For each server, we will attempt to SSH in (nerds love using SSH as a verb) and leave a terminal window open for each machine: ssh -l root web.ourourdomain.com Assuming that we can login without trouble on all three machines, then the next step is to send our public key over to each server: scp .ssh/id_rsa.pub root@web.ourourdomain.com:/root/ Repeat this step with each of our three machines. In each of the open terminal windows, you should now be able to see id_rsa.pub when you enter the following command: ls -a | grep id_rsa.pub If so, we are now ready to either create or append the authorized_keys file in each server's .ssh directory. On each of the servers, enter this command: ls -a .ssh !!! attention \"Important!\" Make sure you read everything below carefully. If you are not sure if you will break something, then make a backup copy of authorized_keys (if it exists) on each of the machines before continuing. If there is no authorized_keys file listed, then we will create it by entering this command while in our /root directory: cat id_rsa.pub > .ssh/authorized_keys If authorized_keys does exist, then we simply want to append our new public key to the ones that are already there: cat id_rsa.pub >> .ssh/authorized_keys Once the key has been either added to authorized_keys , or the authorized_keys file has been created, try to SSH from your Rocky Linux workstation to the server again. You should not be prompted for a password. Once you have verified that you can SSH in without a password, remove the id_rsa.pub file from the /root directory on each machine. rm id_rsa.pub SSH Directory and authorized_keys Security On each of your target machines, make sure that the following permissions are applied: chmod 700 .ssh/ chmod 600 .ssh/authorized_keys","title":"SSH Public and Private Key"},{"location":"guides/security/ssh_public_private_keys/#ssh-public-and-private-key","text":"","title":"SSH Public and Private Key"},{"location":"guides/security/ssh_public_private_keys/#prerequisites","text":"A certain amount of comfort operating from the command line Rocky Linux servers and/or workstations with openssh installed Okay technically, this process should work on any Linux system with openssh installed Optional: familiarity with Linux file and directory permissions","title":"Prerequisites"},{"location":"guides/security/ssh_public_private_keys/#introduction","text":"SSH is a protocol used to access one machine from another, usually via the command line. With SSH, you can run commands on remote computers and servers, send files, and generally manage everything you do from one place. When you are working with multiple Rocky Linux servers in multiple locations, or if you are just trying to save some time accessing these servers, you'll want to use an SSH public and private key pair. Key pairs basically make logging into remote machines and running commands easier. This document will guide you through the process of creating the keys and setting up your servers for easy access with those keys.","title":"Introduction"},{"location":"guides/security/ssh_public_private_keys/#process-for-generating-keys","text":"The following commands are all executed from the command line on your Rocky Linux workstation: ssh-keygen -t rsa Which will display the following: Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Hit Enter to accept the default location. Next the system will show: Enter passphrase (empty for no passphrase): So just hit Enter here. Finally, it will ask for you to re-enter the passphrase: Enter same passphrase again: So hit Enter a final time. You now should have an RSA type public and private key pair in your .ssh directory: ls -a .ssh/ . .. id_rsa id_rsa.pub Now we need to send the public key (id_rsa.pub) to every machine that we are going to be accessing... but before we do that, we need to make sure that we can SSH into the servers that we will be sending the key to. For our example, we are going to be using just three servers. You can either access them via SSH by a DNS name or IP address, but for our example we are going to be using the DNS name. Our example servers are web, mail, and portal. For each server, we will attempt to SSH in (nerds love using SSH as a verb) and leave a terminal window open for each machine: ssh -l root web.ourourdomain.com Assuming that we can login without trouble on all three machines, then the next step is to send our public key over to each server: scp .ssh/id_rsa.pub root@web.ourourdomain.com:/root/ Repeat this step with each of our three machines. In each of the open terminal windows, you should now be able to see id_rsa.pub when you enter the following command: ls -a | grep id_rsa.pub If so, we are now ready to either create or append the authorized_keys file in each server's .ssh directory. On each of the servers, enter this command: ls -a .ssh !!! attention \"Important!\" Make sure you read everything below carefully. If you are not sure if you will break something, then make a backup copy of authorized_keys (if it exists) on each of the machines before continuing. If there is no authorized_keys file listed, then we will create it by entering this command while in our /root directory: cat id_rsa.pub > .ssh/authorized_keys If authorized_keys does exist, then we simply want to append our new public key to the ones that are already there: cat id_rsa.pub >> .ssh/authorized_keys Once the key has been either added to authorized_keys , or the authorized_keys file has been created, try to SSH from your Rocky Linux workstation to the server again. You should not be prompted for a password. Once you have verified that you can SSH in without a password, remove the id_rsa.pub file from the /root directory on each machine. rm id_rsa.pub","title":"Process For Generating Keys"},{"location":"guides/security/ssh_public_private_keys/#ssh-directory-and-authorized_keys-security","text":"On each of your target machines, make sure that the following permissions are applied: chmod 700 .ssh/ chmod 600 .ssh/authorized_keys","title":"SSH Directory and authorized_keys Security"},{"location":"guides/security/ssh_public_private_keys.sv/","text":"SSH Publika och privata nycklar F\u00f6ruts\u00e4ttningar En viss gnutta av bekv\u00e4mligt att jobba fr\u00e5n kommandoraden Rocky Linux servrar och/eller arbetsstationer med openssh installerat Okej tekniskt, s\u00e5 kommer den h\u00e4r processen att fungera p\u00e5 vilket Linux system som helst med openssh installerat Valfritt: bekant med linux-fil och katalogbeh\u00f6righeter Introduktion SSH \u00e4r ett protokoll som anv\u00e4nds f\u00f6r att komma \u00e5t en maskin fr\u00e5n en annan, oftast via kommandoraden. med SSH, s\u00e5 kan du k\u00f6ra kommandon p\u00e5 fj\u00e4rrdatorer och servrar, skicka filer, och generellt hantera allting du g\u00f6r fr\u00e5n en plats. N\u00e4r du jobbar med flera Rocky Linux servrar p\u00e5 flera platser, eller om du bara f\u00f6rs\u00f6ker att spara lite tid f\u00f6r att snabbare f\u00e5 \u00e5tkomst till dessa servrar, s\u00e5 vill du anv\u00e4nda SSH publika och privata nyckelpar. Nyckelpar g\u00f6r det enklare att logga in i fj\u00e4rrmaskiner och k\u00f6ra kommandon. Detta dokument kommer att v\u00e4gleda dig genom processen f\u00f6r att skapa nycklarna och st\u00e4lla in dina servrar f\u00f6r enkel \u00e5tkomst, med sagda nycklar. Processen f\u00f6r att generera nycklar Dessa f\u00f6ljande kommandon k\u00f6rs alla fr\u00e5n kommandoraden p\u00e5 din Rocky Linux arbetsstation: ssh-keygen -t rsa Vilket kommer att visa f\u00f6ljande: Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Tryck p\u00e5 Enter f\u00f6r att acceptera standardplatsen. D\u00e4refter kommer systemet att visas: Enter passphrase (empty for no passphrase): S\u00e5 tryck bara Enter h\u00e4r. Slutligen kommer den att be dig att ange l\u00f6senfrasen igen: Enter same passphrase again: S\u00e5 tryck p\u00e5 Enter en sista g\u00e5ng. Du ska nu ha ett RSA typ publikt och privat nyckelpar i din .ssh katalog: ls -a .ssh/ . .. id_rsa id_rsa.pub Nu beh\u00f6ver vi skicka den publika nyckeln (id_rsa.pub) till varje maskin som vi vill att det ska g\u00e5 att komma \u00e5t... men f\u00f6re vi g\u00f6r det, s\u00e5 m\u00e5ste vi se till att vi kan anv\u00e4nda SSH f\u00f6r att komma \u00e5t servern som vi kommer att skicka nyckeln till. I v\u00e5rat exempel, s\u00e5 kommer vi att anv\u00e4nda bara tre servrar. Du kan antingen komma \u00e5t dem via SSH med ett DNS-namn eller IP-adress, men i v\u00e5rat exempel s\u00e5 kommer vi att anv\u00e4nda DNS-namnet. V\u00e5ra exempel servrar \u00e4r webb, mail, och portal. F\u00f6r varje server, s\u00e5 kommer vi att f\u00f6rs\u00f6ka SSH in (n\u00f6rdar \u00e4lskar att anv\u00e4nda SSH som ett verb) och l\u00e4mnar ett terminalf\u00f6nster \u00f6ppet f\u00f6r varje maskin: ssh -l root web.ourourdomain.com F\u00f6rutsatt att vi kan logga in utan problem p\u00e5 alla tre maskiner, s\u00e5 \u00e4r n\u00e4sta steg \u00e4r att skicka ut v\u00e5ran publika nyckel till varje server: scp .ssh/id_rsa.pub root@web.ourourdomain.com:/root/ Vi upprepar detta steg p\u00e5 var och en av v\u00e5ra tre maskiner. P\u00e5 varje av dom \u00f6ppna terminalf\u00f6nstren, du borde du nu kunna se id_rsa.pub n\u00e4r du anger f\u00f6ljande kommando: ls -a | grep id_rsa.pub Om s\u00e5 \u00e4r fallet, s\u00e5 \u00e4r du nu redo att antingen skapa eller l\u00e4gga till authorized_keys filen p\u00e5 i .ssh katalogen p\u00e5 varje server. P\u00e5 varje en av servrarna, ange detta kommando: ls -a .ssh Viktigt! Se till att du l\u00e4ser allt nedan noggrant. Om du inte \u00e4r s\u00e4ker p\u00e5 om du kommer ha s\u00f6nder n\u00e5gonting, s\u00e5 \u00e4r det alltid bra att ta en s\u00e4kerhetskopia av authorized_keys filen (om den existerar) p\u00e5 varje av maskinerna innan du forts\u00e4tter. Om det inte finns n\u00e5gon authorized_keys fil listad, d\u00e5 kommer vi skapa den genom att ange detta kommando medans vi \u00e4r i v\u00e5ran /root katalog: cat id_rsa.pub > .ssh/authorized_keys Om authorized_keys existerar, d\u00e5 vill vi helt enkelt l\u00e4gga till v\u00e5r nya publika nyckel till de som redan finns d\u00e4r: cat id_rsa.pub >> .ssh/authorized_keys N\u00e4r nyckeln antingen har lagts till i authorized_keys , eller authorized_keys filen har skapats, f\u00f6rs\u00f6k att anv\u00e4nda SSH fr\u00e5n din Rocky Linux-arbetsstation till servern igen. Du ska inte bli ombedd om att skriva in ett l\u00f6senord. N\u00e4r du har verifierat att du kan SSHa in utan ett l\u00f6senord, ta bort id_rsa.pub filen fr\u00e5n /root katalogen p\u00e5 varje maskin. rm id_rsa.pub SSH Katalog och authorized_keys S\u00e4kerhet P\u00e5 var och en av dina m\u00e5lmaskiner, se till att f\u00f6ljande beh\u00f6righeter till\u00e4mpas: chmod 700 .ssh/ chmod 600 .ssh/authorized_keys","title":"SSH Publika och privata nycklar"},{"location":"guides/security/ssh_public_private_keys.sv/#ssh-publika-och-privata-nycklar","text":"","title":"SSH Publika och privata nycklar"},{"location":"guides/security/ssh_public_private_keys.sv/#forutsattningar","text":"En viss gnutta av bekv\u00e4mligt att jobba fr\u00e5n kommandoraden Rocky Linux servrar och/eller arbetsstationer med openssh installerat Okej tekniskt, s\u00e5 kommer den h\u00e4r processen att fungera p\u00e5 vilket Linux system som helst med openssh installerat Valfritt: bekant med linux-fil och katalogbeh\u00f6righeter","title":"F\u00f6ruts\u00e4ttningar"},{"location":"guides/security/ssh_public_private_keys.sv/#introduktion","text":"SSH \u00e4r ett protokoll som anv\u00e4nds f\u00f6r att komma \u00e5t en maskin fr\u00e5n en annan, oftast via kommandoraden. med SSH, s\u00e5 kan du k\u00f6ra kommandon p\u00e5 fj\u00e4rrdatorer och servrar, skicka filer, och generellt hantera allting du g\u00f6r fr\u00e5n en plats. N\u00e4r du jobbar med flera Rocky Linux servrar p\u00e5 flera platser, eller om du bara f\u00f6rs\u00f6ker att spara lite tid f\u00f6r att snabbare f\u00e5 \u00e5tkomst till dessa servrar, s\u00e5 vill du anv\u00e4nda SSH publika och privata nyckelpar. Nyckelpar g\u00f6r det enklare att logga in i fj\u00e4rrmaskiner och k\u00f6ra kommandon. Detta dokument kommer att v\u00e4gleda dig genom processen f\u00f6r att skapa nycklarna och st\u00e4lla in dina servrar f\u00f6r enkel \u00e5tkomst, med sagda nycklar.","title":"Introduktion"},{"location":"guides/security/ssh_public_private_keys.sv/#processen-for-att-generera-nycklar","text":"Dessa f\u00f6ljande kommandon k\u00f6rs alla fr\u00e5n kommandoraden p\u00e5 din Rocky Linux arbetsstation: ssh-keygen -t rsa Vilket kommer att visa f\u00f6ljande: Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Tryck p\u00e5 Enter f\u00f6r att acceptera standardplatsen. D\u00e4refter kommer systemet att visas: Enter passphrase (empty for no passphrase): S\u00e5 tryck bara Enter h\u00e4r. Slutligen kommer den att be dig att ange l\u00f6senfrasen igen: Enter same passphrase again: S\u00e5 tryck p\u00e5 Enter en sista g\u00e5ng. Du ska nu ha ett RSA typ publikt och privat nyckelpar i din .ssh katalog: ls -a .ssh/ . .. id_rsa id_rsa.pub Nu beh\u00f6ver vi skicka den publika nyckeln (id_rsa.pub) till varje maskin som vi vill att det ska g\u00e5 att komma \u00e5t... men f\u00f6re vi g\u00f6r det, s\u00e5 m\u00e5ste vi se till att vi kan anv\u00e4nda SSH f\u00f6r att komma \u00e5t servern som vi kommer att skicka nyckeln till. I v\u00e5rat exempel, s\u00e5 kommer vi att anv\u00e4nda bara tre servrar. Du kan antingen komma \u00e5t dem via SSH med ett DNS-namn eller IP-adress, men i v\u00e5rat exempel s\u00e5 kommer vi att anv\u00e4nda DNS-namnet. V\u00e5ra exempel servrar \u00e4r webb, mail, och portal. F\u00f6r varje server, s\u00e5 kommer vi att f\u00f6rs\u00f6ka SSH in (n\u00f6rdar \u00e4lskar att anv\u00e4nda SSH som ett verb) och l\u00e4mnar ett terminalf\u00f6nster \u00f6ppet f\u00f6r varje maskin: ssh -l root web.ourourdomain.com F\u00f6rutsatt att vi kan logga in utan problem p\u00e5 alla tre maskiner, s\u00e5 \u00e4r n\u00e4sta steg \u00e4r att skicka ut v\u00e5ran publika nyckel till varje server: scp .ssh/id_rsa.pub root@web.ourourdomain.com:/root/ Vi upprepar detta steg p\u00e5 var och en av v\u00e5ra tre maskiner. P\u00e5 varje av dom \u00f6ppna terminalf\u00f6nstren, du borde du nu kunna se id_rsa.pub n\u00e4r du anger f\u00f6ljande kommando: ls -a | grep id_rsa.pub Om s\u00e5 \u00e4r fallet, s\u00e5 \u00e4r du nu redo att antingen skapa eller l\u00e4gga till authorized_keys filen p\u00e5 i .ssh katalogen p\u00e5 varje server. P\u00e5 varje en av servrarna, ange detta kommando: ls -a .ssh Viktigt! Se till att du l\u00e4ser allt nedan noggrant. Om du inte \u00e4r s\u00e4ker p\u00e5 om du kommer ha s\u00f6nder n\u00e5gonting, s\u00e5 \u00e4r det alltid bra att ta en s\u00e4kerhetskopia av authorized_keys filen (om den existerar) p\u00e5 varje av maskinerna innan du forts\u00e4tter. Om det inte finns n\u00e5gon authorized_keys fil listad, d\u00e5 kommer vi skapa den genom att ange detta kommando medans vi \u00e4r i v\u00e5ran /root katalog: cat id_rsa.pub > .ssh/authorized_keys Om authorized_keys existerar, d\u00e5 vill vi helt enkelt l\u00e4gga till v\u00e5r nya publika nyckel till de som redan finns d\u00e4r: cat id_rsa.pub >> .ssh/authorized_keys N\u00e4r nyckeln antingen har lagts till i authorized_keys , eller authorized_keys filen har skapats, f\u00f6rs\u00f6k att anv\u00e4nda SSH fr\u00e5n din Rocky Linux-arbetsstation till servern igen. Du ska inte bli ombedd om att skriva in ett l\u00f6senord. N\u00e4r du har verifierat att du kan SSHa in utan ett l\u00f6senord, ta bort id_rsa.pub filen fr\u00e5n /root katalogen p\u00e5 varje maskin. rm id_rsa.pub","title":"Processen f\u00f6r att generera nycklar"},{"location":"guides/security/ssh_public_private_keys.sv/#ssh-katalog-och-authorized_keys-sakerhet","text":"P\u00e5 var och en av dina m\u00e5lmaskiner, se till att f\u00f6ljande beh\u00f6righeter till\u00e4mpas: chmod 700 .ssh/ chmod 600 .ssh/authorized_keys","title":"SSH Katalog och authorized_keys S\u00e4kerhet"},{"location":"guides/security/ssl_keys_https/","tags":["security","ssl","openssl"],"text":"Generating SSL Keys Prerequisites A workstation and a server running Rocky Linux (OK, Linux, but really, you want Rocky Linux, right?) OpenSSL installed on the machine that you are going to be generating the private key and CSR, as well as on the server where you will eventually be installing your key and certificates Able to run commands comfortably from the command-line Helpful: knowledge of SSL and OpenSSL commands Introduction Nearly every web site today should be running with an SSL (secure socket layer) certificate. This procedure will guide you through generating the private key for your web site and then from this, generating the CSR (certificate signing request) that you will use to purchase your new certificate. Generate The Private Key For the uninitiated, SSL private keys can have different sizes, measured in bits, which basically determines how hard they are to crack. As of 2021, the recommended private key size for a web site is still 2048 bits. You can go higher, but doubling the key size from 2048 bits to 4096 bits is only about 16% more secure, takes more space to store the key, and causes higher CPU loads when the key is processed. This slows down your web site performance without gaining any significant security. Stick with the 2048 key size for now and always keep tabs on what is currently recommended. To start with, let's make sure that OpenSSL is installed on both your workstation and server: dnf install openssl If it is not installed, your system will install it and any needed dependencies. Our example domain is ourownwiki.com. Keep in mind that you would need to purchase and register your domain ahead of time. You can purchase domains through a number of \"Registrars\". If you are not running your own DNS (Domain Name System), you can often use the same providers for DNS hosting. DNS translates your named domain, to numbers (IP addresses, either IPv4 or IPv6) that the Internet can understand. These IP addresses will be where the web site is actually hosted. Let's generate the key using openssl: openssl genrsa -des3 -out ourownwiki.com.key.pass 2048 Note that we named the key, with a .pass extension. That's because as soon as we execute this command, it requests that you enter a passphrase. Enter a simple passphrase that you can remember as we are going to be removing this shortly: Enter pass phrase for ourownwiki.com.key.pass: Verifying - Enter pass phrase for ourownwiki.com.key.pass: Next, let's remove that passphrase. The reason for this is that if you don't remove it, each time your web server restarts and loads up your key, you will need to enter that passphrase. You might not even be around to enter it, or worse, might not have a console at the ready to enter it. Remove it now to avoid all of that: openssl rsa -in ourownwiki.com.key.pass -out ourownwiki.com.key This will request that passphrase once again to remove the passphrase from the key: Enter pass phrase for ourownwiki.com.key.pass: Now that you have entered the passphrase a third time, it has been removed from the key file and saved as ourownwiki.com.key Generate the CSR Next, we need to generate the CSR (certificate signing request) that we will use to purchase our certificate. During the generation of the CSR, you will be prompted for several pieces of information. These are the X.509 attributes of the certificate. One of the prompts will be for \"Common Name (e.g., YOUR name)\". It is important that this field be filled in with the fully qualified domain name of the server to be protected by SSL. If the website to be protected will be https://www.ourownwiki.com, then enter www.ourownwiki.com at this prompt: openssl req -new -key ourownwiki.com.key -out ourownwiki.com.csr This opens up a dialog: Country Name (2 letter code) [XX]: enter the two character country code where your site resides, example \"US\" State or Province Name (full name) []: enter the full official name of your state or province, example \"Nebraska\" Locality Name (eg, city) [Default City]: enter the full city name, example \"Omaha\" Organization Name (eg, company) [Default Company Ltd]: If you want, you can enter an organization that this domain is a part of, or just hit 'Enter' to skip. Organizational Unit Name (eg, section) []: This would describe the division of the organization that your domain falls under. Again, you can just hit 'Enter' to skip. Common Name (eg, your name or your server's hostname) []: Here, we have to enter our site hostname, example \"www.ourownwiki.com\" Email Address []: This field is optional, you can decide to fill it out or just hit 'Enter' to skip. Next, you will be asked to enter extra attributes which can be skipped by hitting 'Enter' through both: Please enter the following 'extra' attributes to be sent with your certificate request A challenge password []: An optional company name []: Now you should have generated your CSR. Purchasing The Certificate Each certificate vendor will have basically the same procedure. You purchase the SSL and term (1 or 2 years, etc.) and then you submit your CSR. To do this, you will need to use the more command, and then copy the contents of your CSR file. more ourownwiki.com.csr Which will show you something like this: -----BEGIN CERTIFICATE REQUEST----- MIICrTCCAZUCAQAwaDELMAkGA1UEBhMCVVMxETAPBgNVBAgMCE5lYnJhc2thMQ4w DAYDVQQHDAVPbWFoYTEcMBoGA1UECgwTRGVmYXVsdCBDb21wYW55IEx0ZDEYMBYG A1UEAwwPd3d3Lm91cndpa2kuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB CgKCAQEAzwN02erkv9JDhpR8NsJ9eNSm/bLW/jNsZxlxOS3BSOOfQDdUkX0rAt4G nFyBAHRAyxyRvxag13O1rVdKtxUv96E+v76KaEBtXTIZOEZgV1visZoih6U44xGr wcrNnotMB5F/T92zYsK2+GG8F1p9zA8UxO5VrKRL7RL3DtcUwJ8GSbuudAnBhueT nLlPk2LB6g6jCaYbSF7RcK9OL304varo6Uk0zSFprrg/Cze8lxNAxbFzfhOBIsTo PafcA1E8f6y522L9Vaen21XsHyUuZBpooopNqXsG62dcpLy7sOXeBnta4LbHsTLb hOmLrK8RummygUB8NKErpXz3RCEn6wIDAQABoAAwDQYJKoZIhvcNAQELBQADggEB ABMLz/omVg8BbbKYNZRevsSZ80leyV8TXpmP+KaSAWhMcGm/bzx8aVAyqOMLR+rC V7B68BqOdBtkj9g3u8IerKNRwv00pu2O/LOsOznphFrRQUaarQwAvKQKaNEG/UPL gArmKdlDilXBcUFaC2WxBWgxXI6tsE40v4y1zJNZSWsCbjZj4Xj41SB7FemB4SAR RhuaGAOwZnzJBjX60OVzDCZHsfokNobHiAZhRWldVNct0jfFmoRXb4EvWVcbLHnS E5feDUgu+YQ6ThliTrj2VJRLOAv0Qsum5Yl1uF+FZF9x6/nU/SurUhoSYHQ6Co93 HFOltYOnfvz6tOEP39T/wMo= -----END CERTIFICATE REQUEST----- You want to copy everything including the \"BEGIN CERTIFICATE REQUEST\" and \"END CERTIFICATE REQUEST\" lines. Then paste these into the CSR field on the web site where you are purchasing the certificate. You may have to perform other verification steps, depending on ownership of the domain, the registrar you are using, etc., before your certificate is issued. When it is issued, it should be issued along with an intermediate certificate from the provider, which you will use in the configuration as well. Conclusion Generating all of the bits and pieces for the purchase of a web site certificate is not terribly difficult and can be performed by the systems administrator or web site administrator using the above procedure.","title":"Generating SSL Keys"},{"location":"guides/security/ssl_keys_https/#generating-ssl-keys","text":"","title":"Generating SSL Keys"},{"location":"guides/security/ssl_keys_https/#prerequisites","text":"A workstation and a server running Rocky Linux (OK, Linux, but really, you want Rocky Linux, right?) OpenSSL installed on the machine that you are going to be generating the private key and CSR, as well as on the server where you will eventually be installing your key and certificates Able to run commands comfortably from the command-line Helpful: knowledge of SSL and OpenSSL commands","title":"Prerequisites"},{"location":"guides/security/ssl_keys_https/#introduction","text":"Nearly every web site today should be running with an SSL (secure socket layer) certificate. This procedure will guide you through generating the private key for your web site and then from this, generating the CSR (certificate signing request) that you will use to purchase your new certificate.","title":"Introduction"},{"location":"guides/security/ssl_keys_https/#generate-the-private-key","text":"For the uninitiated, SSL private keys can have different sizes, measured in bits, which basically determines how hard they are to crack. As of 2021, the recommended private key size for a web site is still 2048 bits. You can go higher, but doubling the key size from 2048 bits to 4096 bits is only about 16% more secure, takes more space to store the key, and causes higher CPU loads when the key is processed. This slows down your web site performance without gaining any significant security. Stick with the 2048 key size for now and always keep tabs on what is currently recommended. To start with, let's make sure that OpenSSL is installed on both your workstation and server: dnf install openssl If it is not installed, your system will install it and any needed dependencies. Our example domain is ourownwiki.com. Keep in mind that you would need to purchase and register your domain ahead of time. You can purchase domains through a number of \"Registrars\". If you are not running your own DNS (Domain Name System), you can often use the same providers for DNS hosting. DNS translates your named domain, to numbers (IP addresses, either IPv4 or IPv6) that the Internet can understand. These IP addresses will be where the web site is actually hosted. Let's generate the key using openssl: openssl genrsa -des3 -out ourownwiki.com.key.pass 2048 Note that we named the key, with a .pass extension. That's because as soon as we execute this command, it requests that you enter a passphrase. Enter a simple passphrase that you can remember as we are going to be removing this shortly: Enter pass phrase for ourownwiki.com.key.pass: Verifying - Enter pass phrase for ourownwiki.com.key.pass: Next, let's remove that passphrase. The reason for this is that if you don't remove it, each time your web server restarts and loads up your key, you will need to enter that passphrase. You might not even be around to enter it, or worse, might not have a console at the ready to enter it. Remove it now to avoid all of that: openssl rsa -in ourownwiki.com.key.pass -out ourownwiki.com.key This will request that passphrase once again to remove the passphrase from the key: Enter pass phrase for ourownwiki.com.key.pass: Now that you have entered the passphrase a third time, it has been removed from the key file and saved as ourownwiki.com.key","title":"Generate The Private Key"},{"location":"guides/security/ssl_keys_https/#generate-the-csr","text":"Next, we need to generate the CSR (certificate signing request) that we will use to purchase our certificate. During the generation of the CSR, you will be prompted for several pieces of information. These are the X.509 attributes of the certificate. One of the prompts will be for \"Common Name (e.g., YOUR name)\". It is important that this field be filled in with the fully qualified domain name of the server to be protected by SSL. If the website to be protected will be https://www.ourownwiki.com, then enter www.ourownwiki.com at this prompt: openssl req -new -key ourownwiki.com.key -out ourownwiki.com.csr This opens up a dialog: Country Name (2 letter code) [XX]: enter the two character country code where your site resides, example \"US\" State or Province Name (full name) []: enter the full official name of your state or province, example \"Nebraska\" Locality Name (eg, city) [Default City]: enter the full city name, example \"Omaha\" Organization Name (eg, company) [Default Company Ltd]: If you want, you can enter an organization that this domain is a part of, or just hit 'Enter' to skip. Organizational Unit Name (eg, section) []: This would describe the division of the organization that your domain falls under. Again, you can just hit 'Enter' to skip. Common Name (eg, your name or your server's hostname) []: Here, we have to enter our site hostname, example \"www.ourownwiki.com\" Email Address []: This field is optional, you can decide to fill it out or just hit 'Enter' to skip. Next, you will be asked to enter extra attributes which can be skipped by hitting 'Enter' through both: Please enter the following 'extra' attributes to be sent with your certificate request A challenge password []: An optional company name []: Now you should have generated your CSR.","title":"Generate the CSR"},{"location":"guides/security/ssl_keys_https/#purchasing-the-certificate","text":"Each certificate vendor will have basically the same procedure. You purchase the SSL and term (1 or 2 years, etc.) and then you submit your CSR. To do this, you will need to use the more command, and then copy the contents of your CSR file. more ourownwiki.com.csr Which will show you something like this: -----BEGIN CERTIFICATE REQUEST----- MIICrTCCAZUCAQAwaDELMAkGA1UEBhMCVVMxETAPBgNVBAgMCE5lYnJhc2thMQ4w DAYDVQQHDAVPbWFoYTEcMBoGA1UECgwTRGVmYXVsdCBDb21wYW55IEx0ZDEYMBYG A1UEAwwPd3d3Lm91cndpa2kuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB CgKCAQEAzwN02erkv9JDhpR8NsJ9eNSm/bLW/jNsZxlxOS3BSOOfQDdUkX0rAt4G nFyBAHRAyxyRvxag13O1rVdKtxUv96E+v76KaEBtXTIZOEZgV1visZoih6U44xGr wcrNnotMB5F/T92zYsK2+GG8F1p9zA8UxO5VrKRL7RL3DtcUwJ8GSbuudAnBhueT nLlPk2LB6g6jCaYbSF7RcK9OL304varo6Uk0zSFprrg/Cze8lxNAxbFzfhOBIsTo PafcA1E8f6y522L9Vaen21XsHyUuZBpooopNqXsG62dcpLy7sOXeBnta4LbHsTLb hOmLrK8RummygUB8NKErpXz3RCEn6wIDAQABoAAwDQYJKoZIhvcNAQELBQADggEB ABMLz/omVg8BbbKYNZRevsSZ80leyV8TXpmP+KaSAWhMcGm/bzx8aVAyqOMLR+rC V7B68BqOdBtkj9g3u8IerKNRwv00pu2O/LOsOznphFrRQUaarQwAvKQKaNEG/UPL gArmKdlDilXBcUFaC2WxBWgxXI6tsE40v4y1zJNZSWsCbjZj4Xj41SB7FemB4SAR RhuaGAOwZnzJBjX60OVzDCZHsfokNobHiAZhRWldVNct0jfFmoRXb4EvWVcbLHnS E5feDUgu+YQ6ThliTrj2VJRLOAv0Qsum5Yl1uF+FZF9x6/nU/SurUhoSYHQ6Co93 HFOltYOnfvz6tOEP39T/wMo= -----END CERTIFICATE REQUEST----- You want to copy everything including the \"BEGIN CERTIFICATE REQUEST\" and \"END CERTIFICATE REQUEST\" lines. Then paste these into the CSR field on the web site where you are purchasing the certificate. You may have to perform other verification steps, depending on ownership of the domain, the registrar you are using, etc., before your certificate is issued. When it is issued, it should be issued along with an intermediate certificate from the provider, which you will use in the configuration as well.","title":"Purchasing The Certificate"},{"location":"guides/security/ssl_keys_https/#conclusion","text":"Generating all of the bits and pieces for the purchase of a web site certificate is not terribly difficult and can be performed by the systems administrator or web site administrator using the above procedure.","title":"Conclusion"},{"location":"guides/security/authentication/active_directory_authentication/","text":"Active Directory Authentication Prerequisites Some understanding of Active Directory Some understanding of LDAP Introduction Microsoft's Active Directory (AD) is, in most enterprises, the de facto authentication system for Windows systems and for external, LDAP-connected services. It allows you to configure users and groups, access control, permissions, auto-mounting, and more. Now, while connecting Linux to an AD cluster cannot support all of the features mentioned, it can handle users, groups, and access control. It is even possible (through some configuration tweaks on the Linux side and some advanced options on the AD side) to distribute SSH keys using AD. This guide, however, will just cover configuring authentication against Active Directory, and will not include any extra configuration on the Windows side. Discovering and joining AD using SSSD !!! Note Throughout this guide, the domain name `ad.company.local` will be used to represent the Active Directory domain. To follow this guide, replace it with the actual domain name your AD domain uses. The first step along the way to join a Linux system into AD is to discover your AD cluster, to ensure that the network configuration is correct on both sides. Preparation Ensure the following ports are open to your Linux host on your domain controller: Service Port(s) Notes DNS 53 (TCP+UDP) Kerberos 88, 464 (TCP+UDP) Used by kadmin for setting & updating passwords LDAP 389 (TCP+UDP) LDAP-GC 3268 (TCP) LDAP Global Catalog - allows you to source user IDs from AD Ensure you have configured your AD domain controller as a DNS server on your Rocky Linux host: With NetworkManager: sh # where your primary NetworkManager connection is 'System eth0' and your AD # server is accessible on the IP address 10.0.0.2. [root@host ~]$ nmcli con mod 'System eth0' ipv4.dns 10.0.0.2 Manually editing the /etc/resolv.conf: ```sh # Edit the resolv.conf file [user@host ~]$ sudo vi /etc/resolv.conf search lan nameserver 10.0.0.2 nameserver 1.1.1.1 # replace this with your preferred public DNS (as a backup) # Make the resolv.conf file unwritable, preventing NetworkManager from # overwriting it. [user@host ~]$ sudo chattr +i /etc/resolv.conf ``` Ensure that the time on both sides (AD host and Linux system) is synchronized To check the time on Rocky Linux: sh [user@host ~]$ date Wed 22 Sep 17:11:35 BST 2021 Install the required packages for AD connection on the Linux side: sh [user@host ~]$ sudo dnf install realmd oddjob oddjob-mkhomedir sssd adcli krb5-workstation Discovery Now, you should be able to successfully discover your AD server(s) from your Linux host. [user@host ~]$ realm discover ad.company.local ad.company.local type: kerberos realm-name: AD.COMPANY.LOCAL domain-name: ad.company.local configured: no server-software: active-directory client-software: sssd required-package: oddjob required-package: oddjob-mkhomedir required-package: sssd required-package: adcli required-package: samba-common This will be discovered using the relevant SRV records stored in your Active Directory DNS service. Joining Once you have successfully discovered your Active Directory installation from the Linux host, you should be able to use realmd to join the domain, which will orchestrate the configuration of sssd using adcli and some other such tools. [user@host ~]$ sudo realm join ad.company.local If this process complains about encryption with KDC has no support for encryption type , try updating the global crypto policy to allow older encryption algorithms: [user@host ~]$ sudo update-crypto-policies --set DEFAULT:AD-SUPPORT If this process succeeds, you should now be able to pull passwd information for an Active Directory user. [user@host ~]$ sudo getent passwd administrator@ad.company.local administrator@ad.company.local:*:1450400500:1450400513:Administrator:/home/administrator@ad.company.local:/bin/bash Attempting to Authenticate Now your users should be able to authenticate to your Linux host against Active Directory. On Windows 10: (which provides its own copy of OpenSSH) C:\\Users\\John.Doe> ssh -l john.doe@ad.company.local linux.host Password for john.doe@ad.company.local: Activate the web console with: systemctl enable --now cockpit.socket Last login: Wed Sep 15 17:37:03 2021 from 10.0.10.241 [john.doe@ad.company.local@host ~]$ If this succeeds, you have successfully configured Linux to use Active Directory as an authentication source. Setting the default domain In a completely default setup, you will need to log in with your AD account by specifying the domain in your username (e.g. john.doe@ad.company.local ). If this is not the desired behaviour, and you instead want to be able to omit the domain name at authentication time, you can configure SSSD to default to a specific domain. This is actually a relatively simple process, and just requires a configuration tweak in your SSSD configuration file. [user@host ~]$ sudo vi /etc/sssd/sssd.conf [sssd] ... default_domain_suffix = ad.company.local By adding the default_domain_suffix , you are instructing SSSD to (if no other domain is specified) infer that the user is trying to authenticate as a user from the ad.company.local domain. This allows you to authenticate as something like john.doe instead of john.doe@ad.company.local . To make this configuration change take effect, you must restart the sssd.service unit with systemctl . [user@host ~]$ sudo systemctl restart sssd","title":"Active Directory Authentication"},{"location":"guides/security/authentication/active_directory_authentication/#active-directory-authentication","text":"","title":"Active Directory Authentication"},{"location":"guides/security/authentication/active_directory_authentication/#prerequisites","text":"Some understanding of Active Directory Some understanding of LDAP","title":"Prerequisites"},{"location":"guides/security/authentication/active_directory_authentication/#introduction","text":"Microsoft's Active Directory (AD) is, in most enterprises, the de facto authentication system for Windows systems and for external, LDAP-connected services. It allows you to configure users and groups, access control, permissions, auto-mounting, and more. Now, while connecting Linux to an AD cluster cannot support all of the features mentioned, it can handle users, groups, and access control. It is even possible (through some configuration tweaks on the Linux side and some advanced options on the AD side) to distribute SSH keys using AD. This guide, however, will just cover configuring authentication against Active Directory, and will not include any extra configuration on the Windows side.","title":"Introduction"},{"location":"guides/security/authentication/active_directory_authentication/#discovering-and-joining-ad-using-sssd","text":"!!! Note Throughout this guide, the domain name `ad.company.local` will be used to represent the Active Directory domain. To follow this guide, replace it with the actual domain name your AD domain uses. The first step along the way to join a Linux system into AD is to discover your AD cluster, to ensure that the network configuration is correct on both sides.","title":"Discovering and joining AD using SSSD"},{"location":"guides/security/authentication/active_directory_authentication/#preparation","text":"Ensure the following ports are open to your Linux host on your domain controller: Service Port(s) Notes DNS 53 (TCP+UDP) Kerberos 88, 464 (TCP+UDP) Used by kadmin for setting & updating passwords LDAP 389 (TCP+UDP) LDAP-GC 3268 (TCP) LDAP Global Catalog - allows you to source user IDs from AD Ensure you have configured your AD domain controller as a DNS server on your Rocky Linux host: With NetworkManager: sh # where your primary NetworkManager connection is 'System eth0' and your AD # server is accessible on the IP address 10.0.0.2. [root@host ~]$ nmcli con mod 'System eth0' ipv4.dns 10.0.0.2 Manually editing the /etc/resolv.conf: ```sh # Edit the resolv.conf file [user@host ~]$ sudo vi /etc/resolv.conf search lan nameserver 10.0.0.2 nameserver 1.1.1.1 # replace this with your preferred public DNS (as a backup) # Make the resolv.conf file unwritable, preventing NetworkManager from # overwriting it. [user@host ~]$ sudo chattr +i /etc/resolv.conf ``` Ensure that the time on both sides (AD host and Linux system) is synchronized To check the time on Rocky Linux: sh [user@host ~]$ date Wed 22 Sep 17:11:35 BST 2021 Install the required packages for AD connection on the Linux side: sh [user@host ~]$ sudo dnf install realmd oddjob oddjob-mkhomedir sssd adcli krb5-workstation","title":"Preparation"},{"location":"guides/security/authentication/active_directory_authentication/#discovery","text":"Now, you should be able to successfully discover your AD server(s) from your Linux host. [user@host ~]$ realm discover ad.company.local ad.company.local type: kerberos realm-name: AD.COMPANY.LOCAL domain-name: ad.company.local configured: no server-software: active-directory client-software: sssd required-package: oddjob required-package: oddjob-mkhomedir required-package: sssd required-package: adcli required-package: samba-common This will be discovered using the relevant SRV records stored in your Active Directory DNS service.","title":"Discovery"},{"location":"guides/security/authentication/active_directory_authentication/#joining","text":"Once you have successfully discovered your Active Directory installation from the Linux host, you should be able to use realmd to join the domain, which will orchestrate the configuration of sssd using adcli and some other such tools. [user@host ~]$ sudo realm join ad.company.local If this process complains about encryption with KDC has no support for encryption type , try updating the global crypto policy to allow older encryption algorithms: [user@host ~]$ sudo update-crypto-policies --set DEFAULT:AD-SUPPORT If this process succeeds, you should now be able to pull passwd information for an Active Directory user. [user@host ~]$ sudo getent passwd administrator@ad.company.local administrator@ad.company.local:*:1450400500:1450400513:Administrator:/home/administrator@ad.company.local:/bin/bash","title":"Joining"},{"location":"guides/security/authentication/active_directory_authentication/#attempting-to-authenticate","text":"Now your users should be able to authenticate to your Linux host against Active Directory. On Windows 10: (which provides its own copy of OpenSSH) C:\\Users\\John.Doe> ssh -l john.doe@ad.company.local linux.host Password for john.doe@ad.company.local: Activate the web console with: systemctl enable --now cockpit.socket Last login: Wed Sep 15 17:37:03 2021 from 10.0.10.241 [john.doe@ad.company.local@host ~]$ If this succeeds, you have successfully configured Linux to use Active Directory as an authentication source.","title":"Attempting to Authenticate"},{"location":"guides/security/authentication/active_directory_authentication/#setting-the-default-domain","text":"In a completely default setup, you will need to log in with your AD account by specifying the domain in your username (e.g. john.doe@ad.company.local ). If this is not the desired behaviour, and you instead want to be able to omit the domain name at authentication time, you can configure SSSD to default to a specific domain. This is actually a relatively simple process, and just requires a configuration tweak in your SSSD configuration file. [user@host ~]$ sudo vi /etc/sssd/sssd.conf [sssd] ... default_domain_suffix = ad.company.local By adding the default_domain_suffix , you are instructing SSSD to (if no other domain is specified) infer that the user is trying to authenticate as a user from the ad.company.local domain. This allows you to authenticate as something like john.doe instead of john.doe@ad.company.local . To make this configuration change take effect, you must restart the sssd.service unit with systemctl . [user@host ~]$ sudo systemctl restart sssd","title":"Setting the default domain"},{"location":"guides/virtualization/vbox-rocky/","tags":["virtualbox","virtualization"],"text":"Rocky on VirtualBox Introduction VirtualBox\u00ae is a powerful virtualization product for both enterprise and home use. Once in a while, someone posts that they are having trouble getting Rocky Linux to run in VirtualBox\u00ae. It has been tested multiple times going back to the release candidate, and works just fine. The problems people usually report often involve video. This document is an attempt to give a step-by-step set of instructions for getting Rocky Linux up and running in VirtualBox\u00ae. The machine used to build this documentation was running Linux but, you can use any of the supported operating systems. Prerequisites A machine (Windows, Mac, Linux, Solaris) with available memory, and hard disk space to build and run the VirtualBox\u00ae instance. VirtualBox\u00ae installed on your machine. You can find that here . A copy of the Rocky Linux DVD ISO for your architecture. (x86_64 or ARM64). Ensure that your OS is 64 bit and that hardware virtualization is turned on in your BIOS. !!! Note Hardware virtualization is 100% necessary in order to install a 64 bit OS. If your configuration screen shows only 32-bit options, then you need to stop and fix this before continuing. Preparing The VirtualBox\u00ae Configuration Once you have VirtualBox\u00ae installed, the next step is to start it. With no images installed you will get a screen that looks something like this: First, we need to tell VirtualBox\u00ae what our OS is going to be: Click \"New\" (saw tooth icon). Type a name. Example: \"Rocky Linux 8.5\". Leave the machine folder as automatically filled. Change the type to \"Linux\". And choose \"Red Hat (64-bit)\". Click \"Next\". Next, we need to allocate some RAM for this machine. By default, VirtualBox\u00ae will automatically fill this to 1024 MB. That will not be optimum for any modern OS, including Rocky Linux. If you've got memory to spare, allocate 2 to 4 GB (2048 MB or 4096 MB) \u2014 or more. Keep in mind that VirtualBox\u00ae is only going to use this memory while the virtual machine is running. There's no screenshot for this one, just change the value based on your available memory. Use your best judgement. Now we need to set up the hard disk size. By default, VirtualBox\u00ae will automatically fill the \"Create a virtual hard disk now\" radio button. Click \"Create\" You will get a dialog box for creating various virtual hard disk types, and there are several hard disk types listed here. See the Oracle VirtualBox documentation for more information about selecting virtual hard disk types. For the purpose of this document, just keep the default (VDI): Click \"Next\" The next screen deals with the storage on the physical hard disk. There are two options. \"Fixed Size\" will be slower to create, faster to use, but less flexible in terms of space (if you need more space, you are stuck with what you created). The default option, \"Dynamically Allocated\", will be faster to create, slower to use, but will give you the option to grow if your disk space needs to change. For the purpose of this document, we are just accepting the default of \"Dynamically allocated.\" Click \"Next\" VirtualBox\u00ae now gives you the option to specify where you want the virtual hard disk file to be located as well as the option to expand the default 8 GB virtual hard disk space. This option is good, because 8 GB of hard disk space isn't enough to install, much less use, any of the GUI install options. Set this to 20 GB (or more) depending on what you want to use the virtual machine for, and how much free disk space you have available: Click \"Create\" We've finished the basic configuration. You should have a screen that looks something like this: Attaching The ISO Image Our next step is to attach the ISO image that you downloaded earlier as a virtual CD ROM device. Click on the \"Settings\" (gear icon) and you should get the following screen: Click the \"Storage\" item in the left-hand menu. Under \"Storage Devices\" in the middle section, click the CD icon that says \"Empty\". Under \"Attributes\" on the right-hand side, click the CD icon. Select \"Choose/Create a Virtual Optical Disk\". Click the \"Add\" button (plus sign icon) and navigate to where your Rocky Linux ISO image is stored. Select the ISO and click \"Open\". You should now have the ISO added to the available devices like this: Highlight the ISO image and then click \"Choose\". The Rocky Linux ISO image now shows selected under the \"Controller:IDE\" in the middle section: Click \"OK\" Video Memory for Graphical Installations VirtualBox\u00ae sets up 16 MB of memory to use for video. That is fine if you are planning on running a bare-bones server without a GUI, but as soon as you add graphics, that's not enough. Users who keep this setting often see a hanging boot screen that never finishes, or other errors. If you are going to be running Rocky Linux with a GUI, you should allocate enough memory to easily run the graphics. If your machine is a bit thin on memory, adjust this value upwards 16 MB at a time until things run smoothly. Your host machine's video resolution is also a factor that you need to consider. Think carefully about what you want your Rocky Linux virtual machine to do, and try to allocate video memory that is compatible with your host machine and your other requirements. You can find more information on display settings from Oracle's official documentation . If you've got plenty of memory, you can set this value to the maximum of 128 MB. To fix this before we start the virtual machine, click on the \"Settings\" (gear icon) and you should get the same settings screen that we got when attaching our ISO image (above). This time: Click on \"Display\" on the left-hand side. In the \"Screen\" tab on the right-hand side, you'll notice the \"Video Memory\" option with the default set to 16 MB. Change this to the value that you want. You can adjust this upwards by coming back to this screen anytime. In our example, we are selecting 128 MB now. !!! Tip There are ways to set the video memory up to 256 MB. If you need more, check out [this document](https://docs.oracle.com/en/virtualization/virtualbox/6.0/user/vboxmanage-modifyvm.html) from Oracle's official documentation. Your screen should look something like this: Click \"OK\" Starting The Installation We've set everything up so that we can start the installation. Note that there are no particular differences in the install of Rocky Linux on a VirtualBox\u00ae machine compared to stand-alone hardware. The installation steps are the same. Now that we have everything prepared for the install, you just need to click \"Start\" (green right-arrow icon) to start installing Rocky. Once you click past the language selection screen, your next screen is the \"Installation Summary\" screen. You need to set any of these items that pertain to you, but the following are musts: Time & Date Software Selection (if you want something besides the default \"Server with GUI\") Installation Destination Network & Hostname User Settings If you are unsure of any of these settings, refer to the document for Installing Rocky . Once you have finished the installation, you should have a running VirtualBox\u00ae instance of Rocky Linux. After installing and rebooting you will get a EULA license agreement screen that you need to agree to, and once you've clicked \"Finish Configuration\", you should get either a graphical (if you chose a GUI option) or command line login. The author chose the default \"Server with GUI\" for demo purposes: Other Information It is not the intent of this document to make you an expert on all of the features that VirtualBox\u00ae can provide. For information on how to do specific things please check the official documentation . !!! tip \"Advanced Tip\" VirtualBox&reg; offers extensive options at the command line using `VBoxManage`. While this document does not cover the use of `VBoxManage`, Oracle's official documentation provides [plenty of details](https://docs.oracle.com/en/virtualization/virtualbox/6.0/user/vboxmanage-intro.html) if you would like to research this further. Conclusion It is easy to create, install, and run a VirtualBox\u00ae Rocky Linux machine. While far from an exhaustive guide, following the steps above should get you a running Rocky Linux install. If you use VirtualBox\u00ae and have a specific configuration that you would like to share, the author invites you to submit new sections to this document.","title":"Rocky on VirtualBox"},{"location":"guides/virtualization/vbox-rocky/#rocky-on-virtualbox","text":"","title":"Rocky on VirtualBox"},{"location":"guides/virtualization/vbox-rocky/#introduction","text":"VirtualBox\u00ae is a powerful virtualization product for both enterprise and home use. Once in a while, someone posts that they are having trouble getting Rocky Linux to run in VirtualBox\u00ae. It has been tested multiple times going back to the release candidate, and works just fine. The problems people usually report often involve video. This document is an attempt to give a step-by-step set of instructions for getting Rocky Linux up and running in VirtualBox\u00ae. The machine used to build this documentation was running Linux but, you can use any of the supported operating systems.","title":"Introduction"},{"location":"guides/virtualization/vbox-rocky/#prerequisites","text":"A machine (Windows, Mac, Linux, Solaris) with available memory, and hard disk space to build and run the VirtualBox\u00ae instance. VirtualBox\u00ae installed on your machine. You can find that here . A copy of the Rocky Linux DVD ISO for your architecture. (x86_64 or ARM64). Ensure that your OS is 64 bit and that hardware virtualization is turned on in your BIOS. !!! Note Hardware virtualization is 100% necessary in order to install a 64 bit OS. If your configuration screen shows only 32-bit options, then you need to stop and fix this before continuing.","title":"Prerequisites"},{"location":"guides/virtualization/vbox-rocky/#preparing-the-virtualbox-configuration","text":"Once you have VirtualBox\u00ae installed, the next step is to start it. With no images installed you will get a screen that looks something like this: First, we need to tell VirtualBox\u00ae what our OS is going to be: Click \"New\" (saw tooth icon). Type a name. Example: \"Rocky Linux 8.5\". Leave the machine folder as automatically filled. Change the type to \"Linux\". And choose \"Red Hat (64-bit)\". Click \"Next\". Next, we need to allocate some RAM for this machine. By default, VirtualBox\u00ae will automatically fill this to 1024 MB. That will not be optimum for any modern OS, including Rocky Linux. If you've got memory to spare, allocate 2 to 4 GB (2048 MB or 4096 MB) \u2014 or more. Keep in mind that VirtualBox\u00ae is only going to use this memory while the virtual machine is running. There's no screenshot for this one, just change the value based on your available memory. Use your best judgement. Now we need to set up the hard disk size. By default, VirtualBox\u00ae will automatically fill the \"Create a virtual hard disk now\" radio button. Click \"Create\" You will get a dialog box for creating various virtual hard disk types, and there are several hard disk types listed here. See the Oracle VirtualBox documentation for more information about selecting virtual hard disk types. For the purpose of this document, just keep the default (VDI): Click \"Next\" The next screen deals with the storage on the physical hard disk. There are two options. \"Fixed Size\" will be slower to create, faster to use, but less flexible in terms of space (if you need more space, you are stuck with what you created). The default option, \"Dynamically Allocated\", will be faster to create, slower to use, but will give you the option to grow if your disk space needs to change. For the purpose of this document, we are just accepting the default of \"Dynamically allocated.\" Click \"Next\" VirtualBox\u00ae now gives you the option to specify where you want the virtual hard disk file to be located as well as the option to expand the default 8 GB virtual hard disk space. This option is good, because 8 GB of hard disk space isn't enough to install, much less use, any of the GUI install options. Set this to 20 GB (or more) depending on what you want to use the virtual machine for, and how much free disk space you have available: Click \"Create\" We've finished the basic configuration. You should have a screen that looks something like this:","title":"Preparing The VirtualBox&reg; Configuration"},{"location":"guides/virtualization/vbox-rocky/#attaching-the-iso-image","text":"Our next step is to attach the ISO image that you downloaded earlier as a virtual CD ROM device. Click on the \"Settings\" (gear icon) and you should get the following screen: Click the \"Storage\" item in the left-hand menu. Under \"Storage Devices\" in the middle section, click the CD icon that says \"Empty\". Under \"Attributes\" on the right-hand side, click the CD icon. Select \"Choose/Create a Virtual Optical Disk\". Click the \"Add\" button (plus sign icon) and navigate to where your Rocky Linux ISO image is stored. Select the ISO and click \"Open\". You should now have the ISO added to the available devices like this: Highlight the ISO image and then click \"Choose\". The Rocky Linux ISO image now shows selected under the \"Controller:IDE\" in the middle section: Click \"OK\"","title":"Attaching The ISO Image"},{"location":"guides/virtualization/vbox-rocky/#video-memory-for-graphical-installations","text":"VirtualBox\u00ae sets up 16 MB of memory to use for video. That is fine if you are planning on running a bare-bones server without a GUI, but as soon as you add graphics, that's not enough. Users who keep this setting often see a hanging boot screen that never finishes, or other errors. If you are going to be running Rocky Linux with a GUI, you should allocate enough memory to easily run the graphics. If your machine is a bit thin on memory, adjust this value upwards 16 MB at a time until things run smoothly. Your host machine's video resolution is also a factor that you need to consider. Think carefully about what you want your Rocky Linux virtual machine to do, and try to allocate video memory that is compatible with your host machine and your other requirements. You can find more information on display settings from Oracle's official documentation . If you've got plenty of memory, you can set this value to the maximum of 128 MB. To fix this before we start the virtual machine, click on the \"Settings\" (gear icon) and you should get the same settings screen that we got when attaching our ISO image (above). This time: Click on \"Display\" on the left-hand side. In the \"Screen\" tab on the right-hand side, you'll notice the \"Video Memory\" option with the default set to 16 MB. Change this to the value that you want. You can adjust this upwards by coming back to this screen anytime. In our example, we are selecting 128 MB now. !!! Tip There are ways to set the video memory up to 256 MB. If you need more, check out [this document](https://docs.oracle.com/en/virtualization/virtualbox/6.0/user/vboxmanage-modifyvm.html) from Oracle's official documentation. Your screen should look something like this: Click \"OK\"","title":"Video Memory for Graphical Installations"},{"location":"guides/virtualization/vbox-rocky/#starting-the-installation","text":"We've set everything up so that we can start the installation. Note that there are no particular differences in the install of Rocky Linux on a VirtualBox\u00ae machine compared to stand-alone hardware. The installation steps are the same. Now that we have everything prepared for the install, you just need to click \"Start\" (green right-arrow icon) to start installing Rocky. Once you click past the language selection screen, your next screen is the \"Installation Summary\" screen. You need to set any of these items that pertain to you, but the following are musts: Time & Date Software Selection (if you want something besides the default \"Server with GUI\") Installation Destination Network & Hostname User Settings If you are unsure of any of these settings, refer to the document for Installing Rocky . Once you have finished the installation, you should have a running VirtualBox\u00ae instance of Rocky Linux. After installing and rebooting you will get a EULA license agreement screen that you need to agree to, and once you've clicked \"Finish Configuration\", you should get either a graphical (if you chose a GUI option) or command line login. The author chose the default \"Server with GUI\" for demo purposes:","title":"Starting The Installation"},{"location":"guides/virtualization/vbox-rocky/#other-information","text":"It is not the intent of this document to make you an expert on all of the features that VirtualBox\u00ae can provide. For information on how to do specific things please check the official documentation . !!! tip \"Advanced Tip\" VirtualBox&reg; offers extensive options at the command line using `VBoxManage`. While this document does not cover the use of `VBoxManage`, Oracle's official documentation provides [plenty of details](https://docs.oracle.com/en/virtualization/virtualbox/6.0/user/vboxmanage-intro.html) if you would like to research this further.","title":"Other Information"},{"location":"guides/virtualization/vbox-rocky/#conclusion","text":"It is easy to create, install, and run a VirtualBox\u00ae Rocky Linux machine. While far from an exhaustive guide, following the steps above should get you a running Rocky Linux install. If you use VirtualBox\u00ae and have a specific configuration that you would like to share, the author invites you to submit new sections to this document.","title":"Conclusion"},{"location":"guides/web/apache-sites-enabled.fr/","text":"Configuration Apache Web Server Multi-Sites' De quoi avez-vous besoin ? Un serveur sous Rocky Linux, Des connaissances de la ligne de commande et des \u00e9diteurs de texte (Cet exemple utilise vi , mais peut \u00eatre adapt\u00e9 \u00e0 votre \u00e9diteur favori), Si vous \u00eates int\u00e9ress\u00e9 pour apprendre \u00e0 utiliser l'\u00e9diteur de texte vi, voici un tutoriel pratique . Des connaissances \u00e9l\u00e9mentaires sur l'installation et le lancement de services web. Configuration Apache Web Server Multi-Sites Il y a de nombreuses fa\u00e7ons pour vous de configurer un site web sur Rocky Linux. Celle-ci est juste une m\u00e9thode utilisant Apache et est con\u00e7ue pour accueillir une configuration multi-sites sur un seul serveur. Bien que cette m\u00e9thode soit con\u00e7ue pour des serveurs multi-sites, elle peut tout aussi bien faire office de configuration de base pour un server mono-site. Pour la petite histoire : cette configuration serveur semble avoir d\u00e9marr\u00e9 sur des syst\u00e8mes Debian, mais est parfaitement adaptable \u00e0 n'importe quel OS Linux faisant tourner Apache. Installer Apache Vous aurez surement besoin d'autres paquets pour votre site web. Par exemple, une version de PHP sera certainement n\u00e9cessaire et peut \u00eatre \u00e9galement une base de donn\u00e9es ou tout autre sortes de paquets. L'installation de PHP et de httpd vous permettra d'obtenir les derni\u00e8res versions de ces logiciels \u00e0 partir des d\u00e9p\u00f4ts de Rocky Linux. Rappelez-vous simplement que vous pourrez avoir besoin de modules \u00e9galement, comme peut \u00eatre php-bcmath ou php-mysqlind. Les sp\u00e9cifications de votre application web devraient d\u00e9tailler ce qui est n\u00e9cessaire. Elles peuvent \u00eatre install\u00e9es \u00e0 n'importe quel moment. Pour l'instant, nous allons installer httpd et PHP, puisqu'ils sont presque in\u00e9vitables : Depuis la ligne de commande, ex\u00e9cuter : dnf install httpd php Ajouter des dossiers suppl\u00e9mentaires Cette m\u00e9thode utilise un ensemble de r\u00e9pertoires suppl\u00e9mentaires, mais ils n'existent pas actuellement sur le syst\u00e8me. Nous devons ajouter deux r\u00e9pertoires dans /etc/httpd/ appel\u00e9s \"sites-available\" et \"sites-enabled\". Depuis la ligne de commande, saisir mkdir /etc/httpd/sites-available puis mkdir /etc/httpd/sites-enabled Nous avons \u00e9galement besoin d'un r\u00e9pertoire dans lequel nos sites vont \u00eatre d\u00e9pos\u00e9s. Cela peut \u00eatre n'importe o\u00f9, mais une bonne fa\u00e7on de conserver les choses organis\u00e9es et de cr\u00e9er un r\u00e9pertoire appel\u00e9 sub-domains. Pour conserver les choses simples, placez le sous /var/www: mkdir /var/www/sub-domains/ Configuration Nous avons aussi besoin d'ajouter une ligne \u00e0 la toute fin du fichier httpd.conf. Pour faire cela, saisissez vi /etc/httpd/conf/httpd.conf , allez en bas du fichier et ajoutez Include /etc/httpd/sites-enabled . Nos fichiers de configuration seront dans /etc/httpd/sites-available et nous allons simplement cr\u00e9er des liens symboliques vers eux dans /etc/httpd/sites-enabled . Pourquoi faisons nous cela ? La raison est plut\u00f4t simple. Imaginons que vous avez 10 sites web fonctionnant tous sur le m\u00eame server sur diff\u00e9rentes adresses IP. Disons que le site B a des mises \u00e0 jour majeures et vous devez faire des changements \u00e0 la configuration de ce site. Disons \u00e9galement qu'il y a quelque chose de faux dans les changements effectu\u00e9s, si bien que lorsque vous red\u00e9marrez httpd pour prendre en compte les nouveaux changements, httpd ne d\u00e9marre pas. Non seulement le site sur lequel vous \u00e9tiez en train de travailler ne d\u00e9marre pas, mais aucun autre non plus. Avec cette m\u00e9thode, vous pouvez simplement supprimer le lien symbolique du site qui pose probl\u00e8me et red\u00e9marrer httpd. Il va recommencer \u00e0 fonctionner et vous pourrez travailler pour tenter de corriger la configuration du site en panne. Cela enl\u00e8ve la pression, en sachant que le t\u00e9l\u00e9phone ne va pas sonner avec un client ou un chef en col\u00e8re parce que le service est coup\u00e9. La configuration du site L'autre b\u00e9n\u00e9fice de cette m\u00e9thode est qu'elle va nous permettre de tout sp\u00e9cifier en dehors du fichier par d\u00e9faut httpd.conf. Laissez le fichier par d\u00e9faut httpd.conf charger les options par d\u00e9faut et laissez les fichiers de configuration de vos sites faire le reste. Chouette non ? De plus, encore une fois, cela rend vraiment simple de d\u00e9panner une configuration de site. Maintenant, disons que vous avez un site web qui charge un wiki. Vous allez avoir besoin d'un fichier de configuration qui rendra le site disponible sur le port 80. Si vous voulez servir le site en SSL (et regardons les choses en face, nous devrions tous faire \u00e7a maintenant) alors vous devrez ajouter une autre section (quasiment identique) au m\u00eame fichier afin d'activer le port 443. Vous pouvez jeter un \u0153il \u00e0 cela ci-dessous dans la section La configuration https - Utiliser un certificat SSL . Nous devons dans un premier temps cr\u00e9er ce fichier de configuration dans sites-available : vi /etc/httpd/sites-available/com.ourownwiki.www Le contenu du fichier de configuration devrait ressembler \u00e0 quelque chose comme ceci : <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Une fois le fichier cr\u00e9\u00e9, nous devons l'\u00e9crire (le sauvegarder) avec : shift : wq Dans notre exemple pr\u00e9c\u00e9dent, le site du wiki est charg\u00e9 depuis le sous r\u00e9pertoire html de com.ourownwiki.www , ce qui veut dire que le r\u00e9pertoire sub-domains que nous nous avons cr\u00e9\u00e9 dans /var/www (pr\u00e9c\u00e9demment) va n\u00e9cessiter des r\u00e9pertoires suppl\u00e9mentaires pour satisfaire cela : mkdir -p /var/www/sub-domains/com.ourownwiki.www/html ... ce qui va cr\u00e9er le chemin complet avec une seule commande. Ensuite, nous allons vouloir installer nos fichiers dans ce r\u00e9pertoire qui composeront le site web. Cela peut \u00eatre quelque chose que vous avez fait vous-m\u00eame ou une installation web que vous installerez (dans le cas d'un wiki que vous auriez t\u00e9l\u00e9charg\u00e9). Copiez vos fichiers dans le r\u00e9pertoire cr\u00e9\u00e9 pr\u00e9c\u00e9demment : cp -Rf wiki_source/* /var/www/sub-domains/com.ourownwiki.www/html/ La configuration https - Utiliser un certificat SSL Comme discut\u00e9 pr\u00e9c\u00e9demment, chaque serveur web cr\u00e9\u00e9 de nos jours devrait fonctionner avec du SSL (Secure Socket Layer). Ce processus commence par la g\u00e9n\u00e9ration d'une clef priv\u00e9e et d'un CSR (Certificate Signing Request) et ensuite par l'envoi du CSR \u00e0 l'autorit\u00e9 de certification pour acheter le certificat SSL. Ce processus de g\u00e9n\u00e9ration de clefs sort du cadre de ce document. Si vous d\u00e9butez dans la g\u00e9n\u00e9ration des clefs pour SSL, merci de consulter la page G\u00e9n\u00e9rer des clefs SSL Vous pouvez aussi utiliser ce processus alternatif pour utiliser un certificat SSL Let's Encrypt Placement des clefs SSL et des certificats Maintenant que vous disposez des fichiers de vos clefs et de vos certificats, nous devons logiquement les placer sur le syst\u00e8me de fichiers de votre serveur web. Comme nous l'avons vu dans l'exemple de fichier de configuration (voir ci-dessus), nous pla\u00e7ons les fichiers web dans /var/www/sub-domains/com.ourownwiki.www/html . Nous voulons placer nos fichiers de certificats et de clefs avec le domaine, mais PAS \u00e0 la racine des pages web (qui dans ce cas est dans le dossier _html). Nous ne voulons absolument pas que nos certificats et clefs puissent \u00eatre potentiellement expos\u00e9es sur internet. \u00c7a serait catastrophique ! A la place, nous allons cr\u00e9er une nouvelle structure de r\u00e9pertoires pour nos fichiers SSL, en dehors de la racine des pages web. mkdir -p /var/www/sub-domains/com.ourownwiki.www/ssl/{ssl.key,ssl.crt,ssl.csr} Si vous d\u00e9butez avec la syntaxe \"tree\", voici ce que veut dire l'exemple pr\u00e9c\u00e9dent : \"Cr\u00e9er un r\u00e9pertoire appel\u00e9 ssl et dans ce r\u00e9pertoire cr\u00e9er trois r\u00e9pertoires appel\u00e9s ssl.key, ssl.crt et ssl.csr.\" Juste une petite note en avance de phase : ce n'est pas n\u00e9cessaire pour le fonctionnement du site web de stocker le CSR dans l'arborescence. Si jamais vous avez besoin d'une nouvelle \u00e9dition de votre certificat depuis un fournisseur diff\u00e9rent par exemple, c'est une bonne id\u00e9e d'avoir une copie de sauvegarde de ce fichier CSR. La question devient alors o\u00f9 le stocker de mani\u00e8re \u00e0 s'en souvenir et le fait de le stocker dans l'arborescence du site web devient logique. En supposant que vous avez nomm\u00e9 vos fichiers .key, .csr et .crt (certificat) avec le nom de votre site et que vous les avez stock\u00e9s dans /root , nous allons alors les copier dans leurs emplacements respectifs que nous venons juste de cr\u00e9er : cp /root/com.wiki.www.key /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/ cp /root/com.wiki.www.csr /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.csr/ cp /root/com.wiki.www.crt /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/ La configuration du site - https Une fois que vous avez g\u00e9n\u00e9r\u00e9 vos clefs et achet\u00e9 les certificats SSL, vous pouvez avancer dans la configuration du site web pour utiliser les nouvelles clefs. Pour les d\u00e9butants, d\u00e9composons le d\u00e9but du fichier de configuration. Par exemple, m\u00eame si nous voulons toujours \u00e9couter sur le port 80 (http standard) pour les requ\u00eates entrantes, nous ne voulons pas qu'elles aboutissent vers le port 80. Nous voulons qu'elles soient redirig\u00e9es vers le port 443 (ou http s\u00e9curis\u00e9, mieux connu sous SSL). Notre section de configuration du port 80 sera r\u00e9duite au minimum : <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> Cette configuration indique de renvoyer toutes les requ\u00eates web en https. L'option apache \"Redirect\" utilis\u00e9e ci-dessus peut \u00eatre remplac\u00e9e par \"Redirect permanent\" une fois que tous les tests ont \u00e9t\u00e9 effectu\u00e9s et que vous pouvez constater que le site fonctionne comme vous voulez qu'il fonctionne. Le \"Redirect\" que nous avons choisi est une redirection temporaire. Une redirection permanente va \u00eatre apprise par les moteurs de recherche et rapidement tout le trafic de votre site qui provient des moteurs de recherche ira seulement vers le port 443 (https) sans passer par le port 80 en premier. Ensuite, nous devons d\u00e9finir la partie https du fichier de configuration. La section http est dupliqu\u00e9e par clart\u00e9 pour montrer que tout cela se passe dans le m\u00eame fichier de configuration : <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> <Virtual Host *:443> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/com.wiki.www.crt SSLCertificateKeyFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/com.wiki.www.key SSLCertificateChainFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/your_providers_intermediate_certificate.crt <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Donc, en d\u00e9composant davantage cette configuration, apr\u00e8s les parties normales de la configuration et sous la partie SSL : SSLEngine on - dit simplement d'utiliser SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - dit d'utiliser tous les protocoles disponibles sauf ceux pour qui des vuln\u00e9rabilit\u00e9s ont \u00e9t\u00e9 d\u00e9couvertes. Vous devriez rechercher r\u00e9guli\u00e8rement quels protocoles sont actuellement acceptables \u00e0 \u00eatre utilis\u00e9s. SSLHonorCipherOrder on - cette directive fonctionne avec la ligne suivante concernant les algorithmes de chiffrements (Cipher Suite) et demande de les utiliser dans le m\u00eame ordre que celui dans lequel ils sont donn\u00e9s. C'est une autre partie de la configuration que vous devriez r\u00e9viser r\u00e9guli\u00e8rement SSLCertificateFile - qui est exactement ce qu'il semble \u00eatre, le fichier du nouveau certificat acquis et son emplacement. SSLCertificateKeyFile - la clef que vous avez g\u00e9n\u00e9r\u00e9e lors de la cr\u00e9ation de la demande de signature de certificat SSLCertificateChainFile - le certificat de votre fournisseur de certificat, souvent appel\u00e9 certificat interm\u00e9diaire. Ensuite, mettez tout en route et s'il n'y a aucune erreur lors du d\u00e9marrage du service web et si en allant sur votre site web le site en https s'affiche sans erreurs, alors vous pouvez continuer. Le mot de la fin Rappelez-vous que notre fichier httpd.conf contient \u00e0 la toute fin du fichier /etc/httpd/sites-enabled , alors, quand httpd red\u00e9marre, il va charger n'importe quel fichier de configuration qui se trouve dans le r\u00e9pertoire sites-enabled . Toutefois, tous nos fichiers de configuration sont dans sites-available . C'est un choix d\u00e9lib\u00e9r\u00e9 de mani\u00e8re \u00e0 pouvoir retirer facilement des configurations dans le cas o\u00f9 le service http refuserait de red\u00e9marrer. Alors, pour activer nos fichiers de configuration, nous devons cr\u00e9er un lien symbolique vers ce fichier dans sites-enabled et ensuite d\u00e9marrer ou red\u00e9marrer le service web. Pour faire cela, nous utilisons la commande : ln -s /etc/httpd/sites-available/com.ourownwiki.www /etc/httpd/sites-enabled/ Cela va cr\u00e9er le lien vers le fichier de configuration dans sites-enabled comme nous le d\u00e9sirons. Maintenant d\u00e9marrez simplement httpd avec systemctl start httpd ou red\u00e9marrez le s'il tourne d\u00e9j\u00e0 : systemctl restart httpd et en supposant que le service red\u00e9marre, vous pouvez acc\u00e9der \u00e0 votre site et le tester.","title":"Configuration Apache Web Server Multi-Sites'"},{"location":"guides/web/apache-sites-enabled.fr/#configuration-apache-web-server-multi-sites","text":"","title":"Configuration Apache Web Server Multi-Sites'"},{"location":"guides/web/apache-sites-enabled.fr/#de-quoi-avez-vous-besoin","text":"Un serveur sous Rocky Linux, Des connaissances de la ligne de commande et des \u00e9diteurs de texte (Cet exemple utilise vi , mais peut \u00eatre adapt\u00e9 \u00e0 votre \u00e9diteur favori), Si vous \u00eates int\u00e9ress\u00e9 pour apprendre \u00e0 utiliser l'\u00e9diteur de texte vi, voici un tutoriel pratique . Des connaissances \u00e9l\u00e9mentaires sur l'installation et le lancement de services web.","title":"De quoi avez-vous besoin ?"},{"location":"guides/web/apache-sites-enabled.fr/#configuration-apache-web-server-multi-sites_1","text":"Il y a de nombreuses fa\u00e7ons pour vous de configurer un site web sur Rocky Linux. Celle-ci est juste une m\u00e9thode utilisant Apache et est con\u00e7ue pour accueillir une configuration multi-sites sur un seul serveur. Bien que cette m\u00e9thode soit con\u00e7ue pour des serveurs multi-sites, elle peut tout aussi bien faire office de configuration de base pour un server mono-site. Pour la petite histoire : cette configuration serveur semble avoir d\u00e9marr\u00e9 sur des syst\u00e8mes Debian, mais est parfaitement adaptable \u00e0 n'importe quel OS Linux faisant tourner Apache.","title":"Configuration Apache Web Server Multi-Sites"},{"location":"guides/web/apache-sites-enabled.fr/#installer-apache","text":"Vous aurez surement besoin d'autres paquets pour votre site web. Par exemple, une version de PHP sera certainement n\u00e9cessaire et peut \u00eatre \u00e9galement une base de donn\u00e9es ou tout autre sortes de paquets. L'installation de PHP et de httpd vous permettra d'obtenir les derni\u00e8res versions de ces logiciels \u00e0 partir des d\u00e9p\u00f4ts de Rocky Linux. Rappelez-vous simplement que vous pourrez avoir besoin de modules \u00e9galement, comme peut \u00eatre php-bcmath ou php-mysqlind. Les sp\u00e9cifications de votre application web devraient d\u00e9tailler ce qui est n\u00e9cessaire. Elles peuvent \u00eatre install\u00e9es \u00e0 n'importe quel moment. Pour l'instant, nous allons installer httpd et PHP, puisqu'ils sont presque in\u00e9vitables : Depuis la ligne de commande, ex\u00e9cuter : dnf install httpd php","title":"Installer Apache"},{"location":"guides/web/apache-sites-enabled.fr/#ajouter-des-dossiers-supplementaires","text":"Cette m\u00e9thode utilise un ensemble de r\u00e9pertoires suppl\u00e9mentaires, mais ils n'existent pas actuellement sur le syst\u00e8me. Nous devons ajouter deux r\u00e9pertoires dans /etc/httpd/ appel\u00e9s \"sites-available\" et \"sites-enabled\". Depuis la ligne de commande, saisir mkdir /etc/httpd/sites-available puis mkdir /etc/httpd/sites-enabled Nous avons \u00e9galement besoin d'un r\u00e9pertoire dans lequel nos sites vont \u00eatre d\u00e9pos\u00e9s. Cela peut \u00eatre n'importe o\u00f9, mais une bonne fa\u00e7on de conserver les choses organis\u00e9es et de cr\u00e9er un r\u00e9pertoire appel\u00e9 sub-domains. Pour conserver les choses simples, placez le sous /var/www: mkdir /var/www/sub-domains/","title":"Ajouter des dossiers suppl\u00e9mentaires"},{"location":"guides/web/apache-sites-enabled.fr/#configuration","text":"Nous avons aussi besoin d'ajouter une ligne \u00e0 la toute fin du fichier httpd.conf. Pour faire cela, saisissez vi /etc/httpd/conf/httpd.conf , allez en bas du fichier et ajoutez Include /etc/httpd/sites-enabled . Nos fichiers de configuration seront dans /etc/httpd/sites-available et nous allons simplement cr\u00e9er des liens symboliques vers eux dans /etc/httpd/sites-enabled . Pourquoi faisons nous cela ? La raison est plut\u00f4t simple. Imaginons que vous avez 10 sites web fonctionnant tous sur le m\u00eame server sur diff\u00e9rentes adresses IP. Disons que le site B a des mises \u00e0 jour majeures et vous devez faire des changements \u00e0 la configuration de ce site. Disons \u00e9galement qu'il y a quelque chose de faux dans les changements effectu\u00e9s, si bien que lorsque vous red\u00e9marrez httpd pour prendre en compte les nouveaux changements, httpd ne d\u00e9marre pas. Non seulement le site sur lequel vous \u00e9tiez en train de travailler ne d\u00e9marre pas, mais aucun autre non plus. Avec cette m\u00e9thode, vous pouvez simplement supprimer le lien symbolique du site qui pose probl\u00e8me et red\u00e9marrer httpd. Il va recommencer \u00e0 fonctionner et vous pourrez travailler pour tenter de corriger la configuration du site en panne. Cela enl\u00e8ve la pression, en sachant que le t\u00e9l\u00e9phone ne va pas sonner avec un client ou un chef en col\u00e8re parce que le service est coup\u00e9.","title":"Configuration"},{"location":"guides/web/apache-sites-enabled.fr/#la-configuration-du-site","text":"L'autre b\u00e9n\u00e9fice de cette m\u00e9thode est qu'elle va nous permettre de tout sp\u00e9cifier en dehors du fichier par d\u00e9faut httpd.conf. Laissez le fichier par d\u00e9faut httpd.conf charger les options par d\u00e9faut et laissez les fichiers de configuration de vos sites faire le reste. Chouette non ? De plus, encore une fois, cela rend vraiment simple de d\u00e9panner une configuration de site. Maintenant, disons que vous avez un site web qui charge un wiki. Vous allez avoir besoin d'un fichier de configuration qui rendra le site disponible sur le port 80. Si vous voulez servir le site en SSL (et regardons les choses en face, nous devrions tous faire \u00e7a maintenant) alors vous devrez ajouter une autre section (quasiment identique) au m\u00eame fichier afin d'activer le port 443. Vous pouvez jeter un \u0153il \u00e0 cela ci-dessous dans la section La configuration https - Utiliser un certificat SSL . Nous devons dans un premier temps cr\u00e9er ce fichier de configuration dans sites-available : vi /etc/httpd/sites-available/com.ourownwiki.www Le contenu du fichier de configuration devrait ressembler \u00e0 quelque chose comme ceci : <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Une fois le fichier cr\u00e9\u00e9, nous devons l'\u00e9crire (le sauvegarder) avec : shift : wq Dans notre exemple pr\u00e9c\u00e9dent, le site du wiki est charg\u00e9 depuis le sous r\u00e9pertoire html de com.ourownwiki.www , ce qui veut dire que le r\u00e9pertoire sub-domains que nous nous avons cr\u00e9\u00e9 dans /var/www (pr\u00e9c\u00e9demment) va n\u00e9cessiter des r\u00e9pertoires suppl\u00e9mentaires pour satisfaire cela : mkdir -p /var/www/sub-domains/com.ourownwiki.www/html ... ce qui va cr\u00e9er le chemin complet avec une seule commande. Ensuite, nous allons vouloir installer nos fichiers dans ce r\u00e9pertoire qui composeront le site web. Cela peut \u00eatre quelque chose que vous avez fait vous-m\u00eame ou une installation web que vous installerez (dans le cas d'un wiki que vous auriez t\u00e9l\u00e9charg\u00e9). Copiez vos fichiers dans le r\u00e9pertoire cr\u00e9\u00e9 pr\u00e9c\u00e9demment : cp -Rf wiki_source/* /var/www/sub-domains/com.ourownwiki.www/html/","title":"La configuration du site"},{"location":"guides/web/apache-sites-enabled.fr/#la-configuration-https-utiliser-un-certificat-ssl","text":"Comme discut\u00e9 pr\u00e9c\u00e9demment, chaque serveur web cr\u00e9\u00e9 de nos jours devrait fonctionner avec du SSL (Secure Socket Layer). Ce processus commence par la g\u00e9n\u00e9ration d'une clef priv\u00e9e et d'un CSR (Certificate Signing Request) et ensuite par l'envoi du CSR \u00e0 l'autorit\u00e9 de certification pour acheter le certificat SSL. Ce processus de g\u00e9n\u00e9ration de clefs sort du cadre de ce document. Si vous d\u00e9butez dans la g\u00e9n\u00e9ration des clefs pour SSL, merci de consulter la page G\u00e9n\u00e9rer des clefs SSL Vous pouvez aussi utiliser ce processus alternatif pour utiliser un certificat SSL Let's Encrypt","title":"La configuration https - Utiliser un certificat SSL"},{"location":"guides/web/apache-sites-enabled.fr/#placement-des-clefs-ssl-et-des-certificats","text":"Maintenant que vous disposez des fichiers de vos clefs et de vos certificats, nous devons logiquement les placer sur le syst\u00e8me de fichiers de votre serveur web. Comme nous l'avons vu dans l'exemple de fichier de configuration (voir ci-dessus), nous pla\u00e7ons les fichiers web dans /var/www/sub-domains/com.ourownwiki.www/html . Nous voulons placer nos fichiers de certificats et de clefs avec le domaine, mais PAS \u00e0 la racine des pages web (qui dans ce cas est dans le dossier _html). Nous ne voulons absolument pas que nos certificats et clefs puissent \u00eatre potentiellement expos\u00e9es sur internet. \u00c7a serait catastrophique ! A la place, nous allons cr\u00e9er une nouvelle structure de r\u00e9pertoires pour nos fichiers SSL, en dehors de la racine des pages web. mkdir -p /var/www/sub-domains/com.ourownwiki.www/ssl/{ssl.key,ssl.crt,ssl.csr} Si vous d\u00e9butez avec la syntaxe \"tree\", voici ce que veut dire l'exemple pr\u00e9c\u00e9dent : \"Cr\u00e9er un r\u00e9pertoire appel\u00e9 ssl et dans ce r\u00e9pertoire cr\u00e9er trois r\u00e9pertoires appel\u00e9s ssl.key, ssl.crt et ssl.csr.\" Juste une petite note en avance de phase : ce n'est pas n\u00e9cessaire pour le fonctionnement du site web de stocker le CSR dans l'arborescence. Si jamais vous avez besoin d'une nouvelle \u00e9dition de votre certificat depuis un fournisseur diff\u00e9rent par exemple, c'est une bonne id\u00e9e d'avoir une copie de sauvegarde de ce fichier CSR. La question devient alors o\u00f9 le stocker de mani\u00e8re \u00e0 s'en souvenir et le fait de le stocker dans l'arborescence du site web devient logique. En supposant que vous avez nomm\u00e9 vos fichiers .key, .csr et .crt (certificat) avec le nom de votre site et que vous les avez stock\u00e9s dans /root , nous allons alors les copier dans leurs emplacements respectifs que nous venons juste de cr\u00e9er : cp /root/com.wiki.www.key /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/ cp /root/com.wiki.www.csr /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.csr/ cp /root/com.wiki.www.crt /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/","title":"Placement des clefs SSL et des certificats"},{"location":"guides/web/apache-sites-enabled.fr/#la-configuration-du-site-https","text":"Une fois que vous avez g\u00e9n\u00e9r\u00e9 vos clefs et achet\u00e9 les certificats SSL, vous pouvez avancer dans la configuration du site web pour utiliser les nouvelles clefs. Pour les d\u00e9butants, d\u00e9composons le d\u00e9but du fichier de configuration. Par exemple, m\u00eame si nous voulons toujours \u00e9couter sur le port 80 (http standard) pour les requ\u00eates entrantes, nous ne voulons pas qu'elles aboutissent vers le port 80. Nous voulons qu'elles soient redirig\u00e9es vers le port 443 (ou http s\u00e9curis\u00e9, mieux connu sous SSL). Notre section de configuration du port 80 sera r\u00e9duite au minimum : <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> Cette configuration indique de renvoyer toutes les requ\u00eates web en https. L'option apache \"Redirect\" utilis\u00e9e ci-dessus peut \u00eatre remplac\u00e9e par \"Redirect permanent\" une fois que tous les tests ont \u00e9t\u00e9 effectu\u00e9s et que vous pouvez constater que le site fonctionne comme vous voulez qu'il fonctionne. Le \"Redirect\" que nous avons choisi est une redirection temporaire. Une redirection permanente va \u00eatre apprise par les moteurs de recherche et rapidement tout le trafic de votre site qui provient des moteurs de recherche ira seulement vers le port 443 (https) sans passer par le port 80 en premier. Ensuite, nous devons d\u00e9finir la partie https du fichier de configuration. La section http est dupliqu\u00e9e par clart\u00e9 pour montrer que tout cela se passe dans le m\u00eame fichier de configuration : <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> <Virtual Host *:443> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/com.wiki.www.crt SSLCertificateKeyFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/com.wiki.www.key SSLCertificateChainFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/your_providers_intermediate_certificate.crt <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Donc, en d\u00e9composant davantage cette configuration, apr\u00e8s les parties normales de la configuration et sous la partie SSL : SSLEngine on - dit simplement d'utiliser SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - dit d'utiliser tous les protocoles disponibles sauf ceux pour qui des vuln\u00e9rabilit\u00e9s ont \u00e9t\u00e9 d\u00e9couvertes. Vous devriez rechercher r\u00e9guli\u00e8rement quels protocoles sont actuellement acceptables \u00e0 \u00eatre utilis\u00e9s. SSLHonorCipherOrder on - cette directive fonctionne avec la ligne suivante concernant les algorithmes de chiffrements (Cipher Suite) et demande de les utiliser dans le m\u00eame ordre que celui dans lequel ils sont donn\u00e9s. C'est une autre partie de la configuration que vous devriez r\u00e9viser r\u00e9guli\u00e8rement SSLCertificateFile - qui est exactement ce qu'il semble \u00eatre, le fichier du nouveau certificat acquis et son emplacement. SSLCertificateKeyFile - la clef que vous avez g\u00e9n\u00e9r\u00e9e lors de la cr\u00e9ation de la demande de signature de certificat SSLCertificateChainFile - le certificat de votre fournisseur de certificat, souvent appel\u00e9 certificat interm\u00e9diaire. Ensuite, mettez tout en route et s'il n'y a aucune erreur lors du d\u00e9marrage du service web et si en allant sur votre site web le site en https s'affiche sans erreurs, alors vous pouvez continuer.","title":"La configuration du site - https"},{"location":"guides/web/apache-sites-enabled.fr/#le-mot-de-la-fin","text":"Rappelez-vous que notre fichier httpd.conf contient \u00e0 la toute fin du fichier /etc/httpd/sites-enabled , alors, quand httpd red\u00e9marre, il va charger n'importe quel fichier de configuration qui se trouve dans le r\u00e9pertoire sites-enabled . Toutefois, tous nos fichiers de configuration sont dans sites-available . C'est un choix d\u00e9lib\u00e9r\u00e9 de mani\u00e8re \u00e0 pouvoir retirer facilement des configurations dans le cas o\u00f9 le service http refuserait de red\u00e9marrer. Alors, pour activer nos fichiers de configuration, nous devons cr\u00e9er un lien symbolique vers ce fichier dans sites-enabled et ensuite d\u00e9marrer ou red\u00e9marrer le service web. Pour faire cela, nous utilisons la commande : ln -s /etc/httpd/sites-available/com.ourownwiki.www /etc/httpd/sites-enabled/ Cela va cr\u00e9er le lien vers le fichier de configuration dans sites-enabled comme nous le d\u00e9sirons. Maintenant d\u00e9marrez simplement httpd avec systemctl start httpd ou red\u00e9marrez le s'il tourne d\u00e9j\u00e0 : systemctl restart httpd et en supposant que le service red\u00e9marre, vous pouvez acc\u00e9der \u00e0 votre site et le tester.","title":"Le mot de la fin"},{"location":"guides/web/apache-sites-enabled/","tags":["web","apache","multisite"],"text":"Apache Web Server Multisite Setup What You Need A server running Rocky Linux Knowledge of the command-line and text editors (This example uses vi , but can be adapted to your favorite editor.) !!! hint If you'd like to learn about the vi text editor, here's a handy tutorial . Basic knowledge about installing and running web services Introduction Rocky Linux has many ways for you to set up a website. This is just one method, using Apache, and is designed for use as a multisite setup on a single server. While this method is designed for multisite servers, it can also act as a base configuration for a single site server as well. Historical fact: This server setup appears to have started with Debian-based systems, but it is perfectly adaptable to any Linux OS running Apache. For those looking for a similar setup for Nginx, take a look at this guide. Install Apache You'll likely need other packages for your website. For instance, a version of PHP will almost certainly be required, and maybe a database or other package will be needed as well. Installing PHP along with httpd will get you the latest version of both from the Rocky Linux repositories. Just remember that you may need modules as well, like perhaps php-bcmath or php-mysqlind. Your web application specifications should detail what is needed. These can be installed at any time. For now, we will install httpd and PHP, as those are almost a forgone conclusion: From the command-line run dnf install httpd php Add Extra Directories This method uses a couple of additional directories, but they don't currently exist on the system. We need to add two directories in /etc/httpd/ called \"sites-available\" and \"sites-enabled.\" From the command-line type mkdir /etc/httpd/sites-available and then mkdir /etc/httpd/sites-enabled We also need a directory where our sites are going to reside. This can be anywhere, but a good way to keep things organized is to create a directory called sub-domains. To keep things simple, put this in /var/www: mkdir /var/www/sub-domains/ Configuration We also need to add a line to the very bottom of the httpd.conf file. To do this, type vi /etc/httpd/conf/httpd.conf and go to the bottom of the file and add Include /etc/httpd/sites-enabled . Our actual configuration files will reside in /etc/httpd/sites-available and we will simply symlink to them in /etc/httpd/sites-enabled . Why do we do this? The reason here is pretty simple. Let's say you have 10 websites all running on the same server on different IP addresses. We will say, too, that site B has some major updates, and you have to make changes to the configuration for that site. Let's say as well, that there is something wrong with the changes made, so when you restart httpd to read in the new changes, httpd doesn't start. Not only will the site you were working on not start, but neither will the rest of them. With this method, you can simply remove the symbolic link for the site that caused the failure, and restart httpd. It\u2019ll start working again, and you can go to work, trying to fix the broken site configuration. It sure takes the pressure off, knowing that the phone isn't going to ring with some angry customer, or an angry boss, because a service is off-line. The Site Configuration The other benefit of this method is that it allows us to fully specify everything outside the default httpd.conf file. Let the default httpd.conf file load the defaults, and let your site configurations do everything else. Sweet, right? Plus again, it makes it very easy to trouble-shoot a broken site configuration. Now, let's say you have a website that loads a wiki. You\u2019ll need a configuration file, which makes the site available via port 80. If you want to serve the website with SSL (and let's face it, we all should be doing that by now) then you need to add another (nearly identical) section to the same file, in order to enable port 443. You can take a look at that below in the Configuration https - Using An SSL Certificate section. So we first need to create this configuration file in sites-available : vi /etc/httpd/sites-available/com.wiki.www The configuration file configuration content would look something like this: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Once the file is created, we need to write (save) it with: shift : wq In our example above, the wiki site is loaded from the \"html\" sub-directory of com.ourownwiki.www , which means that the path we created in /var/www (above) will need some additional directories to satisfy this: mkdir -p /var/www/sub-domains/com.ourownwiki.www/html ... which will create the entire path with a single command. Next we would want to install our files to this directory that will actually run the website. This could be something you made yourself, or an installable web application (in this case a wiki that you downloaded). Copy your files to the path above: cp -Rf wiki_source/* /var/www/sub-domains/com.ourownwiki.www/html/ Configuration https - Using an SSL Certificate As stated earlier, every web server created these days should be running with SSL (AKA the secure socket layer). This process starts by generating a private key and a CSR (which stands for certificate signing request) and then submitting the CSR to the certificate authority to purchase the SSL certificate. The process of generating these keys is somewhat extensive, so it has its own document. If you are new to generating keys for SSL, please take a look at: Generating SSL Keys You can also use this alternate process for using an SSL certificate from Let's Encrypt Placement of the SSL keys and Certificate's Now that you have your keys and certificate files, we need to place them logically in your file system on the web server. As we've seen with the example configuration file (above), we are placing our web files in /var/www/sub-domains/com.ourownwiki.www/html . We want to place our certificate and key files with the domain, but NOT in the document root, which in this case is the html folder. We never want our certificates and keys to potentially be exposed to the web. That would be bad! Instead, we will create a new directory structure for our SSL files, outside the document root: mkdir -p /var/www/sub-domains/com.ourownwiki.www/ssl/{ssl.key,ssl.crt,ssl.csr} If you are new to the \"tree\" syntax for making directories, what the above says is: \"Make a directory called ssl and then make three directories inside called ssl.key, ssl.crt, and ssl.csr.\" Just a note ahead of time: It is not necessary for the functioning of the web server that the CSR file be stored in the tree. If you ever need to re-issue the certificate from a different provider, etc., it's a good idea to have a stored copy of the CSR file. The question becomes where can you store it so that you will remember, and storing it within the tree of your website is logical. Assuming that you have named your key, csr, and crt (certificate) files with the name of your site, and that you have them stored in /root , we will then copy them up to their respective locations that we just created: cp /root/com.wiki.www.key /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/ cp /root/com.wiki.www.csr /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.csr/ cp /root/com.wiki.www.crt /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/ The Site Configuration - https Once you have generated your keys and purchased the SSL certificate, you can now move forward with the configuration of the website using your new keys. For starters, let's break down the beginning of the configuration file. For instance, even though we still want to listen on port 80 (standard http) for incoming requests, we don't want any of those requests to actually go to port 80. We want them to go to port 443 (or http secure, better known as SSL). Our port 80 configuration section will be minimal: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> What this says is to send any regular web request to the https configuration instead. The apache \"Redirect\" option shown above, can be changed to \"Redirect permanent\" once all testing is complete, and you can see that the site operates as you want it to. The \"Redirect\" we have chosen is a temporary redirect. A permanent redirect will be learned by search engines, and soon, any traffic to your site that comes from search engines will go only to port 443 (https) without hitting port 80 (http) first. Next, we need to define the https portion of the configuration file. The http section is duplicated here for clarity to show that this all happens in the same configuration file: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> <Virtual Host *:443> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/com.wiki.www.crt SSLCertificateKeyFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/com.wiki.www.key SSLCertificateChainFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/your_providers_intermediate_certificate.crt <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> So, breaking down this configuration further, after the normal portions of the configuration and down to the SSL portion: SSLEngine on - simply says to use SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - says to use all available protocols, except those that have been found to have vulnerabilities. You should research periodically which protocols are currently acceptable for use. SSLHonorCipherOrder on - this deals with the next line that regarding the cipher suites, and says to deal with them in the order that they are given. This is another area where you should review the cipher suites that you want to include periodically SSLCertificateFile - is exactly what it sounds like, the newly purchased and applied certificate file and its location SSLCertificateKeyFile - the key you generated when creating your certificate signing request SSLCertificateChainFile - the certificate from your certificate provider, often referred to as the intermediate certificate. Next, take everything live and if there are no errors starting the web service and if going to your website reveals HTTPS without errors, then you are ready to go. Taking It Live Remember that our httpd.conf file is including /etc/httpd/sites-enabled at the very end of the file, so when httpd restarts, it will load whatever configuration files are in that sites-enabled directory. Thing is, all of our configuration files are in sites-available . That's by design, so that we can easily remove things in the event that httpd fails to restart. So to enable our configuration file, we need to create a symbolic link to that file in sites-enabled and then start or restart the web service. To do this, we use this command: ln -s /etc/httpd/sites-available/com.ourownwiki.www /etc/httpd/sites-enabled/ This will create the link to the configuration file in sites-enabled , just like we want. Now just start httpd with systemctl start httpd . Or restart it if it\u2019s already running: systemctl restart httpd , and assuming the web service restarts, you can now go and do some testing on your new site.","title":"Apache Multisite"},{"location":"guides/web/apache-sites-enabled/#apache-web-server-multisite-setup","text":"","title":"Apache Web Server Multisite Setup"},{"location":"guides/web/apache-sites-enabled/#what-you-need","text":"A server running Rocky Linux Knowledge of the command-line and text editors (This example uses vi , but can be adapted to your favorite editor.) !!! hint If you'd like to learn about the vi text editor, here's a handy tutorial . Basic knowledge about installing and running web services","title":"What You Need"},{"location":"guides/web/apache-sites-enabled/#introduction","text":"Rocky Linux has many ways for you to set up a website. This is just one method, using Apache, and is designed for use as a multisite setup on a single server. While this method is designed for multisite servers, it can also act as a base configuration for a single site server as well. Historical fact: This server setup appears to have started with Debian-based systems, but it is perfectly adaptable to any Linux OS running Apache. For those looking for a similar setup for Nginx, take a look at this guide.","title":"Introduction"},{"location":"guides/web/apache-sites-enabled/#install-apache","text":"You'll likely need other packages for your website. For instance, a version of PHP will almost certainly be required, and maybe a database or other package will be needed as well. Installing PHP along with httpd will get you the latest version of both from the Rocky Linux repositories. Just remember that you may need modules as well, like perhaps php-bcmath or php-mysqlind. Your web application specifications should detail what is needed. These can be installed at any time. For now, we will install httpd and PHP, as those are almost a forgone conclusion: From the command-line run dnf install httpd php","title":"Install Apache"},{"location":"guides/web/apache-sites-enabled/#add-extra-directories","text":"This method uses a couple of additional directories, but they don't currently exist on the system. We need to add two directories in /etc/httpd/ called \"sites-available\" and \"sites-enabled.\" From the command-line type mkdir /etc/httpd/sites-available and then mkdir /etc/httpd/sites-enabled We also need a directory where our sites are going to reside. This can be anywhere, but a good way to keep things organized is to create a directory called sub-domains. To keep things simple, put this in /var/www: mkdir /var/www/sub-domains/","title":"Add Extra Directories"},{"location":"guides/web/apache-sites-enabled/#configuration","text":"We also need to add a line to the very bottom of the httpd.conf file. To do this, type vi /etc/httpd/conf/httpd.conf and go to the bottom of the file and add Include /etc/httpd/sites-enabled . Our actual configuration files will reside in /etc/httpd/sites-available and we will simply symlink to them in /etc/httpd/sites-enabled . Why do we do this? The reason here is pretty simple. Let's say you have 10 websites all running on the same server on different IP addresses. We will say, too, that site B has some major updates, and you have to make changes to the configuration for that site. Let's say as well, that there is something wrong with the changes made, so when you restart httpd to read in the new changes, httpd doesn't start. Not only will the site you were working on not start, but neither will the rest of them. With this method, you can simply remove the symbolic link for the site that caused the failure, and restart httpd. It\u2019ll start working again, and you can go to work, trying to fix the broken site configuration. It sure takes the pressure off, knowing that the phone isn't going to ring with some angry customer, or an angry boss, because a service is off-line.","title":"Configuration"},{"location":"guides/web/apache-sites-enabled/#the-site-configuration","text":"The other benefit of this method is that it allows us to fully specify everything outside the default httpd.conf file. Let the default httpd.conf file load the defaults, and let your site configurations do everything else. Sweet, right? Plus again, it makes it very easy to trouble-shoot a broken site configuration. Now, let's say you have a website that loads a wiki. You\u2019ll need a configuration file, which makes the site available via port 80. If you want to serve the website with SSL (and let's face it, we all should be doing that by now) then you need to add another (nearly identical) section to the same file, in order to enable port 443. You can take a look at that below in the Configuration https - Using An SSL Certificate section. So we first need to create this configuration file in sites-available : vi /etc/httpd/sites-available/com.wiki.www The configuration file configuration content would look something like this: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Once the file is created, we need to write (save) it with: shift : wq In our example above, the wiki site is loaded from the \"html\" sub-directory of com.ourownwiki.www , which means that the path we created in /var/www (above) will need some additional directories to satisfy this: mkdir -p /var/www/sub-domains/com.ourownwiki.www/html ... which will create the entire path with a single command. Next we would want to install our files to this directory that will actually run the website. This could be something you made yourself, or an installable web application (in this case a wiki that you downloaded). Copy your files to the path above: cp -Rf wiki_source/* /var/www/sub-domains/com.ourownwiki.www/html/","title":"The Site Configuration"},{"location":"guides/web/apache-sites-enabled/#configuration-https-using-an-ssl-certificate","text":"As stated earlier, every web server created these days should be running with SSL (AKA the secure socket layer). This process starts by generating a private key and a CSR (which stands for certificate signing request) and then submitting the CSR to the certificate authority to purchase the SSL certificate. The process of generating these keys is somewhat extensive, so it has its own document. If you are new to generating keys for SSL, please take a look at: Generating SSL Keys You can also use this alternate process for using an SSL certificate from Let's Encrypt","title":"Configuration https - Using an SSL Certificate"},{"location":"guides/web/apache-sites-enabled/#placement-of-the-ssl-keys-and-certificates","text":"Now that you have your keys and certificate files, we need to place them logically in your file system on the web server. As we've seen with the example configuration file (above), we are placing our web files in /var/www/sub-domains/com.ourownwiki.www/html . We want to place our certificate and key files with the domain, but NOT in the document root, which in this case is the html folder. We never want our certificates and keys to potentially be exposed to the web. That would be bad! Instead, we will create a new directory structure for our SSL files, outside the document root: mkdir -p /var/www/sub-domains/com.ourownwiki.www/ssl/{ssl.key,ssl.crt,ssl.csr} If you are new to the \"tree\" syntax for making directories, what the above says is: \"Make a directory called ssl and then make three directories inside called ssl.key, ssl.crt, and ssl.csr.\" Just a note ahead of time: It is not necessary for the functioning of the web server that the CSR file be stored in the tree. If you ever need to re-issue the certificate from a different provider, etc., it's a good idea to have a stored copy of the CSR file. The question becomes where can you store it so that you will remember, and storing it within the tree of your website is logical. Assuming that you have named your key, csr, and crt (certificate) files with the name of your site, and that you have them stored in /root , we will then copy them up to their respective locations that we just created: cp /root/com.wiki.www.key /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/ cp /root/com.wiki.www.csr /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.csr/ cp /root/com.wiki.www.crt /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/","title":"Placement of the SSL keys and Certificate's"},{"location":"guides/web/apache-sites-enabled/#the-site-configuration-https","text":"Once you have generated your keys and purchased the SSL certificate, you can now move forward with the configuration of the website using your new keys. For starters, let's break down the beginning of the configuration file. For instance, even though we still want to listen on port 80 (standard http) for incoming requests, we don't want any of those requests to actually go to port 80. We want them to go to port 443 (or http secure, better known as SSL). Our port 80 configuration section will be minimal: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> What this says is to send any regular web request to the https configuration instead. The apache \"Redirect\" option shown above, can be changed to \"Redirect permanent\" once all testing is complete, and you can see that the site operates as you want it to. The \"Redirect\" we have chosen is a temporary redirect. A permanent redirect will be learned by search engines, and soon, any traffic to your site that comes from search engines will go only to port 443 (https) without hitting port 80 (http) first. Next, we need to define the https portion of the configuration file. The http section is duplicated here for clarity to show that this all happens in the same configuration file: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> <Virtual Host *:443> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/com.wiki.www.crt SSLCertificateKeyFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/com.wiki.www.key SSLCertificateChainFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/your_providers_intermediate_certificate.crt <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> So, breaking down this configuration further, after the normal portions of the configuration and down to the SSL portion: SSLEngine on - simply says to use SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - says to use all available protocols, except those that have been found to have vulnerabilities. You should research periodically which protocols are currently acceptable for use. SSLHonorCipherOrder on - this deals with the next line that regarding the cipher suites, and says to deal with them in the order that they are given. This is another area where you should review the cipher suites that you want to include periodically SSLCertificateFile - is exactly what it sounds like, the newly purchased and applied certificate file and its location SSLCertificateKeyFile - the key you generated when creating your certificate signing request SSLCertificateChainFile - the certificate from your certificate provider, often referred to as the intermediate certificate. Next, take everything live and if there are no errors starting the web service and if going to your website reveals HTTPS without errors, then you are ready to go.","title":"The Site Configuration - https"},{"location":"guides/web/apache-sites-enabled/#taking-it-live","text":"Remember that our httpd.conf file is including /etc/httpd/sites-enabled at the very end of the file, so when httpd restarts, it will load whatever configuration files are in that sites-enabled directory. Thing is, all of our configuration files are in sites-available . That's by design, so that we can easily remove things in the event that httpd fails to restart. So to enable our configuration file, we need to create a symbolic link to that file in sites-enabled and then start or restart the web service. To do this, we use this command: ln -s /etc/httpd/sites-available/com.ourownwiki.www /etc/httpd/sites-enabled/ This will create the link to the configuration file in sites-enabled , just like we want. Now just start httpd with systemctl start httpd . Or restart it if it\u2019s already running: systemctl restart httpd , and assuming the web service restarts, you can now go and do some testing on your new site.","title":"Taking It Live"},{"location":"guides/web/mod_SSL_apache/","text":"'mod_ssl' on Rocky Linux in an httpd Apache Web-Server Environment Apache Web-Server has been used for many years now; 'mod_ssl' is used to provide greater security for the Web-Server and can be installed on almost any version of Linux, including Rocky Linux. The installation of 'mod_ssl' will be part of the creation of a Lamp-Server for Rocky Linux. This procedure is designed to get you up and running with Rocky Linux using 'mod_ssl' in an Apache Web-Server environment.. Prerequisites A Workstation or Server, preferably with Rocky Linux already installed. You should be in the Root environment or type sudo before all of the commands you enter. Install Rocky Linux Minimal When installing Rocky Linux, we used the following sets of packages: Minimal Standard Run System Update First, run the system update command to let the server rebuild the repository cache, so that it could recognize the packages available. dnf update Enabling Repositories With a conventional Rocky Linux Server Installation all necessary Repositories should be in place. Check The Available Repositories Just to be sure check your Repository Listing with: dnf repolist You should get the following back showing all of the enabled repositories: appstream Rocky Linux 8 - AppStream baseos Rocky Linux 8 - BaseOS extras Rocky Linux 8 - Extras powertools Rocky Linux 8 - PowerTools Installing Packages To install 'mod_ssl', run: dnf install mod_ssl To enable the 'mod_ssl' module, run: apachectl restart httpd apachectl -M | grep ssl You should see an output as such: ssl_module (shared) Open TCP port 443 To allow incoming traffic with HTTPS, run: firewall-cmd --zone=public --permanent --add-service=https firewall-cmd --reload At this point you should be able to access the Apache Web-Server via HTTPS. Enter https://your-server-ip or https://your-server-hostname to confirm the 'mod_ssl' configuration. Generate SSL Certificate To generate a new self-signed certificate for Host rocky8 with 365 days expiry, run: openssl req -newkey rsa:2048 -nodes -keyout /etc/pki/tls/private/httpd.key -x509 -days 365 -out /etc/pki/tls/certs/httpd.crt You will see the following output: Generating a RSA private key ................+++++ ..........+++++ writing new private key to '/etc/pki/tls/private/httpd.key' ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Country Name (2 letter code) [XX]:AU State or Province Name (full name) []: Locality Name (eg, city) [Default City]: Organization Name (eg, company) [Default Company Ltd]:LinuxConfig.org Organizational Unit Name (eg, section) []: Common Name (eg, your name or your server's hostname) []:rocky8 Email Address []: After this command completes execution, the following two SSL files will be created, run: ls -l /etc/pki/tls/private/httpd.key /etc/pki/tls/certs/httpd.crt -rw-r--r--. 1 root root 1269 Jan 29 16:05 /etc/pki/tls/certs/httpd.crt -rw-------. 1 root root 1704 Jan 29 16:05 /etc/pki/tls/private/httpd.key Configure Apache Web-Server with New SSL Certificates To include your newly created SSL certificate into the Apache web-server configuration open the ssl.conf file by running: nano /etc/httpd/conf.d/ssl.conf Then change the following lines: FROM: SSLCertificateFile /etc/pki/tls/certs/localhost.crt SSLCertificateKeyFile /etc/pki/tls/private/localhost.key TO: SSLCertificateFile /etc/pki/tls/certs/httpd.crt SSLCertificateKeyFile /etc/pki/tls/private/httpd.key Then reload the Apache Web-Server by running: systemctl reload httpd Test the 'mod_ssl' configuration Enter the following in a web browser: https://your-server-ip or https://your-server-hostname To Redirect All HTTP Traffic To HTTPS Create a new file by running: nano /etc/httpd/conf.d/redirect_http.conf Insert the following content and save file, replacing \"your-server-hostname\" with your hostname. <VirtualHost _default_:80> Servername rocky8 Redirect permanent / https://your-server-hostname/ </VirtualHost/> Apply the change when reloading the Apache service by running: systemctl reload httpd The Apache Web-Server will now be configured to redirect any incoming traffic from http://your-server-hostname to https://your-server-hostname URL. Final Steps We have seen how to install and configure 'mod_ssl'. And, create a new SSL Certificate in order to run a Web-Server under HTTPS Service. Conclusion This tutorial will be part of the tutorial covering installing a LAMP (Linux, Apache Web-Server, Maria Database-Server, and PHP Scripting Language), Server on Rocky Linux version 8.x. Eventually we will be including images to help better understand the installation.","title":"Apache With 'mod_ssl'"},{"location":"guides/web/mod_SSL_apache/#mod_ssl-on-rocky-linux-in-an-httpd-apache-web-server-environment","text":"Apache Web-Server has been used for many years now; 'mod_ssl' is used to provide greater security for the Web-Server and can be installed on almost any version of Linux, including Rocky Linux. The installation of 'mod_ssl' will be part of the creation of a Lamp-Server for Rocky Linux. This procedure is designed to get you up and running with Rocky Linux using 'mod_ssl' in an Apache Web-Server environment..","title":"'mod_ssl' on Rocky Linux in an httpd Apache Web-Server Environment"},{"location":"guides/web/mod_SSL_apache/#prerequisites","text":"A Workstation or Server, preferably with Rocky Linux already installed. You should be in the Root environment or type sudo before all of the commands you enter.","title":"Prerequisites"},{"location":"guides/web/mod_SSL_apache/#install-rocky-linux-minimal","text":"When installing Rocky Linux, we used the following sets of packages: Minimal Standard","title":"Install Rocky Linux Minimal"},{"location":"guides/web/mod_SSL_apache/#run-system-update","text":"First, run the system update command to let the server rebuild the repository cache, so that it could recognize the packages available. dnf update","title":"Run System Update"},{"location":"guides/web/mod_SSL_apache/#enabling-repositories","text":"With a conventional Rocky Linux Server Installation all necessary Repositories should be in place.","title":"Enabling Repositories"},{"location":"guides/web/mod_SSL_apache/#check-the-available-repositories","text":"Just to be sure check your Repository Listing with: dnf repolist You should get the following back showing all of the enabled repositories: appstream Rocky Linux 8 - AppStream baseos Rocky Linux 8 - BaseOS extras Rocky Linux 8 - Extras powertools Rocky Linux 8 - PowerTools","title":"Check The Available Repositories"},{"location":"guides/web/mod_SSL_apache/#installing-packages","text":"To install 'mod_ssl', run: dnf install mod_ssl To enable the 'mod_ssl' module, run: apachectl restart httpd apachectl -M | grep ssl You should see an output as such: ssl_module (shared)","title":"Installing Packages"},{"location":"guides/web/mod_SSL_apache/#open-tcp-port-443","text":"To allow incoming traffic with HTTPS, run: firewall-cmd --zone=public --permanent --add-service=https firewall-cmd --reload At this point you should be able to access the Apache Web-Server via HTTPS. Enter https://your-server-ip or https://your-server-hostname to confirm the 'mod_ssl' configuration.","title":"Open TCP port 443"},{"location":"guides/web/mod_SSL_apache/#generate-ssl-certificate","text":"To generate a new self-signed certificate for Host rocky8 with 365 days expiry, run: openssl req -newkey rsa:2048 -nodes -keyout /etc/pki/tls/private/httpd.key -x509 -days 365 -out /etc/pki/tls/certs/httpd.crt You will see the following output: Generating a RSA private key ................+++++ ..........+++++ writing new private key to '/etc/pki/tls/private/httpd.key' ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter '.', the field will be left blank. ----- Country Name (2 letter code) [XX]:AU State or Province Name (full name) []: Locality Name (eg, city) [Default City]: Organization Name (eg, company) [Default Company Ltd]:LinuxConfig.org Organizational Unit Name (eg, section) []: Common Name (eg, your name or your server's hostname) []:rocky8 Email Address []: After this command completes execution, the following two SSL files will be created, run: ls -l /etc/pki/tls/private/httpd.key /etc/pki/tls/certs/httpd.crt -rw-r--r--. 1 root root 1269 Jan 29 16:05 /etc/pki/tls/certs/httpd.crt -rw-------. 1 root root 1704 Jan 29 16:05 /etc/pki/tls/private/httpd.key","title":"Generate SSL Certificate"},{"location":"guides/web/mod_SSL_apache/#configure-apache-web-server-with-new-ssl-certificates","text":"To include your newly created SSL certificate into the Apache web-server configuration open the ssl.conf file by running: nano /etc/httpd/conf.d/ssl.conf Then change the following lines: FROM: SSLCertificateFile /etc/pki/tls/certs/localhost.crt SSLCertificateKeyFile /etc/pki/tls/private/localhost.key TO: SSLCertificateFile /etc/pki/tls/certs/httpd.crt SSLCertificateKeyFile /etc/pki/tls/private/httpd.key Then reload the Apache Web-Server by running: systemctl reload httpd","title":"Configure Apache Web-Server with New SSL Certificates"},{"location":"guides/web/mod_SSL_apache/#test-the-mod_ssl-configuration","text":"Enter the following in a web browser: https://your-server-ip or https://your-server-hostname","title":"Test the 'mod_ssl' configuration"},{"location":"guides/web/mod_SSL_apache/#to-redirect-all-http-traffic-to-https","text":"Create a new file by running: nano /etc/httpd/conf.d/redirect_http.conf Insert the following content and save file, replacing \"your-server-hostname\" with your hostname. <VirtualHost _default_:80> Servername rocky8 Redirect permanent / https://your-server-hostname/ </VirtualHost/> Apply the change when reloading the Apache service by running: systemctl reload httpd The Apache Web-Server will now be configured to redirect any incoming traffic from http://your-server-hostname to https://your-server-hostname URL.","title":"To Redirect All HTTP Traffic To HTTPS"},{"location":"guides/web/mod_SSL_apache/#final-steps","text":"We have seen how to install and configure 'mod_ssl'. And, create a new SSL Certificate in order to run a Web-Server under HTTPS Service.","title":"Final Steps"},{"location":"guides/web/mod_SSL_apache/#conclusion","text":"This tutorial will be part of the tutorial covering installing a LAMP (Linux, Apache Web-Server, Maria Database-Server, and PHP Scripting Language), Server on Rocky Linux version 8.x. Eventually we will be including images to help better understand the installation.","title":"Conclusion"},{"location":"guides/web/nginx-mainline/","tags":["nginx","web"],"text":"How to Install the Latest Nginx on Rocky Linux Introduction Nginx is a web server designed to be fast, efficient, and compatible with just about anything you can imagine. I personally use it a fair bit and\u2014once you get the hang of it\u2014it\u2019s actually pretty easy to set up and configure. To that end, I've written this beginner's guide. Here\u2019s a short rundown of the ways Nginx stands out/features it has: A basic web server (one would hope) A reverse proxy for directing traffic to multiple sites A built-in load balancer for managing traffic to multiple websites Built-in file caching for speed WebSockets FastCGI support And, of course, IPv6 It\u2019s great! So just sudo dnf install nginx , right? Well, not exactly. We just have to enable the right module first, to enable the \"mainline\" branch, so you can have the latest version of Nginx. !!! Note There's another branch called \"stable\", but it's actually a little outdated for most use cases. It will receive no new features as they are developed, and only the most urgently-needed bug fixes and security upgrades. The developers of Nginx consider the \"mainline\" branch to be well-tested and stable for general use, *as it gets all new features, all security fixes, and all bug fixes.* The only reasons to use the \"stable\" branch include: * You *really* want to be sure that new features and big-fixes won't break any third-party code or custom code of your own. * You want to stick with the Rocky Linux software repositories only. There will be a tutorial at the end of this guide detailing how to enable and install the \"stable\" branch with minimal fuss. Prerequisites and Assumptions You\u2019ll need: An internet-connected Rocky Linux machine or server. A basic familiarity with the command line. The ability to run commands as root, either as the root user or with sudo . A text editor of your choice, whether graphical or command-line based. For this tutorial, I\u2019m using nano . Installing the Repository & Enabling the Module First, make sure your machine is updated: sudo dnf update Then, install the epel-release software repository: sudo dnf install epel-release Then enable the right module for the latest version of nginx . This module will always be called nginx:manline , so just enable it with dnf like so: sudo dnf module enable nginx:mainline It'll give you the usual \"Are you sure you want to do that?\", but this isn't 2nd Edition D&D with Gary Gygax himself, so yes. Of course you do. Hit y to confirm. Installing and Running Nginx Then, install the package nginx from the previously added repository: sudo dnf install nginx The terminal will ask you if you\u2019re fine with installing the repository\u2019s GPG key. You need that, so choose Y for yes. Once the installation is done, start the nginx service and enable it to automatically start on reboot all in one go with: sudo systemctl enable --now nginx To verify that the lastest version of Nginx has been installed, run: nginx -v From there, you could just start dropping HTML files into the /usr/share/nginx/html/ directory to build a simple, static website. The configuration file for the default website/virtual host is called \u201cnginx.conf\u201d and it\u2019s in /etc/nginx/ . It also holds a number of other basic Nginx server configurations, so even if you choose to move the actual website config to another file, you should probably leave the rest of \"nginx.conf\" intact. Configuring the Firewall !!! Note If you are installing Nginx on a container such as LXD/LXC or Docker, you can just skip this part for now. The firewall should be handled by the host OS. If you try to view a web page at your machine\u2019s IP address or domain name from another computer, you\u2019re probably going to get a big fat nothing. Well, that\u2019ll be the case as long as you have a firewall up and running. To open up the necessary ports so that you can actually \"see\" your web pages, we will use Rocky Linux's build-in firewall, firewalld . The firewalld command for doing this is firewall-cmd . There are two ways to do it: the official way, and the manual way. In this instance, the official way is best, but you should know both for future reference. The official way opens up the firewall to the http service, which is of course the service that handles web pages. Just run this: sudo firewall-cmd --permanent --zone=public --add-service=http Let\u2019s break this down: The -\u2013permanent flag tells the firewall to make sure this configuration is used every time the firewall is restarted, and when the server itself is restarted. \u2013-zone=public tells the firewall to take incoming connections to this port from everyone. Lastly, --add-service=http tells firewalld to let all HTTP traffic through to the server. Now here's the manual way to do it. It's pretty much the same, except you're specifically opening up port 80, which is what the HTTP uses. sudo firewall-cmd --permanent --zone=public --add-port=80/tcp \u2013-add-port=80/tcp tells the firewall to accept incoming connections over port 80, as long as they\u2019re using the Transmission Control Protocol, which is what you want in this case. To repeat the process for SSL/HTTPS traffic, just run the command again, and change the service and/or the port number. sudo firewall-cmd --permanent --zone=public --add-service=https # Or, in some other cases: sudo firewall-cmd --permanent --zone=public --add-port=443/tcp These configurations won\u2019t take effect until you force the issue. To do that, tell firewalld to relead its configurations, like so: sudo firewall-cmd --reload !!! Note Now, there\u2019s a very small chance that this won\u2019t work. In those rare cases, make `firewalld` do your bidding with the old turn-it-off-and-turn-it-on-again. ```bash systemctl restart firewalld ``` To make sure the ports have been added properly, run firewall-cmd --list-all . A properly-configured firewall will look a bit like this: public (active) target: default icmp-block-inversion: no interfaces: enp9s0 sources: services: cockpit dhcpv6-client ssh http https ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: And that should be everything you need, firewall-wise. Now you should be able to see a web page that looks something like this: It\u2019s not much at all, but it means the server is working. You can also test that your web page is working from the command line with: curl -I http://[your-ip-address] Creating a Server User and Changing the Website Root Folder While you can just drop your website into the default directory and go (and this might be fine for Nginx when it\u2019s running inside a container, or on a test/development server), it\u2019s not what we call best practice. Instead, it\u2019s a good idea to create a specific Linux user on your system for your website, and put your website files in a directory made just for that user. If you want to build multiple websites, it\u2019s actually a good idea to create multiple users and root directories, both for the sake of organization and the sake of security. In this guide, I\u2019m going to have just the one user: a handsome devil named \u201cwww\u201d. Deciding where to put your website files gets more complicated. Depending on your server setup, you can put your website files in a couple of different places. If you're on a bare-metal (physical) server, or you're installing nginx directly on a VPS, you probably have Security Enhanced Linux (SELinux) running. SELinux is a tool that does a lot to protect your machine, but it also kind of dictates where you can put certain things, like web pages. So if you're installing nginx directly to your machine, then you'll want to put your websites in subdirectories of the default root folder. In this case, the default root is /usr/share/nginx/html , so the website for the \u201cwww\u201d user might go into /usr/share/nginx/html/www . If you're running nginx in a container such as LXD/LXC, however, SELinux will likely not be installed, and you can put your files wherever you like. In this case, I like to put all of a user's website files under a directory in a normal home folder, like so: /home/www/ . I'll continue this guide as though SELinux is installed, though. Just change what you need to based on your use case. You can also learn more about how SELinux works in our guide on the subject . Creating the User First, we make the folder we\u2019re going to use: sudo mkdir /usr/share/nginx/html/www Next, create the www group: sudo groupadd www Then, we create the user: sudo adduser -G nginx -g www -d /usr/share/nginx/html/www www --system --shell=/bin/false That command tells the machine to: Make a user called \u201cwww\u201d (as per the middle bit of text), put all of its files in /usr/share/nginx/html/www , and add it to the following groups: \u201cnginx\u201d as supplemental , \u201cwww\u201d as primary. The --system flag says that the user is not a human user, it's reserved for the system. If you want to create human user accounts to manage different websites, that's a whole other guide. --shell=/bin/false makes sure no one can even try to log in as the \u201cwww\u201d user. The \u201cnginx\u201d group does some real magic. It allows the web server to read and modify files that belong to the \u201cwww\u201d user, and the \u201cwww\u201d user group. See the Rocky Linux guide to user management for more information. Changing the Server Root Folder Now that you have your fancy new user account, it\u2019s time to make nginx look for your website files in that folder. Grab your favorite text editor again. For now, just run: sudo nano /etc/nginx/conf.d/default.conf When the file is open, look for the line that looks like root /usr/share/nginx/html; . Change it to your chosen website root folder, eg. root /usr/share/nginx/html/www; (or /home/www if you're running nginx in containers like I do). Save and close the file, then test your nginx configuration to make sure you didn\u2019t skip a semi-colon or anything: nginx -t If you get the following success message, everything went right: nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful Then, give the server a soft restart with: sudo systemctl reload nginx !!! Note In the unlikely event that the soft restart doesn\u2019t work, give `nginx` a kick in the pants with: ```bash sudo systemctl restart nginx ``` Any HTML files in your new root folder should now be browsable from\u2026 your browser. Changing File Permissions To make sure that nginx can read, write to, and execute any files in the website directory, permissions need to be set properly. First, make sure that all files in the root folder are owned by the server user and its user group with: sudo chown -R www:www /usr/share/nginx/html/www And then, to make sure that users who want to actually browse your website can actually see the pages, you should run these commands (and yes, those semicolons matter): sudo find /usr/share/nginx/html/www -type d -exec chmod 555 \"{}\" \\; sudo find /usr/share/nginx/html/www -type f -exec chmod 444 \"{}\" \\; That basically gives everyone the right to look at files on the server, but not modify them. Only the root and server users get to do that. Getting SSL Certificates for Your Site As of now, our guide to getting SSL certificates with certbot has been updated with some basic instructions for nginx . Go give that a look, as it has full instructions for installing certbot, as well as generating the certificates. The time is coming when browsers might just stop letting people see sites without certificates at all, so make sure you get one for every site. Additional Configuration Options and Guides If you want to see how to make Nginx work with PHP, and PHP-FPM specifically, check out our guide to PHP on Rocky Linux . If you want to learn how to set up Nginx for multiple websites, we now have a guide on just that subject . Installing the Stable Branch From Rocky's Own Repos If you want to use the \u201cstable\u201d branch of nginx , even with its limitations, here's how you do it. First, make sure your OS is updated: sudo dnf update Then, look for the latest nginx version available in the default repos with: sudo dnf module list nginx That should get you a list that looks like this: Rocky Linux 8 - AppStream Name Stream Profiles Summary nginx 1.14 [d] common [d] nginx webserver nginx 1.16 common [d] nginx webserver nginx 1.18 common [d] nginx webserver nginx 1.20 common [d] nginx webserver Choose the highest number on the list, and enable its module like so: sudo dnf module enable nginx:1.20 You'll be asked if you're sure you want to do this, so just choose Y as usual. Then, use the default command to install nginx : sudo dnf install nginx Then you can enable the service and configure your server as detailed above. !!! Note The default configuration file, in this case, is in the base `nginx` configuration folder at `/etc/nginx/nginx.conf`. The root website folder is the same, though. SELinux rules Beware that when enforced, nginx proxy_pass directives will fail with \"502 Bad Gateway\" You can either disable setenforce for development purposes sudo setenforce 0 or you can enable http_d or other services that related to nginx in /var/log/audit/audit.log sudo setsebool httpd_can_network_connect 1 -P Conclusion The basic installation and configuration of nginx are easy, even if it\u2019s more complicated than it should be to get the latest version. But, just follow the steps, and you\u2019ll have one of the best server options out there up and running quickly. Now you just have to go and build yourself a website? What could that take, another ten minutes? Sobs quietly in Web Designer","title":"Nginx"},{"location":"guides/web/nginx-mainline/#how-to-install-the-latest-nginx-on-rocky-linux","text":"","title":"How to Install the Latest Nginx on Rocky Linux"},{"location":"guides/web/nginx-mainline/#introduction","text":"Nginx is a web server designed to be fast, efficient, and compatible with just about anything you can imagine. I personally use it a fair bit and\u2014once you get the hang of it\u2014it\u2019s actually pretty easy to set up and configure. To that end, I've written this beginner's guide. Here\u2019s a short rundown of the ways Nginx stands out/features it has: A basic web server (one would hope) A reverse proxy for directing traffic to multiple sites A built-in load balancer for managing traffic to multiple websites Built-in file caching for speed WebSockets FastCGI support And, of course, IPv6 It\u2019s great! So just sudo dnf install nginx , right? Well, not exactly. We just have to enable the right module first, to enable the \"mainline\" branch, so you can have the latest version of Nginx. !!! Note There's another branch called \"stable\", but it's actually a little outdated for most use cases. It will receive no new features as they are developed, and only the most urgently-needed bug fixes and security upgrades. The developers of Nginx consider the \"mainline\" branch to be well-tested and stable for general use, *as it gets all new features, all security fixes, and all bug fixes.* The only reasons to use the \"stable\" branch include: * You *really* want to be sure that new features and big-fixes won't break any third-party code or custom code of your own. * You want to stick with the Rocky Linux software repositories only. There will be a tutorial at the end of this guide detailing how to enable and install the \"stable\" branch with minimal fuss.","title":"Introduction"},{"location":"guides/web/nginx-mainline/#prerequisites-and-assumptions","text":"You\u2019ll need: An internet-connected Rocky Linux machine or server. A basic familiarity with the command line. The ability to run commands as root, either as the root user or with sudo . A text editor of your choice, whether graphical or command-line based. For this tutorial, I\u2019m using nano .","title":"Prerequisites and Assumptions"},{"location":"guides/web/nginx-mainline/#installing-the-repository-enabling-the-module","text":"First, make sure your machine is updated: sudo dnf update Then, install the epel-release software repository: sudo dnf install epel-release Then enable the right module for the latest version of nginx . This module will always be called nginx:manline , so just enable it with dnf like so: sudo dnf module enable nginx:mainline It'll give you the usual \"Are you sure you want to do that?\", but this isn't 2nd Edition D&D with Gary Gygax himself, so yes. Of course you do. Hit y to confirm.","title":"Installing the Repository &amp; Enabling the Module"},{"location":"guides/web/nginx-mainline/#installing-and-running-nginx","text":"Then, install the package nginx from the previously added repository: sudo dnf install nginx The terminal will ask you if you\u2019re fine with installing the repository\u2019s GPG key. You need that, so choose Y for yes. Once the installation is done, start the nginx service and enable it to automatically start on reboot all in one go with: sudo systemctl enable --now nginx To verify that the lastest version of Nginx has been installed, run: nginx -v From there, you could just start dropping HTML files into the /usr/share/nginx/html/ directory to build a simple, static website. The configuration file for the default website/virtual host is called \u201cnginx.conf\u201d and it\u2019s in /etc/nginx/ . It also holds a number of other basic Nginx server configurations, so even if you choose to move the actual website config to another file, you should probably leave the rest of \"nginx.conf\" intact.","title":"Installing and Running Nginx"},{"location":"guides/web/nginx-mainline/#configuring-the-firewall","text":"!!! Note If you are installing Nginx on a container such as LXD/LXC or Docker, you can just skip this part for now. The firewall should be handled by the host OS. If you try to view a web page at your machine\u2019s IP address or domain name from another computer, you\u2019re probably going to get a big fat nothing. Well, that\u2019ll be the case as long as you have a firewall up and running. To open up the necessary ports so that you can actually \"see\" your web pages, we will use Rocky Linux's build-in firewall, firewalld . The firewalld command for doing this is firewall-cmd . There are two ways to do it: the official way, and the manual way. In this instance, the official way is best, but you should know both for future reference. The official way opens up the firewall to the http service, which is of course the service that handles web pages. Just run this: sudo firewall-cmd --permanent --zone=public --add-service=http Let\u2019s break this down: The -\u2013permanent flag tells the firewall to make sure this configuration is used every time the firewall is restarted, and when the server itself is restarted. \u2013-zone=public tells the firewall to take incoming connections to this port from everyone. Lastly, --add-service=http tells firewalld to let all HTTP traffic through to the server. Now here's the manual way to do it. It's pretty much the same, except you're specifically opening up port 80, which is what the HTTP uses. sudo firewall-cmd --permanent --zone=public --add-port=80/tcp \u2013-add-port=80/tcp tells the firewall to accept incoming connections over port 80, as long as they\u2019re using the Transmission Control Protocol, which is what you want in this case. To repeat the process for SSL/HTTPS traffic, just run the command again, and change the service and/or the port number. sudo firewall-cmd --permanent --zone=public --add-service=https # Or, in some other cases: sudo firewall-cmd --permanent --zone=public --add-port=443/tcp These configurations won\u2019t take effect until you force the issue. To do that, tell firewalld to relead its configurations, like so: sudo firewall-cmd --reload !!! Note Now, there\u2019s a very small chance that this won\u2019t work. In those rare cases, make `firewalld` do your bidding with the old turn-it-off-and-turn-it-on-again. ```bash systemctl restart firewalld ``` To make sure the ports have been added properly, run firewall-cmd --list-all . A properly-configured firewall will look a bit like this: public (active) target: default icmp-block-inversion: no interfaces: enp9s0 sources: services: cockpit dhcpv6-client ssh http https ports: protocols: forward: no masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: And that should be everything you need, firewall-wise. Now you should be able to see a web page that looks something like this: It\u2019s not much at all, but it means the server is working. You can also test that your web page is working from the command line with: curl -I http://[your-ip-address]","title":"Configuring the Firewall"},{"location":"guides/web/nginx-mainline/#creating-a-server-user-and-changing-the-website-root-folder","text":"While you can just drop your website into the default directory and go (and this might be fine for Nginx when it\u2019s running inside a container, or on a test/development server), it\u2019s not what we call best practice. Instead, it\u2019s a good idea to create a specific Linux user on your system for your website, and put your website files in a directory made just for that user. If you want to build multiple websites, it\u2019s actually a good idea to create multiple users and root directories, both for the sake of organization and the sake of security. In this guide, I\u2019m going to have just the one user: a handsome devil named \u201cwww\u201d. Deciding where to put your website files gets more complicated. Depending on your server setup, you can put your website files in a couple of different places. If you're on a bare-metal (physical) server, or you're installing nginx directly on a VPS, you probably have Security Enhanced Linux (SELinux) running. SELinux is a tool that does a lot to protect your machine, but it also kind of dictates where you can put certain things, like web pages. So if you're installing nginx directly to your machine, then you'll want to put your websites in subdirectories of the default root folder. In this case, the default root is /usr/share/nginx/html , so the website for the \u201cwww\u201d user might go into /usr/share/nginx/html/www . If you're running nginx in a container such as LXD/LXC, however, SELinux will likely not be installed, and you can put your files wherever you like. In this case, I like to put all of a user's website files under a directory in a normal home folder, like so: /home/www/ . I'll continue this guide as though SELinux is installed, though. Just change what you need to based on your use case. You can also learn more about how SELinux works in our guide on the subject .","title":"Creating a Server User and Changing the Website Root Folder"},{"location":"guides/web/nginx-mainline/#creating-the-user","text":"First, we make the folder we\u2019re going to use: sudo mkdir /usr/share/nginx/html/www Next, create the www group: sudo groupadd www Then, we create the user: sudo adduser -G nginx -g www -d /usr/share/nginx/html/www www --system --shell=/bin/false That command tells the machine to: Make a user called \u201cwww\u201d (as per the middle bit of text), put all of its files in /usr/share/nginx/html/www , and add it to the following groups: \u201cnginx\u201d as supplemental , \u201cwww\u201d as primary. The --system flag says that the user is not a human user, it's reserved for the system. If you want to create human user accounts to manage different websites, that's a whole other guide. --shell=/bin/false makes sure no one can even try to log in as the \u201cwww\u201d user. The \u201cnginx\u201d group does some real magic. It allows the web server to read and modify files that belong to the \u201cwww\u201d user, and the \u201cwww\u201d user group. See the Rocky Linux guide to user management for more information.","title":"Creating the User"},{"location":"guides/web/nginx-mainline/#changing-the-server-root-folder","text":"Now that you have your fancy new user account, it\u2019s time to make nginx look for your website files in that folder. Grab your favorite text editor again. For now, just run: sudo nano /etc/nginx/conf.d/default.conf When the file is open, look for the line that looks like root /usr/share/nginx/html; . Change it to your chosen website root folder, eg. root /usr/share/nginx/html/www; (or /home/www if you're running nginx in containers like I do). Save and close the file, then test your nginx configuration to make sure you didn\u2019t skip a semi-colon or anything: nginx -t If you get the following success message, everything went right: nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful Then, give the server a soft restart with: sudo systemctl reload nginx !!! Note In the unlikely event that the soft restart doesn\u2019t work, give `nginx` a kick in the pants with: ```bash sudo systemctl restart nginx ``` Any HTML files in your new root folder should now be browsable from\u2026 your browser.","title":"Changing the Server Root Folder"},{"location":"guides/web/nginx-mainline/#changing-file-permissions","text":"To make sure that nginx can read, write to, and execute any files in the website directory, permissions need to be set properly. First, make sure that all files in the root folder are owned by the server user and its user group with: sudo chown -R www:www /usr/share/nginx/html/www And then, to make sure that users who want to actually browse your website can actually see the pages, you should run these commands (and yes, those semicolons matter): sudo find /usr/share/nginx/html/www -type d -exec chmod 555 \"{}\" \\; sudo find /usr/share/nginx/html/www -type f -exec chmod 444 \"{}\" \\; That basically gives everyone the right to look at files on the server, but not modify them. Only the root and server users get to do that.","title":"Changing File Permissions"},{"location":"guides/web/nginx-mainline/#getting-ssl-certificates-for-your-site","text":"As of now, our guide to getting SSL certificates with certbot has been updated with some basic instructions for nginx . Go give that a look, as it has full instructions for installing certbot, as well as generating the certificates. The time is coming when browsers might just stop letting people see sites without certificates at all, so make sure you get one for every site.","title":"Getting SSL Certificates for Your Site"},{"location":"guides/web/nginx-mainline/#additional-configuration-options-and-guides","text":"If you want to see how to make Nginx work with PHP, and PHP-FPM specifically, check out our guide to PHP on Rocky Linux . If you want to learn how to set up Nginx for multiple websites, we now have a guide on just that subject .","title":"Additional Configuration Options and Guides"},{"location":"guides/web/nginx-mainline/#installing-the-stable-branch-from-rockys-own-repos","text":"If you want to use the \u201cstable\u201d branch of nginx , even with its limitations, here's how you do it. First, make sure your OS is updated: sudo dnf update Then, look for the latest nginx version available in the default repos with: sudo dnf module list nginx That should get you a list that looks like this: Rocky Linux 8 - AppStream Name Stream Profiles Summary nginx 1.14 [d] common [d] nginx webserver nginx 1.16 common [d] nginx webserver nginx 1.18 common [d] nginx webserver nginx 1.20 common [d] nginx webserver Choose the highest number on the list, and enable its module like so: sudo dnf module enable nginx:1.20 You'll be asked if you're sure you want to do this, so just choose Y as usual. Then, use the default command to install nginx : sudo dnf install nginx Then you can enable the service and configure your server as detailed above. !!! Note The default configuration file, in this case, is in the base `nginx` configuration folder at `/etc/nginx/nginx.conf`. The root website folder is the same, though.","title":"Installing the Stable Branch From Rocky's Own Repos"},{"location":"guides/web/nginx-mainline/#selinux-rules","text":"Beware that when enforced, nginx proxy_pass directives will fail with \"502 Bad Gateway\" You can either disable setenforce for development purposes sudo setenforce 0 or you can enable http_d or other services that related to nginx in /var/log/audit/audit.log sudo setsebool httpd_can_network_connect 1 -P","title":"SELinux rules"},{"location":"guides/web/nginx-mainline/#conclusion","text":"The basic installation and configuration of nginx are easy, even if it\u2019s more complicated than it should be to get the latest version. But, just follow the steps, and you\u2019ll have one of the best server options out there up and running quickly. Now you just have to go and build yourself a website? What could that take, another ten minutes? Sobs quietly in Web Designer","title":"Conclusion"},{"location":"guides/web/nginx-multisite/","tags":["web","nginx","multisite"],"text":"How to Set up Nginx for Multiple Websites on Rocky Linux Introduction Here it is, my promised guide to Nginx multisite setups on Rocky Linux. I'm going to start off with a note for beginners; the rest of you know what you're here for, so scroll on down. Hi Newbies! One of the things that Nginx does very well is direct traffic from one central point to multiple websites and apps on one server, or on several other servers. This feature is called a \"reverse proxy\", and the relative ease with which Nginx does this is one of the reasons I started using it. Here I'll be showing you how to manage multiple websites on a single Nginx installation, and how to do it in a simple and organized way that will let you make changes quickly and easily. For those looking for a similar setup for Apache, take a look at this guide. I'll be explaining a lot of details... but in the end, the whole process basically involves setting up some folders, and making some small text files. We won't be using overly-complicated website configurations for this guide, so relax with a coffee and have some fun. Once you know how to do it, it'll only take minutes to do every time. This one's easy.* * For given values of \"easy\". Prerequisites and Assumptions This is everything you'll need: A Rocky Linux server connected to the internet, with Nginx already running on it. If you haven't gotten that far, you can follow our guide to installing Nginx first. Some comfort with doing things on the command line, and a terminal-based text editor like nano installed. !!! hint \"In a pinch\" ... you could use something like Filezilla or WinSCP \u2014 and a regular GUI-based text editor \u2014 to replicate most of these steps, but we'll be doing things the nerdy way in this tutorial. At least one domain pointed at your server for one of the test websites. You can use either a second domain or a subdomain for the other. !!! hint If you're doing all of this on a local server, adjust your hosts file as necessary to create simulated domain names. Instructions below. We are assuming that you're running Nginx on a bare metal server or regular VPS, and that SELinux is running. All instructions will be compatible with SELinux by default. All commands must be run as root, either by logging in as the root user, or using sudo . Setting up Your Folders and Test Sites The website folders First, you're going to need a couple of folders for your website files. When you first install Nginx, all of the \"demo\" website files will be in /usr/share/nginx/html . That's fine if you're hosting just the one site, but we're going to get fancy. Ignore the html directory for now, and just navigate its parent folder: cd /usr/share/nginx The test domains for the sake of this tutorial will be site1.server.test and site2.server.test , and we're going to name those website folders accordingly. You should change those domains to whatever you're using, of course. However (and here's a trick I picked up from Smarter People TM ), we're going to write the domain names \"backwards\". eg. \"yourwebsite.com\" would go in a folder called com.yourwebsite . Mind you, you can literally name these folders whatever you want, but there's a good reason for this method, which I've outlined below. For now, just make your folders: mkdir -p test.server.site1/html mkdir -p test.server.site2/html So that command will make, for example, the test.server.site1 folder, and put another folder called html inside of it. That is where you're going to put the actual files you want to serve via the web server. (You could also call it \"webroot\" or something like that.) This is so you can put website-related files that you don't want to make public in the parent directory, while still keeping everything in one place. !!! Note The `-p` flag tells the `mkdir` command to create any missing folders in the path you just defined, so you don't have to make each folder one at a time. For this test, we're keeping the \"websites\" themselves very simple. Just make an HTML file in the first folder with your favorite text editor: nano test.server.site1/html/index.html Then paste in the following bit of HTML: <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"> <title>Site 1</title> </head> <body> <h1>This is Site 1</h1> </body> </html> Save and close your file, then repeat the steps with the test.server.site2 folder, changing \"Site 1\" to \"Site 2\" in the HTML code above. This is just so we can be sure everything is working as intended later on. Your test websites are done, let's move on. The configuration folders Now let's go to the Nginx settings and configuration folder, which is where we'll be working for the rest of this guide: cd /etc/nginx/ If you run the ls command to see what files and folders are in here, you'll see a bunch of different things, most of which are irrelevant today. The ones to note are these: nginx.conf is the file that contains, you guessed it, the default Nginx configuration. We'll be editing that later. conf.d is a directory where you can put custom configuration files. You could use this for websites, but it's better to use it for feature-specific settings that you want on all of your websites. default.d is a directory where your website config might go if you were only running one site on the server, or if your server has a \"primary\" website. Leave it alone for now. We want to create two new folders called sites-available and sites-enabled : mkdir sites-available mkdir sites-enabled What we're going to do is put all of our website configuration files in the sites-available folder. There, you can work on the configuration files as long as you need to, until you're ready to activate the files with a symbolic link to the sites-enabled folder. I'll show you how that works below. For now, we're done with making folders. !!! Note \"Why you (might) want to write your domains backwards:\" Simply put, it's an organizational thing that's especially useful when using the command line with tab completion, but still pretty useful in GUI-based apps. It's designed for people who are running a *lot* of websites or apps on a server. Basically, all of your website folders (and configuration files) will get organized alphabetically; by the top level domain first (eg. .com, .org, etc), then the primary domain, and then by any subdomains. When you're searching through a long list of domains, it can be easier to narrow down what you're looking for this way. It also makes it easier to sort out your folders and config files via command line tools. To list all folders associated with a particular domain, you might run: ```bash ls /usr/share/nginx/ | grep com.yoursite* ``` Which would output something like: ``` com.yoursite.site1 com.yoursite.site2 com.yoursite.site3 ``` Setting up Your Configuration Files Editing nginx.conf By default, Rocky Linux's implementation of Nginx is open to all HTTP traffic, and directs it all to the demo page you might have seen in our guide to installing Nginx. We don't want that. We want traffic from the domains we specify to go to the websites we specify. So from the /etc/nginx/ directory, open up nginx.conf in your favorite text editor: nano nginx.conf First, find the line that looks like this: include /etc/nginx/conf.d/*.conf; And add this bit just below it: include /etc/nginx/sites-enabled/*.conf; That will load in our website configuration files when they're ready to go live. Now head down to the section that looks like this, and either comment it out with the hash sign # , or delete it if you feel so inclined: server { listen 80; listen [::]:80; server_name _; root /usr/share/nginx/www/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; error_page 404 /404.html; location = /404.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } What that would look like \"commented out\": #server { # listen 80; # listen [::]:80; # server_name _; # root /usr/share/nginx/www/html; # # # Load configuration files for the default server block. # include /etc/nginx/default.d/*.conf; # # error_page 404 /404.html; # location = /404.html { # } # # error_page 500 502 503 504 /50x.html; # location = /50x.html { # } #} If you're a beginner, you might want to keep the commented code around for reference, and that goes for the example HTTPS code that's already commented out further down in the file. Save and close the file, then restart the server with: systemctl restart nginx Now no one will see the demo page, at least. Adding the website configuration files Now let's make your test websites available on the server. As previously mentioned, we're going to to this with symbolic links so we have an easy way of turning the websites on and off at will. !!! Note For absolute newbies, symbolic links are basically a way of letting files pretend to be in two folders at once. Change the original file (or \"target\"), and it's changed everywhere that you've linked to it. If you use a program to edit the file via a link, the original gets changed. However, if you delete a link to the target, nothing at all happens to the original file. This trick is what allows us to put the website configuration files in a working directory (`sites-available`), and then \"activate\" them by linking to those files from `sites-enabled`. I'll show you what I mean. Make a configuration file for the first website like so: nano sites-available/test.server.site1.conf Now paste in this code. This is about the simplest working Nginx configuration you can have, and should work fine for most static HTML websites: server { listen 80; listen [::]:80; # virtual server name i.e. domain name # server_name site1.server.test; # document root # root /usr/share/nginx/test.server.site1/html; # log files access_log /var/log/nginx/www_access.log; error_log /var/log/nginx/www_error.log; # Directives to send expires headers and turn off 404 error logging. # location ~* ^.+\\.(ogg|ogv|svg|svgz|eot|otf|woff|mp4|ttf|rss|atom|jpg|jpeg|gif|png|ico|zip|tgz|gz|rar|bz2|doc|xls|exe|ppt|tar|mid|midi|wav|bmp|rtf)$ { access_log off; log_not_found off; expires max; } } And heck, everything from the document root on down is technically optional. Useful and recommended, but not strictly required for the website to function. Anyway, save and close the file, then go into sites-enabled directory: cd sites-enabled Now, create a symbolic link to the configuration file you just made in the sites-available folder.: ln -s ../sites-available/test.server.site1.conf Test your configuration with the nginx -t command, and if you get a message saying everything is okay, reload the server: systemctl restart nginx Then point your browser at the domain you're using for this first site (in my case: site1.server.test), and look for that \"This is Site 1\" message we put in the HTML file. If you have curl installed on your system, you could run curl site1.server.test and see if the HTML code loads in your terminal. !!! Note Some browsers will (with all the best intentions) force you to use HTTPS when you type your server domain into the address bar. If you don't have HTTPS configured, that'll just throw errors at you. Make sure to manually specify \"http://\" in your browser address bar to avoid this issue. If that doesn't work, clear the cache, or use a less picky browser for this part of the testing. I recommend [Min](https://minbrowser.org). If all of that goes right, repeat the steps above, changing the names of the files and the content of the configuration files as you go. \"site1\" to \"site2\" and all of that. Once you have configuration files and symbolic links for both Site 1 and Site 2, and have restarted Nginx, it should look like this: !!! Note You can also create links from outside of the sites-enabled directory with the long form of the `ln -s` command. It would look like `ln -s [source-file] [link]`. In this context, that's: ```bash ln -s /etc/nginx/sites-available/test.server.site1.conf /etc/nginx/sites-enabled/test.server.site1.conf ``` Disabling a website If you need to stop one of your websites to work on it before taking it live again, just delete the symbolic link in sites-enabled: rm /etc/nginx/sites-enabled/test.server.site1.conf Then restart Nginx as usual. To take the site back online, you'll need to re-create the symbolic link, and restart Nginx again. Optional: Editing Your Hosts File This part's definitely for beginners. Everyone else can probably skip. So this section only applies if you're trying out this guide in a local development environment. That is, if you're running your test server on your workstation, or on another machine in your local home or business network. Since pointing external domains at your local machines is a hassle (and potentially dangerous if you don't know what you're doing), you can set up some \"fake\" domains that will work just fine on your local network, and nowhere else. The easiest way to do this is with the hosts file on your computer. The hosts file is literally just a text file that can override DNS settings. As in, you can manually specify a domain name to go with any IP address you want. It'll only work on that one computer, though. So on Mac and Linux, the hosts file is in the /etc/ directory, and can be edited via the command line super easily (you'll need root access). Assuming you're working on a Rocky Linux workstation, just run: nano /etc/hosts On Windows, the hosts file is located at C:\\Windows\\system32\\drivers\\etc\\hosts , and you can just use whatever GUI text editor you want as long as you have Admin access. So if you're working on a Rocky Linux computer, and are running your Nginx server on the same machine, you'd just open up the file, and define the domains/IP addresses you want. If you're running your workstation and test server on the same machine, that'd be: 127.0.0.1 site1.server.test 127.0.0.1 site2.server.test If you're running your Nginx server on another machine on the network, just use the address of that machine, eg.: 192.168.0.45 site1.server.test 192.168.0.45 site2.server.test Then you'll be able to point your browser to those domains and it should work as intended. Setting Up SSL Certificates for Your Sites Go check out our guide to getting SSL certificates with Let's Encrypt and certbot . The instructions there will work just fine. Conclusion Remember, most of the folder/file organization and naming conventions here are technically optional. Your website configuration files mostly just have to go anywhere inside /etc/nginx/ and nginx.conf needs to know where those files are. The actual website files should be somewhere in /usr/share/nginx/ , and the rest is gravy. Try it out, do some Science TM , and don't forget to run nginx -t before you restart Nginx to make sure you didn't miss a semi-colon or anything. It'll save you a lot of time.","title":"Nginx Multisite"},{"location":"guides/web/nginx-multisite/#how-to-set-up-nginx-for-multiple-websites-on-rocky-linux","text":"","title":"How to Set up Nginx for Multiple Websites on Rocky Linux"},{"location":"guides/web/nginx-multisite/#introduction","text":"Here it is, my promised guide to Nginx multisite setups on Rocky Linux. I'm going to start off with a note for beginners; the rest of you know what you're here for, so scroll on down. Hi Newbies! One of the things that Nginx does very well is direct traffic from one central point to multiple websites and apps on one server, or on several other servers. This feature is called a \"reverse proxy\", and the relative ease with which Nginx does this is one of the reasons I started using it. Here I'll be showing you how to manage multiple websites on a single Nginx installation, and how to do it in a simple and organized way that will let you make changes quickly and easily. For those looking for a similar setup for Apache, take a look at this guide. I'll be explaining a lot of details... but in the end, the whole process basically involves setting up some folders, and making some small text files. We won't be using overly-complicated website configurations for this guide, so relax with a coffee and have some fun. Once you know how to do it, it'll only take minutes to do every time. This one's easy.* * For given values of \"easy\".","title":"Introduction"},{"location":"guides/web/nginx-multisite/#prerequisites-and-assumptions","text":"This is everything you'll need: A Rocky Linux server connected to the internet, with Nginx already running on it. If you haven't gotten that far, you can follow our guide to installing Nginx first. Some comfort with doing things on the command line, and a terminal-based text editor like nano installed. !!! hint \"In a pinch\" ... you could use something like Filezilla or WinSCP \u2014 and a regular GUI-based text editor \u2014 to replicate most of these steps, but we'll be doing things the nerdy way in this tutorial. At least one domain pointed at your server for one of the test websites. You can use either a second domain or a subdomain for the other. !!! hint If you're doing all of this on a local server, adjust your hosts file as necessary to create simulated domain names. Instructions below. We are assuming that you're running Nginx on a bare metal server or regular VPS, and that SELinux is running. All instructions will be compatible with SELinux by default. All commands must be run as root, either by logging in as the root user, or using sudo .","title":"Prerequisites and Assumptions"},{"location":"guides/web/nginx-multisite/#setting-up-your-folders-and-test-sites","text":"","title":"Setting up Your Folders and Test Sites"},{"location":"guides/web/nginx-multisite/#the-website-folders","text":"First, you're going to need a couple of folders for your website files. When you first install Nginx, all of the \"demo\" website files will be in /usr/share/nginx/html . That's fine if you're hosting just the one site, but we're going to get fancy. Ignore the html directory for now, and just navigate its parent folder: cd /usr/share/nginx The test domains for the sake of this tutorial will be site1.server.test and site2.server.test , and we're going to name those website folders accordingly. You should change those domains to whatever you're using, of course. However (and here's a trick I picked up from Smarter People TM ), we're going to write the domain names \"backwards\". eg. \"yourwebsite.com\" would go in a folder called com.yourwebsite . Mind you, you can literally name these folders whatever you want, but there's a good reason for this method, which I've outlined below. For now, just make your folders: mkdir -p test.server.site1/html mkdir -p test.server.site2/html So that command will make, for example, the test.server.site1 folder, and put another folder called html inside of it. That is where you're going to put the actual files you want to serve via the web server. (You could also call it \"webroot\" or something like that.) This is so you can put website-related files that you don't want to make public in the parent directory, while still keeping everything in one place. !!! Note The `-p` flag tells the `mkdir` command to create any missing folders in the path you just defined, so you don't have to make each folder one at a time. For this test, we're keeping the \"websites\" themselves very simple. Just make an HTML file in the first folder with your favorite text editor: nano test.server.site1/html/index.html Then paste in the following bit of HTML: <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"> <title>Site 1</title> </head> <body> <h1>This is Site 1</h1> </body> </html> Save and close your file, then repeat the steps with the test.server.site2 folder, changing \"Site 1\" to \"Site 2\" in the HTML code above. This is just so we can be sure everything is working as intended later on. Your test websites are done, let's move on.","title":"The website folders"},{"location":"guides/web/nginx-multisite/#the-configuration-folders","text":"Now let's go to the Nginx settings and configuration folder, which is where we'll be working for the rest of this guide: cd /etc/nginx/ If you run the ls command to see what files and folders are in here, you'll see a bunch of different things, most of which are irrelevant today. The ones to note are these: nginx.conf is the file that contains, you guessed it, the default Nginx configuration. We'll be editing that later. conf.d is a directory where you can put custom configuration files. You could use this for websites, but it's better to use it for feature-specific settings that you want on all of your websites. default.d is a directory where your website config might go if you were only running one site on the server, or if your server has a \"primary\" website. Leave it alone for now. We want to create two new folders called sites-available and sites-enabled : mkdir sites-available mkdir sites-enabled What we're going to do is put all of our website configuration files in the sites-available folder. There, you can work on the configuration files as long as you need to, until you're ready to activate the files with a symbolic link to the sites-enabled folder. I'll show you how that works below. For now, we're done with making folders. !!! Note \"Why you (might) want to write your domains backwards:\" Simply put, it's an organizational thing that's especially useful when using the command line with tab completion, but still pretty useful in GUI-based apps. It's designed for people who are running a *lot* of websites or apps on a server. Basically, all of your website folders (and configuration files) will get organized alphabetically; by the top level domain first (eg. .com, .org, etc), then the primary domain, and then by any subdomains. When you're searching through a long list of domains, it can be easier to narrow down what you're looking for this way. It also makes it easier to sort out your folders and config files via command line tools. To list all folders associated with a particular domain, you might run: ```bash ls /usr/share/nginx/ | grep com.yoursite* ``` Which would output something like: ``` com.yoursite.site1 com.yoursite.site2 com.yoursite.site3 ```","title":"The configuration folders"},{"location":"guides/web/nginx-multisite/#setting-up-your-configuration-files","text":"","title":"Setting up Your Configuration Files"},{"location":"guides/web/nginx-multisite/#editing-nginxconf","text":"By default, Rocky Linux's implementation of Nginx is open to all HTTP traffic, and directs it all to the demo page you might have seen in our guide to installing Nginx. We don't want that. We want traffic from the domains we specify to go to the websites we specify. So from the /etc/nginx/ directory, open up nginx.conf in your favorite text editor: nano nginx.conf First, find the line that looks like this: include /etc/nginx/conf.d/*.conf; And add this bit just below it: include /etc/nginx/sites-enabled/*.conf; That will load in our website configuration files when they're ready to go live. Now head down to the section that looks like this, and either comment it out with the hash sign # , or delete it if you feel so inclined: server { listen 80; listen [::]:80; server_name _; root /usr/share/nginx/www/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; error_page 404 /404.html; location = /404.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } What that would look like \"commented out\": #server { # listen 80; # listen [::]:80; # server_name _; # root /usr/share/nginx/www/html; # # # Load configuration files for the default server block. # include /etc/nginx/default.d/*.conf; # # error_page 404 /404.html; # location = /404.html { # } # # error_page 500 502 503 504 /50x.html; # location = /50x.html { # } #} If you're a beginner, you might want to keep the commented code around for reference, and that goes for the example HTTPS code that's already commented out further down in the file. Save and close the file, then restart the server with: systemctl restart nginx Now no one will see the demo page, at least.","title":"Editing nginx.conf"},{"location":"guides/web/nginx-multisite/#adding-the-website-configuration-files","text":"Now let's make your test websites available on the server. As previously mentioned, we're going to to this with symbolic links so we have an easy way of turning the websites on and off at will. !!! Note For absolute newbies, symbolic links are basically a way of letting files pretend to be in two folders at once. Change the original file (or \"target\"), and it's changed everywhere that you've linked to it. If you use a program to edit the file via a link, the original gets changed. However, if you delete a link to the target, nothing at all happens to the original file. This trick is what allows us to put the website configuration files in a working directory (`sites-available`), and then \"activate\" them by linking to those files from `sites-enabled`. I'll show you what I mean. Make a configuration file for the first website like so: nano sites-available/test.server.site1.conf Now paste in this code. This is about the simplest working Nginx configuration you can have, and should work fine for most static HTML websites: server { listen 80; listen [::]:80; # virtual server name i.e. domain name # server_name site1.server.test; # document root # root /usr/share/nginx/test.server.site1/html; # log files access_log /var/log/nginx/www_access.log; error_log /var/log/nginx/www_error.log; # Directives to send expires headers and turn off 404 error logging. # location ~* ^.+\\.(ogg|ogv|svg|svgz|eot|otf|woff|mp4|ttf|rss|atom|jpg|jpeg|gif|png|ico|zip|tgz|gz|rar|bz2|doc|xls|exe|ppt|tar|mid|midi|wav|bmp|rtf)$ { access_log off; log_not_found off; expires max; } } And heck, everything from the document root on down is technically optional. Useful and recommended, but not strictly required for the website to function. Anyway, save and close the file, then go into sites-enabled directory: cd sites-enabled Now, create a symbolic link to the configuration file you just made in the sites-available folder.: ln -s ../sites-available/test.server.site1.conf Test your configuration with the nginx -t command, and if you get a message saying everything is okay, reload the server: systemctl restart nginx Then point your browser at the domain you're using for this first site (in my case: site1.server.test), and look for that \"This is Site 1\" message we put in the HTML file. If you have curl installed on your system, you could run curl site1.server.test and see if the HTML code loads in your terminal. !!! Note Some browsers will (with all the best intentions) force you to use HTTPS when you type your server domain into the address bar. If you don't have HTTPS configured, that'll just throw errors at you. Make sure to manually specify \"http://\" in your browser address bar to avoid this issue. If that doesn't work, clear the cache, or use a less picky browser for this part of the testing. I recommend [Min](https://minbrowser.org). If all of that goes right, repeat the steps above, changing the names of the files and the content of the configuration files as you go. \"site1\" to \"site2\" and all of that. Once you have configuration files and symbolic links for both Site 1 and Site 2, and have restarted Nginx, it should look like this: !!! Note You can also create links from outside of the sites-enabled directory with the long form of the `ln -s` command. It would look like `ln -s [source-file] [link]`. In this context, that's: ```bash ln -s /etc/nginx/sites-available/test.server.site1.conf /etc/nginx/sites-enabled/test.server.site1.conf ```","title":"Adding the website configuration files"},{"location":"guides/web/nginx-multisite/#disabling-a-website","text":"If you need to stop one of your websites to work on it before taking it live again, just delete the symbolic link in sites-enabled: rm /etc/nginx/sites-enabled/test.server.site1.conf Then restart Nginx as usual. To take the site back online, you'll need to re-create the symbolic link, and restart Nginx again.","title":"Disabling a website"},{"location":"guides/web/nginx-multisite/#optional-editing-your-hosts-file","text":"This part's definitely for beginners. Everyone else can probably skip. So this section only applies if you're trying out this guide in a local development environment. That is, if you're running your test server on your workstation, or on another machine in your local home or business network. Since pointing external domains at your local machines is a hassle (and potentially dangerous if you don't know what you're doing), you can set up some \"fake\" domains that will work just fine on your local network, and nowhere else. The easiest way to do this is with the hosts file on your computer. The hosts file is literally just a text file that can override DNS settings. As in, you can manually specify a domain name to go with any IP address you want. It'll only work on that one computer, though. So on Mac and Linux, the hosts file is in the /etc/ directory, and can be edited via the command line super easily (you'll need root access). Assuming you're working on a Rocky Linux workstation, just run: nano /etc/hosts On Windows, the hosts file is located at C:\\Windows\\system32\\drivers\\etc\\hosts , and you can just use whatever GUI text editor you want as long as you have Admin access. So if you're working on a Rocky Linux computer, and are running your Nginx server on the same machine, you'd just open up the file, and define the domains/IP addresses you want. If you're running your workstation and test server on the same machine, that'd be: 127.0.0.1 site1.server.test 127.0.0.1 site2.server.test If you're running your Nginx server on another machine on the network, just use the address of that machine, eg.: 192.168.0.45 site1.server.test 192.168.0.45 site2.server.test Then you'll be able to point your browser to those domains and it should work as intended.","title":"Optional: Editing Your Hosts File"},{"location":"guides/web/nginx-multisite/#setting-up-ssl-certificates-for-your-sites","text":"Go check out our guide to getting SSL certificates with Let's Encrypt and certbot . The instructions there will work just fine.","title":"Setting Up SSL Certificates for Your Sites"},{"location":"guides/web/nginx-multisite/#conclusion","text":"Remember, most of the folder/file organization and naming conventions here are technically optional. Your website configuration files mostly just have to go anywhere inside /etc/nginx/ and nginx.conf needs to know where those files are. The actual website files should be somewhere in /usr/share/nginx/ , and the rest is gravy. Try it out, do some Science TM , and don't forget to run nginx -t before you restart Nginx to make sure you didn't miss a semi-colon or anything. It'll save you a lot of time.","title":"Conclusion"},{"location":"guides/web/php/","tags":["web","php","php-fpm"],"text":"PHP and PHP-FPM PHP ( P HP H ypertext P reprocessor) is a source scripting language, specially designed for web application development. In 2021, PHP represented a little less than 80% of the web pages generated in the world. PHP is open-source and is the core of the most famous CMS (WordPress, Drupal, Joomla!, Magento, ...). PHP-FPM ( F astCGI P rocess M anager) is integrated to PHP since its version 5.3.3. The FastCGI version of php brings additional functionalities. Generalities CGI ( C ommon G ateway I nterface) and FastCGI allow communication between the web server (Apache, Nginx, ...) and a development language (Php, Python, Java): In the case of CGI , each request leads to the creation of a new process , which is less efficient in terms of performance. FastCGI relies on a certain number of processes for the treatment of its client requests. PHP-FPM, in addition to better performances , brings: The possibility of better partitioning the applications : launching processes with different uid/gid, with personalized php.ini files, The management of the statistics, Log management, Dynamic management of processes and restart without service interruption ('graceful'). !!! Note Since Apache has a php module, the use of php-fpm is more commonly used on an Nginx server. Choose a php version Rocky Linux, like its upstream, offers many versions of the language. Some of them have reached the end of their life but are kept to continue hosting historical applications that are not yet compatible with new versions of PHP. Please refer to the supported-versions page of the php.net website to choose a supported version. To obtain a list of available versions, simply enter the following command: $ sudo dnf module list php Rocky Linux 8 - AppStream Name Stream Profiles Summary php 7.2 [d] common [d], devel, minimal PHP scripting language php 7.3 common [d], devel, minimal PHP scripting language php 7.4 common [d], devel, minimal PHP scripting language Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled Rocky provides, from its AppStream repository, different PHP modules. You will note that the default version of a Rocky 8.5 is 7.2 which has already reached its end of life at the time of writing. You can activate a newer module by entering the following command: sudo dnf module enable php:7.4 ============================================================================================== Package Architecture Version Repository Size ============================================================================================== Enabling module streams: httpd 2.4 php 7.4 Transaction Summary ============================================================================================== Is this ok [y/N]: y Complete! !!! Note You cannot currently install php 8 from the AppStream repositories. For this, you will have to go through the REMI repository. This installation is not covered in this document. You can now proceed to the installation of the php engine. PHP cgi mode First, let's see how to install and use php in its CGI mode. We will only be able to make it work with the Apache web server and its mod_php module. We will see, later in this document, in the FastCGI part (php-fpm) how to integrate PHP in Nginx (but also Apache). Installation The installation of php is quite trivial, since it consists in installing the main package as well as the few php modules that you will need. The example below installs php with the modules that are usually installed with it. $ sudo dnf install php php-cli php-gd php-curl php-zip php-mbstring You can check that the installed version corresponds to the expected one: $ php -v PHP 7.4.19 (cli) (built: May 4 2021 11:06:37) ( NTS ) Copyright (c) The PHP Group Zend Engine v3.4.0, Copyright (c) Zend Technologies with Zend OPcache v7.4.19, Copyright (c), by Zend Technologies Configuration Apache integration To serve php pages in cgi mode, you will have to install the apache server, configure it, activate it and start it. Installation: $ sudo dnf install httpd Activation: $ sudo systemctl enable httpd $ sudo systemctl start httpd $ sudo systemctl status httpd Don't forget to configure the firewall: $ sudo firewall-cmd --add-service=http --permanent $ sudo firewall-cmd --reload The default vhost should work out of the box. PHP provides a phpinfo() function that generates a summary table of its configuration. It's very useful to test the good working of php. However, be careful not to leave such test files lying around on your servers, they represent a huge security risk for your infrastructure. Create the file /var/www/html/info.php ( /var/www/html being the default vhost directory of the default apache configuration): <?php phpinfo(); ?> Use a web browser to check that the server is working properly by going to the page http://yourip/info.php. !!! Warning Do not leave the info.php file on your server! PHP-FPM (FastCGI) As we highlighted earlier in this document, there are many advantages to switching web hosting to php-fpm mode. Installation The installation is limited to the php-fpm package: $ sudo dnf install php-fpm As php-fpm is a service from a system point of view, it must be activated and started: $ sudo systemctl enable php-fpm $ sudo systemctl start php-fpm $ sudo systemctl status php-fpm Configuration The main configuration file is stored under /etc/php-fpm.conf . include=/etc/php-fpm.d/*.conf [global] pid = /run/php-fpm/php-fpm.pid error_log = /var/log/php-fpm/error.log daemonize = yes !!! Note The php-fpm configuration files are widely commented. Go and have a look! As you can see, the files in the /etc/php-fpm/ directory with the .conf extension are always included. By default, a php process pool, named www , is declared in /etc/php-fpm.d/www.conf . [www] user = apache group = apache listen = /run/php-fpm/www.sock listen.acl_users = apache,nginx listen.allowed_clients = 127.0.0.1 pm = dynamic pm.max_children = 50 pm.start_servers = 5 pm.min_spare_servers = 5 pm.max_spare_servers = 35 slowlog = /var/log/php-fpm/www-slow.log php_admin_value[error_log] = /var/log/php-fpm/www-error.log php_admin_flag[log_errors] = on php_value[session.save_handler] = files php_value[session.save_path] = /var/lib/php/session php_value[soap.wsdl_cache_dir] = /var/lib/php/wsdlcache Instructions Description [pool] Process pool name. The configuration file can be composed of several process pools (the name of the pool in brackets starts a new section) listen Defines the listening interface or the unix socket used. Configuring the way to access php-fpm processes There are 2 ways to connect. Via an inet interface such as: listen = 127.0.0.1:9000 . Or via a Unix socket: listen = /run/php-fpm/www.sock . !!! Note The use of a socket when the web server and the php server are on the same machine allows the removal of the TCP/IP layer and optimizes the performances. When working via an interface, you have to configure listen.owner , listen.group , listen.mode to specify the owner, the owner group and the rights of the Unix socket. Warning: both servers (web and php) must have access rights on the socket. When working via a socket, you have to configure listen.allowed_clients to restrict access to the php server to certain IP addresses. Example : listen.allowed_clients = 127.0.0.1 Static or dynamic configuration The processes of php-fpm can be managed statically or dynamically In static mode, the number of child processes is set by the value of pm.max_children ; pm = static pm.max_children = 10 This configuration will launch 10 processes. In dynamic mode, PHP-FPM will launch at most the number of processes specified by the value of pm.max_children , starting by launching a number of processes corresponding to pm.start_servers , and keeping at least the value of pm.min_spare_servers of inactive processes and at most pm.max_spare_servers inactive processes. Example: pm = dynamic pm.max_children = 5 pm.start_servers = 2 pm.min_spare_servers = 1 pm.max_spare_servers = 3 PHP-FPM will create a new process to replace one that has processed a number of requests equivalent to pm.max_requests . By default, pm.max_requests is set to 0, which means that processes are never recycled. Using the pm.max_requests option can be interesting for applications with memory leaks. There is a third mode of operation, the ondemand mode. This mode only starts a process when it receives a request. It is not an optimal mode for sites with strong influences, and is to be reserved for specific needs (sites with very weak requests, management backend, etc.) !!! Note The configuration of the operating mode of PHP-FPM is essential to ensure an optimal functioning of your web server. Process status PHP-FPM offers, like Apache and its mod_status module, a page indicating the status of the process. To activate the page, setup its access path via the pm.status_path directive: pm.status_path = /status $ curl http://localhost/status_php pool: www process manager: dynamic start time: 03/Dec/2021:14:00:00 +0100 start since: 600 accepted conn: 548 listen queue: 0 max listen queue: 15 listen queue len: 128 idle processes: 3 active processes: 3 total processes: 5 max active processes: 5 max children reached: 0 slow requests: 0 Logging long requests The slowlog directive specifies the file that receives logging of requests that are too long (i.e., whose time exceeds the value of the request_slowlog_timeout directive). The default location of the generated file is /var/log/php-fpm/www-slow.log . request_slowlog_timeout = 5 slowlog = /var/log/php-fpm/www-slow.log A value of 0 for request_slowlog_timeout disables logging. NGinx integration The default setting of nginx already includes the necessary configuration to make php work with PHP-FPM. The configuration file fastcgi.conf (or fastcgi_params ) is located under /etc/nginx/ : fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param REQUEST_URI $request_uri; fastcgi_param DOCUMENT_URI $document_uri; fastcgi_param DOCUMENT_ROOT $document_root; fastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param REQUEST_SCHEME $scheme; fastcgi_param HTTPS $https if_not_empty; fastcgi_param GATEWAY_INTERFACE CGI/1.1; fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; fastcgi_param REMOTE_ADDR $remote_addr; fastcgi_param REMOTE_PORT $remote_port; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; # PHP only, required if PHP was built with --enable-force-cgi-redirect fastcgi_param REDIRECT_STATUS 200; In order for nginx to process .php files, the following directives must be added to the site configuration file: If php-fpm is listening on port 9000: location ~ \\.php$ { include /etc/nginx/fastcgi_params; fastcgi_pass 127.0.0.1:9000; } If php-fpm is listening on a unix socket: location ~ \\.php$ { include /etc/nginx/fastcgi_params; fastcgi_pass unix:/run/php-fpm/www.sock; } Apache integration The configuration of apache to use a php pool is quite simple. You just have to use the proxy modules with a ProxyPassMatch directive, for example: <VirtualHost *:80> ServerName web.rockylinux.org DocumentRoot \"/var/www/html/current/public\" <Directory \"/var/www/html/current/public\"> AllowOverride All Options -Indexes +FollowSymLinks Require all granted </Directory> ProxyPassMatch ^/(.*\\.php(/.*)?)$ \"fcgi://127.0.0.1:9000/var/www/html/current/public\" </VirtualHost> Solid configuration of php pools It is essential, to optimize the quantity of requests which will be able to be served, to analyze the memory used by the php scripts and thus to optimize the maximum quantity of launched threads. First of all, we need to know the average amount of memory used by a PHP process, with the command: while true; do ps --no-headers -o \"rss,cmd\" -C php-fpm | grep \"pool www\" | awk '{ sum+=$1 } END { printf (\"%d%s\\n\", sum/NR/1024,\"Mb\") }' >> avg_php_proc; sleep 60; done After a while, this should give us a pretty accurate idea of the average memory footprint of a php process on this server. For the rest of this document, let's say that the result is a memory footprint of 120MB per process at full load. On a server with 8Gb of RAM, keeping 1Gb for the system and 1Gb for the OPCache (see the rest of this document), there is 6Gb left to process PHP requests from clients. We can easily conclude that this server can accept at most 50 threads ((6*1024) / 120) . A good configuration of php-fpm specific to this use case would be: pm = dynamic pm.max_children = 50 pm.start_servers = 12 pm.min_spare_servers = 12 pm.max_spare_servers = 36 pm.process_idle_timeout = 10s; pm.max_requests = 500 with: pm.start_servers = 25% of max_children pm.min_spare_servers = 25% of max_children pm.max_spare_servers = 75% of max_children Opcache configuration The opcache (Optimizer Plus Cache) is the first level of cache on which we can influence. It keeps in memory the compiled php scripts which strongly impacts the execution of the web pages (removes the reading on disk of the script + the compilation time). To configure it, we must work on: The size of the memory dedicated to the opcache according to the hit ratio By configuring correctly the number of php scripts to cache (number of keys + maximum number of scripts) the number of strings to cache To install it: $ sudo dnf install php-opcache To configure it, edit the /etc/php.d/10-opcache.ini configuration file: opcache.memory_consumption=128 opcache.interned_strings_buffer=8 opcache.max_accelerated_files=4000 where: opcache.memory_consumption corresponds to the amount of memory needed for the opcache (to be increased until a correct hit ratio is obtained) opcache.interned_strings_buffer the amount of strings to cache. opcache.max_accelerated_files is near to the result of the find ./ -iname \"*.php\"|wc -l command. You can refer to an info.php page (including the phpinfo(); ) to configure the opcache (see for example the values of Cached scripts and Cached strings ). !!! Note At each new deployment of new code, it will be necessary to empty the opcache (for example by restarting the php-fpm process) !!! Note Don't underestimate the speed gain that can be achieved by setting up and configuring the opcache correctly.","title":"PHP and PHP-FPM"},{"location":"guides/web/php/#php-and-php-fpm","text":"PHP ( P HP H ypertext P reprocessor) is a source scripting language, specially designed for web application development. In 2021, PHP represented a little less than 80% of the web pages generated in the world. PHP is open-source and is the core of the most famous CMS (WordPress, Drupal, Joomla!, Magento, ...). PHP-FPM ( F astCGI P rocess M anager) is integrated to PHP since its version 5.3.3. The FastCGI version of php brings additional functionalities.","title":"PHP and PHP-FPM"},{"location":"guides/web/php/#generalities","text":"CGI ( C ommon G ateway I nterface) and FastCGI allow communication between the web server (Apache, Nginx, ...) and a development language (Php, Python, Java): In the case of CGI , each request leads to the creation of a new process , which is less efficient in terms of performance. FastCGI relies on a certain number of processes for the treatment of its client requests. PHP-FPM, in addition to better performances , brings: The possibility of better partitioning the applications : launching processes with different uid/gid, with personalized php.ini files, The management of the statistics, Log management, Dynamic management of processes and restart without service interruption ('graceful'). !!! Note Since Apache has a php module, the use of php-fpm is more commonly used on an Nginx server.","title":"Generalities"},{"location":"guides/web/php/#choose-a-php-version","text":"Rocky Linux, like its upstream, offers many versions of the language. Some of them have reached the end of their life but are kept to continue hosting historical applications that are not yet compatible with new versions of PHP. Please refer to the supported-versions page of the php.net website to choose a supported version. To obtain a list of available versions, simply enter the following command: $ sudo dnf module list php Rocky Linux 8 - AppStream Name Stream Profiles Summary php 7.2 [d] common [d], devel, minimal PHP scripting language php 7.3 common [d], devel, minimal PHP scripting language php 7.4 common [d], devel, minimal PHP scripting language Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled Rocky provides, from its AppStream repository, different PHP modules. You will note that the default version of a Rocky 8.5 is 7.2 which has already reached its end of life at the time of writing. You can activate a newer module by entering the following command: sudo dnf module enable php:7.4 ============================================================================================== Package Architecture Version Repository Size ============================================================================================== Enabling module streams: httpd 2.4 php 7.4 Transaction Summary ============================================================================================== Is this ok [y/N]: y Complete! !!! Note You cannot currently install php 8 from the AppStream repositories. For this, you will have to go through the REMI repository. This installation is not covered in this document. You can now proceed to the installation of the php engine.","title":"Choose a php version"},{"location":"guides/web/php/#php-cgi-mode","text":"First, let's see how to install and use php in its CGI mode. We will only be able to make it work with the Apache web server and its mod_php module. We will see, later in this document, in the FastCGI part (php-fpm) how to integrate PHP in Nginx (but also Apache).","title":"PHP cgi mode"},{"location":"guides/web/php/#installation","text":"The installation of php is quite trivial, since it consists in installing the main package as well as the few php modules that you will need. The example below installs php with the modules that are usually installed with it. $ sudo dnf install php php-cli php-gd php-curl php-zip php-mbstring You can check that the installed version corresponds to the expected one: $ php -v PHP 7.4.19 (cli) (built: May 4 2021 11:06:37) ( NTS ) Copyright (c) The PHP Group Zend Engine v3.4.0, Copyright (c) Zend Technologies with Zend OPcache v7.4.19, Copyright (c), by Zend Technologies","title":"Installation"},{"location":"guides/web/php/#configuration","text":"","title":"Configuration"},{"location":"guides/web/php/#apache-integration","text":"To serve php pages in cgi mode, you will have to install the apache server, configure it, activate it and start it. Installation: $ sudo dnf install httpd Activation: $ sudo systemctl enable httpd $ sudo systemctl start httpd $ sudo systemctl status httpd Don't forget to configure the firewall: $ sudo firewall-cmd --add-service=http --permanent $ sudo firewall-cmd --reload The default vhost should work out of the box. PHP provides a phpinfo() function that generates a summary table of its configuration. It's very useful to test the good working of php. However, be careful not to leave such test files lying around on your servers, they represent a huge security risk for your infrastructure. Create the file /var/www/html/info.php ( /var/www/html being the default vhost directory of the default apache configuration): <?php phpinfo(); ?> Use a web browser to check that the server is working properly by going to the page http://yourip/info.php. !!! Warning Do not leave the info.php file on your server!","title":"Apache integration"},{"location":"guides/web/php/#php-fpm-fastcgi","text":"As we highlighted earlier in this document, there are many advantages to switching web hosting to php-fpm mode.","title":"PHP-FPM (FastCGI)"},{"location":"guides/web/php/#installation_1","text":"The installation is limited to the php-fpm package: $ sudo dnf install php-fpm As php-fpm is a service from a system point of view, it must be activated and started: $ sudo systemctl enable php-fpm $ sudo systemctl start php-fpm $ sudo systemctl status php-fpm","title":"Installation"},{"location":"guides/web/php/#configuration_1","text":"The main configuration file is stored under /etc/php-fpm.conf . include=/etc/php-fpm.d/*.conf [global] pid = /run/php-fpm/php-fpm.pid error_log = /var/log/php-fpm/error.log daemonize = yes !!! Note The php-fpm configuration files are widely commented. Go and have a look! As you can see, the files in the /etc/php-fpm/ directory with the .conf extension are always included. By default, a php process pool, named www , is declared in /etc/php-fpm.d/www.conf . [www] user = apache group = apache listen = /run/php-fpm/www.sock listen.acl_users = apache,nginx listen.allowed_clients = 127.0.0.1 pm = dynamic pm.max_children = 50 pm.start_servers = 5 pm.min_spare_servers = 5 pm.max_spare_servers = 35 slowlog = /var/log/php-fpm/www-slow.log php_admin_value[error_log] = /var/log/php-fpm/www-error.log php_admin_flag[log_errors] = on php_value[session.save_handler] = files php_value[session.save_path] = /var/lib/php/session php_value[soap.wsdl_cache_dir] = /var/lib/php/wsdlcache Instructions Description [pool] Process pool name. The configuration file can be composed of several process pools (the name of the pool in brackets starts a new section) listen Defines the listening interface or the unix socket used.","title":"Configuration"},{"location":"guides/web/php/#configuring-the-way-to-access-php-fpm-processes","text":"There are 2 ways to connect. Via an inet interface such as: listen = 127.0.0.1:9000 . Or via a Unix socket: listen = /run/php-fpm/www.sock . !!! Note The use of a socket when the web server and the php server are on the same machine allows the removal of the TCP/IP layer and optimizes the performances. When working via an interface, you have to configure listen.owner , listen.group , listen.mode to specify the owner, the owner group and the rights of the Unix socket. Warning: both servers (web and php) must have access rights on the socket. When working via a socket, you have to configure listen.allowed_clients to restrict access to the php server to certain IP addresses. Example : listen.allowed_clients = 127.0.0.1","title":"Configuring the way to access php-fpm processes"},{"location":"guides/web/php/#static-or-dynamic-configuration","text":"The processes of php-fpm can be managed statically or dynamically In static mode, the number of child processes is set by the value of pm.max_children ; pm = static pm.max_children = 10 This configuration will launch 10 processes. In dynamic mode, PHP-FPM will launch at most the number of processes specified by the value of pm.max_children , starting by launching a number of processes corresponding to pm.start_servers , and keeping at least the value of pm.min_spare_servers of inactive processes and at most pm.max_spare_servers inactive processes. Example: pm = dynamic pm.max_children = 5 pm.start_servers = 2 pm.min_spare_servers = 1 pm.max_spare_servers = 3 PHP-FPM will create a new process to replace one that has processed a number of requests equivalent to pm.max_requests . By default, pm.max_requests is set to 0, which means that processes are never recycled. Using the pm.max_requests option can be interesting for applications with memory leaks. There is a third mode of operation, the ondemand mode. This mode only starts a process when it receives a request. It is not an optimal mode for sites with strong influences, and is to be reserved for specific needs (sites with very weak requests, management backend, etc.) !!! Note The configuration of the operating mode of PHP-FPM is essential to ensure an optimal functioning of your web server.","title":"Static or dynamic configuration"},{"location":"guides/web/php/#process-status","text":"PHP-FPM offers, like Apache and its mod_status module, a page indicating the status of the process. To activate the page, setup its access path via the pm.status_path directive: pm.status_path = /status $ curl http://localhost/status_php pool: www process manager: dynamic start time: 03/Dec/2021:14:00:00 +0100 start since: 600 accepted conn: 548 listen queue: 0 max listen queue: 15 listen queue len: 128 idle processes: 3 active processes: 3 total processes: 5 max active processes: 5 max children reached: 0 slow requests: 0","title":"Process status"},{"location":"guides/web/php/#logging-long-requests","text":"The slowlog directive specifies the file that receives logging of requests that are too long (i.e., whose time exceeds the value of the request_slowlog_timeout directive). The default location of the generated file is /var/log/php-fpm/www-slow.log . request_slowlog_timeout = 5 slowlog = /var/log/php-fpm/www-slow.log A value of 0 for request_slowlog_timeout disables logging.","title":"Logging long requests"},{"location":"guides/web/php/#nginx-integration","text":"The default setting of nginx already includes the necessary configuration to make php work with PHP-FPM. The configuration file fastcgi.conf (or fastcgi_params ) is located under /etc/nginx/ : fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param REQUEST_URI $request_uri; fastcgi_param DOCUMENT_URI $document_uri; fastcgi_param DOCUMENT_ROOT $document_root; fastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param REQUEST_SCHEME $scheme; fastcgi_param HTTPS $https if_not_empty; fastcgi_param GATEWAY_INTERFACE CGI/1.1; fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; fastcgi_param REMOTE_ADDR $remote_addr; fastcgi_param REMOTE_PORT $remote_port; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; # PHP only, required if PHP was built with --enable-force-cgi-redirect fastcgi_param REDIRECT_STATUS 200; In order for nginx to process .php files, the following directives must be added to the site configuration file: If php-fpm is listening on port 9000: location ~ \\.php$ { include /etc/nginx/fastcgi_params; fastcgi_pass 127.0.0.1:9000; } If php-fpm is listening on a unix socket: location ~ \\.php$ { include /etc/nginx/fastcgi_params; fastcgi_pass unix:/run/php-fpm/www.sock; }","title":"NGinx integration"},{"location":"guides/web/php/#apache-integration_1","text":"The configuration of apache to use a php pool is quite simple. You just have to use the proxy modules with a ProxyPassMatch directive, for example: <VirtualHost *:80> ServerName web.rockylinux.org DocumentRoot \"/var/www/html/current/public\" <Directory \"/var/www/html/current/public\"> AllowOverride All Options -Indexes +FollowSymLinks Require all granted </Directory> ProxyPassMatch ^/(.*\\.php(/.*)?)$ \"fcgi://127.0.0.1:9000/var/www/html/current/public\" </VirtualHost>","title":"Apache integration"},{"location":"guides/web/php/#solid-configuration-of-php-pools","text":"It is essential, to optimize the quantity of requests which will be able to be served, to analyze the memory used by the php scripts and thus to optimize the maximum quantity of launched threads. First of all, we need to know the average amount of memory used by a PHP process, with the command: while true; do ps --no-headers -o \"rss,cmd\" -C php-fpm | grep \"pool www\" | awk '{ sum+=$1 } END { printf (\"%d%s\\n\", sum/NR/1024,\"Mb\") }' >> avg_php_proc; sleep 60; done After a while, this should give us a pretty accurate idea of the average memory footprint of a php process on this server. For the rest of this document, let's say that the result is a memory footprint of 120MB per process at full load. On a server with 8Gb of RAM, keeping 1Gb for the system and 1Gb for the OPCache (see the rest of this document), there is 6Gb left to process PHP requests from clients. We can easily conclude that this server can accept at most 50 threads ((6*1024) / 120) . A good configuration of php-fpm specific to this use case would be: pm = dynamic pm.max_children = 50 pm.start_servers = 12 pm.min_spare_servers = 12 pm.max_spare_servers = 36 pm.process_idle_timeout = 10s; pm.max_requests = 500 with: pm.start_servers = 25% of max_children pm.min_spare_servers = 25% of max_children pm.max_spare_servers = 75% of max_children","title":"Solid configuration of php pools"},{"location":"guides/web/php/#opcache-configuration","text":"The opcache (Optimizer Plus Cache) is the first level of cache on which we can influence. It keeps in memory the compiled php scripts which strongly impacts the execution of the web pages (removes the reading on disk of the script + the compilation time). To configure it, we must work on: The size of the memory dedicated to the opcache according to the hit ratio By configuring correctly the number of php scripts to cache (number of keys + maximum number of scripts) the number of strings to cache To install it: $ sudo dnf install php-opcache To configure it, edit the /etc/php.d/10-opcache.ini configuration file: opcache.memory_consumption=128 opcache.interned_strings_buffer=8 opcache.max_accelerated_files=4000 where: opcache.memory_consumption corresponds to the amount of memory needed for the opcache (to be increased until a correct hit ratio is obtained) opcache.interned_strings_buffer the amount of strings to cache. opcache.max_accelerated_files is near to the result of the find ./ -iname \"*.php\"|wc -l command. You can refer to an info.php page (including the phpinfo(); ) to configure the opcache (see for example the values of Cached scripts and Cached strings ). !!! Note At each new deployment of new code, it will be necessary to empty the opcache (for example by restarting the php-fpm process) !!! Note Don't underestimate the speed gain that can be achieved by setting up and configuring the opcache correctly.","title":"Opcache configuration"},{"location":"guides/web/apache_hardened_webserver/","tags":["apache","web","security"],"text":"Apache Hardened Webserver Prerequisites and Assumptions A Rocky Linux web server running Apache A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties A comfort level with a command line editor (our examples use vi which will usually invoke the vim editor, but you can substitute your favorite editor) Assumes an iptables firewall, rather than firewalld or a hardware firewall. Assumes the use of a gateway hardware firewall that our trusted devices will sit behind. Assumes a public IP address directly applied to the web server. We are substituting a private IP address for all of our examples. Introduction Whether you are hosting multiple websites for customers, or a single, very important, website for your business, hardening your web server will give you peace of mind, at the expense of a little more up-front work for the administrator. With multiple web sites uploaded by your customers, you can pretty much be guaranteed that one of them will upload a Content Management System (CMS) with the possibility of vulnerabilities. Most customers are focused on ease of use, not security, and what happens is that updating their own CMS becomes a process that falls out of their priority list altogether. While notifying customers of vulnerabilities in their CMS may be possible for a company with a large IT staff, it may not be possible for a small department. The best defense is a hardened web server. Web server hardening can take many forms, which may include any or all of the below tools, and possibly others not defined here. You might elect to use a couple of these tools, and not the others, so for clarity and readability this document is split out into separate documents for each tool. The exception will be the packet-based firewall ( iptables ) which will be included in this main document. A good packet filter firewall based on ports (iptables, firewalld, or hardware firewall - we will use iptables for our example) iptables procedure A Host-based Intrusion Detection System (HIDS), in this case ossec-hids Apache Hardened Web Server - ossec-hids A Web-based Application Firewall (WAF), with mod_security rules Apache Hardened Web Server - mod_security Rootkit Hunter (rkhunter): A scan tool that checks against Linux malware Apache Hardened Web Server - rkhunter Database security (we are using mariadb-server here) MariaDB Database Server A secure FTP or SFTP server (we are using vsftpd here) Secure FTP Server - vsftpd but we also have sftp and SSH lock down procedures here This procedure does not replace the Apache Web Server Multi-Site Setup , it simply adds these security elements to it. If you haven't read it, take some time to look at it before proceeding. Other Considerations Some of the tools outlined here have both free and fee-based options. Depending on your needs or support requirements, you may want to consider the fee-based versions. You should research what is out there and make a decision after weighing all of your options. Know, too, that most of these options can be purchased as hardware appliances. If you'd prefer not to hassle with installing and maintaining your own system, there are options available other than those outlined here. This document uses a straight iptables firewall and requires this procedure on Rocky Linux to disable firewalld and enable the iptables services . Since this document was first written, we now have a couple of excellent firewalld guides; one that allows someone with knowledge of iptables to transfer what they know to firewalld here , and one that is a more dedicated to beginners here . If you prefer to use firewalld , simply skip this step and apply the rules needed. The firewall in our examples here, needs no OUTPUT or FORWARD chains, only INPUT. Your needs may differ! All of these tools need to be tuned to your system. That can only be done with careful monitoring of logs, and reported web experience by your customers. In addition, you will find that there will be ongoing tuning required over time. Even though we are using a private IP address to simulate a public one, all of this could have been done using a one-to-one NAT on the hardware firewall and connecting the web server to that hardware firewall, rather than to the gateway router, with a private IP address. Explaining that requires digging into the hardware firewall shown below, and since that is outside of the scope of this document, it is better to stick with our example of a simulated public IP address. Conventions IP Addresses: We are simulating the public IP address here with a private block: 192.168.1.0/24 and we are using the LAN IP address block as 10.0.0.0/24 In other words, it cannot be routed over the Internet. In reality, neither IP block can be routed over the Internet as they are both reserved for private use, but there is no good way to simulate the public IP block, without using a real IP address that is assigned to some company. Just remember that for our purposes, the 192.168.1.0/24 block is the \"public\" IP block and the 10.0.0.0/24 is the \"private\" IP block. Hardware Firewall: This is the firewall that controls access to your server room devices from your trusted network. This is not the same as our iptables firewall, though it could be another instance of iptables running on another machine. This device will allow ICMP (ping) and SSH (secure shell) to our trusted devices. Defining this device is outside of the scope of this document. The author has used both PfSense and OPNSense and installed on dedicated hardware for this device with great success. This device will have two IP addresses assigned to it. One that will connect to the Internet router's simulated public IP (192.168.1.2) and one that will connect to our local area network, 10.0.0.1. Internet Router IP: We are simulating this with 192.168.1.1/24 Web Server IP: This is the \"public\" IP address assigned to our web server. Again, we are simulating this with the private IP address 192.168.1.10/24 The diagram above shows our general layout. The iptables packet-based firewall runs on the web server (shown above). Install Packages Each individual package section has the needed installation files and any configuration procedure listed. The installation instructions for iptables is part of the disable firewalld and enable the iptables services procedure. Configuring iptables This portion of the documentation assumes that you have elected to install the iptables services and utilities and that you are not planning on using firewalld . If you are planning on using firewalld , you can use this iptables script to guide you in creating the appropriate rules in the firewalld format. Once the script is shown here, we will break it down to describe what is happening. Only the INPUT chain is needed here. The script is being placed in the /etc/ directory and for our example, it is named firewall.conf: vi /etc/firewall.conf and the contents will be: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p tcp -m tcp -s 192.168.1.2 --dport 22 -j ACCEPT iptables -A INPUT -p icmp -m icmp --icmp-type 8 -s 192.168.1.2 -j ACCEPT # dns rules iptables -A INPUT -p udp -m udp -s 8.8.8.8 --sport 53 -d 0/0 -j ACCEPT iptables -A INPUT -p udp -m udp -s 8.8.4.4 --sport 53 -d 0/0 -j ACCEPT # web ports iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT # ftp ports iptables -A INPUT -p tcp -m tcp --dport 20-21 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 7000-7500 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save So here's what is happening above: When we start, we flush all of the rules We then set the default policy for our INPUT chain to DROP, which says, \"Hey, if we haven't explicitly allowed you here, then we are dropping you!\" Then we allow SSH (port 22) from our trusted network, the devices behind the hardware firewall We allow DNS from some public DNS resolvers. (these can also be local DNS servers, if you have them) We allow our web traffic in from anywhere over port 80 and 443. We allow standard FTP (ports 20-21) and the passive ports needed to exchange two-way communications in FTP (7000-7500). These ports can be arbitrarily changed to other ports based on your ftp server configuration. We allow any traffic on the local interface (127.0.0.1) Then we say, that any traffic that has successfully connected based on the rules, should be allowed other traffic (ports) to maintain their connection (ESTABLISHED,RELATED). And finally, we reject all other traffic and set the script to save the rules where iptables expects to find them. Once this script is there, we need to make it executable: chmod +x /etc/firewall.conf We need to enable iptables if we haven't already: systemctl enable iptables We need to start iptables : systemctl start iptables We need to run /etc/firewall.conf: /etc/firewall.conf If we add new rules to the /etc/firewall.conf, just run it again to take those rules live. Keep in mind that with a default DROP policy for the INPUT chain, if you make a mistake, you could lock yourself out remotely. You can always fix this however, from the console on the server. Because the iptables service is enabled, a reboot will restore all rules that have been added with /etc/firewall.conf . Conclusion There are a number of ways to harden an Apache web server to make it more secure. Each operates independently of the other options, so you can choose to install any, or all, of them based on your needs. Each requires some configuration with various tuning required for some to meet your specific needs. Since web services are constantly under attack 24/7 by unscrupulous actors, implementing at least some of these will help an administrator sleep at night.","title":"Apache Hardened Webserver"},{"location":"guides/web/apache_hardened_webserver/#apache-hardened-webserver","text":"","title":"Apache Hardened Webserver"},{"location":"guides/web/apache_hardened_webserver/#prerequisites-and-assumptions","text":"A Rocky Linux web server running Apache A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties A comfort level with a command line editor (our examples use vi which will usually invoke the vim editor, but you can substitute your favorite editor) Assumes an iptables firewall, rather than firewalld or a hardware firewall. Assumes the use of a gateway hardware firewall that our trusted devices will sit behind. Assumes a public IP address directly applied to the web server. We are substituting a private IP address for all of our examples.","title":"Prerequisites and Assumptions"},{"location":"guides/web/apache_hardened_webserver/#introduction","text":"Whether you are hosting multiple websites for customers, or a single, very important, website for your business, hardening your web server will give you peace of mind, at the expense of a little more up-front work for the administrator. With multiple web sites uploaded by your customers, you can pretty much be guaranteed that one of them will upload a Content Management System (CMS) with the possibility of vulnerabilities. Most customers are focused on ease of use, not security, and what happens is that updating their own CMS becomes a process that falls out of their priority list altogether. While notifying customers of vulnerabilities in their CMS may be possible for a company with a large IT staff, it may not be possible for a small department. The best defense is a hardened web server. Web server hardening can take many forms, which may include any or all of the below tools, and possibly others not defined here. You might elect to use a couple of these tools, and not the others, so for clarity and readability this document is split out into separate documents for each tool. The exception will be the packet-based firewall ( iptables ) which will be included in this main document. A good packet filter firewall based on ports (iptables, firewalld, or hardware firewall - we will use iptables for our example) iptables procedure A Host-based Intrusion Detection System (HIDS), in this case ossec-hids Apache Hardened Web Server - ossec-hids A Web-based Application Firewall (WAF), with mod_security rules Apache Hardened Web Server - mod_security Rootkit Hunter (rkhunter): A scan tool that checks against Linux malware Apache Hardened Web Server - rkhunter Database security (we are using mariadb-server here) MariaDB Database Server A secure FTP or SFTP server (we are using vsftpd here) Secure FTP Server - vsftpd but we also have sftp and SSH lock down procedures here This procedure does not replace the Apache Web Server Multi-Site Setup , it simply adds these security elements to it. If you haven't read it, take some time to look at it before proceeding.","title":"Introduction"},{"location":"guides/web/apache_hardened_webserver/#other-considerations","text":"Some of the tools outlined here have both free and fee-based options. Depending on your needs or support requirements, you may want to consider the fee-based versions. You should research what is out there and make a decision after weighing all of your options. Know, too, that most of these options can be purchased as hardware appliances. If you'd prefer not to hassle with installing and maintaining your own system, there are options available other than those outlined here. This document uses a straight iptables firewall and requires this procedure on Rocky Linux to disable firewalld and enable the iptables services . Since this document was first written, we now have a couple of excellent firewalld guides; one that allows someone with knowledge of iptables to transfer what they know to firewalld here , and one that is a more dedicated to beginners here . If you prefer to use firewalld , simply skip this step and apply the rules needed. The firewall in our examples here, needs no OUTPUT or FORWARD chains, only INPUT. Your needs may differ! All of these tools need to be tuned to your system. That can only be done with careful monitoring of logs, and reported web experience by your customers. In addition, you will find that there will be ongoing tuning required over time. Even though we are using a private IP address to simulate a public one, all of this could have been done using a one-to-one NAT on the hardware firewall and connecting the web server to that hardware firewall, rather than to the gateway router, with a private IP address. Explaining that requires digging into the hardware firewall shown below, and since that is outside of the scope of this document, it is better to stick with our example of a simulated public IP address.","title":"Other Considerations"},{"location":"guides/web/apache_hardened_webserver/#conventions","text":"IP Addresses: We are simulating the public IP address here with a private block: 192.168.1.0/24 and we are using the LAN IP address block as 10.0.0.0/24 In other words, it cannot be routed over the Internet. In reality, neither IP block can be routed over the Internet as they are both reserved for private use, but there is no good way to simulate the public IP block, without using a real IP address that is assigned to some company. Just remember that for our purposes, the 192.168.1.0/24 block is the \"public\" IP block and the 10.0.0.0/24 is the \"private\" IP block. Hardware Firewall: This is the firewall that controls access to your server room devices from your trusted network. This is not the same as our iptables firewall, though it could be another instance of iptables running on another machine. This device will allow ICMP (ping) and SSH (secure shell) to our trusted devices. Defining this device is outside of the scope of this document. The author has used both PfSense and OPNSense and installed on dedicated hardware for this device with great success. This device will have two IP addresses assigned to it. One that will connect to the Internet router's simulated public IP (192.168.1.2) and one that will connect to our local area network, 10.0.0.1. Internet Router IP: We are simulating this with 192.168.1.1/24 Web Server IP: This is the \"public\" IP address assigned to our web server. Again, we are simulating this with the private IP address 192.168.1.10/24 The diagram above shows our general layout. The iptables packet-based firewall runs on the web server (shown above).","title":"Conventions"},{"location":"guides/web/apache_hardened_webserver/#install-packages","text":"Each individual package section has the needed installation files and any configuration procedure listed. The installation instructions for iptables is part of the disable firewalld and enable the iptables services procedure.","title":"Install Packages"},{"location":"guides/web/apache_hardened_webserver/#configuring-iptables","text":"This portion of the documentation assumes that you have elected to install the iptables services and utilities and that you are not planning on using firewalld . If you are planning on using firewalld , you can use this iptables script to guide you in creating the appropriate rules in the firewalld format. Once the script is shown here, we will break it down to describe what is happening. Only the INPUT chain is needed here. The script is being placed in the /etc/ directory and for our example, it is named firewall.conf: vi /etc/firewall.conf and the contents will be: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p tcp -m tcp -s 192.168.1.2 --dport 22 -j ACCEPT iptables -A INPUT -p icmp -m icmp --icmp-type 8 -s 192.168.1.2 -j ACCEPT # dns rules iptables -A INPUT -p udp -m udp -s 8.8.8.8 --sport 53 -d 0/0 -j ACCEPT iptables -A INPUT -p udp -m udp -s 8.8.4.4 --sport 53 -d 0/0 -j ACCEPT # web ports iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT # ftp ports iptables -A INPUT -p tcp -m tcp --dport 20-21 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 7000-7500 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save So here's what is happening above: When we start, we flush all of the rules We then set the default policy for our INPUT chain to DROP, which says, \"Hey, if we haven't explicitly allowed you here, then we are dropping you!\" Then we allow SSH (port 22) from our trusted network, the devices behind the hardware firewall We allow DNS from some public DNS resolvers. (these can also be local DNS servers, if you have them) We allow our web traffic in from anywhere over port 80 and 443. We allow standard FTP (ports 20-21) and the passive ports needed to exchange two-way communications in FTP (7000-7500). These ports can be arbitrarily changed to other ports based on your ftp server configuration. We allow any traffic on the local interface (127.0.0.1) Then we say, that any traffic that has successfully connected based on the rules, should be allowed other traffic (ports) to maintain their connection (ESTABLISHED,RELATED). And finally, we reject all other traffic and set the script to save the rules where iptables expects to find them. Once this script is there, we need to make it executable: chmod +x /etc/firewall.conf We need to enable iptables if we haven't already: systemctl enable iptables We need to start iptables : systemctl start iptables We need to run /etc/firewall.conf: /etc/firewall.conf If we add new rules to the /etc/firewall.conf, just run it again to take those rules live. Keep in mind that with a default DROP policy for the INPUT chain, if you make a mistake, you could lock yourself out remotely. You can always fix this however, from the console on the server. Because the iptables service is enabled, a reboot will restore all rules that have been added with /etc/firewall.conf .","title":"Configuring iptables"},{"location":"guides/web/apache_hardened_webserver/#conclusion","text":"There are a number of ways to harden an Apache web server to make it more secure. Each operates independently of the other options, so you can choose to install any, or all, of them based on your needs. Each requires some configuration with various tuning required for some to meet your specific needs. Since web services are constantly under attack 24/7 by unscrupulous actors, implementing at least some of these will help an administrator sleep at night.","title":"Conclusion"},{"location":"guides/web/apache_hardened_webserver/modsecurity/","tags":["web","security","apache","nginx"],"text":"Web-based Application Firewall (WAF) Prerequisites A Rocky Linux Web Server running Apache Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding that installing this tool also requires monitoring of actions and tuning to your environment An account on Comodo's WAF site All commands are run as the root user or sudo Introduction mod_security is an open-source web-based application firewall (WAF). It is just one possible component of a hardened Apache web server setup and can be used with, or without, other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server guide . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing. One thing that is missing with mod_security when installed from the generic Rocky Linux repositories, is that the rules installed are minimal at best. To get a more extensive package of free mod_security rules, we are using Comodo's WAF installation procedure after installing the base package. Note that Comodo is a business that sells lots of tools to help secure networks. The free mod_security tools may not be free forever and they do require that you setup a login with Comodo in order to gain access to the rules. Installing mod_security To install the base package, use this command which will install any missing dependencies. We also need wget so if you haven't installed it, do that as well: dnf install mod_security wget Setting Up Your Comodo account To setup your free account, go to Comodo's WAF site , and click the \"Signup\" link at the top of the page. You will be required to setup username and password information but no credit-card or other billing will be done. The credentials that you use for signing on to the web site will be used in your setup of Comodo's software and also to obtain the rules, so you will need to keep these safe in a password manager somewhere. Please note that the \"Terms and Conditions\" section of the form that you need to fill out to use Comodo Web Application Firewall (CWAF) is written to cover all of their products and services. That said, you should read this carefully before agreeing to the terms! Installing CWAF Before you start, in order for the script to actually run after we download it, you are going to need some development tools. Install the package with: dnf group install 'Development Tools' In addition, you will need to have your web server running for Comodo to see mod_security correctly. So start it if it is not already running: systemctl start httpd After signing up with Comodo, you will get an email with instructions on what to do next. Essentially, what you need to do is to login to the web site with your new credentials and then download the client install script. From the root directory of your server, use the wget command to download the installer: wget https://waf.comodo.com/cpanel/cwaf_client_install.sh Run the installer by typing: bash cwaf_client_install.sh This will extract the installer and start the process, echoing to the screen. You'll get a message part way down: No web host management panel found, continue in 'standalone' mode? [y/n]: Type \"y\" and let the script continue. You may also get this notice: Some required perl modules are missed. Install them? This can take a while. [y/n]: If so type \"y\" and allow those missing modules to install. Enter CWAF login: username@domain.com Enter password for 'username@domain.com' (will not be shown): ************************* Confirm password for 'username@domain.com' (will not be shown): ************************ Please note here that you will probably have to download the rules and install them in the correct location, as the password field requires a punctuation or special character, but the configuration file apparently has issues with this when sending it to Comodo's site from the installer or update script. These scripts will always fail with a credentials error. This probably doesn't affect administrators who have web servers running with a GUI front end (Cpanel / Plesk) but if you are running the program standalone as we are in our example, it does. You can find the workaround below . Enter absolute CWAF installation path prefix (/cwaf will be appended): /usr/local Install into '/usr/local/cwaf' ? [y/n]: Just accept the path as given and then type \"y\" in the next field for the install path. If you have a non-standard path to the configuration file for Apache/nginx, you would enter it here, otherwise just hit 'Enter' for no changes: If you have non-standard Apache/nginx config path enter it here: Here is where the failure comes in, and the only workaround is to manually download and install the rules. Answer the prompts as shown below: Do you want to use HTTP GUI to manage CWAF rules? [y/n]: n Do you want to protect your server with default rule set? [y/n]: y But expect to get the next message as well: Warning! Rules have not been updated. Check your credentials and try again later manually +------------------------------------------------------ | LOG : Warning! Rules have not been updated. Check your credentials and try again later manually +------------------------------------------------------ | Installation complete! | Please add the line: | Include \"/usr/local/cwaf/etc/modsec2_standalone.conf\" | to Apache config file. | To update ModSecurity ruleset run | /usr/local/cwaf/scripts/updater.pl | Restart Apache after that. | You may find useful utility /usr/local/cwaf/scripts/cwaf-cli.pl | Also you may examine file | /usr/local/cwaf/INFO.TXT | for some useful software information. +------------------------------------------------------ | LOG : All Done! | LOG : Exiting That's a little frustrating. You can go to your account on the Comodo web site and change your password and re-run the install script, BUT, it won't change anything. The credentials will still fail. CWAF Rules File Workaround To fix this, we need to manually install the rules from the web site. This is done by logging into your account on https://waf.comodo.com and clicking on the the \"Download Full Rule Set\" link. You'll then need to copy the rules to your web server using scp' Example: scp cwaf_rules-1.233.tgz root@mywebserversdomainname.com:/root/ Once the tar gzip file has been copied over, move the file to the rules directory: mv /root/cwaf_rules-1.233.tgz /usr/local/cwaf/rules/ Then navigate to the rules directory: cd /usr/local/cwaf/rules/ And uncompress the rules: tar xzvf cwaf_rules-1.233.tgz Any partial updates to the rules will have to be handled in the same way. This is where paying for rules and support can come in handy. It all depends on your budget. Configuring CWAF When we installed mod_security , the default configuration file was installed in /etc/httpd/conf.d/mod_security.conf . The next thing we need to do is to modify this in two places. Start by editing the file: vi /etc/httpd/conf.d/mod_security.conf At the very top of the file, you will see: <IfModule mod_security2.c> # Default recommended configuration SecRuleEngine On Beneath the SecRuleEngine On line add SecStatusEngine On so that the top of the file will now look like this: <IfModule mod_security2.c> # Default recommended configuration SecRuleEngine On SecStatusEngine On Next go to the bottom of this configuration file. We need to tell mod_security where to load the rules. You should see this at the bottom of the file before you make changes: # ModSecurity Core Rules Set and Local configuration IncludeOptional modsecurity.d/*.conf IncludeOptional modsecurity.d/activated_rules/*.conf IncludeOptional modsecurity.d/local_rules/*.conf </IfModule> We need to add in one line at the bottom to add the CWAF configuration, which in turn loads the CWAF rules. That line is Include \"/usr/local/cwaf/etc/cwaf.conf\" . The bottom of this file should look like this when you are done: # ModSecurity Core Rules Set and Local configuration IncludeOptional modsecurity.d/*.conf IncludeOptional modsecurity.d/activated_rules/*.conf IncludeOptional modsecurity.d/local_rules/*.conf Include \"/usr/local/cwaf/etc/cwaf.conf\" </IfModule> Now save your changes (with vi it's SHIFT+:+wq! ) and restart httpd: systemctl restart httpd If httpd starts OK, then you are ready to start using mod_security with the CWAF. Conclusion mod_security with CWAF is another tool that can be used to help harden an Apache web server. Because CWAF's passwords require punctuation and because the standalone installation does not send that punctuation correctly, managing CWAF rules requires logging into the CWAF site and downloading rules and changes. mod_security , like other hardening tools, has the potential of false-positive responses, so you must be prepared to tune this tool to your installation. Like other solutions mentioned in the Apache Hardened Web Server guide , there are other free and fee-based solutions for mod_security rules, and for that matter, other WAF applications available. You can take a look at one of these at Atomicorp's mod_security site .","title":"Web-based Application firewall (WAF)"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#web-based-application-firewall-waf","text":"","title":"Web-based Application Firewall (WAF)"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#prerequisites","text":"A Rocky Linux Web Server running Apache Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding that installing this tool also requires monitoring of actions and tuning to your environment An account on Comodo's WAF site All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#introduction","text":"mod_security is an open-source web-based application firewall (WAF). It is just one possible component of a hardened Apache web server setup and can be used with, or without, other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server guide . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing. One thing that is missing with mod_security when installed from the generic Rocky Linux repositories, is that the rules installed are minimal at best. To get a more extensive package of free mod_security rules, we are using Comodo's WAF installation procedure after installing the base package. Note that Comodo is a business that sells lots of tools to help secure networks. The free mod_security tools may not be free forever and they do require that you setup a login with Comodo in order to gain access to the rules.","title":"Introduction"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#installing-mod_security","text":"To install the base package, use this command which will install any missing dependencies. We also need wget so if you haven't installed it, do that as well: dnf install mod_security wget","title":"Installing mod_security"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#setting-up-your-comodo-account","text":"To setup your free account, go to Comodo's WAF site , and click the \"Signup\" link at the top of the page. You will be required to setup username and password information but no credit-card or other billing will be done. The credentials that you use for signing on to the web site will be used in your setup of Comodo's software and also to obtain the rules, so you will need to keep these safe in a password manager somewhere. Please note that the \"Terms and Conditions\" section of the form that you need to fill out to use Comodo Web Application Firewall (CWAF) is written to cover all of their products and services. That said, you should read this carefully before agreeing to the terms!","title":"Setting Up Your Comodo account"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#installing-cwaf","text":"Before you start, in order for the script to actually run after we download it, you are going to need some development tools. Install the package with: dnf group install 'Development Tools' In addition, you will need to have your web server running for Comodo to see mod_security correctly. So start it if it is not already running: systemctl start httpd After signing up with Comodo, you will get an email with instructions on what to do next. Essentially, what you need to do is to login to the web site with your new credentials and then download the client install script. From the root directory of your server, use the wget command to download the installer: wget https://waf.comodo.com/cpanel/cwaf_client_install.sh Run the installer by typing: bash cwaf_client_install.sh This will extract the installer and start the process, echoing to the screen. You'll get a message part way down: No web host management panel found, continue in 'standalone' mode? [y/n]: Type \"y\" and let the script continue. You may also get this notice: Some required perl modules are missed. Install them? This can take a while. [y/n]: If so type \"y\" and allow those missing modules to install. Enter CWAF login: username@domain.com Enter password for 'username@domain.com' (will not be shown): ************************* Confirm password for 'username@domain.com' (will not be shown): ************************ Please note here that you will probably have to download the rules and install them in the correct location, as the password field requires a punctuation or special character, but the configuration file apparently has issues with this when sending it to Comodo's site from the installer or update script. These scripts will always fail with a credentials error. This probably doesn't affect administrators who have web servers running with a GUI front end (Cpanel / Plesk) but if you are running the program standalone as we are in our example, it does. You can find the workaround below . Enter absolute CWAF installation path prefix (/cwaf will be appended): /usr/local Install into '/usr/local/cwaf' ? [y/n]: Just accept the path as given and then type \"y\" in the next field for the install path. If you have a non-standard path to the configuration file for Apache/nginx, you would enter it here, otherwise just hit 'Enter' for no changes: If you have non-standard Apache/nginx config path enter it here: Here is where the failure comes in, and the only workaround is to manually download and install the rules. Answer the prompts as shown below: Do you want to use HTTP GUI to manage CWAF rules? [y/n]: n Do you want to protect your server with default rule set? [y/n]: y But expect to get the next message as well: Warning! Rules have not been updated. Check your credentials and try again later manually +------------------------------------------------------ | LOG : Warning! Rules have not been updated. Check your credentials and try again later manually +------------------------------------------------------ | Installation complete! | Please add the line: | Include \"/usr/local/cwaf/etc/modsec2_standalone.conf\" | to Apache config file. | To update ModSecurity ruleset run | /usr/local/cwaf/scripts/updater.pl | Restart Apache after that. | You may find useful utility /usr/local/cwaf/scripts/cwaf-cli.pl | Also you may examine file | /usr/local/cwaf/INFO.TXT | for some useful software information. +------------------------------------------------------ | LOG : All Done! | LOG : Exiting That's a little frustrating. You can go to your account on the Comodo web site and change your password and re-run the install script, BUT, it won't change anything. The credentials will still fail.","title":"Installing CWAF"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#cwaf-rules-file-workaround","text":"To fix this, we need to manually install the rules from the web site. This is done by logging into your account on https://waf.comodo.com and clicking on the the \"Download Full Rule Set\" link. You'll then need to copy the rules to your web server using scp' Example: scp cwaf_rules-1.233.tgz root@mywebserversdomainname.com:/root/ Once the tar gzip file has been copied over, move the file to the rules directory: mv /root/cwaf_rules-1.233.tgz /usr/local/cwaf/rules/ Then navigate to the rules directory: cd /usr/local/cwaf/rules/ And uncompress the rules: tar xzvf cwaf_rules-1.233.tgz Any partial updates to the rules will have to be handled in the same way. This is where paying for rules and support can come in handy. It all depends on your budget.","title":" CWAF Rules File Workaround"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#configuring-cwaf","text":"When we installed mod_security , the default configuration file was installed in /etc/httpd/conf.d/mod_security.conf . The next thing we need to do is to modify this in two places. Start by editing the file: vi /etc/httpd/conf.d/mod_security.conf At the very top of the file, you will see: <IfModule mod_security2.c> # Default recommended configuration SecRuleEngine On Beneath the SecRuleEngine On line add SecStatusEngine On so that the top of the file will now look like this: <IfModule mod_security2.c> # Default recommended configuration SecRuleEngine On SecStatusEngine On Next go to the bottom of this configuration file. We need to tell mod_security where to load the rules. You should see this at the bottom of the file before you make changes: # ModSecurity Core Rules Set and Local configuration IncludeOptional modsecurity.d/*.conf IncludeOptional modsecurity.d/activated_rules/*.conf IncludeOptional modsecurity.d/local_rules/*.conf </IfModule> We need to add in one line at the bottom to add the CWAF configuration, which in turn loads the CWAF rules. That line is Include \"/usr/local/cwaf/etc/cwaf.conf\" . The bottom of this file should look like this when you are done: # ModSecurity Core Rules Set and Local configuration IncludeOptional modsecurity.d/*.conf IncludeOptional modsecurity.d/activated_rules/*.conf IncludeOptional modsecurity.d/local_rules/*.conf Include \"/usr/local/cwaf/etc/cwaf.conf\" </IfModule> Now save your changes (with vi it's SHIFT+:+wq! ) and restart httpd: systemctl restart httpd If httpd starts OK, then you are ready to start using mod_security with the CWAF.","title":"Configuring CWAF"},{"location":"guides/web/apache_hardened_webserver/modsecurity/#conclusion","text":"mod_security with CWAF is another tool that can be used to help harden an Apache web server. Because CWAF's passwords require punctuation and because the standalone installation does not send that punctuation correctly, managing CWAF rules requires logging into the CWAF site and downloading rules and changes. mod_security , like other hardening tools, has the potential of false-positive responses, so you must be prepared to tune this tool to your installation. Like other solutions mentioned in the Apache Hardened Web Server guide , there are other free and fee-based solutions for mod_security rules, and for that matter, other WAF applications available. You can take a look at one of these at Atomicorp's mod_security site .","title":"Conclusion"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/","tags":["web","security","ossec-hids","hids"],"text":"Host-based Intrusion Detection System (HIDS) Prerequisites Proficiency with a command-line text editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding that installing this tool also requires monitoring of actions and tuning to your environment All commands are run as the root user or using sudo Introduction ossec-hids is a host intrusion detection system that offers automatic action-response steps to help mitigate host intrusion attacks. It is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server document. This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing. Installing Atomicorp's Repository To install ossec-hids , we need a third-party repository from Atomicorp. Atomicorp also offers a reasonably priced fee-based supported version for those who would like professional support if they run into trouble. If you'd prefer support, and have the budget for it, check out Atomicorp's paid ossec-hids version. Since we are going to need just a few packages from Atomicorp's free repository, we are going to modify the repository after we have it downloaded. Downloading the repository requires wget so install that first if you don't have it. Install the EPEL repository as well if you do not have it installed already, with: dnf install wget epel-release Now download and enable Atomicorp's free repository: wget -q -O - http://www.atomicorp.com/installers/atomic | sh This script will ask you to agree to the terms. Either type \"yes\" or hit 'Enter' to accept \"yes\" as the default. Next, it will ask you if you want to enable the repository by default, and again we want to accept the default or type \"yes\". Configuring The Atomicorp Repository We only need the atomic repository for a couple of packages. For this reason, we are going to modify the repository and specify only those packages be chosen: vi /etc/yum.repos.d/atomic.repo And then add this line beneath the \"enabled = 1\" in the top section: includepkgs = ossec* inotify-tools That's the only change we need, so save your changes and get out of the repository, (in vi that would be esc to enter command mode, then : wq to save and quit). This restricts the Atomicorp repository to only install and update these packages. Installing ossec-hids Now that we have the repository downloaded and configured, we need to install the packages: dnf install ossec-hids-server ossec-hids inotify-tools Configuring ossec-hids There are a number of changes that need to be made to the ossec-hids configuration file. Most of these have to do with server administrator notification and log locations. ossec-hids looks at the logs to try and determine if there is an attack, and whether to apply mitigation. It also sends reports to the server administrator, either just as a notification, or that a mitigation procedure has been activated based on what ossec-hids has seen. To edit the configuration file type: vi /var/ossec/etc/ossec.conf We will break apart this configuration showing the changes in line and explaining them as we go: <global> <email_notification>yes</email_notification> <email_to>admin1@youremaildomain.com</email_to> <email_to>admin2@youremaildomain.com</email_to> <smtp_server>localhost</smtp_server> <email_from>ossec-webvms@yourwebserverdomain.com.</email_from> <email_maxperhour>1</email_maxperhour> <white_list>127.0.0.1</white_list> <white_list>192.168.1.2</white_list> </global> By default, email notifications are turned off and the <global> configuration is basically empty. You want to turn on email notification and identify the people who should receive the email reports by email address. The <smtp_server> section currently shows localhost, however you can specify an email server relay if you prefer, or simply setup the postfix email settings for the local host by following this guide . You need to set the \"from\" address, so that you can deal with SPAM filters on your email server which may see this email as SPAM. To avoid getting inundated with email, set the email reporting to 1 per hour. You can expand this or remark out this command if you like while you are getting started with ossec-hids and need to see things quickly. The <white_list> sections deal with the server's localohost IP and with the \"public\" address (remember, we are using a private address to demonstrate this) of the firewall, from which all connections on the trusted network will show. You can add multiple <white_list> entries as needed. <syscheck> <!-- Frequency that syscheck is executed -- default every 22 hours --> <frequency>86400</frequency> ... </syscheck> The <syscheck> section takes a look at a list of directories to include and exclude when looking for compromised files. Think of this as yet another tool for watching and protecting the file system against vulnerabilities. You should review the list of directories and see if there are others that you want to add in to the <syscheck> section. The <rootcheck> section just beneath the <syscheck> section is yet another protection layer. The locations that both <syscheck> and <rootcheck> watch are editable, but you probably will not need to make any changes to them. Changing the <frequency> for the <rootcheck> run to once every 24 hours (86400 seconds) from the default of 22 hours is an optional change shown above. <localfile> <log_format>apache</log_format> <location>/var/log/httpd/*access_log</location> </localfile> <localfile> <log_format>apache</log_format> <location>/var/log/httpd/*error_log</location> </localfile> The <localfile> section deals with the locations of the logs we want to watch. There are entries already in place for syslog and secure logs that you just need to verify the path to, but everything else can be left as is. We do need to add in the Apache log locations however, and we want to add these in as wild_cards, because we could have a bunch of logs for a lot of different web customers. That format is shown above. <command> <name>firewall-drop</name> <executable>firewall-drop.sh</executable> <expect>srcip</expect> </command> <active-response> <command>firewall-drop</command> <location>local</location> <level>7</level> <timeout>1200</timeout> </active-response> Finally, towards the end of the file we need to add the active response section. This section contains two parts, a <command> section, and the <active-response> section. The \"firewall-drop\" script already exists within the ossec path. It tells ossec_hids that if a level of 7 is reached, add a firewall rule to block the IP address for 20 minutes. Obviously, you can change the timeout value. Just remember that the configuration file times are all in seconds. Once you have made all of the configuration changes you need, simply enable and start the service. If everything starts correctly, you should be ready to move on: systemctl enable ossec-hids And then: systemctl start ossec-hids There are a lot of options for the ossec-hids configuration file. You can find out about these options by visiting the official documentation site . Conclusion ossec-hids is just one element of an Apache hardened web server. It can be used with other tools to gain better security for your web site. While the installation and configuration are relatively straight forward, you will find that this is not an 'install it and forget it' application. You will need to tune it to your environment to gain the most security with the least amount of false-positive responses.","title":"Host-based Intrustion Detection System (HIDS)"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/#host-based-intrusion-detection-system-hids","text":"","title":"Host-based Intrusion Detection System (HIDS)"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/#prerequisites","text":"Proficiency with a command-line text editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding that installing this tool also requires monitoring of actions and tuning to your environment All commands are run as the root user or using sudo","title":"Prerequisites"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/#introduction","text":"ossec-hids is a host intrusion detection system that offers automatic action-response steps to help mitigate host intrusion attacks. It is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server document. This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing.","title":"Introduction"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/#installing-atomicorps-repository","text":"To install ossec-hids , we need a third-party repository from Atomicorp. Atomicorp also offers a reasonably priced fee-based supported version for those who would like professional support if they run into trouble. If you'd prefer support, and have the budget for it, check out Atomicorp's paid ossec-hids version. Since we are going to need just a few packages from Atomicorp's free repository, we are going to modify the repository after we have it downloaded. Downloading the repository requires wget so install that first if you don't have it. Install the EPEL repository as well if you do not have it installed already, with: dnf install wget epel-release Now download and enable Atomicorp's free repository: wget -q -O - http://www.atomicorp.com/installers/atomic | sh This script will ask you to agree to the terms. Either type \"yes\" or hit 'Enter' to accept \"yes\" as the default. Next, it will ask you if you want to enable the repository by default, and again we want to accept the default or type \"yes\".","title":"Installing Atomicorp's Repository"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/#configuring-the-atomicorp-repository","text":"We only need the atomic repository for a couple of packages. For this reason, we are going to modify the repository and specify only those packages be chosen: vi /etc/yum.repos.d/atomic.repo And then add this line beneath the \"enabled = 1\" in the top section: includepkgs = ossec* inotify-tools That's the only change we need, so save your changes and get out of the repository, (in vi that would be esc to enter command mode, then : wq to save and quit). This restricts the Atomicorp repository to only install and update these packages.","title":"Configuring The Atomicorp Repository"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/#installing-ossec-hids","text":"Now that we have the repository downloaded and configured, we need to install the packages: dnf install ossec-hids-server ossec-hids inotify-tools","title":"Installing ossec-hids"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/#configuring-ossec-hids","text":"There are a number of changes that need to be made to the ossec-hids configuration file. Most of these have to do with server administrator notification and log locations. ossec-hids looks at the logs to try and determine if there is an attack, and whether to apply mitigation. It also sends reports to the server administrator, either just as a notification, or that a mitigation procedure has been activated based on what ossec-hids has seen. To edit the configuration file type: vi /var/ossec/etc/ossec.conf We will break apart this configuration showing the changes in line and explaining them as we go: <global> <email_notification>yes</email_notification> <email_to>admin1@youremaildomain.com</email_to> <email_to>admin2@youremaildomain.com</email_to> <smtp_server>localhost</smtp_server> <email_from>ossec-webvms@yourwebserverdomain.com.</email_from> <email_maxperhour>1</email_maxperhour> <white_list>127.0.0.1</white_list> <white_list>192.168.1.2</white_list> </global> By default, email notifications are turned off and the <global> configuration is basically empty. You want to turn on email notification and identify the people who should receive the email reports by email address. The <smtp_server> section currently shows localhost, however you can specify an email server relay if you prefer, or simply setup the postfix email settings for the local host by following this guide . You need to set the \"from\" address, so that you can deal with SPAM filters on your email server which may see this email as SPAM. To avoid getting inundated with email, set the email reporting to 1 per hour. You can expand this or remark out this command if you like while you are getting started with ossec-hids and need to see things quickly. The <white_list> sections deal with the server's localohost IP and with the \"public\" address (remember, we are using a private address to demonstrate this) of the firewall, from which all connections on the trusted network will show. You can add multiple <white_list> entries as needed. <syscheck> <!-- Frequency that syscheck is executed -- default every 22 hours --> <frequency>86400</frequency> ... </syscheck> The <syscheck> section takes a look at a list of directories to include and exclude when looking for compromised files. Think of this as yet another tool for watching and protecting the file system against vulnerabilities. You should review the list of directories and see if there are others that you want to add in to the <syscheck> section. The <rootcheck> section just beneath the <syscheck> section is yet another protection layer. The locations that both <syscheck> and <rootcheck> watch are editable, but you probably will not need to make any changes to them. Changing the <frequency> for the <rootcheck> run to once every 24 hours (86400 seconds) from the default of 22 hours is an optional change shown above. <localfile> <log_format>apache</log_format> <location>/var/log/httpd/*access_log</location> </localfile> <localfile> <log_format>apache</log_format> <location>/var/log/httpd/*error_log</location> </localfile> The <localfile> section deals with the locations of the logs we want to watch. There are entries already in place for syslog and secure logs that you just need to verify the path to, but everything else can be left as is. We do need to add in the Apache log locations however, and we want to add these in as wild_cards, because we could have a bunch of logs for a lot of different web customers. That format is shown above. <command> <name>firewall-drop</name> <executable>firewall-drop.sh</executable> <expect>srcip</expect> </command> <active-response> <command>firewall-drop</command> <location>local</location> <level>7</level> <timeout>1200</timeout> </active-response> Finally, towards the end of the file we need to add the active response section. This section contains two parts, a <command> section, and the <active-response> section. The \"firewall-drop\" script already exists within the ossec path. It tells ossec_hids that if a level of 7 is reached, add a firewall rule to block the IP address for 20 minutes. Obviously, you can change the timeout value. Just remember that the configuration file times are all in seconds. Once you have made all of the configuration changes you need, simply enable and start the service. If everything starts correctly, you should be ready to move on: systemctl enable ossec-hids And then: systemctl start ossec-hids There are a lot of options for the ossec-hids configuration file. You can find out about these options by visiting the official documentation site .","title":"Configuring ossec-hids"},{"location":"guides/web/apache_hardened_webserver/ossec-hids/#conclusion","text":"ossec-hids is just one element of an Apache hardened web server. It can be used with other tools to gain better security for your web site. While the installation and configuration are relatively straight forward, you will find that this is not an 'install it and forget it' application. You will need to tune it to your environment to gain the most security with the least amount of false-positive responses.","title":"Conclusion"},{"location":"guides/web/apache_hardened_webserver/rkhunter/","tags":["server","security","rkhunter"],"text":"Rootkit Hunter Prerequisites A Rocky Linux Web Server running Apache Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of what can trigger a response to changed files on the file system (such as package updates) is helpful All commands are run as the root user or sudo Introduction rkhunter (Root Kit Hunter) is a Unix-based tool that scans for rootkits, backdoors, and possible local exploits. It is a good part of a hardened web server, and is designed to notify the administrator quickly when something suspicious happens on the server's file system. rkhunter is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server guide . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing. Installing rkhunter rkhunter requires the EPEL (Extra Packages for Enterprise Linux) repository. So install that repository if you don't have it installed already: dnf install epel-release Then install rkhunter : dnf install rkhunter Configuring rkhunter The only configuration options that need to be set are those dealing with mailing reports to the administrator. To modify the configuration file, run: vi /etc/rkhunter.conf And then search for: #MAIL-ON-WARNING=me@mydomain root@mydomain Remove the remark here and change the me@mydomain.com to reflect your email address. Then change the root@mydomain to root@whatever_the_server_name_is. You may also need to setup Postfix Email for Reporting in order to get the email section to work correctly. Running rkhunter rkhunter can be run by typing it at the command-line. There is a cron job installed for you in /etc/cron.daily , but if you want to automate the procedure on a different schedule, look at the Automating cron jobs guide . You'll also need to move the script somewhere other than /etc/cron.daily , such as /usr/local/sbin and then call it from your custom cron job. The easiest method, of course, is to leave the default cron.daily setup intact. Before you run allow rkhunter to run automatically, run the command manually with the \"--propupd\" flag to create the rkhunter.dat file, and to make sure that your new environment is recognized without issue: rkhunter --propupd To run rkhunter manually: rkhunter --check This will echo back to the screen as the checks are performed, prompting you to [Press <ENTER> to continue] after each section. Conclusion rkhunter is one part of a hardened server strategy that can help in monitoring the file system and reporting any issues to the administrator. It is perhaps one of the easiest hardening tools to install, configure, and run.","title":"Rootkit Hunter"},{"location":"guides/web/apache_hardened_webserver/rkhunter/#rootkit-hunter","text":"","title":"Rootkit Hunter"},{"location":"guides/web/apache_hardened_webserver/rkhunter/#prerequisites","text":"A Rocky Linux Web Server running Apache Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of what can trigger a response to changed files on the file system (such as package updates) is helpful All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/web/apache_hardened_webserver/rkhunter/#introduction","text":"rkhunter (Root Kit Hunter) is a Unix-based tool that scans for rootkits, backdoors, and possible local exploits. It is a good part of a hardened web server, and is designed to notify the administrator quickly when something suspicious happens on the server's file system. rkhunter is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server guide . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing.","title":"Introduction"},{"location":"guides/web/apache_hardened_webserver/rkhunter/#installing-rkhunter","text":"rkhunter requires the EPEL (Extra Packages for Enterprise Linux) repository. So install that repository if you don't have it installed already: dnf install epel-release Then install rkhunter : dnf install rkhunter","title":"Installing rkhunter"},{"location":"guides/web/apache_hardened_webserver/rkhunter/#configuring-rkhunter","text":"The only configuration options that need to be set are those dealing with mailing reports to the administrator. To modify the configuration file, run: vi /etc/rkhunter.conf And then search for: #MAIL-ON-WARNING=me@mydomain root@mydomain Remove the remark here and change the me@mydomain.com to reflect your email address. Then change the root@mydomain to root@whatever_the_server_name_is. You may also need to setup Postfix Email for Reporting in order to get the email section to work correctly.","title":"Configuring rkhunter"},{"location":"guides/web/apache_hardened_webserver/rkhunter/#running-rkhunter","text":"rkhunter can be run by typing it at the command-line. There is a cron job installed for you in /etc/cron.daily , but if you want to automate the procedure on a different schedule, look at the Automating cron jobs guide . You'll also need to move the script somewhere other than /etc/cron.daily , such as /usr/local/sbin and then call it from your custom cron job. The easiest method, of course, is to leave the default cron.daily setup intact. Before you run allow rkhunter to run automatically, run the command manually with the \"--propupd\" flag to create the rkhunter.dat file, and to make sure that your new environment is recognized without issue: rkhunter --propupd To run rkhunter manually: rkhunter --check This will echo back to the screen as the checks are performed, prompting you to [Press <ENTER> to continue] after each section.","title":"Running rkhunter"},{"location":"guides/web/apache_hardened_webserver/rkhunter/#conclusion","text":"rkhunter is one part of a hardened server strategy that can help in monitoring the file system and reporting any issues to the administrator. It is perhaps one of the easiest hardening tools to install, configure, and run.","title":"Conclusion"},{"location":"learning/GitHub/github/","text":"GITHUB A. Penjelasan Git adalah tools yang berfungsi sebagai Version Control System (VCS) dan kalau diartikan ke bahasa kita artinya sebuah sistem pelacak perubahan pada file. Git itu bukanlah sebuah bahasa seperti halnya HTML,CSS atau Js bukan pula sebuah konsep atau aturan baku dalam pemrograman, melainkan sebuah software yang berfungsi untuk mengatur source code dari aplikasi yang sedang anda buat. Fungsi utamanya adalah untuk mengatur versi dari source code anda, menambahkan tanda/checkpoint ketika terjadi perubahan pada kode Anda dan tentunya akan mempermudah Anda untuk tetap mengetahui apa saja yang berubah dari source code Anda. Pada awalnya Git digunakan untuk membantu pengembangan Kernel Linux sebelum akhirnya dipakai lebih luas di berbagai pengembangan software lainnya dan dibuat multi-platform sehingga tersedia di hampir semua OS. B. Tutorial Installan Install Github di linux Menginstall Git untuk Linux Menginstall Git untuk Ubuntu, kamu hanya perlu mengetik perintah ini di terminal: $ sudo apt-get install git Konfigurasi Github Ketika proses instalasinya udah berhasil, langkah selanjutnya adalah set up konfigurasi detail untuk user GitHub, dengan mengetikkan kode dibawah ini. Kamu ganti \"user_name\" sama username GitHub kamu dan \"email_id\" kamu ganti sama email-id yang kamu pakai sewaktu membuat akun GitHub kamu. Nah, di bawah ini perintahnya: $ git config --global user.name \"user_name\" $ git config --global user.email \"email@domain.com\" C. Tutorial Penggunaan Buat Akun Membuka website https://github.com/ Kemudian mengisi Username, Email, dan password , setelah itu akan muncul halaman berikut Kemudian klik Pilih Sesuai kebutuhan dan Kemudian Continue sampai selesai kemudian akan muncul halaman Pada Halaman ini kita masih belum bisa menggunakan github karena kita harus memverifikasi akun yang dikirimkan ke email. Buka email kemudian klik verify email address dan akun sudah bisa dipakai. Upload File Untuk meupload file di github pertama-tama kita buat folder baru untuk projek kita dan kita beri nama latihan-git dengan menuliskan kode $ mkdir latihan-git Setelah membuat folder latihan-git navigasikan terminal kedalam folder latihan-git dengan perintah $ cd latihan-git Agar projek kita dapat diatur oleh git, maka kita perlu melakukan inisiasi git terlebih dahulu, caranya dengan mengetikkan perintah : $ git init Perintah tersebut akan membuat folder .git dan didalamnya berisi file-file yang akan digunakan oleh Git untuk mengatur dan mengontrol project kita. Setelah itu buatlah file dalam folder latihan-git yaitu klik kanan kemudian new document contoh beri nama domi. Kemudian ketikkan perintah $ git add domi Untuk mengetahui file sudah berhasil diupload atau tidak ketikka perintah $ git status Lalu akan muncul status file Setelah file telah terupload kemudian commit file tersebut dengan perintah $ git commit -m \u201cketerangan\u201d Commit berguna untuk menandai file ketika membuat dan diubah kita bisa memberi keterangan misal tanggal.Dan perintah -m untuk menambahkan keterangan misal tanggal. Hapus File Buka dulu folder project git Kemudian ketikkan perintah $ git rm (nama_file) $ git commit -m \"(keterangan)\" Setelah itu di push lagi $ git push Buat Branch Misalkan anda ingin menambahkan suatu fitur, namun anda tidak mau kode yang ada sekarang rusak karena fitur yang akan anda tambahkan masih belum stabil, Dalam Git anda dapat membuat branch terlebih dahulu. Branch ini bisa diartikan sebagai cabang dari branch master. segala perubahan yang anda lakukan pada branch yang anda buat tidak akan berpengaruh pada branch lainnya. Sebagai contoh kita buat branch dengan nama budak dengan perintah $ git branch budak Jika perintah dijalankan dengan benar maka ketika anda mengetikkan perintah git branch akan muncul branch-branch yang telah dibuat. budak master tanda Bintang menandakan bahwa anda sedang bekerja pada branch master, untuk berpindah ke branch yang baru saja dibuat (fix-css) ketikkan perintah berikut: $ git checkout budak Jika peritah di atas benar, maka akan ada pemberitahuan seperti berikut: Switched to branch 'budak' Hapus Branch Cara menghapus branch iyalah mengetikkan perintah $ git branch -d branch-name Kolaborasi Buka Repository Kemudian Pilih Setting Kemudian Klik Collaboration dan masukkan id atau email yang mau di add pada textbox klik \"add collaboration\" Fork Mengambil File dengan Menu Fork : Buka File yang akan di fork di profile orang yang mempunyai file yg ingin di fork setelah muncul seperti halaman di bawah kemudian klik menu fork di pojok kanan atas setelah klik fork maka file yg di fork sudah ada di profile Kasus Untuk mengetahui apa saja yang telah dirubah menurut branch $ git log --decorate Untuk mengetahui apa saja yang telah dirubah $ git diff (mengambil kode action pada branch) Untuk memunculkan apa saja yang file atau folder yang ada di branch yang telah dirubah menurut kode action setiap brach $ git show (mengambil kode action pada branch) Untuk memunculkan versi agar seimbang $ git log --oneline --decorate Rebase $ git fetch origin $ git rebase Squash Sebelum melakukan squash kita lihat status atau interface commit dengan mengetikkan perintah $ git rebase -i Setelah mengetikkan perintah tersebut akan tampil status commit terakhir dari project kita. Kemudian untuk men squash commit project kita ketikkan perintah $ git commit -i HEAD~(angka banyaknya commit kita yg ingin disquash) Kemudian akan muncul kode dan isi commit. Setelah itu ubah kata \"pick\" menjadi \"squash\" pada commit yang ingin dirubah. Setelah itu tekan CTRL+O kemudian enter kemudian CTRL+X","title":"GitHub"},{"location":"learning/GitHub/github/#github","text":"","title":"GITHUB"},{"location":"learning/GitHub/github/#a-penjelasan","text":"Git adalah tools yang berfungsi sebagai Version Control System (VCS) dan kalau diartikan ke bahasa kita artinya sebuah sistem pelacak perubahan pada file. Git itu bukanlah sebuah bahasa seperti halnya HTML,CSS atau Js bukan pula sebuah konsep atau aturan baku dalam pemrograman, melainkan sebuah software yang berfungsi untuk mengatur source code dari aplikasi yang sedang anda buat. Fungsi utamanya adalah untuk mengatur versi dari source code anda, menambahkan tanda/checkpoint ketika terjadi perubahan pada kode Anda dan tentunya akan mempermudah Anda untuk tetap mengetahui apa saja yang berubah dari source code Anda. Pada awalnya Git digunakan untuk membantu pengembangan Kernel Linux sebelum akhirnya dipakai lebih luas di berbagai pengembangan software lainnya dan dibuat multi-platform sehingga tersedia di hampir semua OS.","title":"A. Penjelasan"},{"location":"learning/GitHub/github/#b-tutorial-installan","text":"","title":"B. Tutorial Installan"},{"location":"learning/GitHub/github/#install-github-di-linux","text":"Menginstall Git untuk Linux Menginstall Git untuk Ubuntu, kamu hanya perlu mengetik perintah ini di terminal: $ sudo apt-get install git Konfigurasi Github Ketika proses instalasinya udah berhasil, langkah selanjutnya adalah set up konfigurasi detail untuk user GitHub, dengan mengetikkan kode dibawah ini. Kamu ganti \"user_name\" sama username GitHub kamu dan \"email_id\" kamu ganti sama email-id yang kamu pakai sewaktu membuat akun GitHub kamu. Nah, di bawah ini perintahnya: $ git config --global user.name \"user_name\" $ git config --global user.email \"email@domain.com\"","title":"Install Github di linux"},{"location":"learning/GitHub/github/#c-tutorial-penggunaan","text":"","title":"C. Tutorial Penggunaan"},{"location":"learning/GitHub/github/#buat-akun","text":"Membuka website https://github.com/ Kemudian mengisi Username, Email, dan password , setelah itu akan muncul halaman berikut Kemudian klik Pilih Sesuai kebutuhan dan Kemudian Continue sampai selesai kemudian akan muncul halaman Pada Halaman ini kita masih belum bisa menggunakan github karena kita harus memverifikasi akun yang dikirimkan ke email. Buka email kemudian klik verify email address dan akun sudah bisa dipakai.","title":"Buat Akun"},{"location":"learning/GitHub/github/#upload-file","text":"Untuk meupload file di github pertama-tama kita buat folder baru untuk projek kita dan kita beri nama latihan-git dengan menuliskan kode $ mkdir latihan-git Setelah membuat folder latihan-git navigasikan terminal kedalam folder latihan-git dengan perintah $ cd latihan-git Agar projek kita dapat diatur oleh git, maka kita perlu melakukan inisiasi git terlebih dahulu, caranya dengan mengetikkan perintah : $ git init Perintah tersebut akan membuat folder .git dan didalamnya berisi file-file yang akan digunakan oleh Git untuk mengatur dan mengontrol project kita. Setelah itu buatlah file dalam folder latihan-git yaitu klik kanan kemudian new document contoh beri nama domi. Kemudian ketikkan perintah $ git add domi Untuk mengetahui file sudah berhasil diupload atau tidak ketikka perintah $ git status Lalu akan muncul status file Setelah file telah terupload kemudian commit file tersebut dengan perintah $ git commit -m \u201cketerangan\u201d Commit berguna untuk menandai file ketika membuat dan diubah kita bisa memberi keterangan misal tanggal.Dan perintah -m untuk menambahkan keterangan misal tanggal.","title":"Upload File"},{"location":"learning/GitHub/github/#hapus-file","text":"Buka dulu folder project git Kemudian ketikkan perintah $ git rm (nama_file) $ git commit -m \"(keterangan)\" Setelah itu di push lagi $ git push","title":"Hapus File"},{"location":"learning/GitHub/github/#buat-branch","text":"Misalkan anda ingin menambahkan suatu fitur, namun anda tidak mau kode yang ada sekarang rusak karena fitur yang akan anda tambahkan masih belum stabil, Dalam Git anda dapat membuat branch terlebih dahulu. Branch ini bisa diartikan sebagai cabang dari branch master. segala perubahan yang anda lakukan pada branch yang anda buat tidak akan berpengaruh pada branch lainnya. Sebagai contoh kita buat branch dengan nama budak dengan perintah $ git branch budak Jika perintah dijalankan dengan benar maka ketika anda mengetikkan perintah git branch akan muncul branch-branch yang telah dibuat. budak master tanda Bintang menandakan bahwa anda sedang bekerja pada branch master, untuk berpindah ke branch yang baru saja dibuat (fix-css) ketikkan perintah berikut: $ git checkout budak Jika peritah di atas benar, maka akan ada pemberitahuan seperti berikut: Switched to branch 'budak'","title":"Buat Branch"},{"location":"learning/GitHub/github/#hapus-branch","text":"Cara menghapus branch iyalah mengetikkan perintah $ git branch -d branch-name","title":"Hapus Branch"},{"location":"learning/GitHub/github/#kolaborasi","text":"Buka Repository Kemudian Pilih Setting Kemudian Klik Collaboration dan masukkan id atau email yang mau di add pada textbox klik \"add collaboration\"","title":"Kolaborasi"},{"location":"learning/GitHub/github/#fork","text":"Mengambil File dengan Menu Fork : Buka File yang akan di fork di profile orang yang mempunyai file yg ingin di fork setelah muncul seperti halaman di bawah kemudian klik menu fork di pojok kanan atas setelah klik fork maka file yg di fork sudah ada di profile","title":"Fork"},{"location":"learning/GitHub/github/#kasus","text":"Untuk mengetahui apa saja yang telah dirubah menurut branch $ git log --decorate Untuk mengetahui apa saja yang telah dirubah $ git diff (mengambil kode action pada branch) Untuk memunculkan apa saja yang file atau folder yang ada di branch yang telah dirubah menurut kode action setiap brach $ git show (mengambil kode action pada branch) Untuk memunculkan versi agar seimbang $ git log --oneline --decorate Rebase $ git fetch origin $ git rebase Squash Sebelum melakukan squash kita lihat status atau interface commit dengan mengetikkan perintah $ git rebase -i Setelah mengetikkan perintah tersebut akan tampil status commit terakhir dari project kita. Kemudian untuk men squash commit project kita ketikkan perintah $ git commit -i HEAD~(angka banyaknya commit kita yg ingin disquash) Kemudian akan muncul kode dan isi commit. Setelah itu ubah kata \"pick\" menjadi \"squash\" pada commit yang ingin dirubah. Setelah itu tekan CTRL+O kemudian enter kemudian CTRL+X","title":"Kasus"},{"location":"learning/Linux_Ubuntu/commandLine/","text":"CommandLine A. Penjelasan Ubuntu sangat terkenal dengan CLI-nya (Command Line Interface). CLI sendiri adalah antar muka yang tidak menyediakan grafik, baik berupa gambar-gambar, jendela-jendela ataupun animasi-animasi yang bisa memanjakan pengguna, melainkan hanya berupa teks yang harus diketikkan oleh pengguna. Jadi, apabila user ingin melakukan operasi dalam sistem operasi tersebut, misalnya melakukan copy, rename, cut, delete, dan sebagainya, maka pengguna harus megetikkan perintah berupa teks dengan cara manual dan bukan dengan klik-klik seperti pada interface GUI (Graphic User Interface). Pada Ubuntu versi Desktop sudah menggunakan interface grafik, namun juga disediakan sebuah aplikasi yang diperuntukkan bagi pengguna yang ingin menggunakan tampilan/interface CLI, baik hanya untuk belajar atau memang keahliannya menggunakan CLI, karena memang cukup banyak hal yang bisa dilakukan dengan interface CLI ini yang tidak bisa dilakukan pada interface GUI, terlebih pada Ubuntu versi Server yang semuanya harus dilakukan dengan mode teks, walaupun sebenarnya bisa diinstalkan mode grafiknya. Aplikasi pada Ubuntu Desktop yang bisa digunakan untuk menggunakan mode teks adalah Terminal, yang bisa diakses dengan mengklik Aplication \u2013> Accessories \u2013> Terminal. B. Tutorial Penggunaan Perintah dasar Command Line Perintah dasar Command Line di Linux Ubuntu 16.04 desktop dengan virtual box Perintah-perintah Dasar di Linux Ubuntu.Ubuntu sangat terkenal dengan CLI-nya (Command Line Interface). CLI sendiri adalah antar muka yang tidak menyediakan grafik, baik berupa gambar-gambar, jendela-jendela ataupun animasi-animasi yang bisa memanjakan pengguna, melainkan hanya berupa teks yang harus diketikkan oleh pengguna. Jadi, apabila user ingin melakukan operasi dalam sistem operasi tersebut, misalnya melakukan copy, rename, cut, delete, dan sebagainya, maka pengguna harus megetikkan perintah berupa teks dengan cara manual dan bukan dengan klik-klik seperti pada interface GUI (Graphic User Interface). Berikut ini adalah beberapa perintah yang bisa digunakan di sistem operasi Ubuntu pada mode CLI, baik Desktop maupun Server, yang juga banyak untuk bisa digunakan pada distro yang lain. Pada contoh ini saya menggunakan Ubuntu Desktop 10.10. 1. sudo su Digunakan untuk login sebagai root/pengguna tertinggi Sintaks : sudo su 2. login Digunakan untuk login sebagai user lain, namun harus menjadi root dulu untuk bisa menjalankan peirntah ini. Sintaks : login namauser Contoh : login adam 3. cd Digunakan untuk berpindah direktori Sintaks : cd alamat_direktori Contoh : cd /var/www 4. pwd Digunakan untuk memperlihatkan di direktori mana posisi kita berada sekarang. Sintaks : pwd 5. ls Digunakan untuk melihat isi sebuah direktori. Sintaks : ls 6. cp Digunakan untuk melakukan copy file. Sintaks : cp /direktori/file_yang_ingin_dicopy /direktori tujuan Contoh : cp /etc/file1.txt /var/www 7. mv Digunakan untuk melakukan memindahkan, cut atau rename file. Sintaks : mv /direktori/file_yang_ingin_dicut /direktori tujuan (cut) mv /direktori/file_yang_ingin_direname /nama_baru_file (rename) Contoh: mv /etc/file1.txt /var/www mv /etc/file1.txt file2.txt 8. mkdir Digunakan untuk membuat folder baru. Sintaks : mkdir nama_folder Contoh : mkdir folder1 9. rmdir Digunakan untuk menghapus folder. Sintaks : rmdir nama_folder Contoh : rmdir folder1 10. touch Digunakan untuk membuat file baru. Sintaks : touch nama_file Contoh : touch file1.txt 11. rm Digunakan untuk menghapus file. Sintaks : rm nama_file Contoh : rm file1.txt 12. more Digunakan untuk menampilkan isi sebuah file Sintaks : more nama_fie Contoh : more file1.txt 13. echo Digunakan untuk menuliskan sesuatu kata atau kalimat ke sebuah file. Sintaks : echo \u201cisi pesan\u201d nama_file Contoh : echo \u201cHai ini adalah contoh pesan\u201d >> file1.txt 14. adduser Digunakan untuk menambah user baru. Sintaks : adduser nama_user Contoh : adduser adamkurniawan 15. addgroup Digunakan untuk menambah group baru Sintaks : addgroup nama_group Contoh : addgroup grup1 16. lsusb Digunakan untuk melihat perangkat usb yang sedang terkoneksi ke komputer Sintaks : lsusb 17. lspci Digunakan untuk melihat perangkat pci yang sedang terkoneksi ke komputer Sintaks : lspci 18. lshw Digunakan untuk melihat hardware komputer. Sintaks : lshw 19. dmesg Digunakan untuk melihat hardware yang sedang beraktifitas Sintaks : dmseg 20. top Digunakan untuk melihat proses yang sedang berjalan, seperti Task Manager pada Windows. Sintaks : top 21. cpuinfo Digunakan untuk melihat spesifikasi komputer. Sintaks : more /proc/cpuinfo 22. meminfo Digunakan untuk melihat status RAM Sintaks : more /proc/meminfo 23. clear Digunakan untuk membersihkan layar Sintaks : clear 24. halt Digunakan untuk mematikan komputer, namun harus sebagai root. Sintaks : halt 25. reboot Digunakan untuk merestart komputer, namun harus sebagai root. Sintaks : reboot 26. exit Digunakan untuk keluar dari terminal. Sintaks : exit 27. wget Digunakan untuk mendownload via terminal Sintaks : wget link_download Contoh : wget www.insightcalendar.com/Insight_Calendar_1-1_Setup.exe 28. ifconfig Digunakan untuk melihat konfigurasi ethernet/kartu jaringan. Sintaks : ifconfig 29. apt-get Digunakan untuk memperoleh paket/software dari repository ubuntu secara online. Sintax : apt-get nama_paket Contoh : apt-get update (untuk melakukan update repository) apt-get update wine (untuk mendapatkan paket wine) 30. tar Digunakan untuk melakukan extract file. Sintaks : tar [parameter] nama_file Contoh : tar -xzvf komodo-edit-5.2.4-4343-linux-libcpp6-x86.tar.gz 31. nautilus Digunakan untuk membuka tampilan GUI secara langsung. Sintaks : nautilus Contoh : sudo nautilus (menggunakan mode GUI dengan status root) 32. df -h melihat sisa kapasitas harddisk. sintaks : df -h 33. who digunakan untuk melihat nama login kita. sintaks : who 34. cat digunakan untuk membuka file. sintaks : cat contoh: cat test.txt 35. date melihat tanggal sintaks : date 36. cal melihat kalender sintaks : melihat tanggal 37. hostname Menampilkan nama komputer. sintaks: hostname 38. free Melihat Free memory. sintaks: free 39. History melihat perintah apa saja yang pernah diketik sintaks : History 40. deluser Menghapus user dari sistem sintaks : deluser [nama user] uname -r = Melihat kernel yang digunakan pada OS uname -a = Informasi system kernel anda cat /proc/cpuinfo = Melihat file pada /proc directori yang bukan merupakan file nyata (not real files). cat /proc/interrupts = Melihat alamat interrupt yang dipakai. cat /proc/version = Versi dari Linux dan informasi lainnya. cat /proc/filesystems = Melihat filesystem yang digunakan. cat /etc/printcap = Melihat printer yang telah disetup finger username = Melihat informasi user, coba jalankan; fingerroot last = Melihat user sebelumnya yang telah login di komputer. uptime = Melihat jumlah waktu pemakaian komputer oleh seseorang, terhitung proses reboot terakhir. ps (=print status)= Melihat proses-proses yang dijalankan oleh user ps axu = Melihat seluruh proses yang dijalankan, walaupun tanpa terminal control, juga ditampilkan nama dari user untuk setiap proses. top = Melihat proses yang berjalan, dengan urutan penggunaan cpu. apropos = Untuk mencari perintah pada sistem operasi yang mempunyai fungsi yang sama. chmod = Mengubah perizinan suatu direktori/file. wc = Menghitung jumlah kata, jumlah baris dan jumlah karakter dalam suatu file . man = Singkatan dari manual yaitu untuk menampilkan halaman manual untuk semua perintah UNIX. grep = Mencari isi suatu file di sembarang directori. pwd = Menampilkan nama direktori dimana Anda saat itu sedang berada. ps = Digunakan untuk memonitor informasi tentang proses yang aktif dalam sistem UNIX. kill = Digunakan untuk menghentikan proses yang sedang berjalan. bc = Perintah bc dapat digunakan sebagai calculator. wall = Pengiriman pesan oleh super user. :w di gunakan u/ menyimpan file or sama dengan (save). :q digunakan u/ keluar dari editor tandan mentimpan file. :wq digunakan u/ keluar dari editor sekaligus menyimpan file. tail = Menampilkan 10 baris terakhir dari suatu file. ls \u2013l = Melihat semua file lengkap ls -a = Menampilkan semua file atau direktori yang tersembunyi ls -f = Menampilkan semua file atau direktori tanpa proses shorting grep root /etc/passwd = Mencari kata atau kalimat dalam file Referensi Ubuntu Unix/Linux Command Reference Itu beberapa command yang saya ingat saat ini yang bisa digunakan dibanyak distro Linux, walaupun ada beberapa yang hanya khusus di Ubuntu saja. Jika ada yang saya ingat lagi, akan saya tambah.","title":"Command Line"},{"location":"learning/Linux_Ubuntu/commandLine/#commandline","text":"","title":"CommandLine"},{"location":"learning/Linux_Ubuntu/commandLine/#a-penjelasan","text":"Ubuntu sangat terkenal dengan CLI-nya (Command Line Interface). CLI sendiri adalah antar muka yang tidak menyediakan grafik, baik berupa gambar-gambar, jendela-jendela ataupun animasi-animasi yang bisa memanjakan pengguna, melainkan hanya berupa teks yang harus diketikkan oleh pengguna. Jadi, apabila user ingin melakukan operasi dalam sistem operasi tersebut, misalnya melakukan copy, rename, cut, delete, dan sebagainya, maka pengguna harus megetikkan perintah berupa teks dengan cara manual dan bukan dengan klik-klik seperti pada interface GUI (Graphic User Interface). Pada Ubuntu versi Desktop sudah menggunakan interface grafik, namun juga disediakan sebuah aplikasi yang diperuntukkan bagi pengguna yang ingin menggunakan tampilan/interface CLI, baik hanya untuk belajar atau memang keahliannya menggunakan CLI, karena memang cukup banyak hal yang bisa dilakukan dengan interface CLI ini yang tidak bisa dilakukan pada interface GUI, terlebih pada Ubuntu versi Server yang semuanya harus dilakukan dengan mode teks, walaupun sebenarnya bisa diinstalkan mode grafiknya. Aplikasi pada Ubuntu Desktop yang bisa digunakan untuk menggunakan mode teks adalah Terminal, yang bisa diakses dengan mengklik Aplication \u2013> Accessories \u2013> Terminal.","title":"A. Penjelasan"},{"location":"learning/Linux_Ubuntu/commandLine/#b-tutorial-penggunaan","text":"","title":"B. Tutorial Penggunaan"},{"location":"learning/Linux_Ubuntu/commandLine/#perintah-dasar-command-line","text":"Perintah dasar Command Line di Linux Ubuntu 16.04 desktop dengan virtual box Perintah-perintah Dasar di Linux Ubuntu.Ubuntu sangat terkenal dengan CLI-nya (Command Line Interface). CLI sendiri adalah antar muka yang tidak menyediakan grafik, baik berupa gambar-gambar, jendela-jendela ataupun animasi-animasi yang bisa memanjakan pengguna, melainkan hanya berupa teks yang harus diketikkan oleh pengguna. Jadi, apabila user ingin melakukan operasi dalam sistem operasi tersebut, misalnya melakukan copy, rename, cut, delete, dan sebagainya, maka pengguna harus megetikkan perintah berupa teks dengan cara manual dan bukan dengan klik-klik seperti pada interface GUI (Graphic User Interface). Berikut ini adalah beberapa perintah yang bisa digunakan di sistem operasi Ubuntu pada mode CLI, baik Desktop maupun Server, yang juga banyak untuk bisa digunakan pada distro yang lain. Pada contoh ini saya menggunakan Ubuntu Desktop 10.10. 1. sudo su Digunakan untuk login sebagai root/pengguna tertinggi Sintaks : sudo su 2. login Digunakan untuk login sebagai user lain, namun harus menjadi root dulu untuk bisa menjalankan peirntah ini. Sintaks : login namauser Contoh : login adam 3. cd Digunakan untuk berpindah direktori Sintaks : cd alamat_direktori Contoh : cd /var/www 4. pwd Digunakan untuk memperlihatkan di direktori mana posisi kita berada sekarang. Sintaks : pwd 5. ls Digunakan untuk melihat isi sebuah direktori. Sintaks : ls 6. cp Digunakan untuk melakukan copy file. Sintaks : cp /direktori/file_yang_ingin_dicopy /direktori tujuan Contoh : cp /etc/file1.txt /var/www 7. mv Digunakan untuk melakukan memindahkan, cut atau rename file. Sintaks : mv /direktori/file_yang_ingin_dicut /direktori tujuan (cut) mv /direktori/file_yang_ingin_direname /nama_baru_file (rename) Contoh: mv /etc/file1.txt /var/www mv /etc/file1.txt file2.txt 8. mkdir Digunakan untuk membuat folder baru. Sintaks : mkdir nama_folder Contoh : mkdir folder1 9. rmdir Digunakan untuk menghapus folder. Sintaks : rmdir nama_folder Contoh : rmdir folder1 10. touch Digunakan untuk membuat file baru. Sintaks : touch nama_file Contoh : touch file1.txt 11. rm Digunakan untuk menghapus file. Sintaks : rm nama_file Contoh : rm file1.txt 12. more Digunakan untuk menampilkan isi sebuah file Sintaks : more nama_fie Contoh : more file1.txt 13. echo Digunakan untuk menuliskan sesuatu kata atau kalimat ke sebuah file. Sintaks : echo \u201cisi pesan\u201d nama_file Contoh : echo \u201cHai ini adalah contoh pesan\u201d >> file1.txt 14. adduser Digunakan untuk menambah user baru. Sintaks : adduser nama_user Contoh : adduser adamkurniawan 15. addgroup Digunakan untuk menambah group baru Sintaks : addgroup nama_group Contoh : addgroup grup1 16. lsusb Digunakan untuk melihat perangkat usb yang sedang terkoneksi ke komputer Sintaks : lsusb 17. lspci Digunakan untuk melihat perangkat pci yang sedang terkoneksi ke komputer Sintaks : lspci 18. lshw Digunakan untuk melihat hardware komputer. Sintaks : lshw 19. dmesg Digunakan untuk melihat hardware yang sedang beraktifitas Sintaks : dmseg 20. top Digunakan untuk melihat proses yang sedang berjalan, seperti Task Manager pada Windows. Sintaks : top 21. cpuinfo Digunakan untuk melihat spesifikasi komputer. Sintaks : more /proc/cpuinfo 22. meminfo Digunakan untuk melihat status RAM Sintaks : more /proc/meminfo 23. clear Digunakan untuk membersihkan layar Sintaks : clear 24. halt Digunakan untuk mematikan komputer, namun harus sebagai root. Sintaks : halt 25. reboot Digunakan untuk merestart komputer, namun harus sebagai root. Sintaks : reboot 26. exit Digunakan untuk keluar dari terminal. Sintaks : exit 27. wget Digunakan untuk mendownload via terminal Sintaks : wget link_download Contoh : wget www.insightcalendar.com/Insight_Calendar_1-1_Setup.exe 28. ifconfig Digunakan untuk melihat konfigurasi ethernet/kartu jaringan. Sintaks : ifconfig 29. apt-get Digunakan untuk memperoleh paket/software dari repository ubuntu secara online. Sintax : apt-get nama_paket Contoh : apt-get update (untuk melakukan update repository) apt-get update wine (untuk mendapatkan paket wine) 30. tar Digunakan untuk melakukan extract file. Sintaks : tar [parameter] nama_file Contoh : tar -xzvf komodo-edit-5.2.4-4343-linux-libcpp6-x86.tar.gz 31. nautilus Digunakan untuk membuka tampilan GUI secara langsung. Sintaks : nautilus Contoh : sudo nautilus (menggunakan mode GUI dengan status root) 32. df -h melihat sisa kapasitas harddisk. sintaks : df -h 33. who digunakan untuk melihat nama login kita. sintaks : who 34. cat digunakan untuk membuka file. sintaks : cat contoh: cat test.txt 35. date melihat tanggal sintaks : date 36. cal melihat kalender sintaks : melihat tanggal 37. hostname Menampilkan nama komputer. sintaks: hostname 38. free Melihat Free memory. sintaks: free 39. History melihat perintah apa saja yang pernah diketik sintaks : History 40. deluser Menghapus user dari sistem sintaks : deluser [nama user] uname -r = Melihat kernel yang digunakan pada OS uname -a = Informasi system kernel anda cat /proc/cpuinfo = Melihat file pada /proc directori yang bukan merupakan file nyata (not real files). cat /proc/interrupts = Melihat alamat interrupt yang dipakai. cat /proc/version = Versi dari Linux dan informasi lainnya. cat /proc/filesystems = Melihat filesystem yang digunakan. cat /etc/printcap = Melihat printer yang telah disetup finger username = Melihat informasi user, coba jalankan; fingerroot last = Melihat user sebelumnya yang telah login di komputer. uptime = Melihat jumlah waktu pemakaian komputer oleh seseorang, terhitung proses reboot terakhir. ps (=print status)= Melihat proses-proses yang dijalankan oleh user ps axu = Melihat seluruh proses yang dijalankan, walaupun tanpa terminal control, juga ditampilkan nama dari user untuk setiap proses. top = Melihat proses yang berjalan, dengan urutan penggunaan cpu. apropos = Untuk mencari perintah pada sistem operasi yang mempunyai fungsi yang sama. chmod = Mengubah perizinan suatu direktori/file. wc = Menghitung jumlah kata, jumlah baris dan jumlah karakter dalam suatu file . man = Singkatan dari manual yaitu untuk menampilkan halaman manual untuk semua perintah UNIX. grep = Mencari isi suatu file di sembarang directori. pwd = Menampilkan nama direktori dimana Anda saat itu sedang berada. ps = Digunakan untuk memonitor informasi tentang proses yang aktif dalam sistem UNIX. kill = Digunakan untuk menghentikan proses yang sedang berjalan. bc = Perintah bc dapat digunakan sebagai calculator. wall = Pengiriman pesan oleh super user. :w di gunakan u/ menyimpan file or sama dengan (save). :q digunakan u/ keluar dari editor tandan mentimpan file. :wq digunakan u/ keluar dari editor sekaligus menyimpan file. tail = Menampilkan 10 baris terakhir dari suatu file. ls \u2013l = Melihat semua file lengkap ls -a = Menampilkan semua file atau direktori yang tersembunyi ls -f = Menampilkan semua file atau direktori tanpa proses shorting grep root /etc/passwd = Mencari kata atau kalimat dalam file Referensi Ubuntu Unix/Linux Command Reference Itu beberapa command yang saya ingat saat ini yang bisa digunakan dibanyak distro Linux, walaupun ada beberapa yang hanya khusus di Ubuntu saja. Jika ada yang saya ingat lagi, akan saya tambah.","title":"Perintah dasar Command Line"},{"location":"learning/Linux_Ubuntu/linuxUbuntu/","text":"Linux Ubuntu A. Penjelasan Ubuntu adalah salah satu distribusi Linux yang berbasiskan pada Debian dan memiliki interface desktop. B. Tutorial Installasi Install Ubuntu di Virtual Box Tutorial install Linux Ubuntu 16.04 desktop dengan virtual box : Setelah kita selesai menginstall Virtual Box,langkah selanjutnya adalah menginstall Linux Ubuntu pada Virtual Box.Klik icon New dan akan tampil seperti digambar.Ketikkan Linux pada Name dan pilih version Linux nya Langkah berikutnya mengatur ukuran memori dan klik next/lanjut. Lalu pilih penyimpanan hardisk dan klik buat Pilih tipe hard disk seperti pada gambar dan klik next/lanjut Pada penyimpanan hard disk fisik pilih yang dialokasikan secara dinamik Pilih ukuran berkas dan klik buat Memproses tampilan Ubuntu Dan inilah tampilan Linux Ubuntu Install Ubuntu di Windows Tutorial install Linux Ubuntu 16.04 desktop dual boot dengan windows : Saat anda masih berada pada Desktop Windows 7, tugas anda adalah membuat ruang kosong pada Hardisk di partisi C/System untuk tempat instalasi OS Ubuntu, caranya ialah klik Start --> Computer --> Manage. Selanjutnya pilih Disk Management --> klik kanan pada partisi System/C lalu pilih Shrink Volume... Sebagai Contoh, Saya mebuat ruang kosong dengan ukuran/kapasitas 8156MB atau sekitar 8GB, jika anda sudah menetapkan besar ukuran untuk ruang kosong yang anda akan gunakan, maka silahkan klik Shrink. Setelah proses pembuatan ruang kosong untuk installasi Ubuntu selesai, maka yang harus anda sediakan adalah CD/DVD ubuntu bisa juga menggunakan USB Flashdisk, tapi untuk USB Flashdisk, caranya sedikit berbeda dengan artikel yang saya tulis ini, mungkin anda bisa menyesuaikannya,untuk cara pembuatan anda bisa lihat di situs resmi ubuntu. untuk Membuat CD/DVD untuk USB Flashdisk atau jika anda belum memiliki file installernya bisa download aplikasi instalisasi menggunakan CD/DVD / USB Flashdisk . Jika CD/DVD /USB Flashdisk sudah tersedia, maka anda bisa melanjutkan dengan me-restart PC/Laptop anda. Jangan Lupa Masukkan CD/DVD ke room dan setting boot dari CD/DVD. Jika anda behasil masuk, maka akan ada tampilan seperti gambar di bawah ini lalu pilih bahasa yang akan anda gunakan selama menginstall. Pilih Something Else dan Klik Continue Selanjutnya pilih Free Space dan klik add.. untuk membuat ruang swap Tentukan size untuk ruang swap yang akan dibuat, sebagai contoh saya menggunakan 500/500MB. Pada pilihan Use as pilih Swap area --> OK Untuk tahap selanjutnya, klik add lagi untuk membuat partisi ubuntu. untuk kali ini kita menggunakan semua sisa size pada ruang kosong. Dan untuk pilihan Use as pilih ext4 journaling file system, sedangkan untuk Mount point tambahkan / (garis miring). Jika semua tahap sudah selesai tekan OK Untuk tahap ini tinggal menekan tombol Install Now dan ikuti langkah-langkah install-nya hingga selesai.","title":"Ubuntu Linux"},{"location":"learning/Linux_Ubuntu/linuxUbuntu/#linux-ubuntu","text":"","title":"Linux Ubuntu"},{"location":"learning/Linux_Ubuntu/linuxUbuntu/#a-penjelasan","text":"Ubuntu adalah salah satu distribusi Linux yang berbasiskan pada Debian dan memiliki interface desktop.","title":"A. Penjelasan"},{"location":"learning/Linux_Ubuntu/linuxUbuntu/#b-tutorial-installasi","text":"","title":"B. Tutorial Installasi"},{"location":"learning/Linux_Ubuntu/linuxUbuntu/#install-ubuntu-di-virtual-box","text":"Tutorial install Linux Ubuntu 16.04 desktop dengan virtual box : Setelah kita selesai menginstall Virtual Box,langkah selanjutnya adalah menginstall Linux Ubuntu pada Virtual Box.Klik icon New dan akan tampil seperti digambar.Ketikkan Linux pada Name dan pilih version Linux nya Langkah berikutnya mengatur ukuran memori dan klik next/lanjut. Lalu pilih penyimpanan hardisk dan klik buat Pilih tipe hard disk seperti pada gambar dan klik next/lanjut Pada penyimpanan hard disk fisik pilih yang dialokasikan secara dinamik Pilih ukuran berkas dan klik buat Memproses tampilan Ubuntu Dan inilah tampilan Linux Ubuntu","title":"Install Ubuntu di Virtual Box"},{"location":"learning/Linux_Ubuntu/linuxUbuntu/#install-ubuntu-di-windows","text":"Tutorial install Linux Ubuntu 16.04 desktop dual boot dengan windows : Saat anda masih berada pada Desktop Windows 7, tugas anda adalah membuat ruang kosong pada Hardisk di partisi C/System untuk tempat instalasi OS Ubuntu, caranya ialah klik Start --> Computer --> Manage. Selanjutnya pilih Disk Management --> klik kanan pada partisi System/C lalu pilih Shrink Volume... Sebagai Contoh, Saya mebuat ruang kosong dengan ukuran/kapasitas 8156MB atau sekitar 8GB, jika anda sudah menetapkan besar ukuran untuk ruang kosong yang anda akan gunakan, maka silahkan klik Shrink. Setelah proses pembuatan ruang kosong untuk installasi Ubuntu selesai, maka yang harus anda sediakan adalah CD/DVD ubuntu bisa juga menggunakan USB Flashdisk, tapi untuk USB Flashdisk, caranya sedikit berbeda dengan artikel yang saya tulis ini, mungkin anda bisa menyesuaikannya,untuk cara pembuatan anda bisa lihat di situs resmi ubuntu. untuk Membuat CD/DVD untuk USB Flashdisk atau jika anda belum memiliki file installernya bisa download aplikasi instalisasi menggunakan CD/DVD / USB Flashdisk . Jika CD/DVD /USB Flashdisk sudah tersedia, maka anda bisa melanjutkan dengan me-restart PC/Laptop anda. Jangan Lupa Masukkan CD/DVD ke room dan setting boot dari CD/DVD. Jika anda behasil masuk, maka akan ada tampilan seperti gambar di bawah ini lalu pilih bahasa yang akan anda gunakan selama menginstall. Pilih Something Else dan Klik Continue Selanjutnya pilih Free Space dan klik add.. untuk membuat ruang swap Tentukan size untuk ruang swap yang akan dibuat, sebagai contoh saya menggunakan 500/500MB. Pada pilihan Use as pilih Swap area --> OK Untuk tahap selanjutnya, klik add lagi untuk membuat partisi ubuntu. untuk kali ini kita menggunakan semua sisa size pada ruang kosong. Dan untuk pilihan Use as pilih ext4 journaling file system, sedangkan untuk Mount point tambahkan / (garis miring). Jika semua tahap sudah selesai tekan OK Untuk tahap ini tinggal menekan tombol Install Now dan ikuti langkah-langkah install-nya hingga selesai.","title":"Install Ubuntu di Windows"},{"location":"learning/Virtual_Box/virtualBox/","text":"Virtual Box A. Penjelasan VirtualBox adalah sebuah software yang berfungsi untuk metode pembelajaran dalam menginstall OS (Operating System) secara virtual. Jadi pada intinya anda jika ingin belajar menginstall PC tidak perlu membongkar dan install ulang, cukup menggunakan VirtualBox anda pun bisa menginstall OS ke dalam PC. Hanya saja sifatnya virtual, tetapi tidak akan jauh beda dengan yang aslinya. Kata virtualisasi juga merujuk ke kamus Oxford (Convert \"something\" to a computer-generated simulation of reality) yang artinya Mengubah atau mengkonversi ke bentuk simulasi dari bentuk yang real/nyata. Oracle VM VirtualBox atau sering disebut dengan VirtualBox adalah perangkat lunak virtualisasi yang dapat digunakan untuk mengeksekusi sistem operasi \u201ctambahan\u201d di dalam sistem operasi \u201cutama\u201d. Sebagai contoh, jika seseorang mempunyai sistem operasi MS Windows yang terpasang di komputernya, maka yang bersangkutan dapat pula menjalankan sistem operasi lain yang diinginkan di dalam sistem operasi MS Windows tersebut. VirtualBox bebas didownload dan digunakan (lisensi GNU GPL versi 2) serta mendukung banyak jenis sistem operasi, baik untuk versi 32 bit maupun 64 bit, baik sebagai host, mulai sistem operasi Windows, Linux, Macintosh, dan Solaris, serta sebagai guest untuk lebih banyak sistem operasi, mulai dari Windows (NT 4.0, 2000, XP, 2003 Server, Vista, Windows 7, Windows 8), DOS/Windows 3.x, Linux (2.4, 2.6 dan 3.x), Solaris dan OpenSolaris, OS/2, sampai OpenBSD.: Cara Install B. Tutorial Installasi Install Virtual Box Instalasi VirtualBox dapat menggunakan file instalasi (offline) atau secara online. Instalasi online hanya dapat dilakukan untuk hosts Linux. Untuk sistem operasi Windows (32 bit atau 64 bit), download file aplikasi VirtualBox di bagian VirtualBox for Windows hosts. Selanjutnya klik dua kali pada file aplikasi VirtualBox yang telah didownload tersebut. Selanjutnya muncul layar selamat datang dalam proses instalasi VirtualBox. Klik tombol Next untuk proses selanjutnya. Di bagian ini, kita dapat menentukan fitur apa yang akan diinstall atau tidak, mulai dari dukungan terhadap USB, jaringan sampai script Phyton untuk VirtualBox API. Di bagian ini kita juga dapat menentukan lokasi folder VirtualBox akan diinstall. Biarkan seluruh pengaturan folder dan fitur aplikasi yang akan diinstall. Klik tombol Next untuk proses selanjutnya. Di bagian ini, kita dapat menentukan apakah cara akses VirtualBox secara cepat (shortcut) akan diinstall pada bagian desktop dan Quick Launch Bar. Aktifkan Register file associations agar file dengan ekstensi terkait VirtualBox dikenal oleh sistem operasi. Klik tombol Next untuk proses selanjutnya. Selanjutnya muncul pemberitahuan, bahwa dalam proses instalasi, interface atau kartu jaringan yang ada pada komputer akan dinonaktifkan untuk sementara waktu, namun akan diaktifkan kembali secara otomatis, dengan tambahan kartu jaringan virtual bawaan dari VirtualBox. Klik tombol Yes untuk melanjutkan proses instalasi. VirtualBox sudah memiliki informasi yang diperlukan dan siap untuk diinstall. Klik tombol Install untuk memulai proses instalasi VirtualBox. Pada Windows 7 atau Windows 8, akan muncul layar pop-up User Account Control yang meminta konfirmasi apakah kita akan menginstall aplikasi VirtualBox ke dalam komputer. Klik tombol Yes untuk memulai proses instalasi. Proses instalasi dan penyalinan file aplikasi VirtualBox sedang dilakukan. Apabila dalam proses instalasi muncul pertanyaan terkait keamanan sistem, tandai kotak konfirmasi Always trust software from \"Oracle Corporation\" kemudian tekan tombol Install. Jika yang ditekan adalah tombol Dont Install maka proses instalasi akan dihentikan. Dan apabila kotak konfirmasi Always trust software from \"Oracle Corporation\" tidak diaktifkan, maka pertanyaan terkait keamanan akan muncul beberapa kali dan kita harus menekan tombol Install untuk menyelesaikan proses instalasi VirtualBox. Layar selanjutnya menginformasikan bahwa instalasi VirtualBox sudah selesai dilakukan. Klik tombol Finish untuk keluar dari proses instalasi dan menjalankan aplikasi VirtualBox. Tampilan ruangan aplikasi VirtualBox yang baru diinstall. Jika sudah ada sistem operasi guest yang diinstall, maka akan ditampilkan pada layar sebelah kiri. Indikator Running pada sistem operasi guest menandakan sistem operasi guest sedang aktif. Sementara bagian sebelah kanan merupakan informasi tentang sistem operasi guest yang dipilih.","title":"**Virtual Box**"},{"location":"learning/Virtual_Box/virtualBox/#virtual-box","text":"","title":"Virtual Box"},{"location":"learning/Virtual_Box/virtualBox/#a-penjelasan","text":"VirtualBox adalah sebuah software yang berfungsi untuk metode pembelajaran dalam menginstall OS (Operating System) secara virtual. Jadi pada intinya anda jika ingin belajar menginstall PC tidak perlu membongkar dan install ulang, cukup menggunakan VirtualBox anda pun bisa menginstall OS ke dalam PC. Hanya saja sifatnya virtual, tetapi tidak akan jauh beda dengan yang aslinya. Kata virtualisasi juga merujuk ke kamus Oxford (Convert \"something\" to a computer-generated simulation of reality) yang artinya Mengubah atau mengkonversi ke bentuk simulasi dari bentuk yang real/nyata. Oracle VM VirtualBox atau sering disebut dengan VirtualBox adalah perangkat lunak virtualisasi yang dapat digunakan untuk mengeksekusi sistem operasi \u201ctambahan\u201d di dalam sistem operasi \u201cutama\u201d. Sebagai contoh, jika seseorang mempunyai sistem operasi MS Windows yang terpasang di komputernya, maka yang bersangkutan dapat pula menjalankan sistem operasi lain yang diinginkan di dalam sistem operasi MS Windows tersebut. VirtualBox bebas didownload dan digunakan (lisensi GNU GPL versi 2) serta mendukung banyak jenis sistem operasi, baik untuk versi 32 bit maupun 64 bit, baik sebagai host, mulai sistem operasi Windows, Linux, Macintosh, dan Solaris, serta sebagai guest untuk lebih banyak sistem operasi, mulai dari Windows (NT 4.0, 2000, XP, 2003 Server, Vista, Windows 7, Windows 8), DOS/Windows 3.x, Linux (2.4, 2.6 dan 3.x), Solaris dan OpenSolaris, OS/2, sampai OpenBSD.: Cara Install","title":"A. Penjelasan"},{"location":"learning/Virtual_Box/virtualBox/#b-tutorial-installasi","text":"","title":"B. Tutorial Installasi"},{"location":"learning/Virtual_Box/virtualBox/#install-virtual-box","text":"Instalasi VirtualBox dapat menggunakan file instalasi (offline) atau secara online. Instalasi online hanya dapat dilakukan untuk hosts Linux. Untuk sistem operasi Windows (32 bit atau 64 bit), download file aplikasi VirtualBox di bagian VirtualBox for Windows hosts. Selanjutnya klik dua kali pada file aplikasi VirtualBox yang telah didownload tersebut. Selanjutnya muncul layar selamat datang dalam proses instalasi VirtualBox. Klik tombol Next untuk proses selanjutnya. Di bagian ini, kita dapat menentukan fitur apa yang akan diinstall atau tidak, mulai dari dukungan terhadap USB, jaringan sampai script Phyton untuk VirtualBox API. Di bagian ini kita juga dapat menentukan lokasi folder VirtualBox akan diinstall. Biarkan seluruh pengaturan folder dan fitur aplikasi yang akan diinstall. Klik tombol Next untuk proses selanjutnya. Di bagian ini, kita dapat menentukan apakah cara akses VirtualBox secara cepat (shortcut) akan diinstall pada bagian desktop dan Quick Launch Bar. Aktifkan Register file associations agar file dengan ekstensi terkait VirtualBox dikenal oleh sistem operasi. Klik tombol Next untuk proses selanjutnya. Selanjutnya muncul pemberitahuan, bahwa dalam proses instalasi, interface atau kartu jaringan yang ada pada komputer akan dinonaktifkan untuk sementara waktu, namun akan diaktifkan kembali secara otomatis, dengan tambahan kartu jaringan virtual bawaan dari VirtualBox. Klik tombol Yes untuk melanjutkan proses instalasi. VirtualBox sudah memiliki informasi yang diperlukan dan siap untuk diinstall. Klik tombol Install untuk memulai proses instalasi VirtualBox. Pada Windows 7 atau Windows 8, akan muncul layar pop-up User Account Control yang meminta konfirmasi apakah kita akan menginstall aplikasi VirtualBox ke dalam komputer. Klik tombol Yes untuk memulai proses instalasi. Proses instalasi dan penyalinan file aplikasi VirtualBox sedang dilakukan. Apabila dalam proses instalasi muncul pertanyaan terkait keamanan sistem, tandai kotak konfirmasi Always trust software from \"Oracle Corporation\" kemudian tekan tombol Install. Jika yang ditekan adalah tombol Dont Install maka proses instalasi akan dihentikan. Dan apabila kotak konfirmasi Always trust software from \"Oracle Corporation\" tidak diaktifkan, maka pertanyaan terkait keamanan akan muncul beberapa kali dan kita harus menekan tombol Install untuk menyelesaikan proses instalasi VirtualBox. Layar selanjutnya menginformasikan bahwa instalasi VirtualBox sudah selesai dilakukan. Klik tombol Finish untuk keluar dari proses instalasi dan menjalankan aplikasi VirtualBox. Tampilan ruangan aplikasi VirtualBox yang baru diinstall. Jika sudah ada sistem operasi guest yang diinstall, maka akan ditampilkan pada layar sebelah kiri. Indikator Running pada sistem operasi guest menandakan sistem operasi guest sedang aktif. Sementara bagian sebelah kanan merupakan informasi tentang sistem operasi guest yang dipilih.","title":"Install Virtual Box"},{"location":"learning/Web_Server/apache/","text":"Installasi Apache, PHP A. Penjelasan a. Apache Apache adalah komponen server web dari paket perangkat lunak LAMP (Linux, Apache, MySQL, PHP/Perl/bahasa pemrograman Python). b. PHP PHP adalah singkatan dari \"PHP: Hypertext Prepocessor\", yaitu bahasa pemrograman yang digunakan secara luas untuk penanganan pembuatan dan pengembangan sebuah situs web dan bisa digunakan bersamaan dengan HTML. B. Tutorial Installasi Install Apache Tutorial install APACHE di Linux Ubuntu 16.04 desktop : Apache tersedia di dalam repositori perangkat lunak default Ubuntu, jadi kami akan menginstalnya menggunakan alat manajemen paket konvensional. Kami akan memulai dengan memperbarui indeks paket lokal untuk mencerminkan perubahan hulu terbaru. Setelah itu, kita bisa menginstal paket apache2: $ sudo apt-get update $ sudo apt-get install apache2 Setelah mengkonfirmasikan instalasi, apt-get akan menginstal Apache dan semua dependensi yang dibutuhkan. Install PHP Tutorial install PHP di Linux Ubuntu 16.04 desktop : $ sudo apt-get install php $ sudo apt-get install libapache2-mod-php $ cd /var/www/ $ sudo chown username:www-data . - R","title":"**Installasi Apache, PHP**"},{"location":"learning/Web_Server/apache/#installasi-apache-php","text":"","title":"Installasi Apache, PHP"},{"location":"learning/Web_Server/apache/#a-penjelasan","text":"a. Apache Apache adalah komponen server web dari paket perangkat lunak LAMP (Linux, Apache, MySQL, PHP/Perl/bahasa pemrograman Python). b. PHP PHP adalah singkatan dari \"PHP: Hypertext Prepocessor\", yaitu bahasa pemrograman yang digunakan secara luas untuk penanganan pembuatan dan pengembangan sebuah situs web dan bisa digunakan bersamaan dengan HTML.","title":"A. Penjelasan"},{"location":"learning/Web_Server/apache/#b-tutorial-installasi","text":"","title":"B. Tutorial Installasi"},{"location":"learning/Web_Server/apache/#install-apache","text":"Tutorial install APACHE di Linux Ubuntu 16.04 desktop : Apache tersedia di dalam repositori perangkat lunak default Ubuntu, jadi kami akan menginstalnya menggunakan alat manajemen paket konvensional. Kami akan memulai dengan memperbarui indeks paket lokal untuk mencerminkan perubahan hulu terbaru. Setelah itu, kita bisa menginstal paket apache2: $ sudo apt-get update $ sudo apt-get install apache2 Setelah mengkonfirmasikan instalasi, apt-get akan menginstal Apache dan semua dependensi yang dibutuhkan.","title":"Install Apache"},{"location":"learning/Web_Server/apache/#install-php","text":"Tutorial install PHP di Linux Ubuntu 16.04 desktop : $ sudo apt-get install php $ sudo apt-get install libapache2-mod-php $ cd /var/www/ $ sudo chown username:www-data . - R","title":"Install PHP"},{"location":"learning/Web_Server/webServer/","text":"Web Server A. Penjelasan Merupakan perangkat lunak (software) dalam server yang berfungsi untuk menerima permintaan (request) berupa halaman web melalui protokol HTTP dan atau HTTPS dari client yang lebih dikenal dengan nama browser, kemudian mengirimkan kembali (respon) hasil permintaan tersebut ke dalam bentuk halaman-halaman web yang pada umumnya berbentuk dokumen HTML.Pada pengembangan web tradisional, kita umumnya menggunakan sebuah web server seperti Apache HTTPD atau nginx sebagai penyalur konten statis seperti HTML, CSS, Javascript, maupun gambar. Untuk menambahkan aplikasi web kita kemudian menggunakan penghubung antar web server dengan program yang dikenal dengan nama CGI (Common Gateway Interface). CGI diimplementasikan pada web server sebagai antarmuka penghubung antara web server dengan program yang akan menghasilkan konten secara dinamis. Program-program CGI biasanya dikembangkan dalam bentuk script, meskipun dapat saja dikembangkan dalam bahasa apapun. Contoh dari bahasa pemrograman dan program yang hidup di dalam CGI adalah PHP.Berikut cara kerja CGI dan Web Server a. Fungsi Web Server Untuk mentransfer atau memindahkan berkas yang diminta oleh pengguna melalui protokol komunikasi tertentu. Oleh karena dalam satu halaman web biasanya terdiri dari berbagai macam jenis berkas seperti gambar, video, teks, audio, file dan lain sebagainya, maka pemanfaatan web server berfungsi juga untuk mentransfer keseluruhan aspek pemberkasan dalam halaman tersebut, termasuk teks, gambar, video, audio, file dan sebagainya. Pada saat anda ingin mengakses sebuah halaman website, biasanya anda mengetik halaman tersebut di browser seperti mozilla, chrome dan lain-lain. Setelah anda meminta (biasanya dengan menekan enter) untuk dapat mengakses halaman tersebut, browser akan melakukan permintaan ke web server. Disinilah web server berperan, web server akan mencarikan data yang diminta browser, lalu mengirimkan data tersebut ke browser atau menolaknya jika ternyata data yang diminta tidak ditemukan. b. Contoh Web Server Beberapa contoh web server yang paling banyak digunakan diantaranya adalah : Apache Apache Tomcat Microsoft Internet Information Services (IIS) Nginx Lighttpd Litespeed Zeus Web Server c. Fitur-fitur standar web server Fitur - fitur standar web server : HTTP (Hypertext Transfer Protocol) adalah protokol yang digunakan oleh web server dan web browser untuk dapat berkomunikasi antara satu sama lain. HTTPS (Hypertext Transfer Protocol Secure) adalah merupakan versi aman (secure) dari HTTP. Biasanya protokol HTTP menggunakan port 80 dan protokol HTTPS menggunakan port 443. Logging Virtual Hosting Pengaturan Bandwidth Otektifikasi Kompresi Konten B. Cara Kerja Cara Kerja : Client mengakses suatu website berupa URL melalui web browser Mengirim http request URL melalui internet dan mengirimkan domain ke DNS DNS menterjemahkan domain name ke alamat IP lalu mengirimkan Dan terhubung ke web server melalui jaringan (intranet atau internet). Web server menerima permintaan (request) dari client, dan Web server Mengirimkan apa yang diminta oleh client (response).","title":"**Web Server**"},{"location":"learning/Web_Server/webServer/#web-server","text":"","title":"Web Server"},{"location":"learning/Web_Server/webServer/#a-penjelasan","text":"Merupakan perangkat lunak (software) dalam server yang berfungsi untuk menerima permintaan (request) berupa halaman web melalui protokol HTTP dan atau HTTPS dari client yang lebih dikenal dengan nama browser, kemudian mengirimkan kembali (respon) hasil permintaan tersebut ke dalam bentuk halaman-halaman web yang pada umumnya berbentuk dokumen HTML.Pada pengembangan web tradisional, kita umumnya menggunakan sebuah web server seperti Apache HTTPD atau nginx sebagai penyalur konten statis seperti HTML, CSS, Javascript, maupun gambar. Untuk menambahkan aplikasi web kita kemudian menggunakan penghubung antar web server dengan program yang dikenal dengan nama CGI (Common Gateway Interface). CGI diimplementasikan pada web server sebagai antarmuka penghubung antara web server dengan program yang akan menghasilkan konten secara dinamis. Program-program CGI biasanya dikembangkan dalam bentuk script, meskipun dapat saja dikembangkan dalam bahasa apapun. Contoh dari bahasa pemrograman dan program yang hidup di dalam CGI adalah PHP.Berikut cara kerja CGI dan Web Server a. Fungsi Web Server Untuk mentransfer atau memindahkan berkas yang diminta oleh pengguna melalui protokol komunikasi tertentu. Oleh karena dalam satu halaman web biasanya terdiri dari berbagai macam jenis berkas seperti gambar, video, teks, audio, file dan lain sebagainya, maka pemanfaatan web server berfungsi juga untuk mentransfer keseluruhan aspek pemberkasan dalam halaman tersebut, termasuk teks, gambar, video, audio, file dan sebagainya. Pada saat anda ingin mengakses sebuah halaman website, biasanya anda mengetik halaman tersebut di browser seperti mozilla, chrome dan lain-lain. Setelah anda meminta (biasanya dengan menekan enter) untuk dapat mengakses halaman tersebut, browser akan melakukan permintaan ke web server. Disinilah web server berperan, web server akan mencarikan data yang diminta browser, lalu mengirimkan data tersebut ke browser atau menolaknya jika ternyata data yang diminta tidak ditemukan. b. Contoh Web Server Beberapa contoh web server yang paling banyak digunakan diantaranya adalah : Apache Apache Tomcat Microsoft Internet Information Services (IIS) Nginx Lighttpd Litespeed Zeus Web Server c. Fitur-fitur standar web server Fitur - fitur standar web server : HTTP (Hypertext Transfer Protocol) adalah protokol yang digunakan oleh web server dan web browser untuk dapat berkomunikasi antara satu sama lain. HTTPS (Hypertext Transfer Protocol Secure) adalah merupakan versi aman (secure) dari HTTP. Biasanya protokol HTTP menggunakan port 80 dan protokol HTTPS menggunakan port 443. Logging Virtual Hosting Pengaturan Bandwidth Otektifikasi Kompresi Konten","title":"A. Penjelasan"},{"location":"learning/Web_Server/webServer/#b-cara-kerja","text":"Cara Kerja : Client mengakses suatu website berupa URL melalui web browser Mengirim http request URL melalui internet dan mengirimkan domain ke DNS DNS menterjemahkan domain name ke alamat IP lalu mengirimkan Dan terhubung ke web server melalui jaringan (intranet atau internet). Web server menerima permintaan (request) dari client, dan Web server Mengirimkan apa yang diminta oleh client (response).","title":"B. Cara Kerja"},{"location":"learning/Web_Server/website/","text":"Website Penjelasan Website atau situs dapat diartikan sebagai kumpulan halaman yang menampilkan informasi data teks, data gambar diam atau gerak, data animasi, suara, video dan atau gabungan dari semuanya, baik yang bersifat statis maupun dinamis yang membentuk satu rangkaian bangunan yang saling terkait dimana masing-masing dihubungkan dengan jaringan-jaringan halaman (hyperlink). Bersifat statis apabila isi informasi website tetap, jarang berubah, dan isi informasinya searah hanya dari pemilik website. Bersifat dinamis apabila isi informasi website selalu berubah-ubah, dan isi informasinya interaktif dua arah berasal dari pemilik serta pengguna website. Contoh website statis adalah berisi profil perusahaan, sedangkan website dinamis adalah seperti Friendster, Multiply, dll. Dalam sisi pengembangannya, website statis hanya bisa diupdate oleh pemiliknya saja, sedangkan website dinamis bisa diupdate oleh pengguna maupun pemilik. Dalam mencari informasi dari internet, pengguna akan menuju ke sebuah alamat unik internet (misal: www.namawebsite.com) yang disebut nama domain (Domain Name/URL \u2013 Uniform Resource Locator) dan menemukan informasi berbentuk teks, gambar diam atau bergerak, animasi bergerak, suara ataupun video dalam sebuah media, yang disebut dengan website atau situs. Website ini dibuka melalui sebuah program penjelajah (Browser) yang berada di sebuah komputer. Program penjelajah yang bisa digunakan dalam komputer diantaranya: IE (Internet Explorer), Mozilla, Firefox, Netscape, Opera a. Unsur-unsur dalam penyediaan website Untuk menyediakan sebuah website, maka harus tersedia unsur-unsur penunjangnya, adalah sebagai berikut: Nama domain (Domain name/URL \u2013 Uniform Resource Locator) Nama domain atau biasa disebut dengan Domain Name atau URL adalah alamat unik di dunia internet yang digunakan untuk mengidentifikasi sebuah website, atau dengan kata lain domain name adalah alamat yang digunakan untuk menemukan sebuah website pada dunia internet. Contoh : http://www.baliorange.net Nama domain diperjualbelikan secara bebas di internet dengan status sewa tahunan. Setelah Nama Domain itu terbeli di salah satu penyedia jasa pendaftaran, maka pengguna disediakan sebuah kontrol panel untuk administrasinya. Jika pengguna lupa/tidak memperpanjang masa sewanya, maka nama domain itu akan di lepas lagi ketersediaannya untuk umum. Nama domain sendiri mempunyai identifikasi ekstensi/akhiran sesuai dengan kepentingan dan lokasi keberadaan website tersebut. Contoh nama domain ber-ekstensi internasional adalah com, net, org, info, biz, name, ws. Contoh nama domain ber-ekstensi lokasi Negara Indonesia adalah : .co.id : Untuk Badan Usaha yang mempunyai badan hukum sah .ac.id : Untuk Lembaga Pendidikan .go.id : Khusus untuk Lembaga Pemerintahan Republik Indonesia .mil.id : Khusus untuk Lembaga Militer Republik Indonesia .or.id : Untuk segala macam organisasi yand tidak termasuk dalam kategori \u201cac.id\u201d,\u201dco.id\u201d,\u201dgo.id\u201d,\u201dmil.id\u201d dan lain lain .war.net.id : untuk industri warung internet di Indonesia .sch.id : khusus untuk Lembaga Pendidikan yang menyelenggarakan pendidikan seperti SD, SMP dan atau SMU .web.id : Ditujukan bagi badan usaha, organisasi ataupun perseorangan yang melakukan kegiatannya di World Wide Web. Rumah tempat website (Web hosting) Web Hosting dapat diartikan sebagai ruangan yang terdapat dalam harddisk tempat menyimpan berbagai data, file-file, gambar, video, data email, statistik, database dan lain sebagainya yang akan ditampilkan di website. Besarnya data yang bisa dimasukkan tergantung dari besarnya web hosting yang disewa/dipunyai, semakin besar web hosting semakin besar pula data yang dapat dimasukkan dan ditampilkan dalam website. Web Hosting juga diperoleh dengan menyewa. Pengguna akan memperoleh kontrol panel yang terproteksi dengan username dan password untuk administrasi websitenya. Besarnya hosting ditentukan ruangan harddisk dengan ukuran MB (Mega Byte) atau GB (Giga Byte). Lama penyewaan web hosting rata-rata dihitung per tahun. Penyewaan hosting dilakukan dari perusahaan-perusahaan penyewa web hosting yang banyak dijumpai baik di Indonesia maupun Luar Negeri. Lokasi peletakan pusat data (datacenter) web hosting bermacam-macam. Ada yang di Jakarta, Singapore, Inggris, Amerika, dll dengan harga sewa bervariasi. Bahasa Program (Scripts Program). Adalah bahasa yang digunakan untuk menerjemahkan setiap perintah dalam website yang pada saat diakses. Jenis bahasa program sangat menentukan statis, dinamis atau interaktifnya sebuah website. Semakin banyak ragam bahasa program yang digunakan maka akan terlihat website semakin dinamis, dan interaktif serta terlihat bagus. Beragam bahasa program saat ini telah hadir untuk mendukung kualitas website. Jenis jenis bahasa program yang banyak dipakai para desainer website antara lain HTML, ASP, PHP, JSP, Java Scripts, Java applets, XML, Ajax dsb. Bahasa dasar yang dipakai setiap situs adalah HTML sedangkan PHP, ASP, JSP dan lainnya merupakan bahasa pendukung yang bertindak sebagai pengatur dinamis, dan interaktifnya situs. Bahasa program ASP, PHP, JSP atau lainnya bisa dibuat sendiri. Bahasa program ini biasanya digunakan untuk membangun portal berita, artikel, forum diskusi, buku tamu, anggota organisasi, email, mailing list dan lain sebagainya yang memerlukan update setiap saat. Desain website. Setelah melakukan penyewaan domain name dan web hosting serta penguasaan bahasa program (scripts program), unsur website yang penting dan utama adalah desain. Desain website menentukan kualitas dan keindahan sebuah website. Desain sangat berpengaruh kepada penilaian pengunjung akan bagus tidaknya sebuah website. Untuk membuat website biasanya dapat dilakukan sendiri atau menyewa jasa website designer. Saat ini sangat banyak jasa web designer, terutama di kota-kota besar. Perlu diketahui bahwa kualitas situs sangat ditentukan oleh kualitas designer. Semakin banyak penguasaan web designer tentang beragam program/software pendukung pembuatan situs maka akan dihasilkan situs yang semakin berkualitas, demikian pula sebaliknya. Jasa web designer ini yang umumnya memerlukan biaya yang tertinggi dari seluruh biaya pembangunan situs dan semuanya itu tergantung kualitas designer. Program-program desain website salah satunya adalah Macromedia Firework, Adobe Photoshop, Adobe Dreamweaver, Microsoft Frontpage, dll. Program transfer data ke pusat data. Para web designer mengerjakan website dikomputernya sendiri. Berbagai bahasa program, data informasi teks, gambar, video, dan suara telah menjadi file-file pendukung adanya website. File tersebut bisa dibuka menggunakan program penjelajah (browser) sehingga terlihatlah sebuah website utuh di dalam komputer sendiri (offline). Tetapi file-file tersebut perlu untuk diletakkan dirumah hosting versi online agar terakses ke seluruh dunia. Pengguna akan diberikan akses FTP (File Transfer Protocol) setelah memesan sebuah web hosting untuk memindahkan file-file website ke pusat data web hosting. Untuk dapat menggunakan FTP diperlukan sebuah program FTP, misalnya WS FTP, Smart FTP, Cute FTP, dll. Program FTP ini banyak ditemui di internet dengan status penggunaan gratis maupun harus membayar. Para web designer pun dapat menggunakan fasilitas FTP yang terintegrasi dengan program pembuat website, misal Adobe Dreamweaver. Publikasi website. Keberadaan website tidak ada gunanya dibangun tanpa dikunjungi atau dikenal oleh masyarakat atau pengunjung internet. Karena efektif tidaknya situs sangat tergantung dari besarnya pengunjung dan komentar yang masuk. Untuk mengenalkan situs kepada masyarakat memerlukan apa yang disebut publikasi atau promosi. Publikasi situs di masyarakat dapat dilakukan dengan berbagai cara seperti dengan pamlet-pamlet, selebaran, baliho, kartu nama dan lain sebagainya tapi cara ini bisa dikatakan masih kurang efektif dan sangat terbatas. Cara yang biasanya dilakukan dan paling efektif dengan tak terbatas ruang atau waktu adalah publikasi langsung di internet melalui search engine-search engine (mesin pencari, spt : Yahoo, Google, MSN, Search Indonesia, dsb). Cara publikasi di search engine ada yang gratis dan ada pula yang membayar. Yang gratis biasanya terbatas dan cukup lama untuk bisa masuk dan dikenali di search engine terkenal seperti Yahoo atau Google. Cara efektif publikasi adalah dengan membayar, walaupun harus sedikit mengeluarkan akan tetapi situs cepat masuk ke search engine dan dikenal oleh pengunjung. b. Pemeliharaan Website Untuk mendukung kelanjutan dari situs diperlukan pemeliharaan setiap waktu sesuai yang diinginkan seperti penambahan informasi, berita, artikel, link, gambar atau lain sebagainya. Tanpa pemeliharaan yang baik situs akan terkesan membosankan atau monoton juga akan segera ditinggal pengunjung. Pemeliharaan situs dapat dilakukan per periode tertentu seperti tiap hari, tiap minggu atau tiap bulan sekali secara rutin atau secara periodik saja tergantung kebutuhan (tidak rutin). Pemeliharaan rutin biasanya dipakai oleh situs-situs berita, penyedia artikel, organisasi atau lembaga pemerintah. Sedangkan pemeliharaan periodik bisanya untuk situs-situs pribadi, penjualan/e-commerce, dan lain sebagainya. c. PERPANJANGAN MASA SEWA DOMAIN NAME DAN WEB HOSTING. Perlu dipahami bahwa domain name dan web hosting berstatus sewa. Selama kedua hal itu dibayarkan masa sewa perpanjangannya, maka Anda berhak untuk memilikinya dan mempergunakannya. Banyak terjadi kasus kelupaan dalam memperpanjang masa sewanya, atau sulit untuk menghubungi pihak ketiga (web designer) sebagai perantara pendaftaran awal, maka akan berakibat fatal. Anda akan kehilangan domain name sebagai identitas dalam dunia internet. Pastikan Anda mengingat untuk memperpanjang masa sewanya. Arti penting domain name perlu Anda pahami.","title":"**Website**"},{"location":"learning/Web_Server/website/#website","text":"","title":"Website"},{"location":"learning/Web_Server/website/#penjelasan","text":"Website atau situs dapat diartikan sebagai kumpulan halaman yang menampilkan informasi data teks, data gambar diam atau gerak, data animasi, suara, video dan atau gabungan dari semuanya, baik yang bersifat statis maupun dinamis yang membentuk satu rangkaian bangunan yang saling terkait dimana masing-masing dihubungkan dengan jaringan-jaringan halaman (hyperlink). Bersifat statis apabila isi informasi website tetap, jarang berubah, dan isi informasinya searah hanya dari pemilik website. Bersifat dinamis apabila isi informasi website selalu berubah-ubah, dan isi informasinya interaktif dua arah berasal dari pemilik serta pengguna website. Contoh website statis adalah berisi profil perusahaan, sedangkan website dinamis adalah seperti Friendster, Multiply, dll. Dalam sisi pengembangannya, website statis hanya bisa diupdate oleh pemiliknya saja, sedangkan website dinamis bisa diupdate oleh pengguna maupun pemilik. Dalam mencari informasi dari internet, pengguna akan menuju ke sebuah alamat unik internet (misal: www.namawebsite.com) yang disebut nama domain (Domain Name/URL \u2013 Uniform Resource Locator) dan menemukan informasi berbentuk teks, gambar diam atau bergerak, animasi bergerak, suara ataupun video dalam sebuah media, yang disebut dengan website atau situs. Website ini dibuka melalui sebuah program penjelajah (Browser) yang berada di sebuah komputer. Program penjelajah yang bisa digunakan dalam komputer diantaranya: IE (Internet Explorer), Mozilla, Firefox, Netscape, Opera a. Unsur-unsur dalam penyediaan website Untuk menyediakan sebuah website, maka harus tersedia unsur-unsur penunjangnya, adalah sebagai berikut: Nama domain (Domain name/URL \u2013 Uniform Resource Locator) Nama domain atau biasa disebut dengan Domain Name atau URL adalah alamat unik di dunia internet yang digunakan untuk mengidentifikasi sebuah website, atau dengan kata lain domain name adalah alamat yang digunakan untuk menemukan sebuah website pada dunia internet. Contoh : http://www.baliorange.net Nama domain diperjualbelikan secara bebas di internet dengan status sewa tahunan. Setelah Nama Domain itu terbeli di salah satu penyedia jasa pendaftaran, maka pengguna disediakan sebuah kontrol panel untuk administrasinya. Jika pengguna lupa/tidak memperpanjang masa sewanya, maka nama domain itu akan di lepas lagi ketersediaannya untuk umum. Nama domain sendiri mempunyai identifikasi ekstensi/akhiran sesuai dengan kepentingan dan lokasi keberadaan website tersebut. Contoh nama domain ber-ekstensi internasional adalah com, net, org, info, biz, name, ws. Contoh nama domain ber-ekstensi lokasi Negara Indonesia adalah : .co.id : Untuk Badan Usaha yang mempunyai badan hukum sah .ac.id : Untuk Lembaga Pendidikan .go.id : Khusus untuk Lembaga Pemerintahan Republik Indonesia .mil.id : Khusus untuk Lembaga Militer Republik Indonesia .or.id : Untuk segala macam organisasi yand tidak termasuk dalam kategori \u201cac.id\u201d,\u201dco.id\u201d,\u201dgo.id\u201d,\u201dmil.id\u201d dan lain lain .war.net.id : untuk industri warung internet di Indonesia .sch.id : khusus untuk Lembaga Pendidikan yang menyelenggarakan pendidikan seperti SD, SMP dan atau SMU .web.id : Ditujukan bagi badan usaha, organisasi ataupun perseorangan yang melakukan kegiatannya di World Wide Web. Rumah tempat website (Web hosting) Web Hosting dapat diartikan sebagai ruangan yang terdapat dalam harddisk tempat menyimpan berbagai data, file-file, gambar, video, data email, statistik, database dan lain sebagainya yang akan ditampilkan di website. Besarnya data yang bisa dimasukkan tergantung dari besarnya web hosting yang disewa/dipunyai, semakin besar web hosting semakin besar pula data yang dapat dimasukkan dan ditampilkan dalam website. Web Hosting juga diperoleh dengan menyewa. Pengguna akan memperoleh kontrol panel yang terproteksi dengan username dan password untuk administrasi websitenya. Besarnya hosting ditentukan ruangan harddisk dengan ukuran MB (Mega Byte) atau GB (Giga Byte). Lama penyewaan web hosting rata-rata dihitung per tahun. Penyewaan hosting dilakukan dari perusahaan-perusahaan penyewa web hosting yang banyak dijumpai baik di Indonesia maupun Luar Negeri. Lokasi peletakan pusat data (datacenter) web hosting bermacam-macam. Ada yang di Jakarta, Singapore, Inggris, Amerika, dll dengan harga sewa bervariasi. Bahasa Program (Scripts Program). Adalah bahasa yang digunakan untuk menerjemahkan setiap perintah dalam website yang pada saat diakses. Jenis bahasa program sangat menentukan statis, dinamis atau interaktifnya sebuah website. Semakin banyak ragam bahasa program yang digunakan maka akan terlihat website semakin dinamis, dan interaktif serta terlihat bagus. Beragam bahasa program saat ini telah hadir untuk mendukung kualitas website. Jenis jenis bahasa program yang banyak dipakai para desainer website antara lain HTML, ASP, PHP, JSP, Java Scripts, Java applets, XML, Ajax dsb. Bahasa dasar yang dipakai setiap situs adalah HTML sedangkan PHP, ASP, JSP dan lainnya merupakan bahasa pendukung yang bertindak sebagai pengatur dinamis, dan interaktifnya situs. Bahasa program ASP, PHP, JSP atau lainnya bisa dibuat sendiri. Bahasa program ini biasanya digunakan untuk membangun portal berita, artikel, forum diskusi, buku tamu, anggota organisasi, email, mailing list dan lain sebagainya yang memerlukan update setiap saat. Desain website. Setelah melakukan penyewaan domain name dan web hosting serta penguasaan bahasa program (scripts program), unsur website yang penting dan utama adalah desain. Desain website menentukan kualitas dan keindahan sebuah website. Desain sangat berpengaruh kepada penilaian pengunjung akan bagus tidaknya sebuah website. Untuk membuat website biasanya dapat dilakukan sendiri atau menyewa jasa website designer. Saat ini sangat banyak jasa web designer, terutama di kota-kota besar. Perlu diketahui bahwa kualitas situs sangat ditentukan oleh kualitas designer. Semakin banyak penguasaan web designer tentang beragam program/software pendukung pembuatan situs maka akan dihasilkan situs yang semakin berkualitas, demikian pula sebaliknya. Jasa web designer ini yang umumnya memerlukan biaya yang tertinggi dari seluruh biaya pembangunan situs dan semuanya itu tergantung kualitas designer. Program-program desain website salah satunya adalah Macromedia Firework, Adobe Photoshop, Adobe Dreamweaver, Microsoft Frontpage, dll. Program transfer data ke pusat data. Para web designer mengerjakan website dikomputernya sendiri. Berbagai bahasa program, data informasi teks, gambar, video, dan suara telah menjadi file-file pendukung adanya website. File tersebut bisa dibuka menggunakan program penjelajah (browser) sehingga terlihatlah sebuah website utuh di dalam komputer sendiri (offline). Tetapi file-file tersebut perlu untuk diletakkan dirumah hosting versi online agar terakses ke seluruh dunia. Pengguna akan diberikan akses FTP (File Transfer Protocol) setelah memesan sebuah web hosting untuk memindahkan file-file website ke pusat data web hosting. Untuk dapat menggunakan FTP diperlukan sebuah program FTP, misalnya WS FTP, Smart FTP, Cute FTP, dll. Program FTP ini banyak ditemui di internet dengan status penggunaan gratis maupun harus membayar. Para web designer pun dapat menggunakan fasilitas FTP yang terintegrasi dengan program pembuat website, misal Adobe Dreamweaver. Publikasi website. Keberadaan website tidak ada gunanya dibangun tanpa dikunjungi atau dikenal oleh masyarakat atau pengunjung internet. Karena efektif tidaknya situs sangat tergantung dari besarnya pengunjung dan komentar yang masuk. Untuk mengenalkan situs kepada masyarakat memerlukan apa yang disebut publikasi atau promosi. Publikasi situs di masyarakat dapat dilakukan dengan berbagai cara seperti dengan pamlet-pamlet, selebaran, baliho, kartu nama dan lain sebagainya tapi cara ini bisa dikatakan masih kurang efektif dan sangat terbatas. Cara yang biasanya dilakukan dan paling efektif dengan tak terbatas ruang atau waktu adalah publikasi langsung di internet melalui search engine-search engine (mesin pencari, spt : Yahoo, Google, MSN, Search Indonesia, dsb). Cara publikasi di search engine ada yang gratis dan ada pula yang membayar. Yang gratis biasanya terbatas dan cukup lama untuk bisa masuk dan dikenali di search engine terkenal seperti Yahoo atau Google. Cara efektif publikasi adalah dengan membayar, walaupun harus sedikit mengeluarkan akan tetapi situs cepat masuk ke search engine dan dikenal oleh pengunjung. b. Pemeliharaan Website Untuk mendukung kelanjutan dari situs diperlukan pemeliharaan setiap waktu sesuai yang diinginkan seperti penambahan informasi, berita, artikel, link, gambar atau lain sebagainya. Tanpa pemeliharaan yang baik situs akan terkesan membosankan atau monoton juga akan segera ditinggal pengunjung. Pemeliharaan situs dapat dilakukan per periode tertentu seperti tiap hari, tiap minggu atau tiap bulan sekali secara rutin atau secara periodik saja tergantung kebutuhan (tidak rutin). Pemeliharaan rutin biasanya dipakai oleh situs-situs berita, penyedia artikel, organisasi atau lembaga pemerintah. Sedangkan pemeliharaan periodik bisanya untuk situs-situs pribadi, penjualan/e-commerce, dan lain sebagainya. c. PERPANJANGAN MASA SEWA DOMAIN NAME DAN WEB HOSTING. Perlu dipahami bahwa domain name dan web hosting berstatus sewa. Selama kedua hal itu dibayarkan masa sewa perpanjangannya, maka Anda berhak untuk memilikinya dan mempergunakannya. Banyak terjadi kasus kelupaan dalam memperpanjang masa sewanya, atau sulit untuk menghubungi pihak ketiga (web designer) sebagai perantara pendaftaran awal, maka akan berakibat fatal. Anda akan kehilangan domain name sebagai identitas dalam dunia internet. Pastikan Anda mengingat untuk memperpanjang masa sewanya. Arti penting domain name perlu Anda pahami.","title":"Penjelasan"},{"location":"learning/Web_Server/xampp/","text":"XAMPP A. Penjelasan XAMPP adalah perangkat lunak ( free software) bebas, yang mendukung untuk banyak sistem operasi, yang merupakan kompilasi dari beberapa program. Fungsi XAMPP sendiri adalah sebagai server yang berdiri sendiri (localhost), yang terdiri beberapa program antara lain : Apache HTTP Server, MySQL database, dan penerjemah bahasa yang ditulis dengan bahasa pemrograman PHP dan Perl. a. Komponen- komponen XAMPP, yaitu : X : Program ini dapat dijalankan di banyak sistem operasi, seperti Windows, Linux, Mac OS, dan Solaris. A : Apache, server aplikasi Web. Apache tugas utama adalah untuk menghasilkan halaman web yang benar kepada pengguna terhadap kode PHP yang sudah dituliskan oleh pembuat halaman web. jika perlu kode PHP juga berdasarkan yang tertulis, dapat database diakses dulu (misalnya MySQL) untuk mendukung halaman web yang dihasilkan. M : MySQL, server aplikasi database. Pertumbuhannya disebut SQL singkatan dari Structured Query Language. SQL merupakan bahasa terstruktur yang difungsikan untuk mengolah database. MySQL dapat digunakan untuk membuat dan mengelola database dan isinya. Bisa juga memanfaatkan MySQL guna untuk menambahkan, mengubah, dan menghapus data dalam database. P : PHP, bahasa pemrograman web. Bahasa pemrograman PHP adalah bahasa pemrograman untuk membuat web yang server-side scripting. PHP digunakan untuk membuat halaman web dinamis. Sistem manajemen database yang sering digunakan dengan PHP adalah MySQL. namun PHP juga mendukung Pengelolaan sistem database Oracle, Microsoft Access, Interbase, d-base, PostgreSQL, dan sebagainya. P : Perl, bahasa pemrograman untuk semua tujuan, pertama kali dikembangkan oleh Larry Wall, mesin Unix. Perl dirilis pertama kali tanggal 18 Desember 1987 yang ditandai dengan keluarnya Perl 1. Pada versi-versi selanjutnya, Perl juga tersedia untuk berbagai sistem operasi Unix (SunOS, Linux, BSD, HP-UX), juga tersedia untuk sistem operasi seperti DOS, Windows, PowerPC, BeOS, VMS, EBCDIC, dan PocketPC. B. Cara Kerja Untuk menggunakan XAMPP kamu pastinya harus punya dulu aplikasinya. Aplikasi/Software web server lokal XAMPP ini dapat di unduh secara gratis di www.apachefriends.org. Ada banyak sekali versi XAMPP disana. Untuk mengembangkan sebuah situs web, XAMPP versi 5 mendukung bahasa pemrograman PHP 5 dengan database MySQL, sedangkan versi 7 mendukung bahasa pemrograman PHP terbaru, yaitu PHP 7 dengan database MySQLi. Beberapa halaman dari Web Server Lokal XAMPP a. Control Panel Halaman ini seperti kunci. Untuk menghidupkan XAMPP, kamu harus membuka halaman Control Panel. Lalu nyalakan sistem operasi sesuai program yang ingin digunakan. Untuk mendesain halaman web, bisanya yang dihidupkan hanyalah Apache dan MySQL. b. Localhost Iyap jadi ini adalah halaman untuk mengakses halaman web kita. Untuk mengetest apakah aplikasi sudah menyala, kamu tinggal mengakses halaman di browser dengan mengetik localhost pada Address Bar. c. Htdocs Nah ini adalah halaman untuk membuat halaman webnya. Setelah kamu menginstal XAMPP, maka akan ada halaman htdocs ini yang berlokasi (My Computer -> Local Disk(C) -> xampp -> htdocs). Untuk membuat halaman web, kamu harus membuat sebuah folder di htdocs, lalu isi folder tersebut dengan kode - kode halaman website. Untuk mengaksesnya, kamu hanya perlu membuka browser dan ketik localhost/(NAMA_FOLDER) pada address bar. Contohnya adalah halaman berikut ini : Jadi disini saya mengakses halaman web yang berada di folder blog pada folder htdocs. Berikut ini adalah tampilan halamannya : d. PHPMYADMIN Halaman ini digunakan untuk membuat sebuah database yang berfungsi untuk menyimpan data dari halaman web. Jadi sebenarnya halaman seluruh isi dari halaman web disimpan dalam database. Lalu data dipanggil menggunakan Bahasa Pemrograman PHP sehingga dapat muncul di browser dan dimodifikasi. Untuk mengakses halaman PHPMYADMIN, kamu hanya perlu mengetik localhost/phpmyadmin pada browser. Di halaman phpmyadmin ini ada beberapa menu/tab. Fungsinya adalah sebagai berikut. Tab Database : Untuk membuat database halaman web. Tab SQL : Untuk membuat database menggunakan SQL. Jadi jika kamu sudah memiliki file berekstensi/format .sql, kamu tidak perlu repot membuat database. Cukup meletakan seluruh isi file ke halaman SQL. Tab Status : Untuk menampilkan status dari aplikasi XAMPP. Tab Users : Untuk mengedit nama pengguna dan password XAMPP. Ini digunakan untuk menghubungkan database ke halaman web. Tab Export : Untuk mengunduh kode SQL pada database. Tab Import : Untuk mengimpor kode SQL. Fungsinya sama seperti tab SQL, namun jika tab SQL mengharuskan isi file sql untuk menambah database, kamu memerlukan file berekstensi/format .sql nya. Lalu file diletakan di halaman Import. Tab Settings : Untuk mengelola dan mengatur jalannya aplikasi Dan lainnya...","title":"**XAMPP**"},{"location":"learning/Web_Server/xampp/#xampp","text":"","title":"XAMPP"},{"location":"learning/Web_Server/xampp/#a-penjelasan","text":"XAMPP adalah perangkat lunak ( free software) bebas, yang mendukung untuk banyak sistem operasi, yang merupakan kompilasi dari beberapa program. Fungsi XAMPP sendiri adalah sebagai server yang berdiri sendiri (localhost), yang terdiri beberapa program antara lain : Apache HTTP Server, MySQL database, dan penerjemah bahasa yang ditulis dengan bahasa pemrograman PHP dan Perl. a. Komponen- komponen XAMPP, yaitu : X : Program ini dapat dijalankan di banyak sistem operasi, seperti Windows, Linux, Mac OS, dan Solaris. A : Apache, server aplikasi Web. Apache tugas utama adalah untuk menghasilkan halaman web yang benar kepada pengguna terhadap kode PHP yang sudah dituliskan oleh pembuat halaman web. jika perlu kode PHP juga berdasarkan yang tertulis, dapat database diakses dulu (misalnya MySQL) untuk mendukung halaman web yang dihasilkan. M : MySQL, server aplikasi database. Pertumbuhannya disebut SQL singkatan dari Structured Query Language. SQL merupakan bahasa terstruktur yang difungsikan untuk mengolah database. MySQL dapat digunakan untuk membuat dan mengelola database dan isinya. Bisa juga memanfaatkan MySQL guna untuk menambahkan, mengubah, dan menghapus data dalam database. P : PHP, bahasa pemrograman web. Bahasa pemrograman PHP adalah bahasa pemrograman untuk membuat web yang server-side scripting. PHP digunakan untuk membuat halaman web dinamis. Sistem manajemen database yang sering digunakan dengan PHP adalah MySQL. namun PHP juga mendukung Pengelolaan sistem database Oracle, Microsoft Access, Interbase, d-base, PostgreSQL, dan sebagainya. P : Perl, bahasa pemrograman untuk semua tujuan, pertama kali dikembangkan oleh Larry Wall, mesin Unix. Perl dirilis pertama kali tanggal 18 Desember 1987 yang ditandai dengan keluarnya Perl 1. Pada versi-versi selanjutnya, Perl juga tersedia untuk berbagai sistem operasi Unix (SunOS, Linux, BSD, HP-UX), juga tersedia untuk sistem operasi seperti DOS, Windows, PowerPC, BeOS, VMS, EBCDIC, dan PocketPC.","title":"A. Penjelasan"},{"location":"learning/Web_Server/xampp/#b-cara-kerja","text":"Untuk menggunakan XAMPP kamu pastinya harus punya dulu aplikasinya. Aplikasi/Software web server lokal XAMPP ini dapat di unduh secara gratis di www.apachefriends.org. Ada banyak sekali versi XAMPP disana. Untuk mengembangkan sebuah situs web, XAMPP versi 5 mendukung bahasa pemrograman PHP 5 dengan database MySQL, sedangkan versi 7 mendukung bahasa pemrograman PHP terbaru, yaitu PHP 7 dengan database MySQLi. Beberapa halaman dari Web Server Lokal XAMPP a. Control Panel Halaman ini seperti kunci. Untuk menghidupkan XAMPP, kamu harus membuka halaman Control Panel. Lalu nyalakan sistem operasi sesuai program yang ingin digunakan. Untuk mendesain halaman web, bisanya yang dihidupkan hanyalah Apache dan MySQL. b. Localhost Iyap jadi ini adalah halaman untuk mengakses halaman web kita. Untuk mengetest apakah aplikasi sudah menyala, kamu tinggal mengakses halaman di browser dengan mengetik localhost pada Address Bar. c. Htdocs Nah ini adalah halaman untuk membuat halaman webnya. Setelah kamu menginstal XAMPP, maka akan ada halaman htdocs ini yang berlokasi (My Computer -> Local Disk(C) -> xampp -> htdocs). Untuk membuat halaman web, kamu harus membuat sebuah folder di htdocs, lalu isi folder tersebut dengan kode - kode halaman website. Untuk mengaksesnya, kamu hanya perlu membuka browser dan ketik localhost/(NAMA_FOLDER) pada address bar. Contohnya adalah halaman berikut ini : Jadi disini saya mengakses halaman web yang berada di folder blog pada folder htdocs. Berikut ini adalah tampilan halamannya : d. PHPMYADMIN Halaman ini digunakan untuk membuat sebuah database yang berfungsi untuk menyimpan data dari halaman web. Jadi sebenarnya halaman seluruh isi dari halaman web disimpan dalam database. Lalu data dipanggil menggunakan Bahasa Pemrograman PHP sehingga dapat muncul di browser dan dimodifikasi. Untuk mengakses halaman PHPMYADMIN, kamu hanya perlu mengetik localhost/phpmyadmin pada browser. Di halaman phpmyadmin ini ada beberapa menu/tab. Fungsinya adalah sebagai berikut. Tab Database : Untuk membuat database halaman web. Tab SQL : Untuk membuat database menggunakan SQL. Jadi jika kamu sudah memiliki file berekstensi/format .sql, kamu tidak perlu repot membuat database. Cukup meletakan seluruh isi file ke halaman SQL. Tab Status : Untuk menampilkan status dari aplikasi XAMPP. Tab Users : Untuk mengedit nama pengguna dan password XAMPP. Ini digunakan untuk menghubungkan database ke halaman web. Tab Export : Untuk mengunduh kode SQL pada database. Tab Import : Untuk mengimpor kode SQL. Fungsinya sama seperti tab SQL, namun jika tab SQL mengharuskan isi file sql untuk menambah database, kamu memerlukan file berekstensi/format .sql nya. Lalu file diletakan di halaman Import. Tab Settings : Untuk mengelola dan mengatur jalannya aplikasi Dan lainnya...","title":"B. Cara Kerja"},{"location":"tutorials/","text":"Tutorials Navigations RESERVED","title":"Tutorials"},{"location":"tutorials/#tutorials-navigations","text":"RESERVED","title":"Tutorials Navigations"},{"location":"tutorials/Arch_Linux/","text":"Tutorials Navigations RESERVED","title":"Tutorials"},{"location":"tutorials/Arch_Linux/#tutorials-navigations","text":"RESERVED","title":"Tutorials Navigations"}]}